## seq = false
## max_seq_length = 1
## max_nb_layers = 8
## alpha = 10.
## max_nb_parse = 64
## max_parse_dl_factor = 3.
## max_relaxation_level_parse_layers = 16
## def_match_threshold = 1.
## max_nb_diff = 3
## max_nb_grid_reads = 3
## max_expressions = 100000
## max_refinements = 20
## options
alpha = 10.0
mode = training
timeout_build = 60
timeout_prune = 10
timeout_predict = 3

=====================================
[-400] Checking task 007bbfb7.json: 5 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 17558.0 = 17560.3
DL output with Mo: L = 2.3 + 160789.0 = 160791.3
DL input+output M: L = 4.6 + 178347.0 = 178351.7

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = compose(majorityColor(^), ^, ^)
0.396	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.202	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.002	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
compose(majorityColor(^), ^, ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 3500.4 = 3542.4
DL output with Mo: L = 17.1 + 0.0 = 17.1
DL input+output M: L = 59.1 + 3500.4 = 3559.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
compose(majorityColor(^), ^, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 17.1 + 0.0 = 17.1
DL input+output M: L = 19.4 + 0.0 = 19.4

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 7#7#
7#7#7#
0 7#7#

diff: 
   (0.0 bits)
data: 
0 0 0 0 7#7#0 7#7#
0 0 0 7#7#7#7#7#7#
0 0 0 0 7#7#0 7#7#
0 7#7#0 7#7#0 7#7#
7#7#7#7#7#7#7#7#7#
0 7#7#0 7#7#0 7#7#
0 0 0 0 7#7#0 7#7#
0 0 0 7#7#7#7#7#7#
0 0 0 0 7#7#0 7#7#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 7#7#
7#7#7#
0 7#7#

diff: 
correct output grid

TRAIN 007bbfb7.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
4 0 4 
0 0 0 
0 4 0 

diff: 
   (0.0 bits)
data: 
4 0 4 0 0 0 4 0 4 
0 0 0 0 0 0 0 0 0 
0 4 0 0 0 0 0 4 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 4 0 4 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 4 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 0 4 
0 0 0 
0 4 0 

diff: 
correct output grid

TRAIN 007bbfb7.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 0 0 
0 0 2 
2 0 2 

diff: 
   (0.0 bits)
data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 2 
0 0 0 0 0 0 2 0 2 
0 0 0 0 0 0 0 0 0 
0 0 2 0 0 0 0 0 2 
2 0 2 0 0 0 2 0 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 
0 0 2 
2 0 2 

diff: 
correct output grid

TRAIN 007bbfb7.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: 
6 6 0 
6 0 0 
0 6 6 

diff: 
   (0.0 bits)
data: 
6 6 0 6 6 0 0 0 0 
6 0 0 6 0 0 0 0 0 
0 6 6 0 6 6 0 0 0 
6 6 0 0 0 0 0 0 0 
6 0 0 0 0 0 0 0 0 
0 6 6 0 0 0 0 0 0 
0 0 0 6 6 0 6 6 0 
0 0 0 6 0 0 6 0 0 
0 0 0 0 6 6 0 6 6 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
6 6 0 
6 0 0 
0 6 6 

diff: 
correct output grid

TRAIN 007bbfb7.json/4: 1 1st (SUCCESS)

## instance 5

> Input and output best reading:

data: 
2 2 2 
0 0 0 
0 2 2 

diff: 
   (0.0 bits)
data: 
2 2 2 2 2 2 2 2 2 
0 0 0 0 0 0 0 0 0 
0 2 2 0 2 2 0 2 2 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 2 2 2 2 2 2 
0 0 0 0 0 0 0 0 0 
0 0 0 0 2 2 0 2 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 2 2 
0 0 0 
0 2 2 

diff: 
correct output grid

TRAIN 007bbfb7.json/5: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
7#0 7#
7#0 7#
7#7#0 

diff: 
correct output grid

TEST 007bbfb7.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 0.4 sec (0.4 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-399] Checking task 00d62c1b.json: 5 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 300388.5 = 300390.9
DL output with Mo: L = 2.3 + 300388.5 = 300390.9
DL input+output M: L = 4.6 + 600777.1 = 600781.7

# learning a model for train pairs
2.000	
1.192	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.451	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.306	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.143	OUT ADD ^.layer_0 = ^.layer_0
0.095	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.084	OUT ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.080	IN  ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.077	OUT SPE ^.size = ^.size
0.076	IN  SPE ^.layer_00.shape.color = green
0.075	IN  SPE ^.layer_0.shape.color = green
0.074	OUT SPE ^.layer_01.shape.color = yellow
0.073	OUT SPE ^.layer_00.shape.mask.size.i = ^.layer_00.shape.mask.size.j
0.073	OUT SPE ^.layer_00.pos.j = ^.layer_00.pos.j
0.072	OUT SPE ^.layer_01.shape.mask.model = Full
0.072	IN  SPE ^.color = black
0.071	OUT SPE ^.color = black
0.030	
0.030	IN  GEN ^.layer_0.shape.color = ?
0.030	IN  GEN ^.layer_00.shape.color = ?
0.030	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: rectangle with size (^.layer_00.shape.mask.size.j,?) with model ? with color ? at (?,^.layer_00.pos.j)
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model Full with color yellow at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: rectangle with size (?,?) with model ? with color green at (?,?)
  _0: rectangle with size (?,?) with model ? with color green at (?,?)

DL input  with Mi: L = 77.0 + 12296.9 = 12373.8
DL output with Mo: L = 84.3 + 8941.5 = 9025.8
DL input+output M: L = 161.3 + 21238.3 = 21399.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: rectangle with size (^.layer_00.shape.mask.size.j,?) with model ? with color ? at (?,^.layer_00.pos.j)
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model Full with color yellow at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 40.0 = 110.2
DL output with Mo: L = 84.3 + 8941.5 = 9025.8
DL input+output M: L = 154.6 + 8981.5 = 9136.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _00: rectangle with size (3,1) with model Full with color green at (1,2)
  _0: rectangle with size (4,4) with mask 
. 0 . . 
0 . 0 . 
. 0 . 0 
. . 0 . 
 with color green at (1,1)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _00: rectangle with size (1,1) with model Full with color yellow at (2,2)
  _0: 
. 3 . . 
3 . 3 . 
. 3 . 3 
. . 3 . 
 at (1,1)
  _01: rectangle with size (1,1) with model Full with color yellow at (3,3)
diff: 
   (33.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _00: rectangle with size (3,1) with model Full with color green at (1,2)
  _0: rectangle with size (4,4) with mask 
. 0 . . 
0 . 0 . 
. 0 . 0 
. . 0 . 
 with color green at (1,1)
  + 1 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,6) and color black and layers
  _00: rectangle with size (1,3) with model Full with color green at (2,1)
  _0: rectangle with size (4,4) with mask 
. 0 . . 
0 . 0 . 
. 0 . 0 
. . 0 . 
 with color green at (1,1)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (6,6) and color black and layers
  _00: rectangle with size (3,1) with model Full with color green at (2,3)
  _0: rectangle with size (4,4) with mask 
. 0 . . 
0 . 0 . 
. 0 . 0 
. . 0 . 
 with color green at (1,1)
  + 1 delta pixels
diff: 
! 8 wrong pixels (generated / expected)

TRAIN 00d62c1b.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _00: rectangle with size (1,3) with model Full with color green at (1,2)
  _0: rectangle with size (7,6) with mask 
0 . 0 . . . 
. 0 . 0 . . 
0 . . . 0 . 
. . . 0 . 0 
. 0 . 0 0 . 
0 0 0 . . . 
. 0 . . . . 
 with color green at (1,2)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (3,1) with model Full with color green at (1,2)
  _0: 
3 . 3 . . . 
. 3 . 3 . . 
3 . . . 3 . 
. . . 3 . 3 
. 3 . 3 3 . 
3 3 3 . . . 
. 3 . . . . 
 at (1,2)
  _01: rectangle with size (1,1) with model Full with color yellow at (4,6)
  + 1 delta pixels
diff: 
   (76.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (1,3) with model Full with color green at (1,2)
  _0: rectangle with size (7,6) with mask 
0 . 0 . . . 
. 0 . 0 . . 
0 . . . 0 . 
. . . 0 . 0 
. 0 . 0 0 . 
0 0 0 . . . 
. 0 . . . . 
 with color green at (1,2)
  + 1 delta pixels
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (3,1) with model Full with color green at (1,2)
  _0: rectangle with size (7,6) with mask 
0 . 0 . . . 
. 0 . 0 . . 
0 . . . 0 . 
. . . 0 . 0 
. 0 . 0 0 . 
0 0 0 . . . 
. 0 . . . . 
 with color green at (1,2)
  + 1 delta pixels
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (1,3) with model Full with color green at (2,3)
  _0: rectangle with size (7,6) with mask 
0 . 0 . . . 
. 0 . 0 . . 
0 . . . 0 . 
. . . 0 . 0 
. 0 . 0 0 . 
0 0 0 . . . 
. 0 . . . . 
 with color green at (1,2)
  + 1 delta pixels
diff: 
! 11 wrong pixels (generated / expected)

TRAIN 00d62c1b.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _00: rectangle with size (1,4) with model Full with color green at (7,4)
  _0: rectangle with size (9,9) with mask 
. . . . . 0 . . . 
. . . . 0 . . . . 
. 0 0 . 0 0 . 0 . 
0 . . 0 . . 0 . 0 
. . . 0 . . 0 0 . 
. . . 0 . . 0 . . 
. . . 0 . . 0 . . 
. . . . 0 0 . 0 . 
. . . . . . . . 0 
 with color green at (0,0)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (4,2) with model Full with color yellow at (3,4)
  _0: 
. . . . . 3 . . . 
. . . . 3 . . . . 
. 3 3 . 3 3 . 3 . 
3 . . 3 . . 3 . 3 
. . . 3 . . 3 3 . 
. . . 3 . . 3 . . 
. . . 3 . . 3 . . 
. . . . 3 3 . 3 . 
. . . . . . . . 3 
 at (0,0)
  _01: rectangle with size (1,1) with model Full with color yellow at (3,7)
diff: 
   (37.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (1,4) with model Full with color green at (7,4)
  _0: rectangle with size (9,9) with mask 
. . . . . 0 . . . 
. . . . 0 . . . . 
. 0 0 . 0 0 . 0 . 
0 . . 0 . . 0 . 0 
. . . 0 . . 0 0 . 
. . . 0 . . 0 . . 
. . . 0 . . 0 . . 
. . . . 0 0 . 0 . 
. . . . . . . . 0 
 with color green at (0,0)
  + 1 delta pixels
diff: 
! 19 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (1,7) with model Full with color green at (2,1)
  _0: rectangle with size (9,9) with mask 
. . . . . 0 . . . 
. . . . 0 . . . . 
. 0 0 . 0 0 . 0 . 
0 . . 0 . . 0 . 0 
. . . 0 . . 0 0 . 
. . . 0 . . 0 . . 
. . . 0 . . 0 . . 
. . . . 0 0 . 0 . 
. . . . . . . . 0 
 with color green at (0,0)
  + 2 delta pixels
diff: 
! 25 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (4,1) with model Full with color green at (3,3)
  _0: rectangle with size (4,1) with model Full with color green at (3,6)
  + 14 delta pixels
diff: 
! 33 wrong pixels (generated / expected)

TRAIN 00d62c1b.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _00: rectangle with size (5,1) with model Full with color green at (4,8)
  _0: rectangle with size (9,8) with mask 
0 0 0 0 . . . . 
0 . . 0 . . . . 
0 . . 0 . 0 . . 
0 0 0 0 0 0 0 . 
. 0 . . . . 0 . 
. 0 . . . 0 0 . 
. 0 0 . . 0 . 0 
. 0 . 0 . . 0 . 
. . 0 . . . . . 
 with color green at (1,2)
  + 1 delta pixels
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (1,1) with model Full with color yellow at (7,8)
  _0: 
3 3 3 3 . . . . 
3 . . 3 . . . . 
3 . . 3 . 3 . . 
3 3 3 3 3 3 3 . 
. 3 . . . . 3 . 
. 3 . . . 3 3 . 
. 3 3 . . 3 . 3 
. 3 . 3 . . 3 . 
. . 3 . . . . . 
 at (1,2)
  _01: rectangle with size (2,2) with model Full with color yellow at (2,3)
  + 1 delta pixels
diff: 
   (80.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (5,1) with model Full with color green at (3,7)
  _0: rectangle with size (9,8) with mask 
0 0 0 0 . . . . 
0 . . 0 . . . . 
0 . . 0 . 0 . . 
0 0 0 0 0 0 0 . 
. 0 . . . . 0 . 
. 0 . . . 0 0 . 
. 0 0 . . 0 . 0 
. 0 . 0 . . 0 . 
. . 0 . . . . . 
 with color green at (1,2)
  + 1 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (5,1) with model Full with color green at (4,8)
  _0: rectangle with size (9,8) with mask 
0 0 0 0 . . . . 
0 . . 0 . . . . 
0 . . 0 . 0 . . 
0 0 0 0 0 0 0 . 
. 0 . . . . 0 . 
. 0 . . . 0 0 . 
. 0 0 . . 0 . 0 
. 0 . 0 . . 0 . 
. . 0 . . . . . 
 with color green at (1,2)
  + 1 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (8,1) with model Full with color green at (1,5)
  _0: rectangle with size (9,8) with mask 
0 0 0 0 . . . . 
0 . . 0 . . . . 
0 . . 0 . 0 . . 
0 0 0 0 0 0 0 . 
. 0 . . . . 0 . 
. 0 . . . 0 0 . 
. 0 0 . . 0 . 0 
. 0 . 0 . . 0 . 
. . 0 . . . . . 
 with color green at (1,2)
  + 3 delta pixels
diff: 
! 12 wrong pixels (generated / expected)

TRAIN 00d62c1b.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _00: rectangle with size (5,5) with mask 
0 . . . . 
. 0 . . 0 
. . 0 0 0 
. . 0 . 0 
. . 0 0 0 
 with color green at (12,13)
  _0: rectangle with size (15,12) with mask 
. . . . 0 . . . . . . . 
0 0 0 0 . 0 0 . . . . . 
. . . . 0 . 0 . . . . . 
. . . . 0 0 0 0 0 0 0 0 
. . . . 0 . . . . . . 0 
. . . . 0 . . . . . . 0 
. . . . 0 . . . . . . 0 
. . . . 0 . . . . . . 0 
. . . . 0 0 0 0 0 0 0 0 
. . . . 0 . . . . . . . 
. . . . 0 0 0 . . . . . 
. . 0 0 . . 0 . . . . . 
. . . 0 . . 0 0 . . . . 
. . . 0 0 0 0 . 0 . . . 
. . . . . . 0 . . . . . 
 with color green at (1,4)
  + 7 delta pixels
diff: 
   (2.0 bits)
data: a background with size (20,20) and color black and layers
  _00: rectangle with size (5,5) with mask 
0 . . . . 
. 0 . . 0 
. . 0 0 0 
. . 0 . 0 
. . 0 0 0 
 with color green at (12,13)
  _0: 
. . . . 3 . . . . . . . 
3 3 3 3 . 3 3 . . . . . 
. . . . 3 . 3 . . . . . 
. . . . 3 3 3 3 3 3 3 3 
. . . . 3 . . . . . . 3 
. . . . 3 . . . . . . 3 
. . . . 3 . . . . . . 3 
. . . . 3 . . . . . . 3 
. . . . 3 3 3 3 3 3 3 3 
. . . . 3 . . . . . . . 
. . . . 3 3 3 . . . . . 
. . 3 3 . . 3 . . . . . 
. . . 3 . . 3 3 . . . . 
. . . 3 3 3 3 . 3 . . . 
. . . . . . 3 . . . . . 
 at (1,4)
  _01: rectangle with size (4,6) with model Full with color yellow at (5,9)
  + 14 delta pixels
diff: 
   (665.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _00: rectangle with size (15,12) with mask 
. . . . 0 . . . . . . . 
0 0 0 0 . 0 0 . . . . . 
. . . . 0 . 0 . . . . . 
. . . . 0 0 0 0 0 0 0 0 
. . . . 0 . . . . . . 0 
. . . . 0 . . . . . . 0 
. . . . 0 . . . . . . 0 
. . . . 0 . . . . . . 0 
. . . . 0 0 0 0 0 0 0 0 
. . . . 0 . . . . . . . 
. . . . 0 0 0 . . . . . 
. . 0 0 . . 0 . . . . . 
. . . 0 . . 0 0 . . . . 
. . . 0 0 0 0 . 0 . . . 
. . . . . . 0 . . . . . 
 with color green at (1,4)
  _0: rectangle with size (5,5) with mask 
0 . . . . 
. 0 . . 0 
. . 0 0 0 
. . 0 . 0 
. . 0 0 0 
 with color green at (12,13)
  + 7 delta pixels
diff: 
! 112 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _00: rectangle with size (5,5) with mask 
0 . . . . 
. 0 . . 0 
. . 0 0 0 
. . 0 . 0 
. . 0 0 0 
 with color green at (12,13)
  _0: rectangle with size (15,12) with mask 
. . . . 0 . . . . . . . 
0 0 0 0 . 0 0 . . . . . 
. . . . 0 . 0 . . . . . 
. . . . 0 0 0 0 0 0 0 0 
. . . . 0 . . . . . . 0 
. . . . 0 . . . . . . 0 
. . . . 0 . . . . . . 0 
. . . . 0 . . . . . . 0 
. . . . 0 0 0 0 0 0 0 0 
. . . . 0 . . . . . . . 
. . . . 0 0 0 . . . . . 
. . 0 0 . . 0 . . . . . 
. . . 0 . . 0 0 . . . . 
. . . 0 0 0 0 . 0 . . . 
. . . . . . 0 . . . . . 
 with color green at (1,4)
  + 7 delta pixels
diff: 
! 63 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (20,20) and color black and layers
  _00: rectangle with size (15,12) with mask 
. . . . 0 . . . . . . . 
0 0 0 0 . 0 0 . . . . . 
. . . . 0 . 0 . . . . . 
. . . . 0 0 0 0 0 0 0 0 
. . . . 0 . . . . . . 0 
. . . . 0 . . . . . . 0 
. . . . 0 . . . . . . 0 
. . . . 0 . . . . . . 0 
. . . . 0 0 0 0 0 0 0 0 
. . . . 0 . . . . . . . 
. . . . 0 0 0 . . . . . 
. . 0 0 . . 0 . . . . . 
. . . 0 . . 0 0 . . . . 
. . . 0 0 0 0 . 0 . . . 
. . . . . . 0 . . . . . 
 with color green at (1,4)
  _0: rectangle with size (3,3) with model Full with color green at (14,15)
  + 13 delta pixels
diff: 
! 115 wrong pixels (generated / expected)

TRAIN 00d62c1b.json/5: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _00: rectangle with size (13,17) with mask 
. 0 . . . . . . . . . . . . . . . 
0 . 0 0 . . . . . . . . . . . . . 
. 0 . 0 0 0 0 0 . 0 0 . . . . . . 
. . . 0 . . . . 0 . . 0 . . . . . 
. . . 0 0 0 0 0 . 0 0 0 . . . . . 
. . . . . . . . . . . . 0 0 0 0 0 
. . . . . . . . . . . . 0 . . . 0 
. . . . . . . . . . . . 0 . . . 0 
. . . . . . . . 0 0 0 0 0 . . . 0 
. . . . . . . . 0 . . . 0 . . . 0 
. . . . . . . 0 0 0 0 0 0 . . . 0 
. . . . . 0 0 . 0 . . . 0 0 0 0 0 
. . . . . . . 0 0 . . . . . . . . 
 with color green at (1,1)
  _0: rectangle with size (4,6) with mask 
0 0 0 0 0 0 
. 0 . . . 0 
. 0 . . . 0 
. 0 0 0 0 0 
 with color green at (15,6)
  + 5 delta pixels
diff: 
! 124 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _00: rectangle with size (4,6) with mask 
0 0 0 0 0 0 
. 0 . . . 0 
. 0 . . . 0 
. 0 0 0 0 0 
 with color green at (15,6)
  _0: rectangle with size (13,17) with mask 
. 0 . . . . . . . . . . . . . . . 
0 . 0 0 . . . . . . . . . . . . . 
. 0 . 0 0 0 0 0 . 0 0 . . . . . . 
. . . 0 . . . . 0 . . 0 . . . . . 
. . . 0 0 0 0 0 . 0 0 0 . . . . . 
. . . . . . . . . . . . 0 0 0 0 0 
. . . . . . . . . . . . 0 . . . 0 
. . . . . . . . . . . . 0 . . . 0 
. . . . . . . . 0 0 0 0 0 . . . 0 
. . . . . . . . 0 . . . 0 . . . 0 
. . . . . . . 0 0 0 0 0 0 . . . 0 
. . . . . 0 0 . 0 . . . 0 0 0 0 0 
. . . . . . . 0 0 . . . . . . . . 
 with color green at (1,1)
  + 5 delta pixels
diff: 
! 67 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (20,20) and color black and layers
  _00: rectangle with size (13,17) with mask 
. 0 . . . . . . . . . . . . . . . 
0 . 0 0 . . . . . . . . . . . . . 
. 0 . 0 0 0 0 0 . 0 0 . . . . . . 
. . . 0 . . . . 0 . . 0 . . . . . 
. . . 0 0 0 0 0 . 0 0 0 . . . . . 
. . . . . . . . . . . . 0 0 0 0 0 
. . . . . . . . . . . . 0 . . . 0 
. . . . . . . . . . . . 0 . . . 0 
. . . . . . . . 0 0 0 0 0 . . . 0 
. . . . . . . . 0 . . . 0 . . . 0 
. . . . . . . 0 0 0 0 0 0 . . . 0 
. . . . . 0 0 . 0 . . . 0 0 0 0 0 
. . . . . . . 0 0 . . . . . . . . 
 with color green at (1,1)
  _0: rectangle with size (1,6) with model Full with color green at (15,6)
  + 14 delta pixels
diff: 
! 133 wrong pixels (generated / expected)

TEST 00d62c1b.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 11.9 sec (11.9 sec/task)
bits-train-error = 8941.5 bits (8941.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-398] Checking task 017c7c7b.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 20923.3 = 20925.6
DL output with Mo: L = 2.3 + 31468.7 = 31471.0
DL input+output M: L = 4.6 + 52392.0 = 52396.6

# learning a model for train pairs
2.000	
1.480	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.975	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.561	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.154	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.122	OUT SPE ^.layer_0.shape.mask = fillResizeAlike_strict(transparent, ^.layer_0.shape.mask.size + (3, 0), ^.layer_0.shape.mask)
0.107	OUT SPE ^.size = ^.size + (3, 0)
0.098	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.090	IN  SPE ^.layer_0.shape.color = blue
0.085	OUT SPE ^.layer_0.shape.color = red
0.081	IN  SPE ^.color = black
0.079	OUT SPE ^.color = black
0.004	
0.004	IN  GEN ^.layer_0.shape.color = ?
0.004	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size + (3, 0) and color black and layers
  _0: fillResizeAlike_strict(transparent, ^.layer_0.shape.mask.size + (3, 0), ^.layer_0.shape.mask) with color red at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color blue at (?,?)

DL input  with Mi: L = 45.4 + 1554.2 = 1599.6
DL output with Mo: L = 70.7 + 0.0 = 70.7
DL input+output M: L = 116.1 + 1554.2 = 1670.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size + (3, 0) and color black and layers
  _0: fillResizeAlike_strict(transparent, ^.layer_0.shape.mask.size + (3, 0), ^.layer_0.shape.mask) with color red at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 70.7 + 0.0 = 70.7
DL input+output M: L = 112.7 + 0.0 = 112.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (6,3) and color black and layers
  _0: rectangle with size (6,3) with mask 
. 0 . 
0 0 . 
. 0 . 
. 0 0 
. 0 . 
0 0 . 
 with color blue at (0,0)
diff: 
   (0.0 bits)
data: a background with size (9,3) and color black and layers
  _0: 
. 0 . 
0 0 . 
. 0 . 
. 0 0 
. 0 . 
0 0 . 
. 0 . 
. 0 0 
. 0 . 
 with color red at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,3) and color black and layers
  _0: rectangle with size (6,3) with mask 
. 0 . 
0 0 . 
. 0 . 
. 0 0 
. 0 . 
0 0 . 
 with color blue at (0,0)
diff: 
correct output grid

TRAIN 017c7c7b.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (6,3) and color black and layers
  _0: rectangle with size (6,3) with model Odd Checkboard with color blue at (0,0)
diff: 
   (0.0 bits)
data: a background with size (9,3) and color black and layers
  _0: 
. 0 . 
0 . 0 
. 0 . 
0 . 0 
. 0 . 
0 . 0 
. 0 . 
0 . 0 
. 0 . 
 with color red at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,3) and color black and layers
  _0: rectangle with size (6,3) with model Odd Checkboard with color blue at (0,0)
diff: 
correct output grid

TRAIN 017c7c7b.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (6,3) and color black and layers
  _0: rectangle with size (6,2) with mask 
. 0 
0 0 
. 0 
. 0 
0 0 
. 0 
 with color blue at (0,0)
diff: 
   (0.0 bits)
data: a background with size (9,3) and color black and layers
  _0: 
. 0 
0 0 
. 0 
. 0 
0 0 
. 0 
. 0 
0 0 
. 0 
 with color red at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,3) and color black and layers
  _0: rectangle with size (6,2) with mask 
. 0 
0 0 
. 0 
. 0 
0 0 
. 0 
 with color blue at (0,0)
diff: 
correct output grid

TRAIN 017c7c7b.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,3) and color black and layers
  _0: rectangle with size (6,3) with mask 
0 0 0 
. 0 . 
. 0 . 
0 0 0 
. 0 . 
. 0 . 
 with color blue at (0,0)
diff: 
correct output grid

TEST 017c7c7b.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 2.6 sec (2.6 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-397] Checking task 025d127b.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79133.4 = 79135.8
DL output with Mo: L = 2.3 + 79133.4 = 79135.8
DL input+output M: L = 4.6 + 158266.9 = 158271.5

# learning a model for train pairs
2.000	
1.188	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.375	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.252	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.129	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.122	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.115	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.110	OUT SPE ^.size = ^.size
0.107	OUT SPE ^.layer_0.pos = ^.layer_0.pos + (0, 1)
0.106	OUT SPE ^.layer_0.shape.mask.size.j = average(^.layer_0.shape.mask.size.j, ^.layer_01.shape.mask.size.j)
0.104	OUT SPE ^.layer_01.pos.i = ^.layer_01.pos.i
0.103	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_0.shape.mask.size.i
0.102	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.100	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.099	OUT SPE ^.layer_01.shape.mask.size.j = ^.layer_0.shape.mask.size.j / colorCount(^)
0.098	OUT SPE ^.layer_01.shape.mask.size.i = ^.layer_01.shape.mask.size.i
0.097	OUT SPE ^.layer_01.pos.j = right(^.layer_0) - ^.layer_01.shape.mask.size.i
0.096	IN  SPE ^.color = black
0.095	OUT SPE ^.color = black
0.038	
0.038	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i,average(^.layer_0.shape.mask.size.j, ^.layer_01.shape.mask.size.j)) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos + (0, 1)
  _01: rectangle with size (^.layer_01.shape.mask.size.i,^.layer_0.shape.mask.size.j / colorCount(^)) with model ? with color ^.layer_01.shape.color at (^.layer_01.pos.i,right(^.layer_0) - ^.layer_01.shape.mask.size.i)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.3 + 4504.8 = 4575.2
DL output with Mo: L = 182.9 + 2788.5 = 2971.5
DL input+output M: L = 253.3 + 7293.3 = 7546.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i,average(^.layer_0.shape.mask.size.j, ^.layer_01.shape.mask.size.j)) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos + (0, 1)
  _01: rectangle with size (^.layer_01.shape.mask.size.i,^.layer_0.shape.mask.size.j / colorCount(^)) with model ? with color ^.layer_01.shape.color at (^.layer_01.pos.i,right(^.layer_0) - ^.layer_01.shape.mask.size.i)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 182.9 + 2788.5 = 2971.5
DL input+output M: L = 253.2 + 2788.5 = 3041.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (14,9) and color black and layers
  _0: rectangle with size (5,6) with mask 
0 0 0 . . . 
0 . . 0 . . 
. 0 . . 0 . 
. . 0 . . 0 
. . . 0 0 0 
 with color pink at (1,1)
  _01: rectangle with size (3,4) with mask 
0 0 0 . 
0 . . 0 
. 0 0 0 
 with color red at (7,2)
diff: 
   (0.0 bits)
data: a background with size (14,9) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 . . 
0 . . 0 . 
. 0 . . 0 
. . 0 . 0 
. . 0 0 0 
 with color pink at (1,2)
  _01: rectangle with size (3,3) with model Border with color red at (7,3)
diff: 
   (33.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,9) and color black and layers
  _0: rectangle with size (5,6) with mask 
0 0 0 . . . 
0 . . 0 . . 
. 0 . . 0 . 
. . 0 . . 0 
. . . 0 0 0 
 with color pink at (1,1)
  _01: rectangle with size (3,4) with mask 
0 0 0 . 
0 . . 0 
. 0 0 0 
 with color red at (7,2)
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,9) and color black and layers
  _0: rectangle with size (3,4) with mask 
0 0 0 . 
0 . . 0 
. 0 0 0 
 with color red at (7,2)
  _01: rectangle with size (5,6) with mask 
0 0 0 . . . 
0 . . 0 . . 
. 0 . . 0 . 
. . 0 . . 0 
. . . 0 0 0 
 with color pink at (1,1)
diff: 
! 29 wrong pixels (generated / expected)

TRAIN 025d127b.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (8,9) and color black and layers
  _0: rectangle with size (1,5) with model Full with color cyan at (1,1)
  _01: rectangle with size (1,5) with model Full with color cyan at (5,4)
  + 6 delta pixels
diff: 
   (0.0 bits)
data: a background with size (8,9) and color black and layers
  _0: rectangle with size (1,5) with model Full with color cyan at (1,2)
  _01: rectangle with size (1,5) with model Full with color cyan at (5,4)
  + 6 delta pixels
diff: 
   (245.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,9) and color black and layers
  _0: rectangle with size (1,5) with model Full with color cyan at (1,1)
  _01: rectangle with size (1,5) with model Full with color cyan at (5,4)
  + 6 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,9) and color black and layers
  _0: rectangle with size (1,5) with model Full with color cyan at (5,4)
  _01: rectangle with size (1,5) with model Full with color cyan at (1,1)
  + 6 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (8,9) and color black and layers
  _0: rectangle with size (1,5) with model Full with color cyan at (1,1)
  _01: rectangle with size (2,1) with model Full with color cyan at (4,8)
  + 9 delta pixels
diff: 
! 13 wrong pixels (generated / expected)

TRAIN 025d127b.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,6) with model Full with color yellow at (1,1)
  _01: rectangle with size (1,6) with model Full with color yellow at (5,4)
  + 6 delta pixels
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,6) with model Full with color yellow at (5,4)
  _01: rectangle with size (1,6) with model Full with color yellow at (1,1)
  + 6 delta pixels
diff: 
! 15 wrong pixels (generated / expected)

TEST 025d127b.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 9.0 sec (9.0 sec/task)
bits-train-error = 2788.5 bits (2788.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-396] Checking task 045e512c.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 552662.4 = 552664.8
DL output with Mo: L = 2.3 + 552662.4 = 552664.8
DL input+output M: L = 4.6 + 1105324.9 = 1105329.5

# learning a model for train pairs
2.000	
1.027	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.123	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.105	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.087	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.075	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.061	OUT ADD ^.layer_00 = ^.layer_0
0.052	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.044	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.040	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.037	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.035	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.032	OUT SPE ^.layer_01.shape = coloring(^.layer_0.shape, ^.layer_01.shape.color)
0.030	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.022	
0.022	IN  DEL ^.layer_011
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: coloring(^.layer_0.shape, ^.layer_01.shape.color) at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 4387.0 = 4485.1
DL output with Mo: L = 190.8 + 11925.8 = 12116.5
DL input+output M: L = 288.9 + 16312.7 = 16601.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: coloring(^.layer_0.shape, ^.layer_01.shape.color) at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 40.0 = 110.2
DL output with Mo: L = 190.8 + 11925.8 = 12116.5
DL input+output M: L = 261.0 + 11965.8 = 12226.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (21,21) and color black and layers
  _0: rectangle with size (3,3) with model Border with color cyan at (6,6)
  _01: rectangle with size (1,3) with model Full with color red at (10,6)
  + 3 delta pixels
diff: 
   (2.0 bits)
data: a background with size (21,21) and color black and layers
  _00: 
8 8 8 
8 . 8 
8 8 8 
 at (6,6)
  _0: rectangle with size (1,11) with model Full with color green at (6,10)
  _01: 
2 2 2 
2 . 2 
2 2 2 
 at (10,6)
  _011: rectangle with size (7,3) with model Full with color red at (14,6)
  _0111: rectangle with size (3,3) with model Border with color green at (6,10)
  _01111: rectangle with size (3,3) with model Border with color green at (6,14)
  _011111: rectangle with size (3,3) with model Border with color green at (6,18)
  + 7 delta pixels
diff: 
   (523.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (3,3) with model Border with color cyan at (6,6)
  _01: rectangle with size (3,1) with model Full with color green at (6,10)
  + 3 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21
>> Trial 2
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (3,3) with model Border with color cyan at (6,6)
  _01: rectangle with size (1,3) with model Full with color red at (10,6)
  + 3 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21
>> Trial 3
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (3,1) with model Full with color green at (6,10)
  _01: rectangle with size (3,3) with model Border with color cyan at (6,6)
  + 3 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21

TRAIN 045e512c.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (21,21) and color black and layers
  _0: rectangle with size (3,3) with model +-cross with color blue at (7,11)
  _01: rectangle with size (1,1) with model Full with color red at (8,9)
  + 2 delta pixels
diff: 
   (2.0 bits)
data: a background with size (21,21) and color black and layers
  _00: 
. 1 . 
1 1 1 
. 1 . 
 at (7,11)
  _0: rectangle with size (3,3) with model +-cross with color yellow at (3,11)
  _01: 
. 2 . 
2 2 2 
. 2 . 
 at (7,3)
  _011: rectangle with size (3,3) with model +-cross with color red at (7,7)
  _0111: rectangle with size (3,3) with model +-cross with color yellow at (7,15)
  _01111: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color yellow at (0,11)
  _011111: rectangle with size (3,2) with mask 
0 . 
0 0 
0 . 
 with color red at (7,0)
  + 4 delta pixels
diff: 
   (403.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (3,3) with model +-cross with color blue at (7,11)
  _01: rectangle with size (1,1) with model Full with color yellow at (5,12)
  + 2 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21
>> Trial 2
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (3,3) with model +-cross with color blue at (7,11)
  _01: rectangle with size (1,1) with model Full with color red at (8,9)
  + 2 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21

TRAIN 045e512c.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (21,21) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 0 
 with color grey at (7,6)
  _01: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color blue at (11,10)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (21,21) and color black and layers
  _00: 
5#5#. 
5#. 5#
. 5#5#
 at (7,6)
  _0: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 0 
 with color pink at (3,10)
  _01: 
1 1 . 
1 . 1 
. 1 1 
 at (11,10)
  _011: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 0 
 with color blue at (15,14)
  _0111: rectangle with size (2,3) with mask 
0 . 0 
. 0 0 
 with color pink at (0,14)
  _01111: rectangle with size (1,2) with model Full with color blue at (19,18)
  _011111: rectangle with size (1,1) with model Full with color blue at (20,20)
  + 1 delta pixels
diff: 
   (265.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 0 
 with color grey at (7,6)
  _01: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color blue at (11,10)
  + 2 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21
>> Trial 2
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color blue at (11,10)
  _01: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 0 
 with color grey at (7,6)
  + 2 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21

TRAIN 045e512c.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
0 . 0 
0 . 0 
 with color cyan at (7,6)
  _01: rectangle with size (3,1) with model Full with color red at (7,10)
  + 5 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21
>> Trial 2
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
0 . 0 
0 . 0 
 with color cyan at (7,6)
  _01: rectangle with size (1,3) with model Full with color green at (11,6)
  + 5 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21
>> Trial 3
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (3,1) with model Full with color red at (7,10)
  _01: rectangle with size (3,3) with mask 
0 0 0 
0 . 0 
0 . 0 
 with color cyan at (7,6)
  + 5 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21

TEST 045e512c.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.4 sec (59.4 sec/task)
bits-train-error = 11925.8 bits (11925.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-395] Checking task 0520fde7.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 24423.7 = 24426.1
DL output with Mo: L = 2.3 + 10534.8 = 10537.1
DL input+output M: L = 4.6 + 34958.5 = 34963.2

# learning a model for train pairs
2.000	
1.259	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.797	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.643	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.523	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.422	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.323	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.287	OUT SPE ^.size = '(3, 3)
0.271	OUT SPE ^.layer_0.shape.color = red
0.256	IN  SPE ^.layer_011.shape.mask = 
0 
0 
0 

0.246	OUT SPE ^.layer_0.shape.mask.size.i = area(^.layer_01.shape) - 2
0.237	OUT SPE ^.layer_0.pos.j = bottom(^.layer_01) - 1
0.229	OUT SPE ^.layer_0.shape.mask.size.j = area(^.layer_01.shape) / '2
0.222	OUT SPE ^.color = black
0.215	OUT SPE ^.layer_0.pos.i = max(^.layer_0.pos.j, ^.layer_011.pos.j) - 3
0.208	IN  SPE ^.layer_011.shape.color = grey
0.069	
0.069	IN  GEN ^.layer_011.shape.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: rectangle with size (area(^.layer_01.shape) - 2,area(^.layer_01.shape) / '2) with model ? with color red at (max(^.layer_0.pos.j, ^.layer_011.pos.j) - 3,bottom(^.layer_01) - 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: 
0 
0 
0 
 with color grey at (?,?)

DL input  with Mi: L = 97.5 + 3391.3 = 3488.8
DL output with Mo: L = 185.7 + 503.6 = 689.4
DL input+output M: L = 283.2 + 3895.0 = 4178.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: rectangle with size (area(^.layer_01.shape) - 2,area(^.layer_01.shape) / '2) with model ? with color red at (max(^.layer_0.pos.j, ^.layer_011.pos.j) - 3,bottom(^.layer_01) - 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: 
0 
0 
0 
 with color ? at (?,?)

DL input  with Mi: L = 94.1 + 0.0 = 94.1
DL output with Mo: L = 185.7 + 503.6 = 689.4
DL input+output M: L = 279.9 + 503.6 = 783.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,7) and color black and layers
  _0: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color blue at (0,4)
  _01: rectangle with size (3,2) with model Even Checkboard with color blue at (0,0)
  _011: 
0 
0 
0 
 with color grey at (0,3)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (1,1)
diff: 
   (2.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,7) and color black and layers
  _0: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color blue at (0,4)
  _01: rectangle with size (3,2) with model Even Checkboard with color blue at (0,0)
  _011: 
0 
0 
0 
 with color grey at (0,3)
diff: 
correct output grid

TRAIN 0520fde7.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (3,7) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. . 0 
0 0 . 
 with color blue at (0,0)
  _01: rectangle with size (3,3) with model +-cross with color blue at (0,4)
  _011: 
0 
0 
0 
 with color grey at (0,3)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,2) with model Even Checkboard with color red at (0,1)
diff: 
   (6.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,7) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. . 0 
0 0 . 
 with color blue at (0,0)
  _01: rectangle with size (3,3) with model +-cross with color blue at (0,4)
  _011: 
0 
0 
0 
 with color grey at (0,3)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,7) and color black and layers
  _0: rectangle with size (3,3) with model +-cross with color blue at (0,4)
  _01: rectangle with size (3,3) with mask 
0 0 . 
. . 0 
0 0 . 
 with color blue at (0,0)
  _011: 
0 
0 
0 
 with color grey at (0,3)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,7) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. . 0 
0 0 . 
 with color blue at (0,0)
  _01: rectangle with size (3,1) with model Full with color grey at (0,3)
  _011: 
0 
0 
0 
 with color blue at (0,5)
  + 2 delta pixels
diff: 
! 2 wrong pixels (generated / expected)

TRAIN 0520fde7.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,7) and color blue and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. 0 . 
. 0 . 
 with color black at (0,4)
  _01: rectangle with size (2,3) with mask 
0 0 . 
. . 0 
 with color black at (0,0)
  _011: 
0 
0 
0 
 with color grey at (0,3)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (1,0)
  + 1 delta pixels
diff: 
   (40.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,7) and color blue and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. 0 . 
. 0 . 
 with color black at (0,4)
  _01: rectangle with size (2,3) with mask 
0 0 . 
. . 0 
 with color black at (0,0)
  _011: 
0 
0 
0 
 with color grey at (0,3)
  + 1 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,7) and color blue and layers
  _0: rectangle with size (2,3) with mask 
0 0 . 
. . 0 
 with color black at (0,0)
  _01: rectangle with size (3,3) with mask 
0 0 0 
. 0 . 
. 0 . 
 with color black at (0,4)
  _011: 
0 
0 
0 
 with color grey at (0,3)
  + 1 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 0520fde7.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,7) and color black and layers
  _0: rectangle with size (3,3) with model Even Checkboard with color blue at (0,0)
  _01: rectangle with size (3,3) with mask 
0 . 0 
0 . 0 
. 0 . 
 with color blue at (0,4)
  _011: 
0 
0 
0 
 with color grey at (0,3)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,7) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 . 0 
. 0 . 
 with color blue at (0,4)
  _01: rectangle with size (3,3) with model Even Checkboard with color blue at (0,0)
  _011: 
0 
0 
0 
 with color grey at (0,3)
diff: 
! 6 wrong pixels (generated / expected)

TEST 0520fde7.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 6.2 sec (6.2 sec/task)
bits-train-error = 503.6 bits (503.6 bits/task)
acc-train-micro = 0.33 tasks (33.33%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.33
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-394] Checking task 05269061.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 57672.1 = 57674.4
DL output with Mo: L = 2.3 + 57672.1 = 57674.4
DL input+output M: L = 4.6 + 115344.1 = 115348.8

# learning a model for train pairs
2.000	
1.235	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.235	OUT SPE ^ = fillResizeAlike_total(black, ^.size, ^)
0.168	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.116	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.080	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.079	IN  SPE ^.color = black
0.002	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
fillResizeAlike_total(black, ^.size, ^)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.2 + 4425.4 = 4523.6
DL output with Mo: L = 21.8 + 0.0 = 21.8
DL input+output M: L = 120.1 + 4425.4 = 4545.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
fillResizeAlike_total(black, ^.size, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 21.8 + 0.0 = 21.8
DL input+output M: L = 24.2 + 0.0 = 24.2

# train input/output grids

## instance 1

> Input and output best reading:

data: 
2 8 3 0 0 0 0 
8 3 0 0 0 0 0 
3 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
2 8 3 2 8 3 2 
8 3 2 8 3 2 8 
3 2 8 3 2 8 3 
2 8 3 2 8 3 2 
8 3 2 8 3 2 8 
3 2 8 3 2 8 3 
2 8 3 2 8 3 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 8 3 0 0 0 0 
8 3 0 0 0 0 0 
3 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 05269061.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 0 0 0 0 0 1 
0 0 0 0 0 1 2 
0 0 0 0 1 2 4 
0 0 0 1 2 4 0 
0 0 1 2 4 0 0 

diff: 
   (0.0 bits)
data: 
2 4 1 2 4 1 2 
4 1 2 4 1 2 4 
1 2 4 1 2 4 1 
2 4 1 2 4 1 2 
4 1 2 4 1 2 4 
1 2 4 1 2 4 1 
2 4 1 2 4 1 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 0 0 0 0 0 1 
0 0 0 0 0 1 2 
0 0 0 0 1 2 4 
0 0 0 1 2 4 0 
0 0 1 2 4 0 0 

diff: 
correct output grid

TRAIN 05269061.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 8 3 0 
0 0 0 8 3 0 0 
0 0 8 3 0 0 0 
0 8 3 0 0 0 4 
8 3 0 0 0 4 0 
3 0 0 0 4 0 0 
0 0 0 4 0 0 0 

diff: 
   (0.0 bits)
data: 
4 8 3 4 8 3 4 
8 3 4 8 3 4 8 
3 4 8 3 4 8 3 
4 8 3 4 8 3 4 
8 3 4 8 3 4 8 
3 4 8 3 4 8 3 
4 8 3 4 8 3 4 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 8 3 0 
0 0 0 8 3 0 0 
0 0 8 3 0 0 0 
0 8 3 0 0 0 4 
8 3 0 0 0 4 0 
3 0 0 0 4 0 0 
0 0 0 4 0 0 0 

diff: 
correct output grid

TRAIN 05269061.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 1 0 0 0 0 2 
1 0 0 0 0 2 0 
0 0 0 0 2 0 0 
0 0 0 2 0 0 0 
0 0 2 0 0 0 0 
0 2 0 0 0 0 4 
2 0 0 0 0 4 0 

diff: 
correct output grid

TEST 05269061.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 0.9 sec (0.9 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-393] Checking task 05f2a901.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 130498.8 = 130501.1
DL output with Mo: L = 2.3 + 130498.8 = 130501.1
DL input+output M: L = 4.6 + 260997.6 = 261002.2

# learning a model for train pairs
2.000	
1.119	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.239	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.172	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.098	OUT ADD ^.layer_0 = ^.layer_0.shape at (?,?)
0.068	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.031	OUT ADD ^.layer_01 = ^.layer_01
0.026	OUT SPE ^.size = ^.size
0.023	IN  SPE ^.layer_01.shape.mask = 
0 0 
0 0 

0.020	OUT SPE ^.layer_0.pos = ^.layer_0.pos + translationOnto(^.layer_0, ^.layer_01)
0.019	IN  SPE ^.layer_0.shape.color = red
0.018	IN  SPE ^.layer_01.shape.color = cyan
0.017	IN  SPE ^.color = black
0.017	OUT SPE ^.color = black
0.001	
0.001	IN  GEN ^.layer_01.shape.color = ?
0.001	IN  GEN ^.layer_0.shape.color = ?
0.001	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0.shape at ^.layer_0.pos + translationOnto(^.layer_0, ^.layer_01)
  _01: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at (?,?)
  _01: 
0 0 
0 0 
 with color cyan at (?,?)

DL input  with Mi: L = 74.0 + 2060.5 = 2134.6
DL output with Mo: L = 54.2 + 0.0 = 54.2
DL input+output M: L = 128.2 + 2060.5 = 2188.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0.shape at ^.layer_0.pos + translationOnto(^.layer_0, ^.layer_01)
  _01: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: 
0 0 
0 0 
 with color ? at (?,?)

DL input  with Mi: L = 67.3 + 0.0 = 67.3
DL output with Mo: L = 54.2 + 0.0 = 54.2
DL input+output M: L = 121.5 + 0.0 = 121.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (14,9) and color black and layers
  _0: rectangle with size (2,4) with mask 
. 0 0 0 
0 0 . 0 
 with color red at (2,0)
  _01: 
0 0 
0 0 
 with color cyan at (10,3)
diff: 
   (0.0 bits)
data: a background with size (14,9) and color black and layers
  _0: 
. 2 2 2 
2 2 . 2 
 at (8,0)
  _01: 
8 8 
8 8 
 at (10,3)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,9) and color black and layers
  _0: rectangle with size (2,4) with mask 
. 0 0 0 
0 0 . 0 
 with color red at (2,0)
  _01: 
0 0 
0 0 
 with color cyan at (10,3)
diff: 
correct output grid

TRAIN 05f2a901.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (9,10) and color black and layers
  _0: rectangle with size (4,3) with mask 
. 0 0 
. 0 0 
0 0 0 
. 0 0 
 with color red at (1,0)
  _01: 
0 0 
0 0 
 with color cyan at (4,6)
diff: 
   (0.0 bits)
data: a background with size (9,10) and color black and layers
  _0: 
. 2 2 
. 2 2 
2 2 2 
. 2 2 
 at (1,3)
  _01: 
8 8 
8 8 
 at (4,6)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,10) and color black and layers
  _0: rectangle with size (4,3) with mask 
. 0 0 
. 0 0 
0 0 0 
. 0 0 
 with color red at (1,0)
  _01: 
0 0 
0 0 
 with color cyan at (4,6)
diff: 
correct output grid

TRAIN 05f2a901.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (11,10) and color black and layers
  _0: rectangle with size (3,5) with mask 
. . 0 0 0 
0 0 0 0 0 
. 0 0 . . 
 with color red at (6,1)
  _01: 
0 0 
0 0 
 with color cyan at (1,3)
diff: 
   (0.0 bits)
data: a background with size (11,10) and color black and layers
  _0: 
. . 2 2 2 
2 2 2 2 2 
. 2 2 . . 
 at (3,1)
  _01: 
8 8 
8 8 
 at (1,3)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,10) and color black and layers
  _0: rectangle with size (3,5) with mask 
. . 0 0 0 
0 0 0 0 0 
. 0 0 . . 
 with color red at (6,1)
  _01: 
0 0 
0 0 
 with color cyan at (1,3)
diff: 
correct output grid

TRAIN 05f2a901.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,10) and color black and layers
  _0: rectangle with size (4,2) with mask 
0 . 
0 0 
0 0 
. 0 
 with color red at (4,5)
  _01: 
0 0 
0 0 
 with color cyan at (6,1)
diff: 
correct output grid

TEST 05f2a901.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 3.1 sec (3.1 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-392] Checking task 06df4c85.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 611136.3 = 611138.6
DL output with Mo: L = 2.3 + 611136.3 = 611138.6
DL input+output M: L = 4.6 + 1222272.5 = 1222277.2

# learning a model for train pairs
2.000	
1.487	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.974	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.570	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.202	OUT ADD ^.layer_0 = ^.layer_0
0.161	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.129	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.104	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.094	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.088	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.085	OUT ADD ^.layer_010 = ^.layer_01
0.084	OUT SPE ^.size = ^.size
0.083	IN  ADD ^.layer_010 = point with color ? at (?,?)
0.079	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.077	OUT SPE ^.layer_0111 = ^.layer_011
0.076	OUT SPE ^.layer_01111.shape.mask = 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 

0.076	IN  SPE ^.layer_011.shape.mask = 
0 0 
0 0 

0.073	IN  SPE ^.color = black
0.005	
0.005	IN  GEN ^.color = ?
0.005	IN  GEN ^.layer_011.shape.mask = rectangle with size (?,?) with model ?
0.005	IN  DEL ^.layer_010
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: ^.layer_0
  _010: ^.layer_01
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: ^.layer_011
  _01111: 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
 with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: point with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: 
0 0 
0 0 
 with color ? at (?,?)

DL input  with Mi: L = 113.2 + 41340.8 = 41454.0
DL output with Mo: L = 116.1 + 2908.2 = 3024.2
DL input+output M: L = 229.3 + 44249.0 = 44478.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: ^.layer_0
  _010: ^.layer_01
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: ^.layer_011
  _01111: 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
 with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 0.0 = 98.1
DL output with Mo: L = 116.1 + 2754.6 = 2870.7
DL input+output M: L = 214.2 + 2754.6 = 2968.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (20,20) with mask 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color cyan at (0,0)
  _01: rectangle with size (8,2) with model Full with color red at (3,15)
  _011: rectangle with size (2,2) with model Full with color red at (3,3)
  + 16 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _0: 
. . 8 . . 8 . . 8 . . 8 . . 8 . . 8 . . 
. . 8 . . 8 . . 8 . . 8 . . 8 . . 8 . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . 8 . . 8 . . 8 . . 8 . . 8 . . 8 . . 
. . 8 . . 8 . . 8 . . 8 . . 8 . . 8 . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . 8 . . 8 . . 8 . . 8 . . 8 . . 8 . . 
. . 8 . . 8 . . 8 . . 8 . . 8 . . 8 . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . 8 . . 8 . . 8 . . 8 . . 8 . . 8 . . 
. . 8 . . 8 . . 8 . . 8 . . 8 . . 8 . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . 8 . . 8 . . 8 . . 8 . . 8 . . 8 . . 
. . 8 . . 8 . . 8 . . 8 . . 8 . . 8 . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . 8 . . 8 . . 8 . . 8 . . 8 . . 8 . . 
. . 8 . . 8 . . 8 . . 8 . . 8 . . 8 . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . 8 . . 8 . . 8 . . 8 . . 8 . . 8 . . 
. . 8 . . 8 . . 8 . . 8 . . 8 . . 8 . . 
 at (0,0)
  _010: 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
 at (3,15)
  _01: rectangle with size (2,8) with model Full with color green at (12,3)
  _011: rectangle with size (2,2) with model Full with color blue at (6,9)
  _0111: 
2 2 
2 2 
 at (3,3)
  _01111: 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
 with color red at (3,6)
diff: 
   (90.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (20,20) with mask 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color cyan at (0,0)
  _01: rectangle with size (8,2) with model Full with color red at (3,15)
  _011: rectangle with size (2,2) with model Full with color red at (3,3)
  + 16 delta pixels
diff: 
! 40 wrong pixels (generated / expected)

TRAIN 06df4c85.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (23,23) and color black and layers
  _0: rectangle with size (23,23) with mask 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color blue at (0,0)
  _01: rectangle with size (14,2) with model Full with color red at (3,3)
  _011: rectangle with size (8,2) with model Full with color cyan at (12,18)
  + 32 delta pixels
diff: 
   (0.0 bits)
data: a background with size (23,23) and color black and layers
  _0: 
. . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 
. . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
. . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 
. . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
. . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 
. . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
. . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 
. . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
. . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 
. . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
. . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 
. . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
. . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 
. . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
. . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 
. . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 1 . . 
 at (0,0)
  _010: 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
 at (3,3)
  _01: rectangle with size (2,14) with model Full with color brown at (9,9)
  _011: rectangle with size (2,2) with model Full with color yellow at (3,12)
  _0111: 
8 8 
8 8 
8 8 
8 8 
8 8 
8 8 
8 8 
8 8 
 at (12,18)
  _01111: 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
 with color cyan at (18,9)
diff: 
   (93.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (23,23) with mask 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color blue at (0,0)
  _01: rectangle with size (14,2) with model Full with color red at (3,3)
  _011: rectangle with size (8,2) with model Full with color cyan at (12,18)
  + 32 delta pixels
diff: 
! 48 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (23,23) with mask 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color blue at (0,0)
  _01: rectangle with size (2,14) with model Full with color brown at (9,9)
  _011: rectangle with size (8,2) with model Full with color cyan at (12,18)
  + 32 delta pixels
diff: 
! 48 wrong pixels (generated / expected)

TRAIN 06df4c85.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (23,23) and color black and layers
  _0: rectangle with size (23,23) with mask 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color yellow at (0,0)
  _01: rectangle with size (17,2) with model Full with color green at (3,3)
  _011: rectangle with size (2,2) with model Full with color red at (3,15)
  + 28 delta pixels
diff: 
   (0.0 bits)
data: a background with size (23,23) and color black and layers
  _0: 
. . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 
. . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
. . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 
. . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
. . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 
. . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
. . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 
. . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
. . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 
. . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
. . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 
. . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
. . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 
. . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
. . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 
. . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 4 . . 
 at (0,0)
  _010: 
3 3 
3 3 
3 3 
3 3 
3 3 
3 3 
3 3 
3 3 
3 3 
3 3 
3 3 
3 3 
3 3 
3 3 
3 3 
3 3 
3 3 
 at (3,3)
  _01: rectangle with size (2,11) with model Full with color red at (9,9)
  _011: rectangle with size (2,2) with model Full with color green at (18,6)
  _0111: 
2 2 
2 2 
 at (3,15)
  _01111: 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
 with color green at (18,9)
diff: 
   (92.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (23,23) with mask 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color yellow at (0,0)
  _01: rectangle with size (17,2) with model Full with color green at (3,3)
  _011: rectangle with size (2,2) with model Full with color red at (3,15)
  + 28 delta pixels
diff: 
! 44 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (23,23) with mask 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color yellow at (0,0)
  _01: rectangle with size (17,2) with model Full with color green at (3,3)
  _011: rectangle with size (2,2) with model Full with color red at (9,9)
  + 28 delta pixels
diff: 
! 44 wrong pixels (generated / expected)

TRAIN 06df4c85.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (26,26) and color black and layers
  _0: rectangle with size (26,26) with mask 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color yellow at (0,0)
  _01: rectangle with size (11,2) with model Full with color cyan at (3,6)
  _011: rectangle with size (2,2) with model Full with color red at (3,15)
  + 20 delta pixels
diff: 
! 52 wrong pixels (generated / expected)

TEST 06df4c85.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.4 sec (59.4 sec/task)
bits-train-error = 2754.6 bits (2754.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-391] Checking task 08ed6ac7.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 64315.6 = 64317.9
DL output with Mo: L = 2.3 + 64315.6 = 64317.9
DL input+output M: L = 4.6 + 128631.2 = 128635.9

# learning a model for train pairs
2.000	
1.284	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.568	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.475	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.360	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.266	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.197	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.145	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.123	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.116	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.094	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.084	OUT SPE ^.layer_0 = coloring(^.layer_0, blue)
0.074	OUT SPE ^.layer_01 = coloring(^.layer_01, red)
0.064	OUT SPE ^.layer_011 = coloring(^.layer_011, green)
0.055	OUT SPE ^.layer_0111 = coloring(^.layer_0111, yellow)
0.049	OUT SPE ^.size = ^.size
0.047	IN  SPE ^.layer_0.shape.color = grey
0.045	IN  SPE ^.layer_01.shape.color = grey
0.044	IN  SPE ^.layer_011.shape.color = grey
0.042	IN  SPE ^.layer_0111.shape.color = grey
0.041	IN  SPE ^.layer_0.shape.mask.model = Full
0.040	IN  SPE ^.layer_01.shape.mask.model = Full
0.039	IN  SPE ^.layer_011.shape.mask.model = Full
0.039	IN  SPE ^.layer_0111.shape.mask.model = Full
0.038	IN  SPE ^.color = black
0.037	OUT SPE ^.color = black
0.003	
0.003	IN  GEN ^.layer_0111.shape.color = ?
0.003	IN  GEN ^.layer_011.shape.color = ?
0.003	IN  GEN ^.layer_01.shape.color = ?
0.003	IN  GEN ^.layer_0.shape.color = ?
0.003	IN  GEN ^.layer_0111.shape.mask.model = ?
0.003	IN  GEN ^.layer_011.shape.mask.model = ?
0.003	IN  GEN ^.layer_01.shape.mask.model = ?
0.003	IN  GEN ^.layer_0.shape.mask.model = ?
0.003	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, blue)
  _01: coloring(^.layer_01, red)
  _011: coloring(^.layer_011, green)
  _0111: coloring(^.layer_0111, yellow)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color grey at (?,?)
  _01: rectangle with size (?,?) with model Full with color grey at (?,?)
  _011: rectangle with size (?,?) with model Full with color grey at (?,?)
  _0111: rectangle with size (?,?) with model Full with color grey at (?,?)

DL input  with Mi: L = 141.2 + 2169.9 = 2311.1
DL output with Mo: L = 67.6 + 0.0 = 67.6
DL input+output M: L = 208.9 + 2169.9 = 2378.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, blue)
  _01: coloring(^.layer_01, red)
  _011: coloring(^.layer_011, green)
  _0111: coloring(^.layer_0111, yellow)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 0.0 = 125.8
DL output with Mo: L = 67.6 + 0.0 = 67.6
DL input+output M: L = 193.4 + 0.0 = 193.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,1) with model Full with color grey at (0,5)
  _01: rectangle with size (8,1) with model Full with color grey at (1,1)
  _011: rectangle with size (6,1) with model Full with color grey at (3,3)
  _0111: rectangle with size (3,1) with model Full with color grey at (6,7)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: 
1 
1 
1 
1 
1 
1 
1 
1 
1 
 at (0,5)
  _01: 
2 
2 
2 
2 
2 
2 
2 
2 
 at (1,1)
  _011: 
3 
3 
3 
3 
3 
3 
 at (3,3)
  _0111: 
4 
4 
4 
 at (6,7)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,1) with model Full with color grey at (0,5)
  _01: rectangle with size (8,1) with model Full with color grey at (1,1)
  _011: rectangle with size (6,1) with model Full with color grey at (3,3)
  _0111: rectangle with size (3,1) with model Full with color grey at (6,7)
diff: 
correct output grid

TRAIN 08ed6ac7.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: rectangle with size (8,1) with model Full with color grey at (1,7)
  _01: rectangle with size (5,1) with model Full with color grey at (4,3)
  _011: rectangle with size (4,1) with model Full with color grey at (5,5)
  _0111: rectangle with size (2,1) with model Full with color grey at (7,1)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: 
1 
1 
1 
1 
1 
1 
1 
1 
 at (1,7)
  _01: 
2 
2 
2 
2 
2 
 at (4,3)
  _011: 
3 
3 
3 
3 
 at (5,5)
  _0111: 
4 
4 
 at (7,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (8,1) with model Full with color grey at (1,7)
  _01: rectangle with size (5,1) with model Full with color grey at (4,3)
  _011: rectangle with size (4,1) with model Full with color grey at (5,5)
  _0111: rectangle with size (2,1) with model Full with color grey at (7,1)
diff: 
correct output grid

TRAIN 08ed6ac7.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (8,1) with model Full with color grey at (1,1)
  _01: rectangle with size (7,1) with model Full with color grey at (2,5)
  _011: rectangle with size (5,1) with model Full with color grey at (4,7)
  _0111: rectangle with size (3,1) with model Full with color grey at (6,3)
diff: 
correct output grid

TEST 08ed6ac7.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 10.3 sec (10.3 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-390] Checking task 09629e4f.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 194274.3 = 194276.6
DL output with Mo: L = 2.3 + 194274.3 = 194276.6
DL input+output M: L = 4.6 + 388548.5 = 388553.2

# learning a model for train pairs
2.000	
1.630	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.303	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.006	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.732	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.634	OUT ADD ^.layer_01 = ^.layer_0
0.567	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.500	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.432	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.404	IN  SPE ^.layer_0.shape.mask = 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 

0.394	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.390	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.385	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.381	OUT SPE ^.layer_0111.shape = tiling(^.layer_011.shape, 3, 3)
0.377	OUT SPE ^.layer_011.shape = scaleTo(^.layer_01.shape, '(3, 3))
0.372	OUT SPE ^.layer_01111.shape = tiling(^.layer_0111.shape, 3, 3)
0.368	OUT SPE ^.size = ^.size
0.365	OUT SPE ^.layer_0.shape.mask = 
0 0 0 
0 0 0 
0 0 0 

0.364	IN  SPE ^.layer_0.shape.color = grey
0.363	OUT SPE ^.layer_011.pos.j = right(^.layer_01) - ^.layer_011.pos.j - ^.layer_0.pos.j
0.362	IN  SPE ^.layer_01.shape.mask.model = Full
0.362	IN  SPE ^.color = black
0.361	OUT SPE ^.color = black
0.012	
0.012	IN  GEN ^.layer_0.shape.color = ?
0.012	IN  GEN ^.layer_01.shape.mask.model = ?
0.012	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color ? at (?,?)
  _01: ^.layer_0
  _011: scaleTo(^.layer_01.shape, '(3, 3)) at (?,right(^.layer_01) - ^.layer_011.pos.j - ^.layer_0.pos.j)
  _0111: tiling(^.layer_011.shape, 3, 3) at (?,?)
  _01111: tiling(^.layer_0111.shape, 3, 3) at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 229.8 + 67869.2 = 68098.9
DL output with Mo: L = 192.5 + 1844.0 = 2036.5
DL input+output M: L = 422.3 + 69713.1 = 70135.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color ? at (?,?)
  _01: ^.layer_0
  _011: scaleTo(^.layer_01.shape, '(3, 3)) at (?,right(^.layer_01) - ^.layer_011.pos.j - ^.layer_0.pos.j)
  _0111: tiling(^.layer_011.shape, 3, 3) at (?,?)
  _01111: tiling(^.layer_0111.shape, 3, 3) at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 225.8 + 20.0 = 245.8
DL output with Mo: L = 192.5 + 1844.0 = 2036.5
DL input+output M: L = 418.3 + 1864.0 = 2282.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,4) with model Full with color yellow at (1,1)
  _011: point with color red at (0,0)
  _0111: point with color pink at (0,5)
  + 40 delta pixels
diff: 
   (0.0 bits)
data: a background with size (11,11) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color green at (4,8)
  _01: 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
5#5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
5#5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
 at (0,0)
  _011: 
4 4 4 
4 4 4 
4 4 4 
 at (4,4)
  _0111: 
2 2 2 
2 2 2 
2 2 2 
 at (0,0)
  _01111: 
6 6 6 
6 6 6 
6 6 6 
 at (8,0)
diff: 
   (46.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,4) with model Full with color yellow at (1,1)
  _011: point with color red at (0,0)
  _0111: point with color pink at (0,5)
  + 40 delta pixels
diff: 
! 45 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,4) with model Full with color yellow at (1,1)
  _011: point with color pink at (0,5)
  _0111: point with color red at (0,0)
  + 40 delta pixels
diff: 
! 36 wrong pixels (generated / expected)

TRAIN 09629e4f.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (3,1) with model Full with color yellow at (2,0)
  _011: point with color red at (0,0)
  _0111: point with color green at (0,2)
  + 40 delta pixels
diff: 
   (0.0 bits)
data: a background with size (11,11) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color pink at (8,8)
  _01: 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
5#5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
5#5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
 at (0,0)
  _011: 
4 4 4 
4 4 4 
4 4 4 
 at (8,0)
  _0111: 
2 2 2 
2 2 2 
2 2 2 
 at (0,8)
  _01111: 
3 3 3 
3 3 3 
3 3 3 
 at (4,4)
diff: 
   (46.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (3,1) with model Full with color yellow at (2,0)
  _011: point with color red at (0,0)
  _0111: point with color green at (0,2)
  + 40 delta pixels
diff: 
! 45 wrong pixels (generated / expected)

TRAIN 09629e4f.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (3,1) with model Full with color red at (2,1)
  _011: point with color green at (0,1)
  _0111: point with color pink at (0,5)
  + 40 delta pixels
diff: 
   (0.0 bits)
data: a background with size (11,11) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color yellow at (4,8)
  _01: 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
5#5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
5#5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
 at (0,0)
  _011: 
2 2 2 
2 2 2 
2 2 2 
 at (8,0)
  _0111: 
3 3 3 
3 3 3 
3 3 3 
 at (0,4)
  _01111: 
6 6 6 
6 6 6 
6 6 6 
 at (4,4)
diff: 
   (46.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (3,1) with model Full with color red at (2,1)
  _011: point with color green at (0,1)
  _0111: point with color pink at (0,5)
  + 40 delta pixels
diff: 
! 45 wrong pixels (generated / expected)

TRAIN 09629e4f.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,3) with model Full with color yellow at (0,2)
  _011: point with color green at (0,0)
  _0111: point with color pink at (0,5)
  + 40 delta pixels
diff: 
   (2.0 bits)
data: a background with size (11,11) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color red at (4,4)
  _01: 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
5#5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
5#5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
 at (0,0)
  _011: 
4 4 4 
4 4 4 
4 4 4 
 at (0,4)
  _0111: 
3 3 3 
3 3 3 
3 3 3 
 at (8,4)
  _01111: 
6 6 6 
6 6 6 
6 6 6 
 at (4,8)
diff: 
   (46.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,3) with model Full with color yellow at (0,2)
  _011: point with color green at (0,0)
  _0111: point with color cyan at (0,1)
  + 40 delta pixels
diff: 
! 36 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,3) with model Full with color yellow at (0,2)
  _011: point with color cyan at (0,1)
  _0111: point with color green at (0,0)
  + 40 delta pixels
diff: 
! 39 wrong pixels (generated / expected)

TRAIN 09629e4f.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (3,1) with model Full with color red at (2,0)
  _011: point with color pink at (0,0)
  _0111: point with color yellow at (0,1)
  + 40 delta pixels
diff: 
! 45 wrong pixels (generated / expected)

TEST 09629e4f.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 17.3 sec (17.3 sec/task)
bits-train-error = 1844.0 bits (1844.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-389] Checking task 0962bcdd.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 116186.7 = 116189.0
DL output with Mo: L = 2.3 + 116186.7 = 116189.0
DL input+output M: L = 4.6 + 232373.4 = 232378.1

# learning a model for train pairs
2.000	
1.074	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.315	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.260	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.204	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.156	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.107	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.086	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.064	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.060	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.056	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.053	OUT SPE ^.layer_0.shape.mask = 
0 . . . 0 
. 0 . 0 . 
. . 0 . . 
. 0 . 0 . 
0 . . . 0 

0.049	OUT SPE ^.layer_01.shape.mask = 
0 . . . 0 
. 0 . 0 . 
. . 0 . . 
. 0 . 0 . 
0 . . . 0 

0.045	OUT SPE ^.size = ^.size
0.042	IN  SPE ^.layer_0.shape.mask = 
. 0 . 
0 . 0 
. 0 . 

0.039	IN  SPE ^.layer_01.shape.mask = 
. 0 . 
0 . 0 
. 0 . 

0.037	OUT SPE ^.layer_01.pos = ^.layer_01.pos - (1, 1)
0.035	OUT SPE ^.layer_0.pos = ^.layer_0.pos - (1, 1)
0.033	OUT SPE ^.layer_0111.pos = ^.layer_0111.pos - (2, 2)
0.031	OUT SPE ^.layer_011.pos = ^.layer_011.pos - (2, 2)
0.030	OUT SPE ^.layer_011.shape.mask.size.i = area(^.layer_01.shape) + 1
0.029	OUT SPE ^.layer_011.shape.mask.size = span(^.layer_0.pos, ^.layer_011.pos) + (3, 3)
0.027	OUT SPE ^.layer_0111.shape.mask.size.i = area(^.layer_01.shape) + 1
0.026	OUT SPE ^.layer_0111.shape.mask.size = span(^.layer_01.pos, ^.layer_0111.pos) + (3, 3)
0.025	OUT SPE ^.layer_011.shape.mask.model = +-cross
0.024	OUT SPE ^.layer_0111.shape.mask.model = +-cross
0.023	OUT SPE ^.layer_011.shape.color = majorityColor(^)
0.022	OUT SPE ^.layer_0111.shape.color = majorityColor(^)
0.021	OUT SPE ^.layer_01.shape.color = ^.layer_011.shape.color
0.021	OUT SPE ^.layer_0.shape.color = ^.layer_011.shape.color
0.020	IN  SPE ^.color = black
0.020	OUT SPE ^.color = black
0.004	
0.004	IN  GEN ^.layer_01.shape.mask = rectangle with size (?,?) with model ?
0.004	IN  GEN ^.layer_0.shape.mask = rectangle with size (?,?) with model ?
0.004	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 . . . 0 
. 0 . 0 . 
. . 0 . . 
. 0 . 0 . 
0 . . . 0 
 with color ^.layer_011.shape.color at ^.layer_0.pos - (1, 1)
  _01: 
0 . . . 0 
. 0 . 0 . 
. . 0 . . 
. 0 . 0 . 
0 . . . 0 
 with color ^.layer_011.shape.color at ^.layer_01.pos - (1, 1)
  _011: rectangle with size span(^.layer_0.pos, ^.layer_011.pos) + (3, 3) with model +-cross with color majorityColor(^) at ^.layer_011.pos - (2, 2)
  _0111: rectangle with size span(^.layer_01.pos, ^.layer_0111.pos) + (3, 3) with model +-cross with color majorityColor(^) at ^.layer_0111.pos - (2, 2)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
. 0 . 
0 . 0 
. 0 . 
 with color ? at (?,?)
  _01: 
. 0 . 
0 . 0 
. 0 . 
 with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 123.1 + 1815.1 = 1938.3
DL output with Mo: L = 351.5 + 0.0 = 351.5
DL input+output M: L = 474.6 + 1815.1 = 2289.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 . . . 0 
. 0 . 0 . 
. . 0 . . 
. 0 . 0 . 
0 . . . 0 
 with color ^.layer_011.shape.color at ^.layer_0.pos - (1, 1)
  _01: 
0 . . . 0 
. 0 . 0 . 
. . 0 . . 
. 0 . 0 . 
0 . . . 0 
 with color ^.layer_011.shape.color at ^.layer_01.pos - (1, 1)
  _011: rectangle with size span(^.layer_0.pos, ^.layer_011.pos) + (3, 3) with model +-cross with color majorityColor(^) at ^.layer_011.pos - (2, 2)
  _0111: rectangle with size span(^.layer_01.pos, ^.layer_0111.pos) + (3, 3) with model +-cross with color majorityColor(^) at ^.layer_0111.pos - (2, 2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 106.2 + 0.0 = 106.2
DL output with Mo: L = 351.5 + 0.0 = 351.5
DL input+output M: L = 457.7 + 0.0 = 457.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (3,3) with model Odd Checkboard with color orange at (2,1)
  _01: rectangle with size (3,3) with model Odd Checkboard with color orange at (6,7)
  _011: point with color red at (3,2)
  _0111: point with color red at (7,8)
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _0: 
0 . . . 0 
. 0 . 0 . 
. . 0 . . 
. 0 . 0 . 
0 . . . 0 
 with color red at (1,0)
  _01: 
0 . . . 0 
. 0 . 0 . 
. . 0 . . 
. 0 . 0 . 
0 . . . 0 
 with color red at (5,6)
  _011: rectangle with size (5,5) with model +-cross with color orange at (1,0)
  _0111: rectangle with size (5,5) with model +-cross with color orange at (5,6)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (3,3) with model Odd Checkboard with color orange at (2,1)
  _01: rectangle with size (3,3) with model Odd Checkboard with color orange at (6,7)
  _011: point with color red at (3,2)
  _0111: point with color red at (7,8)
diff: 
correct output grid

TRAIN 0962bcdd.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (3,3) with model Odd Checkboard with color cyan at (2,2)
  _01: rectangle with size (3,3) with model Odd Checkboard with color cyan at (8,7)
  _011: point with color pink at (3,3)
  _0111: point with color pink at (9,8)
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _0: 
0 . . . 0 
. 0 . 0 . 
. . 0 . . 
. 0 . 0 . 
0 . . . 0 
 with color pink at (1,1)
  _01: 
0 . . . 0 
. 0 . 0 . 
. . 0 . . 
. 0 . 0 . 
0 . . . 0 
 with color pink at (7,6)
  _011: rectangle with size (5,5) with model +-cross with color cyan at (1,1)
  _0111: rectangle with size (5,5) with model +-cross with color cyan at (7,6)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (3,3) with model Odd Checkboard with color cyan at (2,2)
  _01: rectangle with size (3,3) with model Odd Checkboard with color cyan at (8,7)
  _011: point with color pink at (3,3)
  _0111: point with color pink at (9,8)
diff: 
correct output grid

TRAIN 0962bcdd.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (3,3) with model Odd Checkboard with color green at (1,7)
  _01: rectangle with size (3,3) with model Odd Checkboard with color green at (6,1)
  _011: point with color yellow at (2,8)
  _0111: point with color yellow at (7,2)
diff: 
correct output grid

TEST 0962bcdd.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 16.3 sec (16.3 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-388] Checking task 0a938d79.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 326509.6 = 326511.9
DL output with Mo: L = 2.3 + 326509.6 = 326511.9
DL input+output M: L = 4.6 + 653019.1 = 653023.8

# learning a model for train pairs
2.000	
1.013	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.345	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.307	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.269	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.230	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.192	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.154	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.151	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.148	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.146	OUT SPE ^.size = ^.size
0.144	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.143	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.143	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.142	OUT SPE ^.layer_011.shape.color = majorityColor(^)
0.141	OUT SPE ^.layer_0111.shape.color = ^.layer_0.shape.color
0.141	OUT SPE ^.layer_0.shape.mask.model = Full
0.141	OUT SPE ^.layer_01.shape.mask.model = Full
0.140	OUT SPE ^.layer_011.shape.mask.model = Full
0.140	OUT SPE ^.layer_0111.shape.mask.model = Full
0.140	OUT SPE ^.layer_01111.shape.mask.model = Full
0.139	IN  SPE ^.color = black
0.139	OUT SPE ^.color = black
0.132	
0.132	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model Full with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: rectangle with size (?,?) with model Full with color ^.layer_01.shape.color at (?,?)
  _011: rectangle with size (?,?) with model Full with color majorityColor(^) at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ^.layer_0.shape.color at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.7 + 2308.1 = 2358.8
DL output with Mo: L = 171.9 + 42844.1 = 43016.0
DL input+output M: L = 222.6 + 45152.1 = 45374.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model Full with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: rectangle with size (?,?) with model Full with color ^.layer_01.shape.color at (?,?)
  _011: rectangle with size (?,?) with model Full with color majorityColor(^) at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ^.layer_0.shape.color at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.6 + 0.0 = 50.6
DL output with Mo: L = 171.9 + 42844.1 = 43016.0
DL input+output M: L = 222.5 + 42844.1 = 43066.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,25) and color black and layers
  _0: point with color red at (0,5)
  _01: point with color cyan at (9,7)
diff: 
   (0.0 bits)
data: a background with size (10,25) and color black and layers
  _0: rectangle with size (10,1) with model Full with color red at (0,5)
  _01: rectangle with size (10,1) with model Full with color cyan at (0,7)
  _011: rectangle with size (10,1) with model Full with color red at (0,9)
  _0111: rectangle with size (10,1) with model Full with color red at (0,13)
  _01111: rectangle with size (10,1) with model Full with color cyan at (0,11)
  + 50 delta pixels
diff: 
   (2176.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,25) and color black and layers
  _0: point with color red at (0,5)
  _01: point with color cyan at (9,7)
diff: 
! 104 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,25) and color black and layers
  _0: point with color cyan at (9,7)
  _01: point with color red at (0,5)
diff: 
! 104 wrong pixels (generated / expected)

TRAIN 0a938d79.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (7,23) and color black and layers
  _0: point with color blue at (0,5)
  _01: point with color green at (6,8)
diff: 
   (0.0 bits)
data: a background with size (7,23) and color black and layers
  _0: rectangle with size (7,1) with model Full with color blue at (0,5)
  _01: rectangle with size (7,1) with model Full with color green at (0,8)
  _011: rectangle with size (7,1) with model Full with color blue at (0,11)
  _0111: rectangle with size (7,1) with model Full with color blue at (0,17)
  _01111: rectangle with size (7,1) with model Full with color green at (0,14)
  + 7 delta pixels
diff: 
   (402.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,23) and color black and layers
  _0: point with color blue at (0,5)
  _01: point with color green at (6,8)
diff: 
! 46 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,23) and color black and layers
  _0: point with color green at (6,8)
  _01: point with color blue at (0,5)
diff: 
! 46 wrong pixels (generated / expected)

TRAIN 0a938d79.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (22,9) and color black and layers
  _0: point with color red at (5,0)
  _01: point with color green at (7,8)
diff: 
   (0.0 bits)
data: a background with size (22,9) and color black and layers
  _0: rectangle with size (1,9) with model Full with color red at (5,0)
  _01: rectangle with size (1,9) with model Full with color green at (7,0)
  _011: rectangle with size (1,9) with model Full with color red at (9,0)
  _0111: rectangle with size (1,9) with model Full with color red at (13,0)
  _01111: rectangle with size (1,9) with model Full with color green at (11,0)
  + 36 delta pixels
diff: 
   (1588.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (22,9) and color black and layers
  _0: point with color red at (5,0)
  _01: point with color green at (7,8)
diff: 
! 85 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (22,9) and color black and layers
  _0: point with color green at (7,8)
  _01: point with color red at (5,0)
diff: 
! 85 wrong pixels (generated / expected)

TRAIN 0a938d79.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (24,8) and color black and layers
  _0: point with color yellow at (7,0)
  _01: point with color blue at (11,0)
diff: 
   (0.0 bits)
data: a background with size (24,8) and color black and layers
  _0: rectangle with size (1,8) with model Full with color yellow at (7,0)
  _01: rectangle with size (1,8) with model Full with color blue at (11,0)
  _011: rectangle with size (1,8) with model Full with color blue at (19,0)
  _0111: rectangle with size (1,8) with model Full with color yellow at (15,0)
  _01111: rectangle with size (1,8) with model Full with color yellow at (23,0)
diff: 
   (117.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (24,8) and color black and layers
  _0: point with color yellow at (7,0)
  _01: point with color blue at (11,0)
diff: 
! 44 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (24,8) and color black and layers
  _0: point with color blue at (11,0)
  _01: point with color yellow at (7,0)
diff: 
! 44 wrong pixels (generated / expected)

TRAIN 0a938d79.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,27) and color black and layers
  _0: point with color green at (0,5)
  _01: point with color yellow at (10,10)
diff: 
! 59 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,27) and color black and layers
  _0: point with color yellow at (10,10)
  _01: point with color green at (0,5)
diff: 
! 59 wrong pixels (generated / expected)

TEST 0a938d79.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 21.0 sec (21.0 sec/task)
bits-train-error = 42844.1 bits (42844.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-387] Checking task 0b148d64.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 459516.6 = 459518.9
DL output with Mo: L = 2.3 + 86011.0 = 86013.3
DL input+output M: L = 4.6 + 545527.6 = 545532.2

# learning a model for train pairs
2.000	
1.354	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.809	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.509	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.304	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.184	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.145	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.101	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.084	OUT SPE ^.layer_0.shape = ^.layer_01.shape
0.054	IN  SPE ^.layer_0.shape.mask = tiling to size (?,?)
of grid ?
0.047	OUT SPE ^.size = ^.layer_01.shape.mask.size
0.044	OUT SPE ^.layer_0.pos = '(0, 0)
0.043	OUT SPE ^.color = black
0.010	

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_01.shape.mask.size and color black and layers
  _0: ^.layer_01.shape at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: tiling to size (?,?)
of grid ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 126.6 + 15013.8 = 15140.4
DL output with Mo: L = 51.7 + 804.4 = 856.0
DL input+output M: L = 178.3 + 15818.2 = 15996.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_01.shape.mask.size and color black and layers
  _0: ^.layer_01.shape at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: tiling to size (?,?)
of grid ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 126.6 + 31.7 = 158.3
DL output with Mo: L = 51.7 + 804.4 = 856.0
DL input+output M: L = 178.3 + 836.1 = 1014.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (21,21) and color black and layers
  _0: tiling to size (9,7)
of grid 
0 0 0 0 . 0 0 
0 0 0 . . . 0 
0 0 . 0 0 0 0 
0 0 . . . 0 0 
0 0 0 . 0 0 0 
0 . . . 0 . . 
0 0 0 . 0 0 0 
0 . 0 0 0 0 0 
0 0 0 0 0 . . 
 with color cyan at (0,14)
  _01: rectangle with size (10,10) with mask 
. 0 0 0 . . 0 0 0 0 
0 . 0 0 0 . . 0 0 0 
. 0 0 0 0 0 0 . 0 . 
0 0 0 0 . 0 0 0 0 0 
0 0 0 0 0 0 . 0 . . 
0 0 0 0 0 . 0 . 0 0 
0 0 . 0 0 . . . . . 
. 0 0 . . 0 0 . . 0 
0 0 0 0 0 0 0 0 0 0 
0 . 0 0 . 0 0 0 0 0 
 with color red at (11,0)
  _011: rectangle with size (9,10) with mask 
0 0 0 0 0 . 0 0 0 0 
0 . . 0 . 0 . 0 0 0 
0 0 0 . . . 0 0 0 0 
0 0 . 0 0 0 0 . 0 0 
0 0 0 0 . 0 0 . 0 0 
. . . 0 0 . 0 . . 0 
0 0 0 0 . . 0 . 0 . 
0 . . 0 . . 0 0 . 0 
0 0 0 0 0 0 . 0 . . 
 with color cyan at (0,0)
  _0111: rectangle with size (10,7) with mask 
0 0 . 0 0 . 0 
0 0 0 0 . 0 . 
0 0 0 . . . 0 
0 0 . 0 0 0 . 
0 0 0 0 0 . . 
0 . 0 . 0 0 0 
0 0 . 0 . . 0 
0 . . . 0 0 . 
. 0 0 . . 0 0 
0 0 0 . 0 0 0 
 with color cyan at (11,14)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
. 2 2 2 . . 2 2 2 2 
2 . 2 2 2 . . 2 2 2 
. 2 2 2 2 2 2 . 2 . 
2 2 2 2 . 2 2 2 2 2 
2 2 2 2 2 2 . 2 . . 
2 2 2 2 2 . 2 . 2 2 
2 2 . 2 2 . . . . . 
. 2 2 . . 2 2 . . 2 
2 2 2 2 2 2 2 2 2 2 
2 . 2 2 . 2 2 2 2 2 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (21,21) and color black and layers
  _0: tiling to size (9,7)
of grid 
0 0 0 0 . 0 0 
0 0 0 . . . 0 
0 0 . 0 0 0 0 
0 0 . . . 0 0 
0 0 0 . 0 0 0 
0 . . . 0 . . 
0 0 0 . 0 0 0 
0 . 0 0 0 0 0 
0 0 0 0 0 . . 
 with color cyan at (0,14)
  _01: rectangle with size (10,10) with mask 
. 0 0 0 . . 0 0 0 0 
0 . 0 0 0 . . 0 0 0 
. 0 0 0 0 0 0 . 0 . 
0 0 0 0 . 0 0 0 0 0 
0 0 0 0 0 0 . 0 . . 
0 0 0 0 0 . 0 . 0 0 
0 0 . 0 0 . . . . . 
. 0 0 . . 0 0 . . 0 
0 0 0 0 0 0 0 0 0 0 
0 . 0 0 . 0 0 0 0 0 
 with color red at (11,0)
  _011: rectangle with size (9,10) with mask 
0 0 0 0 0 . 0 0 0 0 
0 . . 0 . 0 . 0 0 0 
0 0 0 . . . 0 0 0 0 
0 0 . 0 0 0 0 . 0 0 
0 0 0 0 . 0 0 . 0 0 
. . . 0 0 . 0 . . 0 
0 0 0 0 . . 0 . 0 . 
0 . . 0 . . 0 0 . 0 
0 0 0 0 0 0 . 0 . . 
 with color cyan at (0,0)
  _0111: rectangle with size (10,7) with mask 
0 0 . 0 0 . 0 
0 0 0 0 . 0 . 
0 0 0 . . . 0 
0 0 . 0 0 0 . 
0 0 0 0 0 . . 
0 . 0 . 0 0 0 
0 0 . 0 . . 0 
0 . . . 0 0 . 
. 0 0 . . 0 0 
0 0 0 . 0 0 0 
 with color cyan at (11,14)
diff: 
correct output grid

TRAIN 0b148d64.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (18,19) and color black and layers
  _0: tiling to size (6,7)
of grid 
0 . 0 0 0 0 . 
0 0 0 0 . 0 0 
. . 0 0 . 0 . 
0 . 0 . 0 0 . 
. 0 . 0 0 0 0 
0 0 0 . 0 . 0 
 with color red at (0,0)
  _01: rectangle with size (7,9) with mask 
. 0 0 0 0 0 . 0 0 
0 0 0 . . . 0 0 . 
0 0 0 . 0 . 0 . . 
0 0 . . . 0 0 0 0 
0 . . . 0 . 0 . 0 
. 0 0 . 0 0 0 . 0 
. 0 0 . . 0 . 0 . 
 with color green at (11,10)
  _011: rectangle with size (6,9) with mask 
0 . 0 0 0 0 . . . 
. 0 0 0 0 0 . . . 
0 0 0 . 0 0 0 0 0 
. 0 0 0 0 0 0 . . 
. . . 0 0 . 0 0 0 
. . 0 0 0 0 . 0 . 
 with color red at (0,10)
  _0111: rectangle with size (7,7) with mask 
0 . 0 . . . 0 
. 0 0 . . 0 0 
. 0 0 . . 0 . 
0 0 0 . . 0 0 
0 . . 0 0 0 . 
0 . 0 . . . 0 
. 0 0 . 0 0 . 
 with color red at (11,0)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (7,9) and color black and layers
  _0: 
. 3 3 3 3 3 . 3 3 
3 3 3 . . . 3 3 . 
3 3 3 . 3 . 3 . . 
3 3 . . . 3 3 3 3 
3 . . . 3 . 3 . 3 
. 3 3 . 3 3 3 . 3 
. 3 3 . . 3 . 3 . 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,19) and color black and layers
  _0: tiling to size (6,7)
of grid 
0 . 0 0 0 0 . 
0 0 0 0 . 0 0 
. . 0 0 . 0 . 
0 . 0 . 0 0 . 
. 0 . 0 0 0 0 
0 0 0 . 0 . 0 
 with color red at (0,0)
  _01: rectangle with size (7,9) with mask 
. 0 0 0 0 0 . 0 0 
0 0 0 . . . 0 0 . 
0 0 0 . 0 . 0 . . 
0 0 . . . 0 0 0 0 
0 . . . 0 . 0 . 0 
. 0 0 . 0 0 0 . 0 
. 0 0 . . 0 . 0 . 
 with color green at (11,10)
  _011: rectangle with size (6,9) with mask 
0 . 0 0 0 0 . . . 
. 0 0 0 0 0 . . . 
0 0 0 . 0 0 0 0 0 
. 0 0 0 0 0 0 . . 
. . . 0 0 . 0 0 0 
. . 0 0 0 0 . 0 . 
 with color red at (0,10)
  _0111: rectangle with size (7,7) with mask 
0 . 0 . . . 0 
. 0 0 . . 0 0 
. 0 0 . . 0 . 
0 0 0 . . 0 0 
0 . . 0 0 0 . 
0 . 0 . . . 0 
. 0 0 . 0 0 . 
 with color red at (11,0)
  + 2 delta pixels
diff: 
correct output grid

TRAIN 0b148d64.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (19,17) and color black and layers
  _0: tiling to size (7,9)
of grid 
0 0 . 0 . . . . . 
0 0 0 0 0 0 . 0 0 
0 0 0 0 0 0 . 0 0 
0 0 . 0 0 0 0 0 0 
0 0 . . . 0 0 0 . 
0 0 . . 0 0 0 0 0 
0 0 0 . . 0 . . 0 
 with color blue at (0,8)
  _01: rectangle with size (9,6) with mask 
0 . . 0 . 0 
0 0 0 0 . 0 
0 . 0 . . 0 
. 0 0 0 0 . 
0 0 0 . 0 0 
. 0 0 0 0 . 
. 0 0 0 . 0 
. 0 . . . . 
0 0 . . . . 
 with color yellow at (10,0)
  _011: rectangle with size (9,9) with mask 
0 . . 0 0 0 0 0 0 
0 . 0 0 0 0 0 0 . 
. 0 . . 0 0 0 0 0 
0 0 . . 0 . 0 . 0 
0 0 0 0 0 0 0 0 . 
. 0 . . . . 0 0 0 
. 0 . 0 . 0 0 0 . 
0 . 0 0 0 . 0 . 0 
0 0 0 . . 0 0 0 . 
 with color blue at (10,8)
  _0111: rectangle with size (7,6) with mask 
. 0 . 0 0 0 
0 . 0 . . . 
0 0 . 0 0 . 
0 0 . . 0 0 
. 0 0 0 . . 
0 . . 0 . . 
. . . 0 0 . 
 with color blue at (0,0)
  + 2 delta pixels
diff: 
   (3.2 bits)
data: a background with size (9,6) and color black and layers
  _0: 
4 . . 4 . 4 
4 4 4 4 . 4 
4 . 4 . . 4 
. 4 4 4 4 . 
4 4 4 . 4 4 
. 4 4 4 4 . 
. 4 4 4 . 4 
. 4 . . . . 
4 4 . . . . 
 at (0,0)
  + 2 delta pixels
diff: 
   (80.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,17) and color black and layers
  _0: tiling to size (7,9)
of grid 
0 0 . 0 . . . . . 
0 0 0 0 0 0 . 0 0 
0 0 0 0 0 0 . 0 0 
0 0 . 0 0 0 0 0 0 
0 0 . . . 0 0 0 . 
0 0 . . 0 0 0 0 0 
0 0 0 . . 0 . . 0 
 with color blue at (0,8)
  _01: rectangle with size (9,9) with mask 
0 . . 0 0 0 0 0 0 
0 . 0 0 0 0 0 0 . 
. 0 . . 0 0 0 0 0 
0 0 . . 0 . 0 . 0 
0 0 0 0 0 0 0 0 . 
. 0 . . . . 0 0 0 
. 0 . 0 . 0 0 0 . 
0 . 0 0 0 . 0 . 0 
0 0 0 . . 0 0 0 . 
 with color blue at (10,8)
  _011: rectangle with size (9,6) with mask 
0 . . 0 . 0 
0 0 0 0 . 0 
0 . 0 . . 0 
. 0 0 0 0 . 
0 0 0 . 0 0 
. 0 0 0 0 . 
. 0 0 0 . 0 
. 0 . . . . 
0 0 . . . . 
 with color yellow at (10,0)
  _0111: rectangle with size (7,6) with mask 
. 0 . 0 0 0 
0 . 0 . . . 
0 0 . 0 0 . 
0 0 . . 0 0 
. 0 0 0 . . 
0 . . 0 . . 
. . . 0 0 . 
 with color blue at (0,0)
  + 2 delta pixels
diff: 
! size mismatch, 9x9 instead of 9x6
>> Trial 2
data: a background with size (19,17) and color black and layers
  _0: tiling to size (7,9)
of grid 
0 0 . 0 . . . . . 
0 0 0 0 0 0 . 0 0 
0 0 0 0 0 0 . 0 0 
0 0 . 0 0 0 0 0 0 
0 0 . . . 0 0 0 . 
0 0 . . 0 0 0 0 0 
0 0 0 . . 0 . . 0 
 with color blue at (0,8)
  _01: rectangle with size (9,6) with mask 
0 . . 0 . 0 
0 0 0 0 . 0 
0 . 0 . . 0 
. 0 0 0 0 . 
0 0 0 . 0 0 
. 0 0 0 0 . 
. 0 0 0 . 0 
. 0 . . . . 
0 0 . . . . 
 with color yellow at (10,0)
  _011: rectangle with size (9,9) with mask 
0 . . 0 0 0 0 0 0 
0 . 0 0 0 0 0 0 . 
. 0 . . 0 0 0 0 0 
0 0 . . 0 . 0 . 0 
0 0 0 0 0 0 0 0 . 
. 0 . . . . 0 0 0 
. 0 . 0 . 0 0 0 . 
0 . 0 0 0 . 0 . 0 
0 0 0 . . 0 0 0 . 
 with color blue at (10,8)
  _0111: rectangle with size (7,6) with mask 
. 0 . 0 0 0 
0 . 0 . . . 
0 0 . 0 0 . 
0 0 . . 0 0 
. 0 0 0 . . 
0 . . 0 . . 
. . . 0 0 . 
 with color blue at (0,0)
  + 2 delta pixels
diff: 
! 2 wrong pixels (generated / expected)

TRAIN 0b148d64.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,17) and color black and layers
  _0: tiling to size (6,6)
of grid 
0 0 0 0 . 0 
0 . 0 . 0 0 
0 0 . 0 0 . 
. . . 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
 with color blue at (0,0)
  _01: rectangle with size (6,9) with mask 
0 . 0 0 0 0 0 0 . 
. 0 . 0 0 0 . . . 
. . . 0 0 0 0 . . 
. . . 0 0 . 0 . . 
. . . 0 0 0 . 0 0 
. . . . . 0 . . 0 
 with color green at (0,8)
  _011: rectangle with size (5,9) with mask 
0 0 0 . 0 . 0 . . 
. 0 . 0 0 0 . . . 
0 . . . 0 . . . 0 
. 0 0 0 0 0 0 . 0 
. . 0 0 0 . 0 0 . 
 with color green at (10,8)
  _0111: rectangle with size (5,6) with mask 
0 . . . . 0 
. 0 0 . . 0 
0 0 0 0 0 . 
0 . 0 . 0 . 
. 0 0 . . . 
 with color green at (10,0)
  + 6 delta pixels
diff: 
! size mismatch, 6x9 instead of 6x6
>> Trial 2
data: a background with size (15,17) and color black and layers
  _0: tiling to size (6,6)
of grid 
0 0 0 0 . 0 
0 . 0 . 0 0 
0 0 . 0 0 . 
. . . 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
 with color blue at (0,0)
  _01: rectangle with size (5,9) with mask 
0 0 0 . 0 . 0 . . 
. 0 . 0 0 0 . . . 
0 . . . 0 . . . 0 
. 0 0 0 0 0 0 . 0 
. . 0 0 0 . 0 0 . 
 with color green at (10,8)
  _011: rectangle with size (6,9) with mask 
0 . 0 0 0 0 0 0 . 
. 0 . 0 0 0 . . . 
. . . 0 0 0 0 . . 
. . . 0 0 . 0 . . 
. . . 0 0 0 . 0 0 
. . . . . 0 . . 0 
 with color green at (0,8)
  _0111: rectangle with size (5,6) with mask 
0 . . . . 0 
. 0 0 . . 0 
0 0 0 0 0 . 
0 . 0 . 0 . 
. 0 0 . . . 
 with color green at (10,0)
  + 6 delta pixels
diff: 
! size mismatch, 5x9 instead of 6x6

TEST 0b148d64.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 42.8 sec (42.8 sec/task)
bits-train-error = 804.4 bits (804.4 bits/task)
acc-train-micro = 0.67 tasks (66.67%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.67
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-386] Checking task 0ca9ddb6.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 96473.4 = 96475.7
DL output with Mo: L = 2.3 + 96473.4 = 96475.7
DL input+output M: L = 4.6 + 192946.8 = 192951.5

# learning a model for train pairs
2.000	
1.049	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.229	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.191	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.176	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.169	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.157	OUT ADD ^.layer_00 = ^.layer_0
0.150	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.137	OUT ADD ^.layer_011 = ^.layer_01
0.130	OUT ADD ^.layer_0110 = point with color ? at (?,?)
0.123	OUT ADD ^.layer_010 = point with color ? at (?,?)
0.116	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.110	OUT SPE ^.size = ^.size
0.104	OUT SPE ^.layer_0.shape.mask = 
. 0 . 
0 . 0 
. 0 . 

0.101	OUT SPE ^.layer_010.pos = ^.layer_0.pos - (1, 1)
0.099	IN  SPE ^.layer_0.shape.color = red
0.096	OUT SPE ^.layer_0.pos = ^.layer_01.pos - (1, 1)
0.093	OUT SPE ^.layer_0111.pos = ^.layer_01.pos - translationOnto(^.layer_0, ^.layer_01)
0.091	IN  SPE ^.layer_01.shape.color = blue
0.089	OUT SPE ^.layer_0.shape.color = orange
0.088	OUT SPE ^.layer_010.shape.color = yellow
0.086	OUT SPE ^.layer_0111.shape.color = yellow
0.084	OUT SPE ^.layer_0110.shape.color = yellow
0.083	OUT SPE ^.layer_0110.pos.j = center(^.layer_0)
0.081	OUT SPE ^.layer_01.pos.j = ^.layer_0.pos.j - 1
0.080	OUT SPE ^.layer_0110.pos.i = ^.layer_0.pos.i - 1
0.079	IN  SPE ^.color = black
0.049	
0.049	IN  GEN ^.color = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _00: ^.layer_0
  _0: 
. 0 . 
0 . 0 
. 0 . 
 with color orange at ^.layer_01.pos - (1, 1)
  _010: point with color yellow at ^.layer_0.pos - (1, 1)
  _01: rectangle with size (?,?) with model ? with color ? at (?,^.layer_0.pos.j - 1)
  _0110: point with color yellow at (^.layer_0.pos.i - 1,center(^.layer_0))
  _011: ^.layer_01
  _0111: point with color yellow at ^.layer_01.pos - translationOnto(^.layer_0, ^.layer_01)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color red at (?,?)
  _01: point with color blue at (?,?)

DL input  with Mi: L = 57.4 + 2867.4 = 2924.8
DL output with Mo: L = 266.2 + 4406.3 = 4672.4
DL input+output M: L = 323.5 + 7273.7 = 7597.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _00: ^.layer_0
  _0: 
. 0 . 
0 . 0 
. 0 . 
 with color orange at ^.layer_01.pos - (1, 1)
  _010: point with color yellow at ^.layer_0.pos - (1, 1)
  _01: rectangle with size (?,?) with model ? with color ? at (?,^.layer_0.pos.j - 1)
  _0110: point with color yellow at (^.layer_0.pos.i - 1,center(^.layer_0))
  _011: ^.layer_01
  _0111: point with color yellow at ^.layer_01.pos - translationOnto(^.layer_0, ^.layer_01)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color red at (?,?)
  _01: point with color blue at (?,?)

DL input  with Mi: L = 57.2 + 0.0 = 57.2
DL output with Mo: L = 266.2 + 4406.3 = 4672.4
DL input+output M: L = 323.4 + 4406.3 = 4729.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: point with color red at (3,2)
  _01: point with color blue at (6,6)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _00: 
2 
 at (3,2)
  _0: 
. 0 . 
0 . 0 
. 0 . 
 with color orange at (5,5)
  _010: point with color yellow at (2,1)
  _01: rectangle with size (1,1) with model Full with color yellow at (4,1)
  _0110: point with color yellow at (2,3)
  _011: 
1 
 at (6,6)
  _0111: point with color yellow at (4,3)
diff: 
   (23.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color red at (3,2)
  _01: point with color blue at (6,6)
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: point with color blue at (6,6)
  _01: point with color red at (3,2)
diff:   ^.layer_01.shape.color  ^.layer_0.shape.color
! 18 wrong pixels (generated / expected)

TRAIN 0ca9ddb6.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: point with color red at (2,6)
  _01: point with color blue at (3,2)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _00: 
2 
 at (2,6)
  _0: 
. 0 . 
0 . 0 
. 0 . 
 with color orange at (2,1)
  _010: point with color yellow at (1,5)
  _01: rectangle with size (3,3) with model Odd Checkboard with color orange at (5,5)
  _0110: point with color yellow at (1,7)
  _011: 
1 
 at (3,2)
  _0111: point with color yellow at (3,5)
  + 8 delta pixels
diff: 
   (353.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color red at (2,6)
  _01: point with color blue at (3,2)
  + 3 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: point with color red at (2,6)
  _01: point with color blue at (6,6)
  + 3 delta pixels
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,9) and color black and layers
  _0: point with color red at (7,1)
  _01: point with color blue at (3,2)
  + 3 delta pixels
diff: 
! 17 wrong pixels (generated / expected)

TRAIN 0ca9ddb6.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: point with color red at (2,2)
  _01: point with color blue at (7,3)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _00: 
2 
 at (2,2)
  _0: 
. 0 . 
0 . 0 
. 0 . 
 with color orange at (6,2)
  _010: point with color yellow at (1,1)
  _01: rectangle with size (1,1) with model Full with color yellow at (3,1)
  _0110: point with color yellow at (1,3)
  _011: 
1 
 at (7,3)
  _0111: point with color yellow at (3,3)
  + 1 delta pixels
diff: 
   (64.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color red at (2,2)
  _01: point with color blue at (7,3)
  + 1 delta pixels
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: point with color red at (2,2)
  _01: point with color pink at (5,6)
  + 1 delta pixels
diff:   ^.layer_01.shape.color
! 13 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,9) and color black and layers
  _0: point with color pink at (5,6)
  _01: point with color blue at (7,3)
  + 1 delta pixels
diff:   ^.layer_0.shape.color
! 12 wrong pixels (generated / expected)

TRAIN 0ca9ddb6.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color red at (3,2)
  _01: point with color blue at (2,6)
  + 3 delta pixels
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: point with color red at (7,7)
  _01: point with color blue at (2,6)
  + 3 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,9) and color black and layers
  _0: point with color red at (3,2)
  _01: point with color cyan at (5,5)
  + 3 delta pixels
diff:   ^.layer_01.shape.color
! 20 wrong pixels (generated / expected)

TEST 0ca9ddb6.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.3 sec (59.3 sec/task)
bits-train-error = 4406.3 bits (4406.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-385] Checking task 0d3d703e.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 14046.4 = 14048.7
DL output with Mo: L = 2.3 + 14046.4 = 14048.7
DL input+output M: L = 4.6 + 28092.8 = 28097.5

# learning a model for train pairs
2.000	
1.695	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.390	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.154	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.911	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.675	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.432	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.395	OUT SPE ^.size = ^.size
0.358	OUT SPE ^.layer_01.shape.mask = ^.layer_01.shape.mask
0.322	OUT SPE ^.layer_0.shape.mask = ^.layer_0.shape.mask
0.285	IN  SPE ^.layer_0.shape.mask = 
0 
0 
0 

0.249	IN  SPE ^.layer_01.shape.mask = 
0 
0 
0 

0.227	OUT SPE ^.layer_01.pos = ^.layer_01.pos
0.204	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.065	

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: ^.layer_0.shape.mask with color ? at ^.layer_0.pos
  _01: ^.layer_01.shape.mask with color ? at ^.layer_01.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 
0 
0 
 with color ? at (?,?)
  _01: 
0 
0 
0 
 with color ? at (?,?)

DL input  with Mi: L = 62.3 + 1953.4 = 2015.7
DL output with Mo: L = 41.8 + 809.0 = 850.7
DL input+output M: L = 104.1 + 2762.4 = 2866.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: ^.layer_0.shape.mask with color ? at ^.layer_0.pos
  _01: ^.layer_01.shape.mask with color ? at ^.layer_01.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 
0 
0 
 with color ? at (?,?)
  _01: 
0 
0 
0 
 with color ? at (?,?)

DL input  with Mi: L = 62.3 + 0.0 = 62.3
DL output with Mo: L = 41.8 + 809.0 = 850.7
DL input+output M: L = 104.1 + 809.0 = 913.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color blue and layers
  _0: 
0 
0 
0 
 with color green at (0,0)
  _01: 
0 
0 
0 
 with color red at (0,2)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color grey and layers
  _0: 
0 
0 
0 
 with color yellow at (0,0)
  _01: 
0 
0 
0 
 with color pink at (0,2)
diff: 
   (20.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color blue and layers
  _0: 
0 
0 
0 
 with color green at (0,0)
  _01: 
0 
0 
0 
 with color red at (0,2)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color red and layers
  _0: 
0 
0 
0 
 with color green at (0,0)
  _01: 
0 
0 
0 
 with color blue at (0,1)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 0d3d703e.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,3) and color red and layers
  _0: 
0 
0 
0 
 with color green at (0,1)
  _01: 
0 
0 
0 
 with color cyan at (0,2)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color pink and layers
  _0: 
0 
0 
0 
 with color yellow at (0,1)
  _01: 
0 
0 
0 
 with color brown at (0,2)
diff: 
   (20.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color red and layers
  _0: 
0 
0 
0 
 with color green at (0,1)
  _01: 
0 
0 
0 
 with color cyan at (0,2)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color green and layers
  _0: 
0 
0 
0 
 with color red at (0,0)
  _01: 
0 
0 
0 
 with color cyan at (0,2)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 0d3d703e.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,3) and color grey and layers
  _0: 
0 
0 
0 
 with color cyan at (0,1)
  _01: 
0 
0 
0 
 with color pink at (0,2)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color blue and layers
  _0: 
0 
0 
0 
 with color brown at (0,1)
  _01: 
0 
0 
0 
 with color red at (0,2)
diff: 
   (20.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color grey and layers
  _0: 
0 
0 
0 
 with color cyan at (0,1)
  _01: 
0 
0 
0 
 with color pink at (0,2)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color pink and layers
  _0: 
0 
0 
0 
 with color grey at (0,0)
  _01: 
0 
0 
0 
 with color cyan at (0,1)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 0d3d703e.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (3,3) and color red and layers
  _0: 
0 
0 
0 
 with color brown at (0,0)
  _01: 
0 
0 
0 
 with color yellow at (0,1)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color pink and layers
  _0: 
0 
0 
0 
 with color cyan at (0,0)
  _01: 
0 
0 
0 
 with color green at (0,1)
diff: 
   (20.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color red and layers
  _0: 
0 
0 
0 
 with color brown at (0,0)
  _01: 
0 
0 
0 
 with color yellow at (0,1)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color yellow and layers
  _0: 
0 
0 
0 
 with color brown at (0,0)
  _01: 
0 
0 
0 
 with color red at (0,2)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 0d3d703e.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color blue and layers
  _0: 
0 
0 
0 
 with color cyan at (0,0)
  _01: 
0 
0 
0 
 with color green at (0,2)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color green and layers
  _0: 
0 
0 
0 
 with color cyan at (0,0)
  _01: 
0 
0 
0 
 with color blue at (0,1)
diff: 
! 9 wrong pixels (generated / expected)

TEST 0d3d703e.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 6.9 sec (6.9 sec/task)
bits-train-error = 809.0 bits (809.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-384] Checking task 0dfd9992.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 552662.4 = 552664.8
DL output with Mo: L = 2.3 + 552662.4 = 552664.8
DL input+output M: L = 4.6 + 1105324.9 = 1105329.5

# learning a model for train pairs
2.000	
1.781	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.586	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.805	OUT SPE ^ = fillResizeAlike(black, ^.size, ^)
0.761	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.723	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.698	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.681	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.662	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.643	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.625	IN  ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.621	IN  ADD ^.layer_01111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.610	IN  SPE ^.layer_01.shape.color = black
0.610	IN  SPE ^.layer_01111111.shape.mask.model = Full
0.609	IN  SPE ^.layer_0.shape.color = black
0.609	IN  SPE ^.layer_011.shape.mask.model = Full
0.609	IN  SPE ^.layer_0111.shape.mask.model = Full
0.609	IN  SPE ^.layer_01111.shape.mask.model = Full
0.609	IN  SPE ^.layer_0111111.shape.mask.model = Full
0.609	IN  SPE ^.layer_01.shape.mask.model = Full
0.000	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
fillResizeAlike(black, ^.size, ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color black at (?,?)
  _01: rectangle with size (?,?) with model Full with color black at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 245.7 + 336073.9 = 336319.6
DL output with Mo: L = 20.8 + 0.0 = 20.8
DL input+output M: L = 266.6 + 336073.9 = 336340.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
fillResizeAlike(black, ^.size, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 20.8 + 0.0 = 20.8
DL input+output M: L = 23.2 + 0.0 = 23.2

# train input/output grids

## instance 1

> Input and output best reading:

data: 
3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#
6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 
5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 
6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 
3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#0 0 0 0 0 5#
2 5#4 5#2 1 2 5#0 0 2 1 2 5#4 0 0 0 0 0 4 
3 6 5#6 3 2 3 0 0 0 0 2 3 6 5#0 0 0 0 0 5#
6 3 2 3 6 5#6 0 0 0 0 5#6 3 2 3 6 5#6 3 2 
5#2 1 2 5#4 5#0 0 0 0 4 5#2 1 2 5#4 5#2 1 
6 3 2 3 6 5#6 3 0 0 6 5#6 3 2 3 6 5#6 3 2 
3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#
2 5#4 0 0 1 2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 
3 6 5#0 0 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#
6 3 2 0 0 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 
5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 
6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 
3 6 5#6 0 0 0 6 5#6 3 2 3 6 5#6 3 2 3 6 5#
2 5#4 5#0 0 0 5#4 5#2 1 2 5#4 5#2 1 2 5#4 
3 6 5#6 0 0 0 6 5#6 3 2 3 6 5#6 3 2 3 6 5#
6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 
5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 

diff: 
   (0.0 bits)
data: 
3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#
6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 
5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 
6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 
3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#
2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 
3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#
6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 
5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 
6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 
3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#
2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 
3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#
6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 
5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 
6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 
3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#
2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 
3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#
6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 
5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#
6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 
5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 
6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 
3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#0 0 0 0 0 5#
2 5#4 5#2 1 2 5#0 0 2 1 2 5#4 0 0 0 0 0 4 
3 6 5#6 3 2 3 0 0 0 0 2 3 6 5#0 0 0 0 0 5#
6 3 2 3 6 5#6 0 0 0 0 5#6 3 2 3 6 5#6 3 2 
5#2 1 2 5#4 5#0 0 0 0 4 5#2 1 2 5#4 5#2 1 
6 3 2 3 6 5#6 3 0 0 6 5#6 3 2 3 6 5#6 3 2 
3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#
2 5#4 0 0 1 2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 
3 6 5#0 0 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#
6 3 2 0 0 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 
5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 
6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 
3 6 5#6 0 0 0 6 5#6 3 2 3 6 5#6 3 2 3 6 5#
2 5#4 5#0 0 0 5#4 5#2 1 2 5#4 5#2 1 2 5#4 
3 6 5#6 0 0 0 6 5#6 3 2 3 6 5#6 3 2 3 6 5#
6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 3 6 5#6 3 2 
5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 2 5#4 5#2 1 

diff: 
correct output grid

TRAIN 0dfd9992.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
2 7#7#2 6 5#6 2 7#7#2 6 5#6 2 7#7#2 6 5#6 
7#5#5#7#4 3 4 7#5#5#7#4 3 4 7#5#5#7#4 3 4 
7#5#5#7#4 3 4 7#5#5#7#4 3 4 7#5#5#7#4 3 4 
2 7#7#2 0 0 0 0 0 7#2 6 5#6 2 7#0 0 6 5#6 
6 4 4 6 0 0 0 0 0 4 6 3 2 3 6 4 0 0 3 2 3 
5#3 3 5#0 0 0 0 0 3 5#2 1 2 5#3 0 0 2 1 2 
6 4 4 6 0 0 0 0 0 4 6 3 2 3 6 4 0 0 0 0 3 
2 7#7#2 6 5#6 2 7#7#2 6 5#6 2 7#7#0 0 0 6 
0 0 0 0 0 3 4 7#5#5#7#4 3 4 7#5#5#0 0 0 4 
0 0 0 0 0 3 4 7#5#5#7#4 3 4 7#5#5#0 0 0 4 
0 0 0 0 0 5#6 2 7#7#2 6 5#6 2 7#7#2 6 5#6 
6 4 4 6 3 2 3 6 4 4 6 3 2 3 6 4 4 6 3 2 3 
5#3 3 5#2 1 2 5#3 3 5#2 1 2 5#3 3 5#2 1 2 
6 4 4 6 3 2 3 6 4 4 6 3 2 3 6 4 0 0 3 2 3 
2 7#7#2 6 5#6 2 7#7#2 6 5#6 2 7#0 0 6 5#6 
7#5#5#7#4 3 4 7#5#5#7#4 3 4 7#5#0 0 4 3 4 
7#5#5#7#4 3 4 7#5#5#7#4 3 4 7#5#5#7#4 3 4 
2 7#7#2 6 5#6 2 7#7#2 6 5#6 2 7#7#2 6 5#6 
6 4 4 6 3 2 3 6 4 4 6 3 2 3 6 4 4 6 3 2 3 
5#3 3 5#2 1 2 5#3 3 5#2 1 2 5#3 3 5#2 1 2 
6 4 4 6 3 2 3 6 4 4 6 3 2 3 6 4 4 6 3 2 3 

diff: 
   (0.0 bits)
data: 
2 7#7#2 6 5#6 2 7#7#2 6 5#6 2 7#7#2 6 5#6 
7#5#5#7#4 3 4 7#5#5#7#4 3 4 7#5#5#7#4 3 4 
7#5#5#7#4 3 4 7#5#5#7#4 3 4 7#5#5#7#4 3 4 
2 7#7#2 6 5#6 2 7#7#2 6 5#6 2 7#7#2 6 5#6 
6 4 4 6 3 2 3 6 4 4 6 3 2 3 6 4 4 6 3 2 3 
5#3 3 5#2 1 2 5#3 3 5#2 1 2 5#3 3 5#2 1 2 
6 4 4 6 3 2 3 6 4 4 6 3 2 3 6 4 4 6 3 2 3 
2 7#7#2 6 5#6 2 7#7#2 6 5#6 2 7#7#2 6 5#6 
7#5#5#7#4 3 4 7#5#5#7#4 3 4 7#5#5#7#4 3 4 
7#5#5#7#4 3 4 7#5#5#7#4 3 4 7#5#5#7#4 3 4 
2 7#7#2 6 5#6 2 7#7#2 6 5#6 2 7#7#2 6 5#6 
6 4 4 6 3 2 3 6 4 4 6 3 2 3 6 4 4 6 3 2 3 
5#3 3 5#2 1 2 5#3 3 5#2 1 2 5#3 3 5#2 1 2 
6 4 4 6 3 2 3 6 4 4 6 3 2 3 6 4 4 6 3 2 3 
2 7#7#2 6 5#6 2 7#7#2 6 5#6 2 7#7#2 6 5#6 
7#5#5#7#4 3 4 7#5#5#7#4 3 4 7#5#5#7#4 3 4 
7#5#5#7#4 3 4 7#5#5#7#4 3 4 7#5#5#7#4 3 4 
2 7#7#2 6 5#6 2 7#7#2 6 5#6 2 7#7#2 6 5#6 
6 4 4 6 3 2 3 6 4 4 6 3 2 3 6 4 4 6 3 2 3 
5#3 3 5#2 1 2 5#3 3 5#2 1 2 5#3 3 5#2 1 2 
6 4 4 6 3 2 3 6 4 4 6 3 2 3 6 4 4 6 3 2 3 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 7#7#2 6 5#6 2 7#7#2 6 5#6 2 7#7#2 6 5#6 
7#5#5#7#4 3 4 7#5#5#7#4 3 4 7#5#5#7#4 3 4 
7#5#5#7#4 3 4 7#5#5#7#4 3 4 7#5#5#7#4 3 4 
2 7#7#2 0 0 0 0 0 7#2 6 5#6 2 7#0 0 6 5#6 
6 4 4 6 0 0 0 0 0 4 6 3 2 3 6 4 0 0 3 2 3 
5#3 3 5#0 0 0 0 0 3 5#2 1 2 5#3 0 0 2 1 2 
6 4 4 6 0 0 0 0 0 4 6 3 2 3 6 4 0 0 0 0 3 
2 7#7#2 6 5#6 2 7#7#2 6 5#6 2 7#7#0 0 0 6 
0 0 0 0 0 3 4 7#5#5#7#4 3 4 7#5#5#0 0 0 4 
0 0 0 0 0 3 4 7#5#5#7#4 3 4 7#5#5#0 0 0 4 
0 0 0 0 0 5#6 2 7#7#2 6 5#6 2 7#7#2 6 5#6 
6 4 4 6 3 2 3 6 4 4 6 3 2 3 6 4 4 6 3 2 3 
5#3 3 5#2 1 2 5#3 3 5#2 1 2 5#3 3 5#2 1 2 
6 4 4 6 3 2 3 6 4 4 6 3 2 3 6 4 0 0 3 2 3 
2 7#7#2 6 5#6 2 7#7#2 6 5#6 2 7#0 0 6 5#6 
7#5#5#7#4 3 4 7#5#5#7#4 3 4 7#5#0 0 4 3 4 
7#5#5#7#4 3 4 7#5#5#7#4 3 4 7#5#5#7#4 3 4 
2 7#7#2 6 5#6 2 7#7#2 6 5#6 2 7#7#2 6 5#6 
6 4 4 6 3 2 3 6 4 4 6 3 2 3 6 4 4 6 3 2 3 
5#3 3 5#2 1 2 5#3 3 5#2 1 2 5#3 3 5#2 1 2 
6 4 4 6 3 2 3 6 4 4 6 3 2 3 6 4 4 6 3 2 3 

diff: 
correct output grid

TRAIN 0dfd9992.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 
0 0 0 0 0 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
0 0 0 0 0 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 0 0 0 2 3 6 3 
2 1 2 5#0 0 0 0 2 0 0 0 2 1 0 0 0 1 2 5#2 
3 2 3 6 0 0 0 0 3 0 0 0 3 2 3 6 3 2 3 6 3 
6 5#6 1 0 0 0 0 6 0 0 0 6 5#6 1 6 5#6 1 6 
3 2 3 6 0 0 0 0 3 0 0 0 3 2 3 6 3 2 3 6 3 
2 1 2 5#0 0 0 0 2 1 2 5#2 1 2 5#2 1 2 5#2 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 
3 0 0 0 0 0 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
6 0 0 0 0 0 6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 
3 0 0 0 0 0 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
2 0 0 0 0 0 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 
3 0 0 0 0 0 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 

diff: 
   (0.0 bits)
data: 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 
0 0 0 0 0 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
0 0 0 0 0 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 0 0 0 2 3 6 3 
2 1 2 5#0 0 0 0 2 0 0 0 2 1 0 0 0 1 2 5#2 
3 2 3 6 0 0 0 0 3 0 0 0 3 2 3 6 3 2 3 6 3 
6 5#6 1 0 0 0 0 6 0 0 0 6 5#6 1 6 5#6 1 6 
3 2 3 6 0 0 0 0 3 0 0 0 3 2 3 6 3 2 3 6 3 
2 1 2 5#0 0 0 0 2 1 2 5#2 1 2 5#2 1 2 5#2 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 
3 0 0 0 0 0 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
6 0 0 0 0 0 6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 
3 0 0 0 0 0 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
2 0 0 0 0 0 2 5#2 1 2 5#2 1 2 5#2 1 2 5#2 
3 0 0 0 0 0 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 
6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 5#6 1 6 
3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 2 3 6 3 

diff: 
correct output grid

TRAIN 0dfd9992.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
9#6 5#6 9#5#3 3 5#9#6 5#6 9#5#3 3 5#9#6 5#
6 3 2 3 6 2 9#9#2 0 0 0 0 0 2 9#9#2 6 3 2 
5#2 1 2 5#1 8 8 1 0 0 0 0 0 1 8 8 1 5#2 1 
6 3 2 3 6 2 9#9#2 0 0 0 0 0 2 9#9#2 6 3 2 
9#6 5#6 9#5#3 3 5#9#6 5#6 9#5#3 3 5#9#6 5#
5#2 1 2 5#1 8 8 1 5#2 1 2 5#1 8 8 1 5#2 1 
3 9#8 9#3 8 6 6 8 3 9#8 9#3 8 6 6 8 3 9#8 
3 9#8 9#3 8 6 6 8 3 9#8 9#3 8 6 6 8 3 9#8 
5#2 1 2 0 0 0 0 1 5#2 1 2 5#1 8 8 1 5#2 1 
9#6 5#6 0 0 0 0 5#9#6 5#6 9#5#3 3 5#9#6 5#
6 3 2 3 0 0 0 0 2 6 3 2 3 6 2 9#9#2 6 3 2 
5#2 1 2 5#1 8 8 1 5#2 1 2 5#1 8 8 1 5#2 1 
6 3 2 3 6 2 9#9#2 6 3 2 3 6 0 0 9#2 6 3 2 
9#6 5#6 9#5#3 3 5#9#6 5#6 9#0 0 3 5#9#6 5#
5#2 1 2 5#1 8 8 1 5#2 1 2 5#0 0 8 1 5#2 1 
0 0 8 9#0 0 0 6 8 3 9#8 9#3 0 0 6 8 3 9#8 
0 0 8 9#0 0 0 6 8 3 9#8 9#3 8 6 6 8 3 9#8 
5#2 1 2 0 0 0 8 1 5#2 1 2 5#1 8 8 1 5#2 1 
9#6 5#6 0 0 0 3 5#9#6 5#6 9#5#3 3 5#9#6 5#
6 3 2 3 0 0 0 9#2 6 3 2 3 6 2 9#9#2 6 3 2 
5#2 1 2 5#1 8 8 1 5#2 1 2 5#1 8 8 1 5#2 1 

diff: 
correct output grid

TEST 0dfd9992.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 17.5 sec (17.5 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-383] Checking task 0e206a2e.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 280686.4 = 280688.8
DL output with Mo: L = 2.3 + 280686.4 = 280688.8
DL input+output M: L = 4.6 + 561372.9 = 561377.5

# learning a model for train pairs
2.000	
1.056	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.129	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.105	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.081	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.076	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.071	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.068	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.066	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.063	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.061	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.058	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.056	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.053	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.051	OUT SPE ^.size = ^.size
0.049	OUT SPE ^.layer_0111 = ^.layer_01111
0.047	OUT SPE ^.layer_01.shape = applySym(flipDiag1, ^.layer_01.shape)
0.045	OUT SPE ^.layer_011 = ^.layer_011111
0.044	OUT SPE ^.layer_0.shape.mask.size.i = 3
0.044	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.043	OUT SPE ^.layer_01.pos.i = center(^.layer_011) + area(^.layer_0.shape)
0.043	OUT SPE ^.layer_01.pos.j = center(^.layer_0111111) - ^.layer_01.shape.mask.size.j
0.042	OUT SPE ^.layer_0.pos.i = middle(^.layer_01111) - ^.layer_011.pos.i - ^.layer_01.pos.i
0.042	IN  SPE ^.color = black
0.042	OUT SPE ^.color = black
0.011	
0.011	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (3,?) with model ? with color ^.layer_0.shape.color at (middle(^.layer_01111) - ^.layer_011.pos.i - ^.layer_01.pos.i,?)
  _01: applySym(flipDiag1, ^.layer_01.shape) at (center(^.layer_011) + area(^.layer_0.shape),center(^.layer_0111111) - ^.layer_01.shape.mask.size.j)
  _011: ^.layer_011111
  _0111: ^.layer_01111
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)

DL input  with Mi: L = 159.4 + 8748.2 = 8907.6
DL output with Mo: L = 245.4 + 2571.2 = 2816.6
DL input+output M: L = 404.8 + 11319.4 = 11724.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (3,?) with model ? with color ^.layer_0.shape.color at (middle(^.layer_01111) - ^.layer_011.pos.i - ^.layer_01.pos.i,?)
  _01: applySym(flipDiag1, ^.layer_01.shape) at (center(^.layer_011) + area(^.layer_0.shape),center(^.layer_0111111) - ^.layer_01.shape.mask.size.j)
  _011: ^.layer_011111
  _0111: ^.layer_01111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)

DL input  with Mi: L = 159.3 + 31.7 = 191.0
DL output with Mo: L = 245.4 + 2571.2 = 2816.6
DL input+output M: L = 404.7 + 2602.9 = 3007.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (14,18) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 . 
0 . 0 
 with color cyan at (7,7)
  _01: rectangle with size (3,3) with mask 
. 0 . 
. 0 . 
0 . 0 
 with color cyan at (1,2)
  _011: point with color green at (2,2)
  _0111: point with color blue at (2,4)
  _01111: point with color yellow at (2,15)
  _011111: point with color green at (4,13)
  _0111111: point with color yellow at (3,3)
  + 7 delta pixels
diff: 
   (3.2 bits)
data: a background with size (14,18) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
. 0 . 
0 0 0 
 with color cyan at (2,14)
  _01: 
. . 8 
8 8 . 
. . 8 
 at (9,1)
  _011: 
3 
 at (4,13)
  _0111: 
4 
 at (2,15)
  + 4 delta pixels
diff: 
   (191.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,18) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 . 
0 . 0 
 with color cyan at (7,7)
  _01: rectangle with size (3,3) with mask 
. 0 . 
. 0 . 
0 . 0 
 with color cyan at (1,2)
  _011: point with color green at (2,2)
  _0111: point with color blue at (2,4)
  _01111: point with color yellow at (2,15)
  _011111: point with color yellow at (3,3)
  _0111111: point with color green at (4,13)
  + 7 delta pixels
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,18) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 . 
0 . 0 
 with color cyan at (7,7)
  _01: rectangle with size (3,3) with mask 
. 0 . 
. 0 . 
0 . 0 
 with color cyan at (1,2)
  _011: point with color green at (2,2)
  _0111: point with color blue at (2,4)
  _01111: point with color yellow at (2,15)
  _011111: point with color yellow at (3,3)
  _0111111: point with color blue at (4,17)
  + 7 delta pixels
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (14,18) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 . 
0 . 0 
 with color cyan at (7,7)
  _01: rectangle with size (3,3) with mask 
. 0 . 
. 0 . 
0 . 0 
 with color cyan at (1,2)
  _011: point with color green at (2,2)
  _0111: point with color blue at (2,4)
  _01111: point with color yellow at (2,15)
  _011111: point with color green at (4,13)
  _0111111: point with color yellow at (3,3)
  + 7 delta pixels
diff: 
! 16 wrong pixels (generated / expected)

TRAIN 0e206a2e.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (14,15) and color black and layers
  _0: rectangle with size (5,3) with mask 
. 0 0 
. 0 . 
. 0 . 
. 0 . 
0 . 0 
 with color green at (4,3)
  _01: rectangle with size (1,1) with model Full with color red at (3,4)
  _011: point with color yellow at (4,3)
  _0111: point with color blue at (8,4)
  _01111: point with color yellow at (10,13)
  _011111: point with color blue at (11,9)
  _0111111: point with color red at (11,14)
diff: 
   (0.0 bits)
data: a background with size (14,15) and color black and layers
  _0: rectangle with size (3,5) with mask 
0 . . . . 
. 0 0 0 0 
0 . . . 0 
 with color green at (10,9)
  _01: 
2 
 at (11,14)
  _011: 
1 
 at (11,9)
  _0111: 
4 
 at (10,13)
diff: 
   (31.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,15) and color black and layers
  _0: rectangle with size (5,3) with mask 
. 0 0 
. 0 . 
. 0 . 
. 0 . 
0 . 0 
 with color green at (4,3)
  _01: rectangle with size (1,1) with model Full with color red at (3,4)
  _011: point with color yellow at (4,3)
  _0111: point with color blue at (8,4)
  _01111: point with color yellow at (10,13)
  _011111: point with color blue at (11,9)
  _0111111: point with color red at (11,14)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,15) and color black and layers
  _0: rectangle with size (5,3) with mask 
. 0 0 
. 0 . 
. 0 . 
. 0 . 
0 . 0 
 with color green at (4,3)
  _01: rectangle with size (1,1) with model Full with color red at (3,4)
  _011: point with color yellow at (4,3)
  _0111: point with color blue at (8,4)
  _01111: point with color yellow at (10,13)
  _011111: point with color red at (11,14)
  _0111111: point with color blue at (11,9)
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (14,15) and color black and layers
  _0: rectangle with size (5,3) with mask 
. 0 0 
. 0 . 
. 0 . 
. 0 . 
0 . 0 
 with color green at (4,3)
  _01: rectangle with size (1,1) with model Full with color red at (3,4)
  _011: point with color yellow at (4,3)
  _0111: point with color blue at (8,4)
  _01111: point with color blue at (11,9)
  _011111: point with color yellow at (10,13)
  _0111111: point with color red at (11,14)
diff: 
! 13 wrong pixels (generated / expected)

TRAIN 0e206a2e.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (16,14) and color black and layers
  _0: rectangle with size (3,6) with mask 
0 . . . 0 . 
. 0 0 0 . 0 
. . . . 0 . 
 with color cyan at (3,5)
  _01: rectangle with size (1,1) with model Full with color yellow at (2,9)
  _011: point with color blue at (4,5)
  _0111: point with color red at (4,9)
  _01111: point with color blue at (11,1)
  _011111: point with color red at (11,5)
  _0111111: point with color yellow at (13,5)
diff: 
   (0.0 bits)
data: a background with size (16,14) and color black and layers
  _0: rectangle with size (3,6) with mask 
. . . . 0 . 
. 0 0 0 . 0 
0 . . . 0 . 
 with color cyan at (10,1)
  _01: 
4 
 at (13,5)
  _011: 
2 
 at (11,5)
  _0111: 
1 
 at (11,1)
diff: 
   (34.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,14) and color black and layers
  _0: rectangle with size (3,6) with mask 
0 . . . 0 . 
. 0 0 0 . 0 
. . . . 0 . 
 with color cyan at (3,5)
  _01: rectangle with size (1,1) with model Full with color yellow at (2,9)
  _011: point with color blue at (4,5)
  _0111: point with color red at (4,9)
  _01111: point with color blue at (11,1)
  _011111: point with color red at (11,5)
  _0111111: point with color yellow at (13,5)
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (16,14) and color black and layers
  _0: rectangle with size (3,6) with mask 
0 . . . 0 . 
. 0 0 0 . 0 
. . . . 0 . 
 with color cyan at (3,5)
  _01: rectangle with size (1,1) with model Full with color yellow at (2,9)
  _011: point with color blue at (4,5)
  _0111: point with color red at (4,9)
  _01111: point with color blue at (11,1)
  _011111: point with color yellow at (13,5)
  _0111111: point with color red at (11,5)
diff: 
! 12 wrong pixels (generated / expected)

TRAIN 0e206a2e.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (24,19) and color black and layers
  _0: rectangle with size (4,5) with mask 
. 0 . . . 
0 . 0 0 . 
. 0 . . 0 
0 0 0 . . 
 with color grey at (3,6)
  _01: rectangle with size (3,4) with mask 
0 . . . 
. 0 . 0 
. . 0 . 
 with color grey at (9,10)
  _011: point with color blue at (4,7)
  _0111: point with color yellow at (4,10)
  _01111: point with color red at (6,5)
  _011111: point with color red at (9,11)
  _0111111: point with color yellow at (11,11)
  + 7 delta pixels
diff: 
! 30 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (24,19) and color black and layers
  _0: rectangle with size (4,5) with mask 
. 0 . . . 
0 . 0 0 . 
. 0 . . 0 
0 0 0 . . 
 with color grey at (3,6)
  _01: rectangle with size (3,4) with mask 
0 . . . 
. 0 . 0 
. . 0 . 
 with color grey at (9,10)
  _011: point with color blue at (4,7)
  _0111: point with color yellow at (4,10)
  _01111: point with color red at (6,5)
  _011111: point with color red at (9,11)
  _0111111: point with color blue at (11,13)
  + 7 delta pixels
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (24,19) and color black and layers
  _0: rectangle with size (4,5) with mask 
. 0 . . . 
0 . 0 0 . 
. 0 . . 0 
0 0 0 . . 
 with color grey at (3,6)
  _01: rectangle with size (3,4) with mask 
0 . . . 
. 0 . 0 
. . 0 . 
 with color grey at (9,10)
  _011: point with color blue at (4,7)
  _0111: point with color yellow at (4,10)
  _01111: point with color red at (6,5)
  _011111: point with color yellow at (11,11)
  _0111111: point with color red at (9,11)
  + 7 delta pixels
diff: 
! 30 wrong pixels (generated / expected)

TEST 0e206a2e.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 50.0 sec (50.0 sec/task)
bits-train-error = 2571.2 bits (2571.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-382] Checking task 10fcaaa3.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 19802.8 = 19805.1
DL output with Mo: L = 2.3 + 80187.8 = 80190.1
DL input+output M: L = 4.6 + 99990.6 = 99995.2

# learning a model for train pairs
2.000	
1.150	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.607	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.472	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.404	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.356	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.337	OUT ADD ^.layer_00 = ^.layer_0
0.324	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.310	OUT ADD ^.layer_010 = ^.layer_0.shape at (?,?)
0.299	OUT ADD ^.layer_0100 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.287	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.280	OUT ADD ^.layer_0101 = point with color ? at (?,?)
0.271	OUT SPE ^.size = tiling(^.size, 2, 2)
0.266	IN  SPE ^.color = black
0.263	OUT SPE ^.layer_0.pos.j = '0
0.262	OUT SPE ^.layer_01.shape.mask.size.i = 1
0.260	OUT SPE ^.layer_011.shape.mask.size.i = 1
0.259	OUT SPE ^.layer_01.shape.mask.model = Full
0.163	
0.163	IN  GEN ^.color = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size tiling(^.size, 2, 2) and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,'0)
  _0100: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_0.shape at (?,?)
  _0101: point with color ? at (?,?)
  _01: rectangle with size (1,?) with model Full with color ? at (?,?)
  _011: rectangle with size (1,?) with model ? with color ? at (?,?)
  _0111: point with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.3 + 1883.9 = 1916.2
DL output with Mo: L = 204.8 + 12773.0 = 12977.8
DL input+output M: L = 237.1 + 14657.0 = 14894.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size tiling(^.size, 2, 2) and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,'0)
  _0100: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_0.shape at (?,?)
  _0101: point with color ? at (?,?)
  _01: rectangle with size (1,?) with model Full with color ? at (?,?)
  _011: rectangle with size (1,?) with model ? with color ? at (?,?)
  _0111: point with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 0.0 = 32.2
DL output with Mo: L = 204.8 + 12773.0 = 12977.8
DL input+output M: L = 236.9 + 12773.0 = 13010.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (2,4) and color black and layers
  _0: point with color grey at (1,1)
diff: 
   (0.0 bits)
data: a background with size (4,8) and color black and layers
  _00: 
5#
 at (1,1)
  _0: rectangle with size (1,7) with model Full with color cyan at (2,0)
  _0100: rectangle with size (3,1) with model Full with color grey at (1,5)
  _010: 
5#
 at (3,1)
  _0101: point with color cyan at (0,0)
  _01: rectangle with size (1,1) with model Full with color cyan at (0,2)
  _011: rectangle with size (1,1) with model Full with color cyan at (0,4)
  _0111: point with color cyan at (0,6)
  + 3 delta pixels
diff: 
   (253.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (2,4) and color black and layers
  _0: point with color grey at (1,1)
diff: 
! 13 wrong pixels (generated / expected)

TRAIN 10fcaaa3.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,4) and color black and layers
  _0: point with color pink at (0,2)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,8) and color black and layers
  _00: 
6 
 at (0,2)
  _0: rectangle with size (4,8) with mask 
0 0 0 0 0 0 0 0 
. . . 0 . . . 0 
0 . . . 0 . . . 
0 0 0 0 0 0 0 0 
 with color cyan at (1,0)
  _0100: rectangle with size (2,2) with model Even Checkboard with color pink at (2,1)
  _010: 
6 
 at (0,6)
  _0101: point with color pink at (2,5)
  _01: rectangle with size (1,1) with model Full with color pink at (3,6)
  _011: rectangle with size (1,1) with model Full with color pink at (5,1)
  _0111: point with color pink at (5,5)
diff: 
   (179.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,4) and color black and layers
  _0: point with color pink at (0,2)
  + 1 delta pixels
diff: 
! 29 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,4) and color black and layers
  _0: point with color pink at (2,1)
  + 1 delta pixels
diff: 
! 29 wrong pixels (generated / expected)

TRAIN 10fcaaa3.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (5,3) and color black and layers
  _0: point with color yellow at (1,1)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,6) and color cyan and layers
  _00: 
4 
 at (1,1)
  _0: rectangle with size (5,6) with mask 
. 0 . . 0 . 
0 . 0 0 . 0 
. 0 . . 0 . 
0 . . 0 . 0 
. 0 0 . 0 0 
 with color black at (0,0)
  _0100: rectangle with size (4,6) with mask 
0 . 0 0 . 0 
. 0 . . 0 . 
0 . . 0 . 0 
. 0 0 . 0 0 
 with color black at (6,0)
  _010: 
4 
 at (1,4)
  _0101: point with color yellow at (4,0)
  _01: rectangle with size (1,4) with model Full with color yellow at (6,1)
  _011: rectangle with size (1,4) with model Full with color yellow at (9,0)
  _0111: point with color yellow at (4,3)
diff: 
   (221.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,3) and color black and layers
  _0: point with color yellow at (1,1)
  + 1 delta pixels
diff: 
! 33 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,3) and color black and layers
  _0: point with color yellow at (4,0)
  + 1 delta pixels
diff: 
! 33 wrong pixels (generated / expected)

TRAIN 10fcaaa3.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (4,4) and color black and layers
  _0: point with color red at (1,1)
diff: 
   (0.0 bits)
data: a background with size (8,8) and color black and layers
  _00: 
2 
 at (1,1)
  _0: rectangle with size (1,7) with model Full with color cyan at (0,0)
  _0100: rectangle with size (1,7) with model Full with color cyan at (2,0)
  _010: 
2 
 at (1,5)
  _0101: point with color cyan at (4,0)
  _01: rectangle with size (1,5) with model Full with color cyan at (4,2)
  _011: rectangle with size (1,1) with model Full with color red at (5,1)
  _0111: point with color red at (5,5)
  + 12 delta pixels
diff: 
   (623.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,4) and color black and layers
  _0: point with color red at (1,1)
diff: 
! 21 wrong pixels (generated / expected)

TRAIN 10fcaaa3.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,5) and color black and layers
  _0: point with color green at (0,1)
  + 2 delta pixels
diff: 
! 49 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,5) and color black and layers
  _0: point with color green at (3,3)
  + 2 delta pixels
diff: 
! 49 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (6,5) and color black and layers
  _0: point with color green at (5,1)
  + 2 delta pixels
diff: 
! 49 wrong pixels (generated / expected)

TEST 10fcaaa3.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 58.6 sec (58.6 sec/task)
bits-train-error = 12773.0 bits (12773.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-381] Checking task 11852cab.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.106	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.243	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.227	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.204	OUT ADD ^.layer_0 = ^.layer_0
0.198	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.188	OUT ADD ^.layer_01 = ^.layer_01
0.181	OUT ADD ^.layer_011 = ^.layer_01.shape at (?,?)
0.174	OUT ADD ^.layer_010 = ^.layer_01.shape at (?,?)
0.167	OUT ADD ^.layer_0111 = ^.layer_01.shape at (?,?)
0.162	OUT ADD ^.layer_01111 = point with color ? at (?,?)
0.156	OUT ADD ^.layer_011111 = point with color ? at (?,?)
0.151	OUT ADD ^.layer_0111111 = point with color ? at (?,?)
0.145	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.140	OUT SPE ^.size = ^.size
0.135	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.129	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.123	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.119	OUT SPE ^.layer_011111 = ^.layer_011111
0.115	OUT SPE ^.layer_01111 = ^.layer_011
0.110	OUT SPE ^.layer_0111111 = ^.layer_01111
0.108	OUT SPE ^.layer_0111.pos = ^.layer_0.pos + (3, 3)
0.105	OUT SPE ^.layer_010.pos = corner(^.layer_01.pos, ^.layer_0.pos) + (0, 3)
0.103	OUT SPE ^.layer_011.pos = corner(^.layer_0.pos, ^.layer_01.pos) + (3, 0)
0.102	IN  SPE ^.color = black
0.101	OUT SPE ^.color = black
0.040	
0.040	IN  DEL ^.layer_0111
0.040	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _010: ^.layer_01.shape at corner(^.layer_01.pos, ^.layer_0.pos) + (0, 3)
  _01: ^.layer_01
  _011: ^.layer_01.shape at corner(^.layer_0.pos, ^.layer_01.pos) + (3, 0)
  _0111: ^.layer_01.shape at ^.layer_0.pos + (3, 3)
  _01111: ^.layer_011
  _011111: ^.layer_011111
  _0111111: ^.layer_01111
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)

DL input  with Mi: L = 132.0 + 7361.7 = 7493.7
DL output with Mo: L = 180.0 + 4470.8 = 4650.8
DL input+output M: L = 312.0 + 11832.5 = 12144.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _010: ^.layer_01.shape at corner(^.layer_01.pos, ^.layer_0.pos) + (0, 3)
  _01: ^.layer_01
  _011: ^.layer_01.shape at corner(^.layer_0.pos, ^.layer_01.pos) + (3, 0)
  _0111: ^.layer_01.shape at ^.layer_0.pos + (3, 3)
  _01111: ^.layer_011
  _011111: ^.layer_011111
  _0111111: ^.layer_01111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)

DL input  with Mi: L = 114.2 + 0.0 = 114.2
DL output with Mo: L = 180.0 + 4470.8 = 4650.8
DL input+output M: L = 294.2 + 4470.8 = 4765.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (2,3)
  _01: point with color green at (1,2)
  _011: point with color cyan at (1,4)
  _01111: point with color cyan at (3,2)
  _011111: point with color green at (3,4)
  + 5 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
2 2 2 
 at (2,3)
  _010: 
3 
 at (1,6)
  _01: 
3 
 at (1,2)
  _011: 
3 
 at (5,2)
  _0111: 
3 
 at (5,6)
  _01111: 
8 
 at (1,4)
  _011111: 
3 
 at (3,4)
  _0111111: 
8 
 at (3,2)
  + 5 delta pixels
diff: 
   (202.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (2,3)
  _01: point with color green at (1,2)
  _011: point with color cyan at (1,4)
  _01111: point with color cyan at (3,2)
  _011111: point with color green at (3,4)
  + 5 delta pixels
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (2,3)
  _01: point with color green at (1,2)
  _011: point with color cyan at (1,4)
  _01111: point with color cyan at (3,2)
  _011111: point with color cyan at (3,6)
  + 5 delta pixels
diff: 
! 5 wrong pixels (generated / expected)

TRAIN 11852cab.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Even Checkboard with color yellow at (3,3)
  _01: point with color red at (2,2)
  _011: point with color green at (2,4)
  _01111: point with color green at (4,2)
  _011111: point with color green at (4,6)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
4 . 4 
. 4 . 
4 . 4 
 at (3,3)
  _010: 
2 
 at (2,6)
  _01: 
2 
 at (2,2)
  _011: 
2 
 at (6,2)
  _0111: 
2 
 at (6,6)
  _01111: 
3 
 at (2,4)
  _011111: 
3 
 at (4,6)
  _0111111: 
3 
 at (4,2)
  + 1 delta pixels
diff: 
   (41.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Even Checkboard with color yellow at (3,3)
  _01: point with color red at (2,2)
  _011: point with color green at (2,4)
  _01111: point with color green at (4,2)
  _011111: point with color green at (4,6)
  + 1 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Even Checkboard with color yellow at (3,3)
  _01: point with color red at (2,2)
  _011: point with color green at (2,4)
  _01111: point with color green at (4,2)
  _011111: point with color green at (6,4)
  + 1 delta pixels
diff: 
! 1 wrong pixels (generated / expected)

TRAIN 11852cab.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,5) with model Full with color cyan at (1,3)
  _01: point with color yellow at (2,4)
  _011: point with color cyan at (3,3)
  _01111: point with color blue at (3,5)
  _011111: point with color cyan at (3,7)
  + 5 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
8 8 8 8 8 
 at (1,3)
  _010: 
4 
 at (2,6)
  _01: 
4 
 at (2,4)
  _011: 
4 
 at (4,4)
  _0111: 
4 
 at (4,6)
  _01111: 
8 
 at (3,3)
  _011111: 
8 
 at (3,7)
  _0111111: 
1 
 at (3,5)
  + 5 delta pixels
diff: 
   (202.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,5) with model Full with color cyan at (1,3)
  _01: point with color yellow at (2,4)
  _011: point with color cyan at (3,3)
  _01111: point with color blue at (3,5)
  _011111: point with color cyan at (3,7)
  + 5 delta pixels
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,5) with model Full with color cyan at (1,3)
  _01: point with color yellow at (2,4)
  _011: point with color cyan at (3,3)
  _01111: point with color blue at (3,5)
  _011111: point with color cyan at (5,3)
  + 5 delta pixels
diff: 
! 5 wrong pixels (generated / expected)

TRAIN 11852cab.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (3,2)
  _01: point with color blue at (2,1)
  _011: point with color yellow at (2,3)
  _01111: point with color blue at (2,5)
  _011111: point with color blue at (4,3)
  + 5 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (3,2)
  _01: point with color blue at (2,1)
  _011: point with color yellow at (2,3)
  _01111: point with color blue at (2,5)
  _011111: point with color red at (5,2)
  + 5 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TEST 11852cab.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 32.8 sec (32.8 sec/task)
bits-train-error = 4470.8 bits (4470.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-380] Checking task 1190e5a7.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 450099.3 = 450101.6
DL output with Mo: L = 2.3 + 17174.3 = 17176.6
DL input+output M: L = 4.6 + 467273.6 = 467278.2

# learning a model for train pairs
2.000	
1.040	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.332	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.066	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.051	OUT SPE ^.color = ^.color
0.025	
0.025	IN  DEL ^.layer_0

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ^.color and layers
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 11625.8 = 11667.8
DL output with Mo: L = 14.3 + 409.2 = 423.5
DL input+output M: L = 56.3 + 12035.0 = 12091.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ^.color and layers
WHERE (Mi)
a background with size (?,?) and color ? and layers

DL input  with Mi: L = 12.9 + 0.0 = 12.9
DL output with Mo: L = 14.3 + 409.2 = 423.5
DL input+output M: L = 27.3 + 409.2 = 436.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (15,15) and color green and layers
  + 57 delta pixels
diff: 
   (0.0 bits)
data: a background with size (2,4) and color green and layers
diff: 
   (12.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color green and layers
  + 57 delta pixels
diff: 
! size mismatch, 10x10 instead of 2x4
>> Trial 2
data: a background with size (15,15) and color orange and layers
  + 168 delta pixels
diff: 
! size mismatch, 10x10 instead of 2x4
>> Trial 3
data: a background with size (15,15) and color black and layers
  + 225 delta pixels
diff: 
! size mismatch, 10x10 instead of 2x4

TRAIN 1190e5a7.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (11,11) and color blue and layers
  + 31 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,2) and color blue and layers
diff: 
   (11.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color blue and layers
  + 31 delta pixels
diff: 
! size mismatch, 10x10 instead of 3x2
>> Trial 2
data: a background with size (11,11) and color cyan and layers
  + 90 delta pixels
diff: 
! size mismatch, 10x10 instead of 3x2
>> Trial 3
data: a background with size (11,11) and color black and layers
  + 121 delta pixels
diff: 
! size mismatch, 10x10 instead of 3x2

TRAIN 1190e5a7.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (27,27) and color green and layers
  + 223 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,5) and color green and layers
diff: 
   (16.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (27,27) and color green and layers
  + 223 delta pixels
diff: 
! size mismatch, 10x10 instead of 6x5
>> Trial 2
data: a background with size (27,27) and color blue and layers
  + 506 delta pixels
diff: 
! size mismatch, 10x10 instead of 6x5
>> Trial 3
data: a background with size (27,27) and color black and layers
  + 729 delta pixels
diff: 
! size mismatch, 10x10 instead of 6x5

TRAIN 1190e5a7.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (22,22) and color blue and layers
  + 124 delta pixels
diff: 
! size mismatch, 10x10 instead of 5x3
>> Trial 2
data: a background with size (22,22) and color grey and layers
  + 360 delta pixels
diff: 
! size mismatch, 10x10 instead of 5x3
>> Trial 3
data: a background with size (22,22) and color black and layers
  + 484 delta pixels
diff: 
! size mismatch, 10x10 instead of 5x3

TEST 1190e5a7.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 2.0 sec (2.0 sec/task)
bits-train-error = 409.2 bits (409.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-379] Checking task 137eaa0f.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 145705.7 = 145708.0
DL output with Mo: L = 2.3 + 10534.8 = 10537.1
DL input+output M: L = 4.6 + 156240.5 = 156245.1

# learning a model for train pairs
2.000	
1.091	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.815	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.681	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.546	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.475	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.407	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.371	OUT SPE ^.size = '(3, 3)
0.338	OUT SPE ^.layer_01.shape.mask = 
0 0 

0.322	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.284	OUT SPE ^.layer_011.shape.mask = ^.layer_0.shape.mask
0.273	OUT SPE ^.layer_011.pos.j = '0
0.263	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.246	OUT SPE ^.layer_01.shape = ^.layer_01.shape
0.230	OUT SPE ^.layer_011.shape = ^.layer_0.shape
0.219	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_0.shape.mask.size.i
0.208	IN  ADD ^.layer_010 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.199	OUT SPE ^.layer_0.shape.mask.size.j = ^.layer_01.shape.mask.size.i
0.191	OUT SPE ^.layer_0.shape.mask.model = Full
0.183	OUT SPE ^.layer_011.pos.i = ^.layer_0.pos.i - ^.layer_01.shape.mask.size.j
0.175	OUT SPE ^.layer_01.pos.j = ^.layer_0.pos.i - ^.layer_01.shape.mask.size.j
0.168	OUT SPE ^.layer_0111.pos.i = bottom(^.layer_0) - area(^.layer_010.shape)
0.161	OUT SPE ^.layer_0111.pos.j = bottom(^.layer_0) - area(^.layer_010.shape)
0.154	OUT SPE ^.layer_0.pos.i = min(^.layer_0.pos.i, ^.layer_010.pos.i) / '2
0.149	IN  ADD ^.layer_00 = point with color ? at (?,?)
0.134	OUT SPE ^.layer_0111.shape = ^.layer_00.shape
0.127	OUT SPE ^.layer_0.pos.j = ^.layer_00.pos.i - ^.layer_01.shape.mask.size.i
0.120	OUT SPE ^.layer_01.pos.i = span(^.layer_0.pos.i, ^.layer_01.pos.i) - ^.layer_01.pos.i - ^.layer_00.pos.i
0.120	IN  SPE ^.layer_010.shape.mask.model = Full
0.119	IN  SPE ^.layer_01.shape.mask.model = Full
0.119	IN  SPE ^.color = black
0.071	
0.071	IN  GEN ^.layer_01.shape.mask.model = ?
0.071	IN  GEN ^.layer_010.shape.mask.model = ?
0.071	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color ? and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i,^.layer_01.shape.mask.size.i) with model Full with color ? at (min(^.layer_0.pos.i, ^.layer_010.pos.i) / '2,^.layer_00.pos.i - ^.layer_01.shape.mask.size.i)
  _01: ^.layer_01.shape at (span(^.layer_0.pos.i, ^.layer_01.pos.i) - ^.layer_01.pos.i - ^.layer_00.pos.i,^.layer_0.pos.i - ^.layer_01.shape.mask.size.j)
  _011: ^.layer_0.shape at (^.layer_0.pos.i - ^.layer_01.shape.mask.size.j,'0)
  _0111: ^.layer_00.shape at (bottom(^.layer_0) - area(^.layer_010.shape),bottom(^.layer_0) - area(^.layer_010.shape))
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 117.2 + 7001.0 = 7118.2
DL output with Mo: L = 429.6 + 307.7 = 737.3
DL input+output M: L = 546.7 + 7308.8 = 7855.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color ? and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i,^.layer_01.shape.mask.size.i) with model Full with color ? at (min(^.layer_0.pos.i, ^.layer_010.pos.i) / '2,^.layer_00.pos.i - ^.layer_01.shape.mask.size.i)
  _01: ^.layer_01.shape at (span(^.layer_0.pos.i, ^.layer_01.pos.i) - ^.layer_01.pos.i - ^.layer_00.pos.i,^.layer_0.pos.i - ^.layer_01.shape.mask.size.j)
  _011: ^.layer_0.shape at (^.layer_0.pos.i - ^.layer_01.shape.mask.size.j,'0)
  _0111: ^.layer_00.shape at (bottom(^.layer_0) - area(^.layer_010.shape),bottom(^.layer_0) - area(^.layer_010.shape))
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 116.0 + 63.4 = 179.4
DL output with Mo: L = 429.6 + 307.7 = 737.3
DL input+output M: L = 545.6 + 371.1 = 916.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _00: point with color grey at (2,3)
  _0: rectangle with size (1,2) with model Full with color yellow at (3,2)
  _010: rectangle with size (1,2) with model Full with color pink at (1,6)
  _01: rectangle with size (2,1) with model Full with color orange at (7,6)
  + 2 delta pixels
diff: 
   (3.2 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,2) with model Full with color pink at (0,0)
  _01: 
7#
7#
 at (0,2)
  _011: 
4 4 
 at (2,0)
  _0111: 
5#
 at (1,1)
diff: 
   (8.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _00: point with color grey at (2,3)
  _0: rectangle with size (1,2) with model Full with color pink at (1,6)
  _010: rectangle with size (1,2) with model Full with color yellow at (3,2)
  _01: rectangle with size (2,1) with model Full with color orange at (7,6)
  + 2 delta pixels
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,11) and color black and layers
  _00: point with color grey at (2,3)
  _0: rectangle with size (1,2) with model Full with color pink at (1,6)
  _010: rectangle with size (2,1) with model Full with color orange at (7,6)
  _01: rectangle with size (1,2) with model Full with color yellow at (3,2)
  + 2 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (11,11) and color black and layers
  _00: point with color grey at (2,3)
  _0: rectangle with size (1,2) with model Full with color yellow at (3,2)
  _010: rectangle with size (1,2) with model Full with color pink at (1,6)
  _01: rectangle with size (2,1) with model Full with color orange at (7,6)
  + 2 delta pixels
diff: 
! 2 wrong pixels (generated / expected)

TRAIN 137eaa0f.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _00: point with color pink at (2,1)
  _0: rectangle with size (1,3) with model Full with color orange at (3,4)
  _010: rectangle with size (1,3) with model Full with color green at (8,6)
  _01: rectangle with size (1,2) with model Full with color red at (8,2)
  + 4 delta pixels
diff: 
   (3.2 bits)
data: a background with size (3,3) and color green and layers
  _0: rectangle with size (1,1) with model Full with color grey at (1,1)
  _01: 
2 2 
 at (0,1)
  _011: 
7#7#7#
 at (1,0)
  _0111: 
6 
 at (0,0)
diff: 
   (14.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _00: point with color pink at (2,1)
  _0: rectangle with size (1,3) with model Full with color green at (8,6)
  _010: rectangle with size (1,2) with model Full with color red at (8,2)
  _01: rectangle with size (1,3) with model Full with color orange at (3,4)
  + 4 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,11) and color black and layers
  _00: point with color pink at (2,1)
  _0: rectangle with size (1,3) with model Full with color orange at (3,4)
  _010: rectangle with size (1,3) with model Full with color green at (8,6)
  _01: rectangle with size (1,2) with model Full with color red at (8,2)
  + 4 delta pixels
diff: 
! 4 wrong pixels (generated / expected)

TRAIN 137eaa0f.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _00: point with color grey at (3,1)
  _0: rectangle with size (2,3) with mask 
. 0 0 
0 . . 
 with color blue at (2,0)
  _010: rectangle with size (2,1) with model Full with color red at (4,6)
  _01: rectangle with size (1,2) with model Full with color brown at (9,6)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,1) with model Full with color red at (1,2)
  _01: 
9#9#
 at (2,0)
  _011: 
. 1 1 
1 . . 
 at (0,0)
  _0111: 
5#
 at (1,1)
diff: 
   (8.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _00: point with color grey at (3,1)
  _0: rectangle with size (2,3) with mask 
. 0 0 
0 . . 
 with color blue at (2,0)
  _010: rectangle with size (2,1) with model Full with color red at (4,6)
  _01: rectangle with size (1,2) with model Full with color brown at (9,6)
  + 2 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,11) and color black and layers
  _00: point with color grey at (3,1)
  _0: rectangle with size (2,3) with mask 
. 0 0 
0 . . 
 with color blue at (2,0)
  _010: rectangle with size (1,2) with model Full with color brown at (9,6)
  _01: rectangle with size (2,1) with model Full with color red at (4,6)
  + 2 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (11,11) and color black and layers
  _00: point with color blue at (3,0)
  _0: rectangle with size (1,2) with model Full with color blue at (2,1)
  _010: rectangle with size (2,1) with model Full with color red at (4,6)
  _01: rectangle with size (1,2) with model Full with color brown at (9,6)
  + 3 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 137eaa0f.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _00: point with color grey at (2,8)
  _0: rectangle with size (3,2) with mask 
. 0 
0 . 
0 . 
 with color brown at (1,7)
  _010: rectangle with size (1,2) with model Full with color red at (10,3)
  _01: rectangle with size (1,1) with model Full with color yellow at (3,0)
  + 5 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,11) and color black and layers
  _00: point with color grey at (2,8)
  _0: rectangle with size (3,2) with mask 
. 0 
0 . 
0 . 
 with color brown at (1,7)
  _010: rectangle with size (1,2) with model Full with color red at (10,3)
  _01: rectangle with size (1,1) with model Full with color grey at (4,1)
  + 5 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (11,11) and color black and layers
  _00: point with color grey at (2,8)
  _0: rectangle with size (3,2) with mask 
. 0 
0 . 
0 . 
 with color brown at (1,7)
  _010: rectangle with size (1,1) with model Full with color yellow at (3,0)
  _01: rectangle with size (1,2) with model Full with color red at (10,3)
  + 5 delta pixels
diff: 
! 8 wrong pixels (generated / expected)

TEST 137eaa0f.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 17.4 sec (17.4 sec/task)
bits-train-error = 307.7 bits (307.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-378] Checking task 150deff5.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 99764.8 = 99767.1
DL output with Mo: L = 2.3 + 99764.8 = 99767.1
DL input+output M: L = 4.6 + 199529.6 = 199534.3

# learning a model for train pairs
2.000	
1.230	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.459	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.257	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.168	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.121	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.090	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.076	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.070	OUT SPE ^.size = ^.size
0.066	OUT SPE ^.layer_0111.shape.mask = 
0 
0 
0 

0.063	OUT SPE ^.layer_01.pos = ^.layer_0.pos
0.062	IN  SPE ^.layer_0.shape.color = grey
0.060	OUT SPE ^.layer_0111.shape.color = red
0.058	OUT SPE ^.layer_0.pos.i = ^.layer_0.pos.j
0.057	OUT SPE ^.layer_011.pos.j = bottom(^.layer_0) - 1
0.055	OUT SPE ^.layer_0.shape.mask.size.j = ^.size.i / '3
0.054	OUT SPE ^.layer_011.shape.mask.size.j = ^.size.i / '3
0.053	OUT SPE ^.layer_011.shape.mask.model = Full
0.052	IN  SPE ^.color = black
0.052	OUT SPE ^.color = black
0.027	
0.027	IN  GEN ^.layer_0.shape.color = ?
0.027	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,^.size.i / '3) with model ? with color ? at (^.layer_0.pos.j,?)
  _01: rectangle with size (?,?) with model ? with color ? at ^.layer_0.pos
  _011: rectangle with size (?,^.size.i / '3) with model Full with color ? at (?,bottom(^.layer_0) - 1)
  _0111: 
0 
0 
0 
 with color red at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)

DL input  with Mi: L = 45.4 + 2449.2 = 2494.6
DL output with Mo: L = 207.6 + 2448.5 = 2656.1
DL input+output M: L = 253.0 + 4897.7 = 5150.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,^.size.i / '3) with model ? with color ? at (^.layer_0.pos.j,?)
  _01: rectangle with size (?,?) with model ? with color ? at ^.layer_0.pos
  _011: rectangle with size (?,^.size.i / '3) with model Full with color ? at (?,bottom(^.layer_0) - 1)
  _0111: 
0 
0 
0 
 with color red at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 207.6 + 2448.5 = 2656.1
DL input+output M: L = 249.6 + 2448.5 = 2698.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,11) and color black and layers
  _0: rectangle with size (6,6) with mask 
0 0 . . . . 
0 0 0 0 0 . 
. 0 0 0 . . 
. 0 0 0 0 0 
. 0 . . 0 0 
. . . 0 0 0 
 with color grey at (1,2)
diff: 
   (0.0 bits)
data: a background with size (9,11) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (2,4)
  _01: rectangle with size (5,6) with mask 
0 0 . . . . 
0 0 . . . . 
. . 0 0 . . 
. . 0 0 0 0 
. . . . 0 0 
 with color cyan at (1,2)
  _011: rectangle with size (1,3) with model Full with color red at (6,5)
  _0111: 
0 
0 
0 
 with color red at (3,3)
diff: 
   (97.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,11) and color black and layers
  _0: rectangle with size (6,6) with mask 
0 0 . . . . 
0 0 0 0 0 . 
. 0 0 0 . . 
. 0 0 0 0 0 
. 0 . . 0 0 
. . . 0 0 0 
 with color grey at (1,2)
diff: 
! 34 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,11) and color black and layers
  _0: rectangle with size (3,3) with model Full with color grey at (2,3)
  + 12 delta pixels
diff: 
! 35 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,11) and color black and layers
  _0: rectangle with size (3,2) with model Full with color grey at (4,6)
  + 15 delta pixels
diff: 
! 36 wrong pixels (generated / expected)

TRAIN 150deff5.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (8,10) and color black and layers
  _0: rectangle with size (6,6) with mask 
0 0 0 0 0 0 
0 0 0 0 0 0 
. . 0 . . 0 
. . . 0 0 0 
. . . 0 0 0 
. . . 0 . . 
 with color grey at (1,1)
diff: 
   (0.0 bits)
data: a background with size (8,10) and color black and layers
  _0: rectangle with size (6,2) with mask 
0 . 
0 . 
0 . 
. 0 
. 0 
. 0 
 with color red at (1,3)
  _01: rectangle with size (2,5) with model Full with color cyan at (1,1)
  _011: rectangle with size (2,2) with model Full with color cyan at (4,5)
  _0111: 
0 
0 
0 
 with color red at (1,6)
diff: 
   (82.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,10) and color black and layers
  _0: rectangle with size (6,6) with mask 
0 0 0 0 0 0 
0 0 0 0 0 0 
. . 0 . . 0 
. . . 0 0 0 
. . . 0 0 0 
. . . 0 . . 
 with color grey at (1,1)
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,10) and color black and layers
  _0: rectangle with size (2,6) with model Full with color grey at (1,1)
  + 9 delta pixels
diff: 
! 26 wrong pixels (generated / expected)

TRAIN 150deff5.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (8,9) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 0 0 
. . . 0 0 
. . 0 . . 
. . 0 0 0 
. . 0 0 0 
 with color grey at (1,1)
diff: 
   (0.0 bits)
data: a background with size (8,9) and color black and layers
  _0: rectangle with size (2,2) with model Full with color cyan at (1,4)
  _01: rectangle with size (1,3) with model Full with color red at (1,1)
  _011: rectangle with size (2,2) with model Full with color cyan at (4,4)
  _0111: 
0 
0 
0 
 with color red at (3,3)
diff: 
   (64.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,9) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 0 0 
. . . 0 0 
. . 0 . . 
. . 0 0 0 
. . 0 0 0 
 with color grey at (1,1)
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,9) and color black and layers
  _0: rectangle with size (2,3) with model Full with color grey at (4,3)
  + 8 delta pixels
diff: 
! 23 wrong pixels (generated / expected)

TRAIN 150deff5.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,11) and color black and layers
  _0: rectangle with size (7,7) with mask 
. 0 0 . 0 0 0 
. 0 0 . . 0 . 
0 0 0 0 0 0 . 
. . . 0 0 0 . 
. . 0 0 0 . . 
. . . . 0 0 . 
. . . . 0 0 . 
 with color grey at (0,1)
diff: 
! 30 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,11) and color black and layers
  _0: rectangle with size (3,2) with model Full with color grey at (0,2)
  + 18 delta pixels
diff: 
! 31 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (8,11) and color black and layers
  _0: rectangle with size (1,6) with model Full with color grey at (2,1)
  + 18 delta pixels
diff: 
! 31 wrong pixels (generated / expected)

TEST 150deff5.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 14.3 sec (14.3 sec/task)
bits-train-error = 2448.5 bits (2448.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-377] Checking task 178fcbfb.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 107942.6 = 107944.9
DL output with Mo: L = 2.3 + 107942.6 = 107944.9
DL input+output M: L = 4.6 + 215885.1 = 215889.8

# learning a model for train pairs
2.000	
1.051	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.436	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.343	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.250	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.164	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.121	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.102	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.096	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.090	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.083	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.077	OUT SPE ^.layer_01.shape = scaleTo(^.layer_01.shape, projJ(^.size) + (1, 0))
0.072	OUT SPE ^.size = ^.size
0.068	OUT SPE ^.layer_0.shape.mask = scaleTo(^.layer_0.shape.mask, projJ(^.size) + (1, 0))
0.065	OUT SPE ^.layer_01.pos = projI(^.layer_01.pos)
0.062	OUT SPE ^.layer_0.pos = projI(^.layer_011.pos)
0.060	IN  SPE ^.layer_01.shape.color = green
0.059	OUT SPE ^.layer_0111.shape.color = red
0.057	OUT SPE ^.layer_01111.shape.color = red
0.056	OUT SPE ^.layer_0111.pos.i = '0
0.054	OUT SPE ^.layer_0.shape = scaleTo(^.layer_011.shape, projJ(^.size) + (1, 0))
0.053	OUT SPE ^.layer_011.shape.color = ^.layer_0.shape.color
0.052	OUT SPE ^.layer_0111.shape.mask.size.j = 1
0.051	OUT SPE ^.layer_01111.shape.mask.size.j = 1
0.050	OUT SPE ^.layer_011.pos.j = center(^.layer_011) - ^.layer_011.pos.i - ^.layer_01.pos.i
0.049	OUT SPE ^.layer_011.shape.mask.size.i = 1
0.048	OUT SPE ^.layer_011.shape.mask.model = Full
0.047	OUT SPE ^.layer_0111.shape.mask.model = Full
0.046	OUT SPE ^.layer_01111.shape.mask.model = Full
0.046	IN  SPE ^.color = black
0.045	OUT SPE ^.color = black
0.016	
0.016	IN  GEN ^.layer_01.shape.color = ?
0.016	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: scaleTo(^.layer_011.shape, projJ(^.size) + (1, 0)) at projI(^.layer_011.pos)
  _01: scaleTo(^.layer_01.shape, projJ(^.size) + (1, 0)) at projI(^.layer_01.pos)
  _011: rectangle with size (1,?) with model Full with color ^.layer_0.shape.color at (?,center(^.layer_011) - ^.layer_011.pos.i - ^.layer_01.pos.i)
  _0111: rectangle with size (?,1) with model Full with color red at ('0,?)
  _01111: rectangle with size (?,1) with model Full with color red at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)
  _01: point with color green at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 72.1 + 3164.1 = 3236.2
DL output with Mo: L = 278.3 + 1348.5 = 1626.8
DL input+output M: L = 350.4 + 4512.6 = 4863.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: scaleTo(^.layer_011.shape, projJ(^.size) + (1, 0)) at projI(^.layer_011.pos)
  _01: scaleTo(^.layer_01.shape, projJ(^.size) + (1, 0)) at projI(^.layer_01.pos)
  _011: rectangle with size (1,?) with model Full with color ^.layer_0.shape.color at (?,center(^.layer_011) - ^.layer_011.pos.i - ^.layer_01.pos.i)
  _0111: rectangle with size (?,1) with model Full with color red at ('0,?)
  _01111: rectangle with size (?,1) with model Full with color red at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 68.7 + 0.0 = 68.7
DL output with Mo: L = 278.3 + 1348.5 = 1626.8
DL input+output M: L = 347.0 + 1348.5 = 1695.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: point with color red at (2,2)
  _01: point with color green at (4,7)
  _011: point with color blue at (6,3)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: 
1 1 1 1 1 1 1 1 1 
 at (6,0)
  _01: 
3 3 3 3 3 3 3 3 3 
 at (4,0)
  _011: rectangle with size (1,1) with model Full with color red at (5,2)
  _0111: rectangle with size (4,1) with model Full with color red at (0,2)
  _01111: rectangle with size (2,1) with model Full with color red at (7,2)
diff: 
   (37.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color red at (2,2)
  _01: point with color green at (4,7)
  _011: point with color blue at (6,3)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: point with color red at (2,2)
  _01: point with color blue at (6,3)
  _011: point with color green at (4,7)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,9) and color black and layers
  _0: point with color green at (4,7)
  _01: point with color red at (2,2)
  _011: point with color blue at (6,3)
diff: 
! 26 wrong pixels (generated / expected)

TRAIN 178fcbfb.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,8) and color black and layers
  _0: point with color green at (1,1)
  _01: point with color green at (4,3)
  _011: point with color blue at (6,1)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,8) and color black and layers
  _0: 
1 1 1 1 1 1 1 1 
 at (6,0)
  _01: 
3 3 3 3 3 3 3 3 
 at (4,0)
  _011: rectangle with size (1,8) with model Full with color green at (1,0)
  _0111: rectangle with size (1,1) with model Full with color red at (0,5)
  _01111: rectangle with size (8,1) with model Full with color red at (2,5)
diff: 
   (43.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,8) and color black and layers
  _0: point with color green at (1,1)
  _01: point with color green at (4,3)
  _011: point with color blue at (6,1)
  + 1 delta pixels
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,8) and color black and layers
  _0: point with color green at (1,1)
  _01: point with color green at (4,3)
  _011: point with color red at (7,5)
  + 1 delta pixels
diff: 
! 32 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,8) and color black and layers
  _0: point with color green at (1,1)
  _01: point with color blue at (6,1)
  _011: point with color green at (4,3)
  + 1 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TRAIN 178fcbfb.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,11) and color black and layers
  _0: point with color blue at (1,1)
  _01: point with color green at (3,8)
  _011: point with color green at (6,2)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,11) and color black and layers
  _0: 
3 3 3 3 3 3 3 3 3 3 3 
 at (6,0)
  _01: 
3 3 3 3 3 3 3 3 3 3 3 
 at (3,0)
  _011: rectangle with size (1,11) with model Full with color blue at (1,0)
  _0111: rectangle with size (10,1) with model Full with color red at (0,3)
  _01111: rectangle with size (10,1) with model Full with color red at (0,9)
diff: 
   (53.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,11) and color black and layers
  _0: point with color blue at (1,1)
  _01: point with color green at (3,8)
  _011: point with color green at (6,2)
  + 2 delta pixels
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,11) and color black and layers
  _0: point with color blue at (1,1)
  _01: point with color green at (3,8)
  _011: point with color red at (8,3)
  + 2 delta pixels
diff: 
! 44 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,11) and color black and layers
  _0: point with color blue at (1,1)
  _01: point with color green at (6,2)
  _011: point with color green at (3,8)
  + 2 delta pixels
diff: 
! 26 wrong pixels (generated / expected)

TRAIN 178fcbfb.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,11) and color black and layers
  _0: point with color green at (0,3)
  _01: point with color red at (1,9)
  _011: point with color green at (3,5)
  + 3 delta pixels
diff: 
! 54 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,11) and color black and layers
  _0: point with color green at (0,3)
  _01: point with color red at (1,9)
  _011: point with color red at (5,4)
  + 3 delta pixels
diff: 
! 72 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,11) and color black and layers
  _0: point with color green at (0,3)
  _01: point with color green at (3,5)
  _011: point with color red at (1,9)
  + 3 delta pixels
diff: 
! 56 wrong pixels (generated / expected)

TEST 178fcbfb.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 12.7 sec (12.7 sec/task)
bits-train-error = 1348.5 bits (1348.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-376] Checking task 1a07d186.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 325733.0 = 325735.3
DL output with Mo: L = 2.3 + 325733.0 = 325735.3
DL input+output M: L = 4.6 + 651465.9 = 651470.6

# learning a model for train pairs
2.000	
1.119	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.243	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.180	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.122	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.083	OUT ADD ^.layer_01 = ^.layer_0
0.044	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.042	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.040	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.038	OUT SPE ^.size = ^.size
0.036	IN  ADD ^.layer_00 = point with color ? at (?,?)
0.034	IN  ADD ^.layer_001 = point with color ? at (?,?)
0.031	IN  ADD ^.layer_0011 = point with color ? at (?,?)
0.029	IN  ADD ^.layer_00111 = point with color ? at (?,?)
0.029	OUT SPE ^.layer_011.shape.color = ^.layer_0.shape.color
0.028	OUT SPE ^.layer_0111.shape.color = ^.layer_0.shape.color
0.027	OUT SPE ^.layer_011.pos = ^.layer_0011.pos - translationOnto(^.layer_0, ^.layer_0011)
0.027	OUT SPE ^.layer_0.shape.color = majorityColor(^)
0.026	OUT SPE ^.layer_0.pos.j = min(^.layer_01.pos.j, ^.layer_001.pos.j)
0.026	OUT SPE ^.layer_0.pos.i = min(^.layer_0.pos.i, ^.layer_01.pos.i) - ^.layer_001.pos.i - ^.layer_00.pos.i
0.026	IN  SPE ^.layer_0.shape.mask.model = Full
0.026	IN  SPE ^.layer_01.shape.mask.model = Full
0.025	IN  SPE ^.color = black
0.025	OUT SPE ^.color = black
0.007	
0.006	IN  DEL ^.layer_00111
0.006	IN  GEN ^.layer_01.shape.mask.model = ?
0.006	IN  GEN ^.layer_0.shape.mask.model = ?
0.006	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color majorityColor(^) at (min(^.layer_0.pos.i, ^.layer_01.pos.i) - ^.layer_001.pos.i - ^.layer_00.pos.i,min(^.layer_01.pos.j, ^.layer_001.pos.j))
  _01: ^.layer_0
  _011: point with color ^.layer_0.shape.color at ^.layer_0011.pos - translationOnto(^.layer_0, ^.layer_0011)
  _0111: point with color ^.layer_0.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: point with color ? at (?,?)
  _001: point with color ? at (?,?)
  _0011: point with color ? at (?,?)
  _00111: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 142.8 + 6117.6 = 6260.4
DL output with Mo: L = 277.1 + 1663.9 = 1941.0
DL input+output M: L = 420.0 + 7781.4 = 8201.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color majorityColor(^) at (min(^.layer_0.pos.i, ^.layer_01.pos.i) - ^.layer_001.pos.i - ^.layer_00.pos.i,min(^.layer_01.pos.j, ^.layer_001.pos.j))
  _01: ^.layer_0
  _011: point with color ^.layer_0.shape.color at ^.layer_0011.pos - translationOnto(^.layer_0, ^.layer_0011)
  _0111: point with color ^.layer_0.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: point with color ? at (?,?)
  _001: point with color ? at (?,?)
  _0011: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 124.0 + 40.0 = 164.0
DL output with Mo: L = 277.1 + 1663.9 = 1941.0
DL input+output M: L = 401.1 + 1703.9 = 2105.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (18,19) and color black and layers
  _00: point with color yellow at (3,1)
  _001: point with color green at (3,6)
  _0011: point with color yellow at (7,9)
  _0: rectangle with size (18,1) with model Full with color yellow at (0,12)
  _01: rectangle with size (18,1) with model Full with color green at (0,3)
  + 2 delta pixels
diff: 
   (2.0 bits)
data: a background with size (18,19) and color black and layers
  _0: rectangle with size (18,2) with mask 
0 . 
0 . 
0 . 
0 0 
0 . 
0 . 
0 . 
0 . 
0 . 
0 . 
0 . 
0 0 
0 . 
0 . 
0 . 
0 . 
0 . 
0 . 
 with color green at (0,3)
  _01: 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
 at (0,12)
  _011: point with color yellow at (7,11)
  _0111: point with color yellow at (3,11)
diff: 
   (68.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,19) and color black and layers
  _00: point with color yellow at (3,1)
  _001: point with color green at (3,6)
  _0011: point with color yellow at (7,9)
  _0: rectangle with size (18,1) with model Full with color green at (0,3)
  _01: rectangle with size (18,1) with model Full with color yellow at (0,12)
  + 2 delta pixels
diff: 
! 28 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (18,19) and color black and layers
  _00: point with color yellow at (3,1)
  _001: point with color green at (3,6)
  _0011: point with color yellow at (7,9)
  _0: rectangle with size (18,1) with model Full with color yellow at (0,12)
  _01: rectangle with size (18,1) with model Full with color green at (0,3)
  + 2 delta pixels
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (18,19) and color black and layers
  _00: point with color yellow at (3,1)
  _001: point with color green at (3,6)
  _0011: point with color red at (10,7)
  _0: rectangle with size (18,1) with model Full with color green at (0,3)
  _01: rectangle with size (18,1) with model Full with color yellow at (0,12)
  + 2 delta pixels
diff: 
! 28 wrong pixels (generated / expected)

TRAIN 1a07d186.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (15,14) and color black and layers
  _00: point with color red at (0,3)
  _001: point with color yellow at (1,9)
  _0011: point with color blue at (5,10)
  _0: rectangle with size (1,14) with model Full with color blue at (10,0)
  _01: rectangle with size (1,14) with model Full with color red at (3,0)
  + 3 delta pixels
diff: 
   (2.0 bits)
data: a background with size (15,14) and color black and layers
  _0: rectangle with size (3,14) with mask 
. . . 0 . . . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . 0 . . . 0 . . . 
 with color red at (2,0)
  _01: 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 
 at (10,0)
  _011: point with color blue at (9,10)
  _0111: point with color blue at (11,2)
diff: 
   (73.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,14) and color black and layers
  _00: point with color red at (0,3)
  _001: point with color yellow at (1,9)
  _0011: point with color blue at (5,10)
  _0: rectangle with size (1,14) with model Full with color red at (3,0)
  _01: rectangle with size (1,14) with model Full with color blue at (10,0)
  + 3 delta pixels
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,14) and color black and layers
  _00: point with color red at (0,3)
  _001: point with color yellow at (1,9)
  _0011: point with color blue at (5,10)
  _0: rectangle with size (1,14) with model Full with color blue at (10,0)
  _01: rectangle with size (1,14) with model Full with color red at (3,0)
  + 3 delta pixels
diff: 
! 19 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,14) and color black and layers
  _00: point with color red at (0,3)
  _001: point with color yellow at (1,9)
  _0011: point with color red at (7,6)
  _0: rectangle with size (1,14) with model Full with color red at (3,0)
  _01: rectangle with size (1,14) with model Full with color blue at (10,0)
  + 3 delta pixels
diff: 
! 21 wrong pixels (generated / expected)

TRAIN 1a07d186.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (15,16) and color black and layers
  _00: point with color blue at (1,3)
  _001: point with color cyan at (1,7)
  _0011: point with color cyan at (8,11)
  _0: rectangle with size (1,16) with model Full with color cyan at (5,0)
  _01: rectangle with size (1,1) with model Full with color cyan at (12,3)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (15,16) and color black and layers
  _0: rectangle with size (2,1) with model Full with color cyan at (5,3)
  _01: 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
 at (5,0)
  _011: point with color cyan at (6,11)
  _0111: point with color cyan at (4,7)
diff: 
   (24.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,16) and color black and layers
  _00: point with color blue at (1,3)
  _001: point with color cyan at (1,7)
  _0011: point with color cyan at (8,11)
  _0: rectangle with size (1,16) with model Full with color cyan at (5,0)
  _01: rectangle with size (1,1) with model Full with color cyan at (12,3)
  + 1 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,16) and color black and layers
  _00: point with color blue at (1,3)
  _001: point with color cyan at (1,7)
  _0011: point with color cyan at (8,11)
  _0: rectangle with size (1,16) with model Full with color cyan at (5,0)
  _01: rectangle with size (1,1) with model Full with color blue at (13,12)
  + 1 delta pixels
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,16) and color black and layers
  _00: point with color blue at (1,3)
  _001: point with color cyan at (1,7)
  _0011: point with color cyan at (8,11)
  _0: rectangle with size (1,1) with model Full with color cyan at (12,3)
  _01: rectangle with size (1,16) with model Full with color cyan at (5,0)
  + 1 delta pixels
diff: 
! 22 wrong pixels (generated / expected)

TRAIN 1a07d186.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,26) and color black and layers
  _00: point with color red at (2,16)
  _001: point with color cyan at (4,24)
  _0011: point with color cyan at (5,9)
  _0: rectangle with size (19,1) with model Full with color red at (0,4)
  _01: rectangle with size (19,1) with model Full with color green at (0,11)
  + 27 delta pixels
diff: 
! 47 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (19,26) and color black and layers
  _00: point with color red at (2,16)
  _001: point with color cyan at (4,24)
  _0011: point with color cyan at (5,9)
  _0: rectangle with size (19,1) with model Full with color green at (0,11)
  _01: rectangle with size (19,1) with model Full with color red at (0,4)
  + 27 delta pixels
diff: 
! 47 wrong pixels (generated / expected)

TEST 1a07d186.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 32.4 sec (32.4 sec/task)
bits-train-error = 1663.9 bits (1663.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-375] Checking task 1b2d62fb.json: 5 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 68229.8 = 68232.1
DL output with Mo: L = 2.3 + 29066.6 = 29068.9
DL input+output M: L = 4.6 + 97296.4 = 97301.1

# learning a model for train pairs
2.000	
1.264	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.772	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.593	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.439	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.318	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.234	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.210	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.199	IN  SPE ^.layer_01.shape.mask = 
0 
0 
0 
0 
0 

0.190	OUT SPE ^.layer_0.shape.color = cyan
0.186	OUT SPE ^.color = black
0.181	IN  SPE ^.layer_01.shape.color = blue
0.074	
0.074	IN  GEN ^.layer_01.shape.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color cyan at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: 
0 
0 
0 
0 
0 
 with color blue at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 99.3 + 7363.3 = 7462.6
DL output with Mo: L = 53.6 + 2042.7 = 2096.3
DL input+output M: L = 152.9 + 9406.0 = 9558.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color cyan at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: 
0 
0 
0 
0 
0 
 with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 96.0 + 0.0 = 96.0
DL output with Mo: L = 53.6 + 2042.7 = 2096.3
DL input+output M: L = 149.6 + 2042.7 = 2192.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (5,7) and color brown and layers
  _0: rectangle with size (5,3) with mask 
0 . . 
0 0 . 
. 0 . 
0 0 0 
0 . . 
 with color black at (0,0)
  _01: 
0 
0 
0 
0 
0 
 with color blue at (0,3)
  _011: rectangle with size (3,2) with mask 
. 0 
. 0 
0 0 
 with color black at (1,5)
diff: 
   (0.0 bits)
data: a background with size (5,3) and color black and layers
  _0: rectangle with size (1,2) with model Full with color cyan at (3,1)
diff: 
   (20.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,7) and color brown and layers
  _0: rectangle with size (5,3) with mask 
0 . . 
0 0 . 
. 0 . 
0 0 0 
0 . . 
 with color black at (0,0)
  _01: 
0 
0 
0 
0 
0 
 with color blue at (0,3)
  _011: rectangle with size (3,2) with mask 
. 0 
. 0 
0 0 
 with color black at (1,5)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,7) and color brown and layers
  _0: rectangle with size (3,2) with mask 
. 0 
. 0 
0 0 
 with color black at (1,5)
  _01: 
0 
0 
0 
0 
0 
 with color blue at (0,3)
  _011: rectangle with size (5,3) with mask 
0 . . 
0 0 . 
. 0 . 
0 0 0 
0 . . 
 with color black at (0,0)
diff: 
! size mismatch, 3x2 instead of 5x3

TRAIN 1b2d62fb.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (5,7) and color brown and layers
  _0: rectangle with size (5,3) with mask 
0 0 0 
. 0 . 
0 . . 
0 0 0 
0 . . 
 with color black at (0,0)
  _01: 
0 
0 
0 
0 
0 
 with color blue at (0,3)
  _011: rectangle with size (1,2) with model Full with color black at (0,5)
diff: 
   (0.0 bits)
data: a background with size (5,3) and color black and layers
  _0: rectangle with size (1,2) with model Full with color cyan at (0,1)
diff: 
   (20.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,7) and color brown and layers
  _0: rectangle with size (5,3) with mask 
0 0 0 
. 0 . 
0 . . 
0 0 0 
0 . . 
 with color black at (0,0)
  _01: 
0 
0 
0 
0 
0 
 with color blue at (0,3)
  _011: rectangle with size (1,2) with model Full with color black at (0,5)
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,7) and color brown and layers
  _0: rectangle with size (1,2) with model Full with color black at (0,5)
  _01: 
0 
0 
0 
0 
0 
 with color blue at (0,3)
  _011: rectangle with size (5,3) with mask 
0 0 0 
. 0 . 
0 . . 
0 0 0 
0 . . 
 with color black at (0,0)
diff: 
! size mismatch, 1x2 instead of 5x3

TRAIN 1b2d62fb.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (5,7) and color black and layers
  _0: rectangle with size (5,3) with mask 
0 . 0 
. 0 . 
0 . . 
. 0 0 
. 0 . 
 with color brown at (0,4)
  _01: 
0 
0 
0 
0 
0 
 with color blue at (0,3)
  _011: rectangle with size (5,3) with mask 
0 . . 
0 . . 
0 . . 
. 0 0 
. . 0 
 with color brown at (0,0)
diff: 
   (0.0 bits)
data: a background with size (5,3) and color black and layers
  _0: rectangle with size (5,3) with mask 
. 0 . 
. . 0 
. 0 0 
0 . . 
0 . . 
 with color cyan at (0,0)
diff: 
   (39.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,7) and color black and layers
  _0: rectangle with size (5,3) with mask 
0 . 0 
. 0 . 
0 . . 
. 0 0 
. 0 . 
 with color brown at (0,4)
  _01: 
0 
0 
0 
0 
0 
 with color blue at (0,3)
  _011: rectangle with size (5,3) with mask 
0 . . 
0 . . 
0 . . 
. 0 0 
. . 0 
 with color brown at (0,0)
diff: 
! 8 wrong pixels (generated / expected)

TRAIN 1b2d62fb.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (5,7) and color black and layers
  _0: rectangle with size (5,3) with mask 
. 0 0 
0 . . 
0 0 0 
. 0 . 
0 . . 
 with color brown at (0,0)
  _01: 
0 
0 
0 
0 
0 
 with color blue at (0,3)
  _011: rectangle with size (3,3) with mask 
0 . . 
0 . . 
0 0 0 
 with color brown at (0,4)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,3) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 . 0 
. 0 0 
 with color cyan at (3,0)
  + 2 delta pixels
diff: 
   (104.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,7) and color black and layers
  _0: rectangle with size (5,3) with mask 
. 0 0 
0 . . 
0 0 0 
. 0 . 
0 . . 
 with color brown at (0,0)
  _01: 
0 
0 
0 
0 
0 
 with color blue at (0,3)
  _011: rectangle with size (3,3) with mask 
0 . . 
0 . . 
0 0 0 
 with color brown at (0,4)
  + 2 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,7) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
0 . . 
0 0 0 
 with color brown at (0,4)
  _01: 
0 
0 
0 
0 
0 
 with color blue at (0,3)
  _011: rectangle with size (5,3) with mask 
. 0 0 
0 . . 
0 0 0 
. 0 . 
0 . . 
 with color brown at (0,0)
  + 2 delta pixels
diff: 
! size mismatch, 3x3 instead of 5x3

TRAIN 1b2d62fb.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: a background with size (5,7) and color black and layers
  _0: rectangle with size (5,3) with mask 
. 0 0 
0 . 0 
0 0 0 
0 . . 
0 0 0 
 with color brown at (0,0)
  _01: 
0 
0 
0 
0 
0 
 with color blue at (0,3)
  _011: rectangle with size (3,3) with mask 
0 . 0 
0 0 0 
. . 0 
 with color brown at (0,4)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,3) and color black and layers
  _0: rectangle with size (1,2) with model Full with color cyan at (3,1)
diff: 
   (20.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,7) and color black and layers
  _0: rectangle with size (5,3) with mask 
. 0 0 
0 . 0 
0 0 0 
0 . . 
0 0 0 
 with color brown at (0,0)
  _01: 
0 
0 
0 
0 
0 
 with color blue at (0,3)
  _011: rectangle with size (3,3) with mask 
0 . 0 
0 0 0 
. . 0 
 with color brown at (0,4)
  + 2 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,7) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 0 
. . 0 
 with color brown at (0,4)
  _01: 
0 
0 
0 
0 
0 
 with color blue at (0,3)
  _011: rectangle with size (5,3) with mask 
. 0 0 
0 . 0 
0 0 0 
0 . . 
0 0 0 
 with color brown at (0,0)
  + 2 delta pixels
diff: 
! size mismatch, 3x3 instead of 5x3

TRAIN 1b2d62fb.json/5: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,7) and color black and layers
  _0: rectangle with size (5,3) with mask 
0 0 . 
. 0 0 
0 0 . 
0 0 0 
. 0 0 
 with color brown at (0,0)
  _01: 
0 
0 
0 
0 
0 
 with color blue at (0,3)
  _011: rectangle with size (3,3) with mask 
. 0 . 
0 . 0 
. 0 0 
 with color brown at (2,4)
  + 1 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TEST 1b2d62fb.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 9.9 sec (9.9 sec/task)
bits-train-error = 2042.7 bits (2042.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-374] Checking task 1b60fb0c.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.305	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.703	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.428	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.130	OUT ADD ^.layer_0 = ^.layer_0
0.048	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.043	OUT SPE ^.size = ^.size
0.042	OUT SPE ^.layer_01.shape.mask.size.j = ^.layer_0.shape.mask.size.j - 3
0.040	IN  SPE ^.layer_0.shape.color = blue
0.039	OUT SPE ^.layer_01.shape.color = red
0.038	OUT SPE ^.layer_01.pos.j = 1
0.037	IN  SPE ^.color = black
0.036	OUT SPE ^.color = black
0.009	
0.009	IN  GEN ^.layer_0.shape.color = ?
0.009	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (?,^.layer_0.shape.mask.size.j - 3) with model ? with color red at (?,1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color blue at (?,?)

DL input  with Mi: L = 45.4 + 3307.9 = 3353.3
DL output with Mo: L = 77.5 + 940.0 = 1017.5
DL input+output M: L = 122.9 + 4247.9 = 4370.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (?,^.layer_0.shape.mask.size.j - 3) with model ? with color red at (?,1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 77.5 + 940.0 = 1017.5
DL input+output M: L = 119.5 + 940.0 = 1059.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (8,6) with mask 
0 0 0 . . . 
. 0 0 . . . 
. 0 . . . 0 
. 0 0 0 0 0 
. 0 0 . 0 0 
. . 0 . . . 
. 0 0 . . . 
. 0 0 0 . . 
 with color blue at (1,3)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
1 1 1 . . . 
. 1 1 . . . 
. 1 . . . 1 
. 1 1 1 1 1 
. 1 1 . 1 1 
. . 1 . . . 
. 1 1 . . . 
. 1 1 1 . . 
 at (1,3)
  _01: rectangle with size (3,3) with mask 
0 0 . 
0 0 0 
0 . . 
 with color red at (4,1)
diff: 
   (22.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (8,6) with mask 
0 0 0 . . . 
. 0 0 . . . 
. 0 . . . 0 
. 0 0 0 0 0 
. 0 0 . 0 0 
. . 0 . . . 
. 0 0 . . . 
. 0 0 0 . . 
 with color blue at (1,3)
diff: 
! 11 wrong pixels (generated / expected)

TRAIN 1b60fb0c.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (9,7) with mask 
0 0 0 0 0 . . 
0 0 0 0 0 . . 
. . 0 . . 0 0 
. . 0 . . 0 0 
. . 0 0 0 0 0 
. . 0 . . 0 0 
. . 0 . . 0 0 
0 0 0 0 0 . . 
0 0 0 0 0 . . 
 with color blue at (1,3)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
1 1 1 1 1 . . 
1 1 1 1 1 . . 
. . 1 . . 1 1 
. . 1 . . 1 1 
. . 1 1 1 1 1 
. . 1 . . 1 1 
. . 1 . . 1 1 
1 1 1 1 1 . . 
1 1 1 1 1 . . 
 at (1,3)
  _01: rectangle with size (5,4) with mask 
0 0 . . 
0 0 . . 
0 0 0 0 
0 0 . . 
0 0 . . 
 with color red at (3,1)
diff: 
   (35.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (9,7) with mask 
0 0 0 0 0 . . 
0 0 0 0 0 . . 
. . 0 . . 0 0 
. . 0 . . 0 0 
. . 0 0 0 0 0 
. . 0 . . 0 0 
. . 0 . . 0 0 
0 0 0 0 0 . . 
0 0 0 0 0 . . 
 with color blue at (1,3)
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (9,7) with model Full with color blue at (1,3)
  + 26 delta pixels
diff: 
! 42 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,5) with model Full with color blue at (1,3)
  + 27 delta pixels
diff: 
! 43 wrong pixels (generated / expected)

TRAIN 1b60fb0c.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (9,7) with mask 
0 0 0 0 0 . . 
. . 0 . . . . 
. 0 0 0 . . 0 
. . 0 . 0 . 0 
. . 0 0 0 0 0 
. . 0 . 0 . 0 
. 0 0 0 . . 0 
. . 0 . . . . 
0 0 0 0 0 . . 
 with color blue at (1,3)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
1 1 1 1 1 . . 
. . 1 . . . . 
. 1 1 1 . . 1 
. . 1 . 1 . 1 
. . 1 1 1 1 1 
. . 1 . 1 . 1 
. 1 1 1 . . 1 
. . 1 . . . . 
1 1 1 1 1 . . 
 at (1,3)
  _01: rectangle with size (5,4) with mask 
0 . . . 
0 . 0 . 
0 0 0 0 
0 . 0 . 
0 . . . 
 with color red at (3,1)
diff: 
   (36.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (9,7) with mask 
0 0 0 0 0 . . 
. . 0 . . . . 
. 0 0 0 . . 0 
. . 0 . 0 . 0 
. . 0 0 0 0 0 
. . 0 . 0 . 0 
. 0 0 0 . . 0 
. . 0 . . . . 
0 0 0 0 0 . . 
 with color blue at (1,3)
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,5) with model Full with color blue at (1,3)
  + 26 delta pixels
diff: 
! 40 wrong pixels (generated / expected)

TRAIN 1b60fb0c.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,8) with mask 
. . 0 . . . . . 
0 0 0 0 0 . . . 
. . 0 0 . . 0 . 
. . 0 . . . 0 . 
. . 0 0 0 0 0 0 
. . 0 0 . 0 0 . 
. . . 0 . . 0 . 
. . 0 0 . . . . 
. 0 0 0 0 0 . . 
. . . 0 . . . . 
 with color blue at (0,2)
diff: 
! 14 wrong pixels (generated / expected)

TEST 1b60fb0c.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.4 sec (3.4 sec/task)
bits-train-error = 940.0 bits (940.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-373] Checking task 1bfc4729.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79850.6 = 79852.9
DL output with Mo: L = 2.3 + 79850.6 = 79852.9
DL input+output M: L = 4.6 + 159701.1 = 159705.8

# learning a model for train pairs
2.000	
1.026	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.550	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.314	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.077	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.060	OUT SPE ^.layer_0.shape.mask = 
0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . 0 
0 . . . . . . . . 0 

0.043	OUT SPE ^.layer_01.shape.mask = 
0 . . . . . . . . 0 
0 . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 

0.037	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.031	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.026	OUT SPE ^.size = ^.size
0.023	OUT SPE ^.layer_0.pos = '(0, 0)
0.021	OUT SPE ^.layer_01.pos = projI(^.layer_01.pos) - (2, 0)
0.019	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.018	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.017	IN  SPE ^.color = black
0.017	OUT SPE ^.color = black
0.003	
0.003	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . 0 
0 . . . . . . . . 0 
 with color ^.layer_0.shape.color at '(0, 0)
  _01: 
0 . . . . . . . . 0 
0 . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 
 with color ^.layer_01.shape.color at projI(^.layer_01.pos) - (2, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.7 + 1075.3 = 1126.1
DL output with Mo: L = 195.6 + 0.0 = 195.6
DL input+output M: L = 246.3 + 1075.3 = 1321.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . 0 
0 . . . . . . . . 0 
 with color ^.layer_0.shape.color at '(0, 0)
  _01: 
0 . . . . . . . . 0 
0 . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 
 with color ^.layer_01.shape.color at projI(^.layer_01.pos) - (2, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.6 + 0.0 = 50.6
DL output with Mo: L = 195.6 + 0.0 = 195.6
DL input+output M: L = 246.2 + 0.0 = 246.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color pink at (2,2)
  _01: point with color orange at (7,7)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . 0 
0 . . . . . . . . 0 
 with color pink at (0,0)
  _01: 
0 . . . . . . . . 0 
0 . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 
 with color orange at (5,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color pink at (2,2)
  _01: point with color orange at (7,7)
diff: 
correct output grid

TRAIN 1bfc4729.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color blue at (2,6)
  _01: point with color yellow at (7,5)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . 0 
0 . . . . . . . . 0 
 with color blue at (0,0)
  _01: 
0 . . . . . . . . 0 
0 . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 
 with color yellow at (5,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (2,6)
  _01: point with color yellow at (7,5)
diff: 
correct output grid

TRAIN 1bfc4729.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color red at (2,4)
  _01: point with color cyan at (7,6)
diff: 
correct output grid

TEST 1bfc4729.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.8 sec (1.8 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-372] Checking task 1c786137.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 413548.8 = 413551.1
DL output with Mo: L = 2.3 + 56387.5 = 56389.9
DL input+output M: L = 4.6 + 469936.3 = 469941.0

# learning a model for train pairs
2.000	
1.674	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.371	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.228	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
1.140	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.608	OUT SPE ^ = crop(^, ^.layer_0)
0.562	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.533	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.515	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.498	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.482	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.468	IN  ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.455	IN  ADD ^.layer_01111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.455	IN  SPE ^.layer_0.shape.mask.model = Border
0.001	
0.001	IN  DEL ^.layer_01111111
0.001	IN  DEL ^.layer_0111111
0.001	IN  DEL ^.layer_011111
0.001	IN  DEL ^.layer_01111
0.001	IN  DEL ^.layer_0111
0.000	IN  DEL ^.layer_011
0.000	IN  DEL ^.layer_01
0.000	IN  GEN ^.layer_0.shape.mask.model = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
crop(^, ^.layer_0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model Border with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 239.0 + 187750.9 = 187989.9
DL output with Mo: L = 15.0 + 0.0 = 15.0
DL input+output M: L = 254.1 + 187750.9 = 188005.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
crop(^, ^.layer_0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 15.0 + 0.0 = 15.0
DL input+output M: L = 57.0 + 0.0 = 57.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (23,21) and color black and layers
  _0: rectangle with size (8,10) with model Border with color red at (3,4)
  + 328 delta pixels
diff: 
   (0.0 bits)
data: 
0 0 8 0 3 3 3 3 
1 0 0 0 3 0 3 1 
3 3 0 3 3 0 8 1 
3 3 5#1 0 3 0 0 
5#1 3 0 1 3 1 1 
5#0 8 0 3 0 8 8 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (23,21) and color black and layers
  _0: rectangle with size (8,10) with model Border with color red at (3,4)
  + 328 delta pixels
diff: 
correct output grid

TRAIN 1c786137.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (13,16) and color black and layers
  _0: rectangle with size (7,5) with model Border with color yellow at (6,2)
  + 114 delta pixels
diff: 
   (0.0 bits)
data: 
3 3 0 
9#3 9#
6 6 0 
9#0 0 
6 3 9#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,16) and color black and layers
  _0: rectangle with size (7,5) with model Border with color yellow at (6,2)
  + 114 delta pixels
diff: 
correct output grid

TRAIN 1c786137.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (17,18) and color black and layers
  _0: rectangle with size (10,12) with model Border with color cyan at (2,3)
  + 159 delta pixels
diff: 
   (0.0 bits)
data: 
0 0 5#3 3 3 2 2 5#0 
3 0 0 5#5#5#5#2 0 5#
3 5#0 2 0 3 0 5#3 0 
3 2 5#5#0 5#3 0 5#0 
5#2 5#2 5#0 2 2 2 2 
0 5#2 5#0 0 0 0 3 3 
2 3 2 3 0 0 5#0 5#0 
3 2 5#0 5#0 0 0 5#5#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,18) and color black and layers
  _0: rectangle with size (10,12) with model Border with color cyan at (2,3)
  + 159 delta pixels
diff: 
correct output grid

TRAIN 1c786137.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,16) and color cyan and layers
  _0: rectangle with size (10,11) with model Border with color green at (4,3)
  + 152 delta pixels
diff: 
correct output grid

TEST 1c786137.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 9.8 sec (9.8 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-371] Checking task 1caeab9d.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79174.6 = 79177.0
DL output with Mo: L = 2.3 + 79174.6 = 79177.0
DL input+output M: L = 4.6 + 158349.3 = 158353.9

# learning a model for train pairs
2.000	
1.188	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.377	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.329	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.270	OUT ADD ^.layer_0 = ^.layer_0
0.221	IN  ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.166	OUT ADD ^.layer_00 = ^.layer_00.shape at (?,?)
0.116	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.060	OUT ADD ^.layer_01 = ^.layer_01.shape at (?,?)
0.052	OUT SPE ^.size = ^.size
0.049	OUT SPE ^.layer_01.pos = corner(^.layer_0.pos, ^.layer_01.pos)
0.045	OUT SPE ^.layer_00.pos = corner(^.layer_0.pos, ^.layer_00.pos)
0.042	IN  SPE ^.layer_0.shape.color = blue
0.040	IN  SPE ^.layer_00.shape.color = red
0.038	IN  SPE ^.layer_01.shape.color = yellow
0.037	IN  SPE ^.layer_00.shape.mask.model = Full
0.036	IN  SPE ^.layer_0.shape.mask.model = Full
0.035	IN  SPE ^.layer_01.shape.mask.model = Full
0.034	IN  SPE ^.color = black
0.033	OUT SPE ^.color = black
0.002	
0.002	IN  GEN ^.layer_01.shape.color = ?
0.002	IN  GEN ^.layer_00.shape.color = ?
0.002	IN  GEN ^.layer_01.shape.mask.model = ?
0.002	IN  GEN ^.layer_0.shape.mask.model = ?
0.002	IN  GEN ^.layer_00.shape.mask.model = ?
0.002	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_00.shape at corner(^.layer_0.pos, ^.layer_00.pos)
  _0: ^.layer_0
  _01: ^.layer_01.shape at corner(^.layer_0.pos, ^.layer_01.pos)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: rectangle with size (?,?) with model Full with color red at (?,?)
  _0: rectangle with size (?,?) with model Full with color blue at (?,?)
  _01: rectangle with size (?,?) with model Full with color yellow at (?,?)

DL input  with Mi: L = 109.7 + 2446.9 = 2556.6
DL output with Mo: L = 65.9 + 0.0 = 65.9
DL input+output M: L = 175.6 + 2446.9 = 2622.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_00.shape at corner(^.layer_0.pos, ^.layer_00.pos)
  _0: ^.layer_0
  _01: ^.layer_01.shape at corner(^.layer_0.pos, ^.layer_01.pos)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color blue at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 101.4 + 0.0 = 101.4
DL output with Mo: L = 65.9 + 0.0 = 65.9
DL input+output M: L = 167.3 + 0.0 = 167.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (5,10) and color black and layers
  _00: rectangle with size (2,2) with model Full with color red at (0,1)
  _0: rectangle with size (2,2) with model Full with color blue at (1,7)
  _01: rectangle with size (2,2) with model Full with color yellow at (2,4)
diff: 
   (0.0 bits)
data: a background with size (5,10) and color black and layers
  _00: 
2 2 
2 2 
 at (1,1)
  _0: 
1 1 
1 1 
 at (1,7)
  _01: 
4 4 
4 4 
 at (1,4)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,10) and color black and layers
  _00: rectangle with size (2,2) with model Full with color red at (0,1)
  _0: rectangle with size (2,2) with model Full with color blue at (1,7)
  _01: rectangle with size (2,2) with model Full with color yellow at (2,4)
diff: 
correct output grid

TRAIN 1caeab9d.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _00: rectangle with size (2,3) with model Full with color yellow at (0,7)
  _0: rectangle with size (2,3) with model Full with color blue at (5,4)
  _01: rectangle with size (2,3) with model Full with color red at (2,1)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
4 4 4 
4 4 4 
 at (5,7)
  _0: 
1 1 1 
1 1 1 
 at (5,4)
  _01: 
2 2 2 
2 2 2 
 at (5,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (2,3) with model Full with color yellow at (0,7)
  _0: rectangle with size (2,3) with model Full with color blue at (5,4)
  _01: rectangle with size (2,3) with model Full with color red at (2,1)
diff: 
correct output grid

TRAIN 1caeab9d.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (5,10) and color black and layers
  _00: rectangle with size (2,1) with model Full with color red at (1,3)
  _0: rectangle with size (2,1) with model Full with color blue at (2,1)
  _01: rectangle with size (2,1) with model Full with color yellow at (3,6)
diff: 
   (0.0 bits)
data: a background with size (5,10) and color black and layers
  _00: 
2 
2 
 at (2,3)
  _0: 
1 
1 
 at (2,1)
  _01: 
4 
4 
 at (2,6)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,10) and color black and layers
  _00: rectangle with size (2,1) with model Full with color red at (1,3)
  _0: rectangle with size (2,1) with model Full with color blue at (2,1)
  _01: rectangle with size (2,1) with model Full with color yellow at (3,6)
diff: 
correct output grid

TRAIN 1caeab9d.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (3,3) with mask 
. 0 0 
. 0 0 
0 . . 
 with color red at (0,7)
  _0: rectangle with size (3,3) with mask 
. 0 0 
. 0 0 
0 . . 
 with color blue at (2,0)
  _01: rectangle with size (3,3) with mask 
. 0 0 
. 0 0 
0 . . 
 with color yellow at (5,3)
diff: 
correct output grid

TEST 1caeab9d.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 2.4 sec (2.4 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-370] Checking task 1cf80156.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 159366.0 = 159368.4
DL output with Mo: L = 2.3 + 17826.3 = 17828.6
DL input+output M: L = 4.6 + 177192.3 = 177197.0

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = strip(^)
0.069	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.014	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.014	IN  SPE ^.color = black
0.001	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
strip(^)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.1 + 2103.5 = 2145.6
DL output with Mo: L = 9.3 + 0.0 = 9.3
DL input+output M: L = 51.4 + 2103.5 = 2155.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
strip(^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 9.3 + 0.0 = 9.3
DL input+output M: L = 11.6 + 0.0 = 11.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 2 2 2 0 0 0 0 0 
0 0 0 0 0 2 0 0 0 0 0 0 
0 0 0 2 2 2 0 0 0 0 0 0 
0 0 0 2 0 2 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
0 2 2 2 
0 0 2 0 
2 2 2 0 
2 0 2 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 2 2 2 0 0 0 0 0 
0 0 0 0 0 2 0 0 0 0 0 0 
0 0 0 2 2 2 0 0 0 0 0 0 
0 0 0 2 0 2 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 1cf80156.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 1 0 0 0 0 0 0 0 0 0 
0 0 1 1 0 0 0 0 0 0 0 0 
0 0 0 1 0 0 0 0 0 0 0 0 
0 0 1 1 1 0 0 0 0 0 0 0 
0 0 0 0 1 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
1 0 0 
1 1 0 
0 1 0 
1 1 1 
0 0 1 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 1 0 0 0 0 0 0 0 0 0 
0 0 1 1 0 0 0 0 0 0 0 0 
0 0 0 1 0 0 0 0 0 0 0 0 
0 0 1 1 1 0 0 0 0 0 0 0 
0 0 0 0 1 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 1cf80156.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 8 0 8 0 0 0 0 0 
0 0 0 8 8 8 8 0 0 0 0 0 
0 0 0 0 0 0 8 8 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
0 8 0 8 0 
8 8 8 8 0 
0 0 0 8 8 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 8 0 8 0 0 0 0 0 
0 0 0 8 8 8 8 0 0 0 0 0 
0 0 0 0 0 0 8 8 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 1cf80156.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 6 6 6 6 0 0 0 0 
0 0 0 0 6 0 0 0 0 0 0 0 
0 0 6 0 6 0 0 0 0 0 0 0 
0 0 6 6 6 6 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TEST 1cf80156.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 0.8 sec (0.8 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-369] Checking task 1e0a9b12.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 29946.7 = 29949.1
DL output with Mo: L = 2.3 + 29946.7 = 29949.1
DL input+output M: L = 4.6 + 59893.5 = 59898.1

# learning a model for train pairs
2.000	
1.276	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.551	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.478	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.428	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.391	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.365	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.340	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.316	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.294	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.270	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.247	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.231	OUT SPE ^.size = ^.size
0.215	OUT SPE ^.layer_01.shape = coloring(^.layer_01.shape, ^.layer_0111.shape.color)
0.203	OUT SPE ^.layer_0.shape.mask = 
0 
0 

0.199	OUT SPE ^.layer_0111.pos.j = bottom(^.layer_01)
0.192	OUT SPE ^.layer_01.pos = max(^.layer_0111.pos, ^.layer_01111.pos)
0.188	OUT SPE ^.layer_0.pos.j = ^.layer_0111.pos.j - 1
0.184	OUT SPE ^.layer_0111.pos.i = span(^.layer_0111.pos.i, ^.layer_01111.pos.i) + 1
0.181	OUT SPE ^.layer_011.pos.i = span(^.layer_0.pos.i, ^.layer_0111.pos.i)
0.177	OUT SPE ^.layer_011.shape.mask.size.j = 1
0.174	OUT SPE ^.layer_0.pos.i = span(^.layer_0111.pos.i, ^.layer_01111.pos.i)
0.171	OUT SPE ^.layer_011.pos.j = max(^.layer_01.pos.j, ^.layer_011.pos.j) - ^.layer_011.pos.j - ^.layer_0.pos.j
0.168	IN  SPE ^.layer_0.shape.mask.model = Full
0.165	IN  SPE ^.layer_01.shape.mask.model = Full
0.163	OUT SPE ^.layer_011.shape.mask.model = Full
0.160	IN  SPE ^.color = black
0.158	OUT SPE ^.color = black
0.038	
0.038	IN  GEN ^.layer_01.shape.mask.model = ?
0.038	IN  GEN ^.layer_0.shape.mask.model = ?
0.038	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 
0 
 with color ? at (span(^.layer_0111.pos.i, ^.layer_01111.pos.i),^.layer_0111.pos.j - 1)
  _01: coloring(^.layer_01.shape, ^.layer_0111.shape.color) at max(^.layer_0111.pos, ^.layer_01111.pos)
  _011: rectangle with size (?,1) with model Full with color ? at (span(^.layer_0.pos.i, ^.layer_0111.pos.i),max(^.layer_01.pos.j, ^.layer_011.pos.j) - ^.layer_011.pos.j - ^.layer_0.pos.j)
  _0111: point with color ? at (span(^.layer_0111.pos.i, ^.layer_01111.pos.i) + 1,bottom(^.layer_01))
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 125.1 + 3592.8 = 3718.0
DL output with Mo: L = 334.8 + 669.7 = 1004.5
DL input+output M: L = 459.9 + 4262.5 = 4722.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 
0 
 with color ? at (span(^.layer_0111.pos.i, ^.layer_01111.pos.i),^.layer_0111.pos.j - 1)
  _01: coloring(^.layer_01.shape, ^.layer_0111.shape.color) at max(^.layer_0111.pos, ^.layer_01111.pos)
  _011: rectangle with size (?,1) with model Full with color ? at (span(^.layer_0.pos.i, ^.layer_0111.pos.i),max(^.layer_01.pos.j, ^.layer_011.pos.j) - ^.layer_011.pos.j - ^.layer_0.pos.j)
  _0111: point with color ? at (span(^.layer_0111.pos.i, ^.layer_01111.pos.i) + 1,bottom(^.layer_01))
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 124.0 + 20.0 = 144.0
DL output with Mo: L = 334.8 + 669.7 = 1004.5
DL input+output M: L = 458.8 + 689.7 = 1148.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (4,4) and color black and layers
  _0: rectangle with size (1,1) with model Full with color yellow at (0,1)
  _01: rectangle with size (1,1) with model Full with color brown at (0,3)
  _011: point with color yellow at (2,1)
  _0111: point with color pink at (2,2)
  _01111: point with color blue at (3,0)
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: 
0 
0 
 with color yellow at (2,1)
  _01: 
6 
 at (3,2)
  _011: rectangle with size (1,1) with model Full with color brown at (3,3)
  _0111: point with color blue at (3,0)
diff: 
   (20.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (1,1) with model Full with color yellow at (0,1)
  _01: rectangle with size (1,1) with model Full with color brown at (0,3)
  _011: point with color yellow at (2,1)
  _0111: point with color pink at (2,2)
  _01111: point with color blue at (3,0)
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (1,1) with model Full with color yellow at (0,1)
  _01: rectangle with size (1,1) with model Full with color brown at (0,3)
  _011: point with color yellow at (2,1)
  _0111: point with color blue at (3,0)
  _01111: point with color pink at (2,2)
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (1,1) with model Full with color yellow at (0,1)
  _01: rectangle with size (1,1) with model Full with color brown at (0,3)
  _011: point with color pink at (2,2)
  _0111: point with color yellow at (2,1)
  _01111: point with color blue at (3,0)
diff: 
! 5 wrong pixels (generated / expected)

TRAIN 1e0a9b12.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _0: rectangle with size (3,1) with model Full with color yellow at (3,0)
  _01: rectangle with size (2,1) with model Full with color orange at (4,2)
  _011: point with color brown at (0,5)
  _0111: point with color cyan at (1,3)
  _01111: point with color cyan at (4,3)
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _0: 
0 
0 
 with color orange at (4,2)
  _01: 
8 
8 
 at (4,3)
  _011: rectangle with size (3,1) with model Full with color yellow at (3,0)
  _0111: point with color brown at (5,5)
diff: 
   (23.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (3,1) with model Full with color yellow at (3,0)
  _01: rectangle with size (2,1) with model Full with color orange at (4,2)
  _011: point with color brown at (0,5)
  _0111: point with color cyan at (1,3)
  _01111: point with color cyan at (4,3)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (3,1) with model Full with color yellow at (3,0)
  _01: rectangle with size (2,1) with model Full with color orange at (4,2)
  _011: point with color brown at (0,5)
  _0111: point with color cyan at (4,3)
  _01111: point with color cyan at (1,3)
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (3,1) with model Full with color yellow at (3,0)
  _01: rectangle with size (2,1) with model Full with color orange at (4,2)
  _011: point with color cyan at (1,3)
  _0111: point with color brown at (0,5)
  _01111: point with color cyan at (4,3)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 1e0a9b12.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,1) with model Full with color green at (1,1)
  _01: rectangle with size (1,1) with model Full with color blue at (0,3)
  _011: point with color blue at (2,3)
  _0111: point with color red at (2,4)
  _01111: point with color green at (4,1)
  + 1 delta pixels
diff: 
   (2.0 bits)
data: a background with size (5,5) and color black and layers
  _0: 
0 
0 
 with color blue at (3,3)
  _01: 
2 
 at (4,4)
  _011: rectangle with size (3,1) with model Full with color green at (2,1)
  _0111: point with color pink at (4,0)
diff: 
   (23.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,1) with model Full with color green at (1,1)
  _01: rectangle with size (1,1) with model Full with color blue at (0,3)
  _011: point with color blue at (2,3)
  _0111: point with color red at (2,4)
  _01111: point with color pink at (3,0)
  + 1 delta pixels
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,1) with model Full with color green at (1,1)
  _01: rectangle with size (1,1) with model Full with color blue at (0,3)
  _011: point with color blue at (2,3)
  _0111: point with color red at (2,4)
  _01111: point with color green at (4,1)
  + 1 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,1) with model Full with color green at (1,1)
  _01: rectangle with size (1,1) with model Full with color blue at (0,3)
  _011: point with color blue at (2,3)
  _0111: point with color pink at (3,0)
  _01111: point with color red at (2,4)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 1e0a9b12.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,1) with model Full with color grey at (3,0)
  _01: rectangle with size (1,1) with model Full with color red at (0,1)
  _011: point with color yellow at (0,3)
  _0111: point with color green at (0,4)
  _01111: point with color grey at (1,0)
  + 3 delta pixels
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,1) with model Full with color grey at (3,0)
  _01: rectangle with size (1,1) with model Full with color red at (0,1)
  _011: point with color yellow at (0,3)
  _0111: point with color green at (0,4)
  _01111: point with color pink at (2,2)
  + 3 delta pixels
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,1) with model Full with color grey at (3,0)
  _01: rectangle with size (1,1) with model Full with color red at (0,1)
  _011: point with color yellow at (0,3)
  _0111: point with color grey at (1,0)
  _01111: point with color green at (0,4)
  + 3 delta pixels
diff: 
! 10 wrong pixels (generated / expected)

TEST 1e0a9b12.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 22.8 sec (22.8 sec/task)
bits-train-error = 669.7 bits (669.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-368] Checking task 1e32b0e9.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 357321.9 = 357324.2
DL output with Mo: L = 2.3 + 357321.9 = 357324.2
DL input+output M: L = 4.6 + 714643.8 = 714648.5

# learning a model for train pairs
2.000	
1.276	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.686	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.487	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.266	OUT ADD ^.layer_0 = ^.layer_0
0.243	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.223	IN  SPE ^.layer_0.shape.mask = 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 

0.203	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.186	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.165	OUT ADD ^.layer_010 = ^.layer_01
0.153	OUT ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.143	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.131	OUT ADD ^.layer_0111 = ^.layer_011
0.123	OUT ADD ^.layer_001 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.114	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.108	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.103	OUT SPE ^.layer_01.shape.mask = ^.layer_01.shape.mask
0.095	OUT SPE ^.layer_001.shape = coloring(^.layer_01.shape, majorityColor(^))
0.073	
0.072	IN  GEN ^.layer_0.shape.mask = rectangle with size (?,?) with model ?
0.072	IN  DEL ^.layer_0111
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _001: coloring(^.layer_01.shape, majorityColor(^)) at (?,?)
  _0: ^.layer_0
  _010: ^.layer_01
  _01: ^.layer_01.shape.mask with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: ^.layer_011
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
 with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 358.2 + 7973.4 = 8331.6
DL output with Mo: L = 176.9 + 25385.5 = 25562.5
DL input+output M: L = 535.1 + 33359.0 = 33894.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _001: coloring(^.layer_01.shape, majorityColor(^)) at (?,?)
  _0: ^.layer_0
  _010: ^.layer_01
  _01: ^.layer_01.shape.mask with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: ^.layer_011
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 0.0 = 98.1
DL output with Mo: L = 176.9 + 25385.5 = 25562.5
DL input+output M: L = 275.0 + 25385.5 = 25660.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (17,17) and color black and layers
  _0: rectangle with size (17,17) with mask 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (3,3) with model +-cross with color red at (1,1)
  _011: rectangle with size (3,3) with model +-cross with color red at (13,1)
  + 7 delta pixels
diff: 
   (0.0 bits)
data: a background with size (17,17) and color black and layers
  _00: rectangle with size (1,9) with model Full with color cyan at (14,7)
  _001: 
. 8 . 
8 8 8 
. 8 . 
 at (1,7)
  _0: 
. . . . . 8 . . . . . 8 . . . . . 
. . . . . 8 . . . . . 8 . . . . . 
. . . . . 8 . . . . . 8 . . . . . 
. . . . . 8 . . . . . 8 . . . . . 
. . . . . 8 . . . . . 8 . . . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . . . . 8 . . . . . 8 . . . . . 
. . . . . 8 . . . . . 8 . . . . . 
. . . . . 8 . . . . . 8 . . . . . 
. . . . . 8 . . . . . 8 . . . . . 
. . . . . 8 . . . . . 8 . . . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . . . . 8 . . . . . 8 . . . . . 
. . . . . 8 . . . . . 8 . . . . . 
. . . . . 8 . . . . . 8 . . . . . 
. . . . . 8 . . . . . 8 . . . . . 
. . . . . 8 . . . . . 8 . . . . . 
 at (0,0)
  _010: 
. 2 . 
2 2 2 
. 2 . 
 at (1,1)
  _01: 
. 0 . 
0 0 0 
. 0 . 
 with color cyan at (7,1)
  _011: rectangle with size (3,3) with model +-cross with color cyan at (7,13)
  _0111: 
. 2 . 
2 2 2 
. 2 . 
 at (13,1)
  _01111: rectangle with size (3,3) with model Odd Checkboard with color red at (7,7)
  + 13 delta pixels
diff: 
   (708.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (17,17) with mask 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (3,3) with model +-cross with color red at (1,1)
  _011: rectangle with size (3,3) with model +-cross with color red at (13,1)
  + 7 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x17
>> Trial 2
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (3,3) with model +-cross with color red at (1,1)
  _01: rectangle with size (17,17) with mask 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
 with color cyan at (0,0)
  _011: rectangle with size (3,3) with model +-cross with color red at (13,1)
  + 7 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x17

TRAIN 1e32b0e9.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (17,17) and color black and layers
  _0: rectangle with size (17,17) with mask 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
 with color red at (0,0)
  _01: rectangle with size (3,3) with model Full with color blue at (1,1)
  _011: rectangle with size (3,3) with model Odd Checkboard with color blue at (13,7)
  + 5 delta pixels
diff: 
   (0.0 bits)
data: a background with size (17,17) and color black and layers
  _00: rectangle with size (9,3) with model Full with color red at (7,1)
  _001: 
2 2 2 
2 2 2 
2 2 2 
 at (7,7)
  _0: 
. . . . . 2 . . . . . 2 . . . . . 
. . . . . 2 . . . . . 2 . . . . . 
. . . . . 2 . . . . . 2 . . . . . 
. . . . . 2 . . . . . 2 . . . . . 
. . . . . 2 . . . . . 2 . . . . . 
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 
. . . . . 2 . . . . . 2 . . . . . 
. . . . . 2 . . . . . 2 . . . . . 
. . . . . 2 . . . . . 2 . . . . . 
. . . . . 2 . . . . . 2 . . . . . 
. . . . . 2 . . . . . 2 . . . . . 
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 
. . . . . 2 . . . . . 2 . . . . . 
. . . . . 2 . . . . . 2 . . . . . 
. . . . . 2 . . . . . 2 . . . . . 
. . . . . 2 . . . . . 2 . . . . . 
. . . . . 2 . . . . . 2 . . . . . 
 at (0,0)
  _010: 
1 1 1 
1 1 1 
1 1 1 
 at (1,1)
  _01: 
0 0 0 
0 0 0 
0 0 0 
 with color red at (13,13)
  _011: rectangle with size (9,3) with model Full with color red at (1,13)
  _0111: 
. 1 . 
1 . 1 
. 1 . 
 at (13,7)
  _01111: rectangle with size (3,3) with model Full with color red at (1,7)
  + 25 delta pixels
diff: 
   (1201.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (17,17) with mask 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
 with color red at (0,0)
  _01: rectangle with size (3,3) with model Full with color blue at (1,1)
  _011: rectangle with size (3,3) with model Odd Checkboard with color blue at (13,7)
  + 5 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x17
>> Trial 2
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (17,17) with mask 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
 with color red at (0,0)
  _01: rectangle with size (3,3) with model Odd Checkboard with color blue at (13,7)
  _011: rectangle with size (3,3) with model Full with color blue at (1,1)
  + 5 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x17
>> Trial 3
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (3,3) with model Full with color blue at (1,1)
  _01: rectangle with size (17,17) with mask 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
 with color red at (0,0)
  _011: rectangle with size (3,3) with model Odd Checkboard with color blue at (13,7)
  + 5 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x17

TRAIN 1e32b0e9.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (17,17) and color black and layers
  _0: rectangle with size (17,17) with mask 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
 with color blue at (0,0)
  _01: rectangle with size (3,3) with model Odd Checkboard with color green at (1,1)
  _011: rectangle with size (2,2) with model Odd Checkboard with color green at (7,1)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (17,17) and color black and layers
  _00: rectangle with size (3,3) with model Odd Checkboard with color blue at (7,7)
  _001: 
. 1 . 
1 . 1 
. 1 . 
 at (7,13)
  _0: 
. . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
. . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
. . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 
 at (0,0)
  _010: 
. 3 . 
3 . 3 
. 3 . 
 at (1,1)
  _01: 
. 0 . 
0 . 0 
. 0 . 
 with color blue at (13,1)
  _011: rectangle with size (3,3) with model Odd Checkboard with color blue at (13,7)
  _0111: 
. 3 
3 . 
 at (7,1)
  _01111: rectangle with size (3,2) with model Even Checkboard with color blue at (1,8)
  + 11 delta pixels
diff: 
   (628.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (17,17) with mask 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
 with color blue at (0,0)
  _01: rectangle with size (3,3) with model Odd Checkboard with color green at (1,1)
  _011: rectangle with size (2,2) with model Odd Checkboard with color green at (7,1)
  + 4 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x17
>> Trial 2
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (17,17) with mask 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
 with color blue at (0,0)
  _01: rectangle with size (3,3) with model Odd Checkboard with color green at (1,1)
  _011: rectangle with size (2,2) with model Odd Checkboard with color green at (14,14)
  + 4 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x17
>> Trial 3
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (17,17) with mask 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
 with color blue at (0,0)
  _01: rectangle with size (2,2) with model Odd Checkboard with color green at (7,1)
  _011: rectangle with size (3,3) with model Odd Checkboard with color green at (1,1)
  + 4 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x17

TRAIN 1e32b0e9.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (17,17) with mask 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
 with color brown at (0,0)
  _01: rectangle with size (3,3) with model Border with color yellow at (1,1)
  _011: rectangle with size (3,3) with model Odd Checkboard with color yellow at (7,1)
  + 6 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x17
>> Trial 2
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (3,3) with model Border with color yellow at (1,1)
  _01: rectangle with size (17,17) with mask 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 
 with color brown at (0,0)
  _011: rectangle with size (3,3) with model Odd Checkboard with color yellow at (7,1)
  + 6 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x17

TEST 1e32b0e9.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.5 sec (59.5 sec/task)
bits-train-error = 25385.5 bits (25385.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-367] Checking task 1f0c79e5.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 128631.2 = 128633.5
DL output with Mo: L = 2.3 + 128631.2 = 128633.5
DL input+output M: L = 4.6 + 257262.4 = 257267.1

# learning a model for train pairs
2.000	
1.057	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.353	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.095	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.071	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.063	IN  ADD ^.layer_00 = point with color ? at (?,?)
0.057	OUT SPE ^.size = ^.size
0.053	IN  SPE ^.layer_0.shape.mask = 
0 0 
0 0 

0.052	IN  SPE ^.color = black
0.051	OUT SPE ^.color = black
0.032	
0.031	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: point with color ? at (?,?)
  _0: 
0 0 
0 0 
 with color ? at (?,?)

DL input  with Mi: L = 57.6 + 2514.2 = 2571.8
DL output with Mo: L = 38.9 + 3976.0 = 4014.9
DL input+output M: L = 96.5 + 6490.2 = 6586.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 38.9 + 3976.0 = 4014.9
DL input+output M: L = 41.2 + 3976.0 = 4017.3

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 4 2 0 0 0 0 0 
0 0 4 4 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (6,7) with mask 
. . . . 0 0 0 
. . . 0 0 0 . 
. . 0 0 0 . . 
. 0 0 0 . . . 
0 0 0 . . . . 
0 0 . . . . . 
 with color yellow at (0,2)
diff: 
   (78.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 4 2 0 0 0 0 0 
0 0 4 4 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
! 21 wrong pixels (generated / expected)

TRAIN 1f0c79e5.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 
0 0 3 3 0 0 0 0 0 
0 0 3 2 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (8,7) with mask 
0 0 . . . . . 
0 0 0 . . . . 
. 0 0 0 . . . 
. . 0 0 0 . . 
. . . 0 0 0 . 
. . . . 0 0 0 
. . . . . 0 0 
. . . . . . 0 
 with color green at (1,2)
diff: 
   (90.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 
0 0 3 3 0 0 0 0 0 
0 0 3 2 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
! 24 wrong pixels (generated / expected)

TRAIN 1f0c79e5.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 6 2 0 0 0 0 
0 0 0 2 6 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,9) with mask 
. . . . . . 0 0 0 
. . . . . 0 0 0 . 
. . . . 0 0 0 . . 
. . . 0 0 0 . . . 
. . 0 0 0 . . . . 
. 0 0 0 . . . . . 
0 0 0 . . . . . . 
0 0 . . . . . . . 
0 . . . . . . . . 
 with color pink at (0,0)
diff: 
   (110.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 6 2 0 0 0 0 
0 0 0 2 6 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
! 28 wrong pixels (generated / expected)

TRAIN 1f0c79e5.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 2 2 0 0 0 0 
0 0 0 2 7#0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,9) with mask 
0 0 . . . . 0 0 0 
0 0 0 . . 0 0 0 . 
. 0 0 0 0 0 0 . . 
. . 0 0 0 0 . . . 
. . 0 0 0 . . . . 
. 0 0 0 . . . . . 
0 0 0 . . . . . . 
0 0 . . . . . . . 
0 . . . . . . . . 
 with color orange at (0,0)
diff: 
   (118.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 2 2 0 0 0 0 
0 0 0 2 7#0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
! 33 wrong pixels (generated / expected)

TRAIN 1f0c79e5.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 2 2 0 0 
0 0 0 0 0 8 2 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
! 28 wrong pixels (generated / expected)

TEST 1f0c79e5.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 2.3 sec (2.3 sec/task)
bits-train-error = 3976.0 bits (3976.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-366] Checking task 1f642eb9.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.179	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.359	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.241	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.170	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.165	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.155	OUT ADD ^.layer_01 = ^.layer_01
0.148	OUT ADD ^.layer_00 = ^.layer_01.shape at (?,?)
0.142	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.132	OUT ADD ^.layer_011 = ^.layer_011
0.125	OUT ADD ^.layer_001 = ^.layer_011.shape at (?,?)
0.119	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.109	OUT ADD ^.layer_0111 = ^.layer_0111
0.102	OUT ADD ^.layer_000 = ^.layer_0111.shape at (?,?)
0.097	OUT SPE ^.size = ^.size
0.094	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.092	OUT SPE ^.layer_00.pos = ^.layer_01.pos + (3, 0)
0.089	OUT SPE ^.layer_001.pos = max(^.layer_0.pos, ^.layer_011.pos)
0.088	OUT SPE ^.layer_0.shape.mask.size.j = ^.layer_0.shape.mask.size.j
0.086	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.085	IN  SPE ^.layer_0.shape.color = cyan
0.084	OUT SPE ^.layer_000.pos.j = right(^.layer_0)
0.083	OUT SPE ^.layer_000.pos.i = average(^.layer_0.pos.i, ^.layer_0111.pos.i) + ^.layer_01.pos.j - ^.layer_0.pos.j
0.082	IN  SPE ^.layer_0.shape.mask.model = Full
0.082	OUT SPE ^.layer_0.shape.mask.model = Full
0.081	IN  SPE ^.color = black
0.080	OUT SPE ^.color = black
0.039	
0.039	IN  GEN ^.layer_0.shape.color = ?
0.039	IN  GEN ^.layer_0.shape.mask.model = ?
0.039	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _000: ^.layer_0111.shape at (average(^.layer_0.pos.i, ^.layer_0111.pos.i) + ^.layer_01.pos.j - ^.layer_0.pos.j,right(^.layer_0))
  _00: ^.layer_01.shape at ^.layer_01.pos + (3, 0)
  _001: ^.layer_011.shape at max(^.layer_0.pos, ^.layer_011.pos)
  _0: rectangle with size (?,^.layer_0.shape.mask.size.j) with model Full with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: ^.layer_01
  _011: ^.layer_011
  _0111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color cyan at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 100.3 + 4954.2 = 5054.6
DL output with Mo: L = 282.1 + 4279.0 = 4561.1
DL input+output M: L = 382.5 + 9233.2 = 9615.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _000: ^.layer_0111.shape at (average(^.layer_0.pos.i, ^.layer_0111.pos.i) + ^.layer_01.pos.j - ^.layer_0.pos.j,right(^.layer_0))
  _00: ^.layer_01.shape at ^.layer_01.pos + (3, 0)
  _001: ^.layer_011.shape at max(^.layer_0.pos, ^.layer_011.pos)
  _0: rectangle with size (?,^.layer_0.shape.mask.size.j) with model Full with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: ^.layer_01
  _011: ^.layer_011
  _0111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 96.4 + 31.7 = 128.1
DL output with Mo: L = 282.1 + 4279.0 = 4561.1
DL input+output M: L = 378.5 + 4310.7 = 4689.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,2) with model Full with color cyan at (3,4)
  _01: point with color brown at (0,4)
  _011: point with color pink at (6,0)
  _0111: point with color yellow at (9,5)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _000: 
4 
 at (6,5)
  _00: 
9#
 at (3,4)
  _001: 
6 
 at (6,4)
  _0: rectangle with size (3,2) with model Full with color cyan at (3,4)
  _01: 
9#
 at (0,4)
  _011: 
6 
 at (6,0)
  _0111: 
4 
 at (9,5)
diff: 
   (6.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,2) with model Full with color cyan at (3,4)
  _01: point with color brown at (0,4)
  _011: point with color pink at (6,0)
  _0111: point with color yellow at (9,5)
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,2) with model Full with color cyan at (3,4)
  _01: point with color pink at (6,0)
  _011: point with color brown at (0,4)
  _0111: point with color yellow at (9,5)
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 1f642eb9.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,3) with model Full with color cyan at (3,3)
  _01: point with color orange at (0,4)
  _011: point with color pink at (3,0)
  _0111: point with color red at (5,9)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _000: 
2 
 at (5,5)
  _00: 
7#
 at (3,4)
  _001: 
6 
 at (3,3)
  _0: rectangle with size (5,3) with model Full with color cyan at (3,3)
  _01: 
7#
 at (0,4)
  _011: 
6 
 at (3,0)
  _0111: 
2 
 at (5,9)
  + 4 delta pixels
diff: 
   (170.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,3) with model Full with color cyan at (3,3)
  _01: point with color orange at (0,4)
  _011: point with color pink at (3,0)
  _0111: point with color red at (5,9)
  + 2 delta pixels
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,3) with model Full with color cyan at (3,3)
  _01: point with color orange at (0,4)
  _011: point with color pink at (3,0)
  _0111: point with color green at (7,0)
  + 2 delta pixels
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,3) with model Full with color cyan at (3,3)
  _01: point with color orange at (0,4)
  _011: point with color red at (5,9)
  _0111: point with color pink at (3,0)
  + 2 delta pixels
diff: 
! 13 wrong pixels (generated / expected)

TRAIN 1f642eb9.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,3) with model Full with color cyan at (3,3)
  _01: point with color yellow at (0,3)
  _011: point with color green at (4,0)
  _0111: point with color pink at (3,9)
  + 3 delta pixels
diff: 
   (3.2 bits)
data: a background with size (10,10) and color black and layers
  _000: 
6 
 at (3,5)
  _00: 
4 
 at (3,3)
  _001: 
3 
 at (4,3)
  _0: rectangle with size (5,3) with model Full with color cyan at (3,3)
  _01: 
4 
 at (0,3)
  _011: 
3 
 at (4,0)
  _0111: 
6 
 at (3,9)
  + 6 delta pixels
diff: 
   (250.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,3) with model Full with color cyan at (3,3)
  _01: point with color yellow at (0,3)
  _011: point with color green at (4,0)
  _0111: point with color pink at (3,9)
  + 3 delta pixels
diff: 
! 12 wrong pixels (generated / expected)

TRAIN 1f642eb9.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with model Full with color cyan at (3,2)
  _01: point with color pink at (0,3)
  _011: point with color red at (0,5)
  _0111: point with color brown at (3,0)
  + 4 delta pixels
diff: 
! 14 wrong pixels (generated / expected)

TEST 1f642eb9.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 38.3 sec (38.3 sec/task)
bits-train-error = 4279.0 bits (4279.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-365] Checking task 1f85a75f.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 769510.8 = 769513.2
DL output with Mo: L = 2.3 + 9324.9 = 9327.2
DL input+output M: L = 4.6 + 778835.8 = 778840.4

# learning a model for train pairs
2.000	
1.086	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.379	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.209	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.192	OUT SPE ^.layer_0.pos = '(0, 0)
0.178	OUT SPE ^.size.j = 3
0.165	OUT SPE ^.layer_0.shape.mask.size.j = 3
0.156	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.102	OUT SPE ^.layer_0.shape = ^.layer_0.shape
0.087	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.081	OUT SPE ^.color = black
0.079	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.078	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.077	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.076	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.075	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.074	IN  SPE ^.layer_01111.shape.mask = 
0 
0 

0.073	IN  ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.073	IN  SPE ^.layer_011111.shape.mask = 
0 0 

0.071	IN  ADD ^.layer_011110 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.071	IN  SPE ^.layer_011110.shape.mask = 
. 0 
0 . 

0.070	IN  SPE ^.layer_011.shape.mask = 
0 0 

0.070	IN  SPE ^.layer_0111111.shape.mask = 
0 
0 

0.069	IN  SPE ^.layer_0111.shape.mask = 
0 
0 

0.069	IN  SPE ^.color = black
0.004	
0.004	IN  DEL ^.layer_011110
0.004	IN  DEL ^.layer_01
0.004	IN  DEL ^.layer_0111111
0.004	IN  DEL ^.layer_011111
0.004	IN  DEL ^.layer_01111
0.004	IN  DEL ^.layer_0111
0.004	IN  DEL ^.layer_011
0.004	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: ^.layer_0.shape at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: 
0 0 
 with color ? at (?,?)
  _0111: 
0 
0 
 with color ? at (?,?)
  _011110: 
. 0 
0 . 
 with color ? at (?,?)
  _01111: 
0 
0 
 with color ? at (?,?)
  _011111: 
0 0 
 with color ? at (?,?)
  _0111111: 
0 
0 
 with color ? at (?,?)

DL input  with Mi: L = 209.5 + 50033.6 = 50243.1
DL output with Mo: L = 37.8 + 0.0 = 37.8
DL input+output M: L = 247.4 + 50033.6 = 50280.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: ^.layer_0.shape at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 37.8 + 0.0 = 37.8
DL input+output M: L = 79.8 + 0.0 = 79.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (30,30) and color black and layers
  _0: rectangle with size (5,3) with mask 
0 0 . 
0 0 0 
0 . 0 
0 0 0 
. 0 0 
 with color green at (10,17)
  + 92 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,3) and color black and layers
  _0: 
3 3 . 
3 3 3 
3 . 3 
3 3 3 
. 3 3 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (5,3) with mask 
0 0 . 
0 0 0 
0 . 0 
0 0 0 
. 0 0 
 with color green at (10,17)
  + 92 delta pixels
diff: 
correct output grid

TRAIN 1f85a75f.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (30,30) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
. 0 0 
 with color yellow at (9,11)
  + 43 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
. 4 . 
4 4 4 
. 4 4 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
. 0 0 
 with color yellow at (9,11)
  + 43 delta pixels
diff: 
correct output grid

TRAIN 1f85a75f.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 0 0 
0 0 . 0 
0 0 . 0 
. 0 0 0 
 with color red at (12,19)
  + 130 delta pixels
diff: 
correct output grid

TEST 1f85a75f.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 17.5 sec (17.5 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-364] Checking task 1f876c06.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.080	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.253	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.214	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.177	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.149	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.137	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.128	OUT SPE ^.layer_01.shape.mask = 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 

0.123	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.117	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.112	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.106	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.100	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.094	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.089	OUT SPE ^.size = ^.size
0.087	OUT SPE ^.layer_0111.pos = min(^.layer_0.pos, ^.layer_0111.pos)
0.084	OUT SPE ^.layer_0.pos = ^.layer_01.pos
0.083	OUT SPE ^.layer_0111.shape.color = ^.layer_0.shape.color
0.081	OUT SPE ^.layer_0.shape.color = ^.layer_01.shape.color
0.080	OUT SPE ^.layer_011.pos.i = center(^.layer_01111) / '2
0.079	OUT SPE ^.layer_01.shape.color = ^.layer_011111.shape.color
0.078	OUT SPE ^.layer_011.pos.j = min(^.layer_011.pos.j, ^.layer_01111.pos.j) / '3
0.077	OUT SPE ^.layer_01.pos.i = min(^.layer_0111.pos.j, ^.layer_01111.pos.j) + 2
0.076	OUT SPE ^.layer_01.pos.j = span(^.layer_01111.pos.i, ^.layer_011111.pos.i) - ^.layer_011111.pos.j - ^.layer_01.pos.j
0.076	IN  SPE ^.color = black
0.075	OUT SPE ^.color = black
0.031	
0.031	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at ^.layer_01.pos
  _01: 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color ^.layer_011111.shape.color at (min(^.layer_0111.pos.j, ^.layer_01111.pos.j) + 2,span(^.layer_01111.pos.i, ^.layer_011111.pos.i) - ^.layer_011111.pos.j - ^.layer_01.pos.j)
  _011: rectangle with size (?,?) with model ? with color ? at (center(^.layer_01111) / '2,min(^.layer_011.pos.j, ^.layer_01111.pos.j) / '3)
  _0111: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at min(^.layer_0.pos, ^.layer_0111.pos)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)

DL input  with Mi: L = 122.2 + 5307.3 = 5429.5
DL output with Mo: L = 420.3 + 3137.8 = 3558.1
DL input+output M: L = 542.5 + 8445.1 = 8987.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at ^.layer_01.pos
  _01: 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color ^.layer_011111.shape.color at (min(^.layer_0111.pos.j, ^.layer_01111.pos.j) + 2,span(^.layer_01111.pos.i, ^.layer_011111.pos.i) - ^.layer_011111.pos.j - ^.layer_01.pos.j)
  _011: rectangle with size (?,?) with model ? with color ? at (center(^.layer_01111) / '2,min(^.layer_011.pos.j, ^.layer_01111.pos.j) / '3)
  _0111: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at min(^.layer_0.pos, ^.layer_0111.pos)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)

DL input  with Mi: L = 122.1 + 20.0 = 142.1
DL output with Mo: L = 420.3 + 3137.8 = 3558.1
DL input+output M: L = 542.4 + 3157.8 = 3700.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color red at (0,2)
  _01: point with color pink at (0,5)
  _011: point with color red at (2,0)
  _0111: point with color pink at (4,9)
  _01111: point with color yellow at (5,3)
  _011111: point with color yellow at (9,7)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color pink at (0,5)
  _01: 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color yellow at (5,3)
  _011: rectangle with size (1,1) with model Full with color red at (2,0)
  _0111: rectangle with size (1,1) with model Full with color red at (0,2)
  + 1 delta pixels
diff: 
   (102.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color red at (0,2)
  _01: point with color pink at (0,5)
  _011: point with color red at (2,0)
  _0111: point with color pink at (4,9)
  _01111: point with color yellow at (5,3)
  _011111: point with color yellow at (9,7)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color red at (0,2)
  _01: point with color pink at (0,5)
  _011: point with color red at (2,0)
  _0111: point with color pink at (4,9)
  _01111: point with color yellow at (9,7)
  _011111: point with color yellow at (5,3)
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color red at (0,2)
  _01: point with color pink at (0,5)
  _011: point with color red at (2,0)
  _0111: point with color yellow at (5,3)
  _01111: point with color pink at (4,9)
  _011111: point with color yellow at (9,7)
diff: 
! 24 wrong pixels (generated / expected)

TRAIN 1f876c06.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color brown at (0,0)
  _01: point with color green at (0,7)
  _011: point with color cyan at (2,6)
  _0111: point with color green at (2,9)
  _01111: point with color brown at (3,3)
  _011111: point with color orange at (5,5)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
. 0 . 
. . 0 
 with color green at (0,7)
  _01: 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color orange at (5,5)
  _011: rectangle with size (6,6) with mask 
. . . . . 0 
. . . . 0 . 
. . . 0 . . 
. . 0 . . . 
. 0 . . . . 
0 . . . . . 
 with color cyan at (2,1)
  _0111: rectangle with size (4,4) with mask 
0 . . . 
. 0 . . 
. . 0 . 
. . . 0 
 with color brown at (0,0)
diff: 
   (102.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color brown at (0,0)
  _01: point with color green at (0,7)
  _011: point with color cyan at (2,6)
  _0111: point with color green at (2,9)
  _01111: point with color brown at (3,3)
  _011111: point with color orange at (5,5)
  + 2 delta pixels
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color brown at (0,0)
  _01: point with color green at (0,7)
  _011: point with color cyan at (2,6)
  _0111: point with color green at (2,9)
  _01111: point with color brown at (3,3)
  _011111: point with color cyan at (7,1)
  + 2 delta pixels
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color brown at (0,0)
  _01: point with color green at (0,7)
  _011: point with color cyan at (2,6)
  _0111: point with color green at (2,9)
  _01111: point with color orange at (5,5)
  _011111: point with color brown at (3,3)
  + 2 delta pixels
diff: 
! 22 wrong pixels (generated / expected)

TRAIN 1f876c06.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color pink at (0,3)
  _01: point with color cyan at (0,5)
  _011: point with color yellow at (2,2)
  _0111: point with color pink at (3,0)
  _01111: point with color cyan at (4,9)
  _011111: point with color yellow at (6,6)
  + 2 delta pixels
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color cyan at (0,5)
  _01: 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color yellow at (2,2)
  _011: rectangle with size (5,5) with mask 
. . . . 0 
. . . 0 . 
. . 0 . . 
. 0 . . . 
0 . . . . 
 with color brown at (5,0)
  _0111: rectangle with size (4,4) with mask 
. . . 0 
. . 0 . 
. 0 . . 
0 . . . 
 with color pink at (0,0)
diff: 
   (108.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color pink at (0,3)
  _01: point with color cyan at (0,5)
  _011: point with color yellow at (2,2)
  _0111: point with color pink at (3,0)
  _01111: point with color cyan at (4,9)
  _011111: point with color brown at (5,4)
  + 2 delta pixels
diff: 
! 32 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color pink at (0,3)
  _01: point with color cyan at (0,5)
  _011: point with color yellow at (2,2)
  _0111: point with color pink at (3,0)
  _01111: point with color cyan at (4,9)
  _011111: point with color yellow at (6,6)
  + 2 delta pixels
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color pink at (0,3)
  _01: point with color cyan at (0,5)
  _011: point with color yellow at (2,2)
  _0111: point with color pink at (3,0)
  _01111: point with color brown at (5,4)
  _011111: point with color cyan at (4,9)
  + 2 delta pixels
diff: 
! 28 wrong pixels (generated / expected)

TRAIN 1f876c06.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color green at (0,6)
  _01: point with color brown at (0,9)
  _011: point with color orange at (1,0)
  _0111: point with color green at (3,3)
  _01111: point with color brown at (3,6)
  _011111: point with color pink at (4,0)
  + 4 delta pixels
diff: 
! 31 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color green at (0,6)
  _01: point with color brown at (0,9)
  _011: point with color orange at (1,0)
  _0111: point with color green at (3,3)
  _01111: point with color brown at (3,6)
  _011111: point with color yellow at (5,9)
  + 4 delta pixels
diff: 
! 34 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color green at (0,6)
  _01: point with color brown at (0,9)
  _011: point with color orange at (1,0)
  _0111: point with color green at (3,3)
  _01111: point with color pink at (4,0)
  _011111: point with color brown at (3,6)
  + 4 delta pixels
diff: 
! 34 wrong pixels (generated / expected)

TEST 1f876c06.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 53.1 sec (53.1 sec/task)
bits-train-error = 3137.8 bits (3137.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-363] Checking task 1fad071e.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 96473.4 = 96475.7
DL output with Mo: L = 2.3 + 5986.8 = 5989.1
DL input+output M: L = 4.6 + 102460.2 = 102464.8

# learning a model for train pairs
2.000	
1.340	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.699	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.563	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.523	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.484	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.445	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.405	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.366	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.338	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.322	IN  ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.315	IN  ADD ^.layer_01111111 = point with color ? at (?,?)
0.281	OUT SPE ^.layer_0.pos = '(0, 0)
0.253	OUT SPE ^.layer_0.shape.color = blue
0.237	OUT SPE ^.size.i = 1
0.220	OUT SPE ^.layer_0.shape.mask.size.i = 1
0.206	OUT SPE ^.layer_0.shape.mask.model = Full
0.170	OUT SPE ^.size.j = area(^.layer_0.shape) + 1
0.143	OUT SPE ^.layer_0.shape.mask.size.j = ^.layer_011111.shape.mask.size.j * '2
0.131	OUT SPE ^.color = black
0.126	IN  SPE ^.layer_0.shape.mask = 
0 0 
0 0 

0.122	IN  SPE ^.layer_01.shape.mask = 
0 0 
0 0 

0.118	IN  SPE ^.layer_011.shape.mask = 
0 0 
0 0 

0.114	IN  SPE ^.layer_0111.shape.mask = 
0 0 
0 0 

0.110	IN  SPE ^.layer_01111.shape.mask = 
0 0 
0 0 

0.108	IN  SPE ^.layer_01.shape.color = blue
0.106	IN  SPE ^.layer_0111.shape.color = red
0.104	IN  SPE ^.layer_011111.shape.color = blue
0.104	IN  SPE ^.layer_011111.shape.mask.model = Full
0.103	IN  SPE ^.layer_0111111.shape.mask.model = Full
0.102	IN  SPE ^.color = black
0.021	
0.021	IN  DEL ^.layer_0111111
0.020	IN  DEL ^.layer_01111111
0.020	IN  GEN ^.layer_011111.shape.color = ?
0.020	IN  GEN ^.layer_0111.shape.color = ?
0.020	IN  GEN ^.layer_01.shape.color = ?
0.020	IN  GEN ^.layer_011111.shape.mask.model = ?
0.020	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (1,area(^.layer_0.shape) + 1) and color black and layers
  _0: rectangle with size (1,^.layer_011111.shape.mask.size.j * '2) with model Full with color blue at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
0 0 
0 0 
 with color ? at (?,?)
  _01: 
0 0 
0 0 
 with color blue at (?,?)
  _011: 
0 0 
0 0 
 with color ? at (?,?)
  _0111: 
0 0 
0 0 
 with color red at (?,?)
  _01111: 
0 0 
0 0 
 with color ? at (?,?)
  _011111: rectangle with size (?,?) with model Full with color blue at (?,?)
  _0111111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111111: point with color ? at (?,?)

DL input  with Mi: L = 222.3 + 7822.7 = 8045.1
DL output with Mo: L = 110.7 + 0.0 = 110.7
DL input+output M: L = 333.1 + 7822.7 = 8155.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (1,area(^.layer_0.shape) + 1) and color black and layers
  _0: rectangle with size (1,^.layer_011111.shape.mask.size.j * '2) with model Full with color blue at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 0 
0 0 
 with color ? at (?,?)
  _01: 
0 0 
0 0 
 with color ? at (?,?)
  _011: 
0 0 
0 0 
 with color ? at (?,?)
  _0111: 
0 0 
0 0 
 with color ? at (?,?)
  _01111: 
0 0 
0 0 
 with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 166.2 + 0.0 = 166.2
DL output with Mo: L = 110.7 + 0.0 = 110.7
DL input+output M: L = 277.0 + 0.0 = 277.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (0,4)
  _01: 
0 0 
0 0 
 with color blue at (1,1)
  _011: 
0 0 
0 0 
 with color red at (2,7)
  _0111: 
0 0 
0 0 
 with color red at (4,2)
  _01111: 
0 0 
0 0 
 with color blue at (5,5)
  _011111: rectangle with size (1,1) with model Full with color blue at (0,8)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (1,5) and color black and layers
  _0: rectangle with size (1,2) with model Full with color blue at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (0,4)
  _01: 
0 0 
0 0 
 with color blue at (1,1)
  _011: 
0 0 
0 0 
 with color red at (2,7)
  _0111: 
0 0 
0 0 
 with color red at (4,2)
  _01111: 
0 0 
0 0 
 with color blue at (5,5)
  _011111: rectangle with size (1,1) with model Full with color blue at (0,8)
  + 3 delta pixels
diff: 
correct output grid

TRAIN 1fad071e.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: 
0 0 
0 0 
 with color blue at (0,0)
  _01: 
0 0 
0 0 
 with color blue at (1,5)
  _011: 
0 0 
0 0 
 with color blue at (4,1)
  _0111: 
0 0 
0 0 
 with color red at (4,4)
  _01111: 
0 0 
0 0 
 with color red at (7,3)
  _011111: rectangle with size (2,2) with model Full with color blue at (7,6)
  + 6 delta pixels
diff: 
   (0.0 bits)
data: a background with size (1,5) and color black and layers
  _0: rectangle with size (1,4) with model Full with color blue at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: 
0 0 
0 0 
 with color blue at (0,0)
  _01: 
0 0 
0 0 
 with color blue at (1,5)
  _011: 
0 0 
0 0 
 with color blue at (4,1)
  _0111: 
0 0 
0 0 
 with color red at (4,4)
  _01111: 
0 0 
0 0 
 with color red at (7,3)
  _011111: rectangle with size (2,2) with model Full with color blue at (7,6)
  + 6 delta pixels
diff: 
correct output grid

TRAIN 1fad071e.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (0,0)
  _01: 
0 0 
0 0 
 with color blue at (0,3)
  _011: 
0 0 
0 0 
 with color blue at (1,7)
  _0111: 
0 0 
0 0 
 with color red at (3,1)
  _01111: 
0 0 
0 0 
 with color blue at (4,4)
  _011111: rectangle with size (2,2) with model Full with color blue at (7,1)
  + 8 delta pixels
diff: 
   (0.0 bits)
data: a background with size (1,5) and color black and layers
  _0: rectangle with size (1,4) with model Full with color blue at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (0,0)
  _01: 
0 0 
0 0 
 with color blue at (0,3)
  _011: 
0 0 
0 0 
 with color blue at (1,7)
  _0111: 
0 0 
0 0 
 with color red at (3,1)
  _01111: 
0 0 
0 0 
 with color blue at (4,4)
  _011111: rectangle with size (2,2) with model Full with color blue at (7,1)
  + 8 delta pixels
diff: 
correct output grid

TRAIN 1fad071e.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (0,5)
  _01: 
0 0 
0 0 
 with color blue at (1,0)
  _011: 
0 0 
0 0 
 with color blue at (3,5)
  _0111: 
0 0 
0 0 
 with color red at (4,1)
  _01111: 
0 0 
0 0 
 with color red at (6,6)
  _011111: rectangle with size (2,2) with model Full with color red at (7,0)
  + 7 delta pixels
diff: 
! 1 wrong pixels (generated / expected)

TEST 1fad071e.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 21.0 sec (21.0 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-362] Checking task 2013d3e2.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79850.6 = 79852.9
DL output with Mo: L = 2.3 + 7023.2 = 7025.5
DL input+output M: L = 4.6 + 86873.8 = 86878.4

# learning a model for train pairs
2.000	
1.226	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.851	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.776	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.698	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.633	OUT ADD ^.layer_010 = point with color ? at (?,?)
0.570	OUT ADD ^.layer_0101 = point with color ? at (?,?)
0.520	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.485	OUT SPE ^.size = '(3, 3)
0.459	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.431	OUT SPE ^.layer_01.shape.mask = 
0 

0.396	OUT SPE ^.layer_0.shape.mask = fillResizeAlike_strict(transparent, ^.layer_0.shape.mask.size / '2, ^.layer_0.shape.mask)
0.375	OUT SPE ^.layer_011.pos = '(2, 2)
0.354	OUT SPE ^.layer_010.pos = '(1, 1)
0.343	OUT SPE ^.layer_0101.pos.j = 2
0.328	OUT SPE ^.layer_01.shape.color = majorityColor(^)
0.318	OUT SPE ^.layer_0.pos.j = 1
0.308	OUT SPE ^.layer_01.pos.j = '0
0.301	OUT SPE ^.color = black
0.295	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.280	OUT SPE ^.layer_010.shape = ^.layer_01.shape
0.274	IN  ADD ^.layer_010 = point with color ? at (?,?)
0.267	OUT SPE ^.layer_01.pos.i = ^.layer_01.pos.j / '3
0.260	OUT SPE ^.layer_0.pos.i = span(^.layer_0.pos.i, ^.layer_010.pos.i) - 1
0.254	OUT SPE ^.layer_0101.pos.i = span(^.layer_0.pos.i, ^.layer_010.pos.i) - 2
0.248	IN  ADD ^.layer_0101 = point with color ? at (?,?)
0.243	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.228	OUT SPE ^.layer_0101.shape = ^.layer_011.shape
0.222	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.205	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.075	
0.075	IN  DEL ^.layer_01111
0.074	IN  DEL ^.layer_0111
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: fillResizeAlike_strict(transparent, ^.layer_0.shape.mask.size / '2, ^.layer_0.shape.mask) with color ? at (span(^.layer_0.pos.i, ^.layer_010.pos.i) - 1,1)
  _010: ^.layer_01.shape at '(1, 1)
  _0101: ^.layer_011.shape at (span(^.layer_0.pos.i, ^.layer_010.pos.i) - 2,2)
  _01: 
0 
 with color majorityColor(^) at (^.layer_01.pos.j / '3,'0)
  _011: point with color ? at '(2, 2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: point with color ? at (?,?)
  _0101: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 159.3 + 10358.4 = 10517.7
DL output with Mo: L = 288.1 + 225.2 = 513.3
DL input+output M: L = 447.4 + 10583.6 = 11031.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: fillResizeAlike_strict(transparent, ^.layer_0.shape.mask.size / '2, ^.layer_0.shape.mask) with color ? at (span(^.layer_0.pos.i, ^.layer_010.pos.i) - 1,1)
  _010: ^.layer_01.shape at '(1, 1)
  _0101: ^.layer_011.shape at (span(^.layer_0.pos.i, ^.layer_010.pos.i) - 2,2)
  _01: 
0 
 with color majorityColor(^) at (^.layer_01.pos.j / '3,'0)
  _011: point with color ? at '(2, 2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: point with color ? at (?,?)
  _0101: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 114.2 + 0.0 = 114.2
DL output with Mo: L = 288.1 + 225.2 = 513.3
DL input+output M: L = 402.3 + 225.2 = 627.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 0 . 
0 . . 0 
0 . . 0 
. 0 0 . 
 with color cyan at (3,3)
  _010: point with color orange at (2,4)
  _0101: point with color pink at (3,3)
  _01: point with color pink at (3,6)
  _011: point with color orange at (4,2)
  + 12 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
. 0 
0 . 
 with color cyan at (1,1)
  _010: 
6 
 at (1,1)
  _0101: 
7#
 at (0,2)
  _01: 
0 
 with color orange at (2,0)
  _011: point with color yellow at (2,2)
diff: 
   (11.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 0 . 
0 . . 0 
0 . . 0 
. 0 0 . 
 with color cyan at (3,3)
  _010: point with color orange at (2,4)
  _0101: point with color pink at (3,3)
  _01: point with color pink at (3,6)
  _011: point with color orange at (4,2)
  + 12 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 0 . 
0 . . 0 
0 . . 0 
. 0 0 . 
 with color cyan at (3,3)
  _010: point with color orange at (2,4)
  _0101: point with color pink at (3,3)
  _01: point with color pink at (3,6)
  _011: point with color yellow at (4,4)
  + 12 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 0 . 
0 . . 0 
0 . . 0 
. 0 0 . 
 with color cyan at (3,3)
  _010: point with color orange at (2,4)
  _0101: point with color pink at (3,3)
  _01: point with color orange at (4,2)
  _011: point with color pink at (3,6)
  + 12 delta pixels
diff: 
! 7 wrong pixels (generated / expected)

TRAIN 2013d3e2.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color red at (3,3)
  _010: point with color blue at (1,1)
  _0101: point with color blue at (1,6)
  _01: point with color green at (2,2)
  _011: point with color pink at (2,3)
  + 12 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
0 
 with color grey at (2,1)
  _010: 
3 
 at (1,1)
  _0101: 
6 
 at (1,2)
  _01: 
0 
 with color blue at (0,0)
  _011: point with color red at (2,2)
diff: 
   (11.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color red at (3,3)
  _010: point with color blue at (1,1)
  _0101: point with color blue at (1,6)
  _01: point with color green at (2,2)
  _011: point with color pink at (2,3)
  + 12 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color red at (3,3)
  _010: point with color blue at (1,1)
  _0101: point with color blue at (1,6)
  _01: point with color green at (2,2)
  _011: point with color grey at (2,4)
  + 12 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color red at (3,3)
  _010: point with color blue at (1,1)
  _0101: point with color blue at (1,6)
  _01: point with color pink at (2,3)
  _011: point with color green at (2,2)
  + 12 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 2013d3e2.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color green at (4,4)
  _010: point with color cyan at (2,5)
  _0101: point with color yellow at (3,3)
  _01: point with color yellow at (3,6)
  _011: point with color cyan at (4,2)
  + 12 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color green at (4,4)
  _010: point with color cyan at (2,5)
  _0101: point with color yellow at (3,3)
  _01: point with color cyan at (4,2)
  _011: point with color yellow at (3,6)
  + 12 delta pixels
diff: 
! 5 wrong pixels (generated / expected)

TEST 2013d3e2.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 57.6 sec (57.6 sec/task)
bits-train-error = 225.2 bits (225.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-361] Checking task 2204b7a8.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.252	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.504	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.414	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.314	OUT ADD ^.layer_0 = ^.layer_0
0.223	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.123	OUT ADD ^.layer_01 = ^.layer_01
0.118	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.112	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.106	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.101	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.095	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.089	OUT ADD ^.layer_01111 = point with color ? at (?,?)
0.084	OUT SPE ^.size = ^.size
0.080	OUT SPE ^.layer_0111 = coloring(^.layer_0111, majorityColor(^))
0.076	OUT SPE ^.layer_01111 = coloring(^.layer_01111, majorityColor(^))
0.073	OUT SPE ^.layer_011.pos = ^.layer_011.pos
0.071	IN  SPE ^.layer_011.shape.color = green
0.070	IN  SPE ^.layer_0111.shape.color = green
0.069	IN  SPE ^.layer_01111.shape.color = green
0.068	IN  SPE ^.layer_0.shape.mask.model = Full
0.067	IN  SPE ^.layer_01.shape.mask.model = Full
0.067	IN  SPE ^.color = black
0.066	OUT SPE ^.color = black
0.020	
0.020	IN  GEN ^.layer_01111.shape.color = ?
0.020	IN  GEN ^.layer_0111.shape.color = ?
0.020	IN  GEN ^.layer_011.shape.color = ?
0.020	IN  GEN ^.layer_01.shape.mask.model = ?
0.020	IN  GEN ^.layer_0.shape.mask.model = ?
0.020	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_01
  _011: point with color ? at ^.layer_011.pos
  _0111: coloring(^.layer_0111, majorityColor(^))
  _01111: coloring(^.layer_01111, majorityColor(^))
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: point with color green at (?,?)
  _0111: point with color green at (?,?)
  _01111: point with color green at (?,?)

DL input  with Mi: L = 135.1 + 5473.9 = 5609.0
DL output with Mo: L = 71.7 + 2216.7 = 2288.4
DL input+output M: L = 206.8 + 7690.6 = 7897.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_01
  _011: point with color ? at ^.layer_011.pos
  _0111: coloring(^.layer_0111, majorityColor(^))
  _01111: coloring(^.layer_01111, majorityColor(^))
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 124.0 + 0.0 = 124.0
DL output with Mo: L = 71.7 + 2216.7 = 2288.4
DL input+output M: L = 195.7 + 2216.7 = 2412.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color blue at (0,0)
  _01: rectangle with size (10,1) with model Full with color red at (0,9)
  _011: point with color green at (1,6)
  _0111: point with color green at (4,4)
  _01111: point with color green at (6,2)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
1 
1 
1 
1 
1 
1 
1 
1 
1 
1 
 at (0,0)
  _01: 
2 
2 
2 
2 
2 
2 
2 
2 
2 
2 
 at (0,9)
  _011: point with color red at (1,6)
  _0111: 
1 
 at (4,4)
  _01111: 
1 
 at (6,2)
diff: 
   (5.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color blue at (0,0)
  _01: rectangle with size (10,1) with model Full with color red at (0,9)
  _011: point with color green at (1,6)
  _0111: point with color green at (4,4)
  _01111: point with color green at (6,2)
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color blue at (0,0)
  _01: rectangle with size (10,1) with model Full with color red at (0,9)
  _011: point with color green at (4,4)
  _0111: point with color green at (1,6)
  _01111: point with color green at (6,2)
diff: 
! 2 wrong pixels (generated / expected)

TRAIN 2204b7a8.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color yellow at (0,0)
  _01: rectangle with size (1,10) with model Full with color orange at (9,0)
  _011: point with color green at (2,1)
  _0111: point with color green at (2,7)
  _01111: point with color green at (3,3)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
4 4 4 4 4 4 4 4 4 4 
 at (0,0)
  _01: 
7#7#7#7#7#7#7#7#7#7#
 at (9,0)
  _011: point with color yellow at (2,1)
  _0111: 
4 
 at (2,7)
  _01111: 
4 
 at (3,3)
  + 2 delta pixels
diff: 
   (87.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color yellow at (0,0)
  _01: rectangle with size (1,10) with model Full with color orange at (9,0)
  _011: point with color green at (2,1)
  _0111: point with color green at (2,7)
  _01111: point with color green at (3,3)
  + 2 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color yellow at (0,0)
  _01: rectangle with size (1,10) with model Full with color orange at (9,0)
  _011: point with color green at (2,1)
  _0111: point with color green at (2,7)
  _01111: point with color green at (6,4)
  + 2 delta pixels
diff: 
! 4 wrong pixels (generated / expected)

TRAIN 2204b7a8.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color cyan at (0,0)
  _01: rectangle with size (1,10) with model Full with color brown at (9,0)
  _011: point with color green at (2,4)
  _0111: point with color green at (3,1)
  _01111: point with color green at (3,7)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
8 8 8 8 8 8 8 8 8 8 
 at (0,0)
  _01: 
9#9#9#9#9#9#9#9#9#9#
 at (9,0)
  _011: point with color cyan at (2,4)
  _0111: 
8 
 at (3,1)
  _01111: 
8 
 at (3,7)
  + 3 delta pixels
diff: 
   (128.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color cyan at (0,0)
  _01: rectangle with size (1,10) with model Full with color brown at (9,0)
  _011: point with color green at (2,4)
  _0111: point with color green at (3,1)
  _01111: point with color green at (3,7)
  + 3 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color cyan at (0,0)
  _01: rectangle with size (1,10) with model Full with color brown at (9,0)
  _011: point with color green at (2,4)
  _0111: point with color green at (3,1)
  _01111: point with color green at (6,1)
  + 3 delta pixels
diff: 
! 5 wrong pixels (generated / expected)

TRAIN 2204b7a8.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color grey at (0,0)
  _01: rectangle with size (10,1) with model Full with color yellow at (0,9)
  _011: point with color green at (0,1)
  _0111: point with color green at (1,5)
  _01111: point with color green at (1,8)
  + 6 delta pixels
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color grey at (0,0)
  _01: rectangle with size (10,1) with model Full with color yellow at (0,9)
  _011: point with color green at (0,1)
  _0111: point with color green at (1,5)
  _01111: point with color green at (3,3)
  + 6 delta pixels
diff: 
! 8 wrong pixels (generated / expected)

TEST 2204b7a8.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 14.9 sec (14.9 sec/task)
bits-train-error = 2216.7 bits (2216.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-360] Checking task 22168020.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.153	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.445	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.270	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.194	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.123	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.095	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.090	OUT SPE ^.size = ^.size
0.087	OUT SPE ^.layer_01.pos = min(^.layer_0.pos, ^.layer_01.pos)
0.085	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_0.shape.mask.size.i
0.084	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.083	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.082	IN  SPE ^.color = black
0.081	OUT SPE ^.color = black
0.035	
0.035	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i,?) with model ? with color ^.layer_0.shape.color at (?,?)
  _01: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at min(^.layer_0.pos, ^.layer_01.pos)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.3 + 5652.4 = 5722.7
DL output with Mo: L = 85.5 + 3946.5 = 4032.0
DL input+output M: L = 155.9 + 9598.8 = 9754.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i,?) with model ? with color ^.layer_0.shape.color at (?,?)
  _01: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at min(^.layer_0.pos, ^.layer_01.pos)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 40.0 = 110.2
DL output with Mo: L = 85.5 + 3946.5 = 4032.0
DL input+output M: L = 155.7 + 3986.5 = 4142.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color green at (4,4)
  _01: rectangle with size (1,1) with model Full with color green at (1,8)
  + 5 delta pixels
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,6) with model Full with color green at (1,2)
  _01: rectangle with size (5,2) with model Full with color green at (1,4)
  + 4 delta pixels
diff: 
   (201.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color green at (4,4)
  _01: rectangle with size (1,1) with model Full with color green at (1,1)
  + 5 delta pixels
diff: 
! 23 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color green at (4,4)
  _01: rectangle with size (1,1) with model Full with color green at (1,8)
  + 5 delta pixels
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color green at (4,4)
  _01: rectangle with size (1,1) with model Full with color green at (2,2)
  + 5 delta pixels
diff: 
! 22 wrong pixels (generated / expected)

TRAIN 22168020.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,6) with mask 
0 . . . . 0 
. 0 . . 0 . 
. . 0 0 . . 
. . 0 0 . . 
 with color yellow at (6,4)
  _01: rectangle with size (4,6) with mask 
0 . . . . 0 
. 0 . . 0 . 
. . 0 0 . . 
. . 0 0 . . 
 with color blue at (2,0)
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,6) with mask 
0 0 0 0 0 0 
. 0 0 0 0 . 
. . 0 0 . . 
. . 0 0 . . 
 with color yellow at (6,4)
  _01: rectangle with size (4,6) with mask 
0 0 0 0 0 0 
. 0 0 0 0 . 
. . 0 0 . . 
. . 0 0 . . 
 with color blue at (2,0)
diff: 
   (87.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,6) with mask 
0 . . . . 0 
. 0 . . 0 . 
. . 0 0 . . 
. . 0 0 . . 
 with color blue at (2,0)
  _01: rectangle with size (4,6) with mask 
0 . . . . 0 
. 0 . . 0 . 
. . 0 0 . . 
. . 0 0 . . 
 with color yellow at (6,4)
diff: 
! 30 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,6) with mask 
0 . . . . 0 
. 0 . . 0 . 
. . 0 0 . . 
. . 0 0 . . 
 with color yellow at (6,4)
  _01: rectangle with size (4,6) with mask 
0 . . . . 0 
. 0 . . 0 . 
. . 0 0 . . 
. . 0 0 . . 
 with color blue at (2,0)
diff: 
! 33 wrong pixels (generated / expected)

TRAIN 22168020.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,8) with mask 
0 . . . . . . 0 
. 0 . . . . 0 . 
. . 0 . . 0 . . 
. . . 0 0 . . . 
. . . 0 0 . . . 
 with color cyan at (5,1)
  _01: rectangle with size (4,6) with mask 
0 . . . . 0 
. 0 . . 0 . 
. . 0 0 . . 
. . 0 0 . . 
 with color pink at (0,0)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,8) with mask 
0 0 0 0 0 0 0 0 
. 0 0 0 0 0 0 . 
. . 0 0 0 0 . . 
. . . 0 0 . . . 
. . . 0 0 . . . 
 with color cyan at (5,1)
  _01: rectangle with size (4,6) with mask 
0 0 0 0 0 0 
. 0 0 0 0 . 
. . 0 0 . . 
. . 0 0 . . 
 with color pink at (0,0)
diff: 
   (105.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,8) with mask 
0 . . . . . . 0 
. 0 . . . . 0 . 
. . 0 . . 0 . . 
. . . 0 0 . . . 
. . . 0 0 . . . 
 with color cyan at (5,1)
  _01: rectangle with size (4,6) with mask 
0 . . . . 0 
. 0 . . 0 . 
. . 0 0 . . 
. . 0 0 . . 
 with color pink at (0,0)
diff: 
! 43 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,6) with mask 
0 . . . . 0 
. 0 . . 0 . 
. . 0 0 . . 
. . 0 0 . . 
 with color pink at (0,0)
  _01: rectangle with size (5,8) with mask 
0 . . . . . . 0 
. 0 . . . . 0 . 
. . 0 . . 0 . . 
. . . 0 0 . . . 
. . . 0 0 . . . 
 with color cyan at (5,1)
diff: 
! 38 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,8) with mask 
0 . . . . . . 0 
. 0 . . . . 0 . 
. . 0 . . 0 . . 
. . . 0 0 . . . 
. . . 0 0 . . . 
 with color cyan at (5,1)
  _01: rectangle with size (2,2) with model Full with color pink at (2,2)
  + 4 delta pixels
diff: 
! 41 wrong pixels (generated / expected)

TRAIN 22168020.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,6) with mask 
0 . . . . 0 
. 0 . . 0 . 
. . 0 0 . . 
. . 0 0 . . 
 with color orange at (2,4)
  _01: rectangle with size (4,6) with mask 
0 . . . . 0 
. 0 . . 0 . 
. . 0 0 . . 
. . 0 0 . . 
 with color green at (6,1)
  + 6 delta pixels
diff: 
! 40 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,6) with mask 
0 . . . . 0 
. 0 . . 0 . 
. . 0 0 . . 
. . 0 0 . . 
 with color green at (6,1)
  _01: rectangle with size (4,6) with mask 
0 . . . . 0 
. 0 . . 0 . 
. . 0 0 . . 
. . 0 0 . . 
 with color orange at (2,4)
  + 6 delta pixels
diff: 
! 40 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,6) with mask 
0 . . . . 0 
. 0 . . 0 . 
. . 0 0 . . 
. . 0 0 . . 
 with color orange at (2,4)
  _01: rectangle with size (3,4) with mask 
0 . . 0 
. 0 0 . 
. 0 0 . 
 with color yellow at (1,0)
  + 8 delta pixels
diff: 
! 40 wrong pixels (generated / expected)

TEST 22168020.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 6.6 sec (6.6 sec/task)
bits-train-error = 3946.5 bits (3946.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-359] Checking task 22233c11.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.053	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.146	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.116	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.076	OUT ADD ^.layer_0 = ^.layer_0
0.060	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.054	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.049	OUT SPE ^.size = ^.size
0.047	OUT SPE ^.layer_01.shape.mask.size = ^.layer_0.shape.mask.size / '2
0.045	IN  SPE ^.layer_0.shape.color = green
0.044	OUT SPE ^.layer_01.shape.color = cyan
0.043	OUT SPE ^.layer_01.pos.j = right(^.layer_0) + 1
0.042	OUT SPE ^.layer_01.shape.mask.model = Full
0.041	IN  SPE ^.color = black
0.041	OUT SPE ^.color = black
0.020	
0.020	IN  GEN ^.layer_0.shape.color = ?
0.020	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size ^.layer_0.shape.mask.size / '2 with model Full with color cyan at (?,right(^.layer_0) + 1)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color green at (?,?)

DL input  with Mi: L = 45.4 + 2434.4 = 2479.8
DL output with Mo: L = 118.2 + 2285.0 = 2403.2
DL input+output M: L = 163.6 + 4719.4 = 4883.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size ^.layer_0.shape.mask.size / '2 with model Full with color cyan at (?,right(^.layer_0) + 1)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 118.2 + 2285.0 = 2403.2
DL input+output M: L = 160.2 + 2285.0 = 2445.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Even Checkboard with color green at (3,2)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
3 . 
. 3 
 at (3,2)
  _01: rectangle with size (1,1) with model Full with color cyan at (2,4)
  _011: rectangle with size (2,2) with model Odd Checkboard with color green at (6,6)
  + 3 delta pixels
diff: 
   (162.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Even Checkboard with color green at (3,2)
  + 2 delta pixels
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Odd Checkboard with color green at (6,6)
  + 2 delta pixels
diff: 
! 11 wrong pixels (generated / expected)

TRAIN 22233c11.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . 0 0 
. . 0 0 
0 0 . . 
0 0 . . 
 with color green at (3,1)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
. . 3 3 
. . 3 3 
3 3 . . 
3 3 . . 
 at (3,1)
  _01: rectangle with size (2,2) with model Full with color cyan at (7,5)
  _011: rectangle with size (2,1) with model Full with color cyan at (1,0)
diff: 
   (34.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . 0 0 
. . 0 0 
0 0 . . 
0 0 . . 
 with color green at (3,1)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color green at (3,3)
  + 4 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color green at (5,1)
  + 4 delta pixels
diff: 
! 14 wrong pixels (generated / expected)

TRAIN 22233c11.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Even Checkboard with color green at (3,3)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
3 . 
. 3 
 at (3,3)
  _01: rectangle with size (1,1) with model Full with color cyan at (2,5)
  _011: rectangle with size (1,1) with model Full with color cyan at (5,2)
diff: 
   (32.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Even Checkboard with color green at (3,3)
diff: 
! 7 wrong pixels (generated / expected)

TRAIN 22233c11.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,6) with mask 
. . . 0 0 0 
. . . 0 0 0 
. . . 0 0 0 
0 0 0 . . . 
0 0 0 . . . 
0 0 0 . . . 
 with color green at (2,3)
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Full with color green at (2,6)
  + 9 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Full with color green at (5,3)
  + 9 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TEST 22233c11.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 6.4 sec (6.4 sec/task)
bits-train-error = 2285.0 bits (2285.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-358] Checking task 2281f1f4.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.076	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.279	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.257	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.244	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.225	OUT ADD ^.layer_01 = ^.layer_0
0.212	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.203	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.195	OUT SPE ^.layer_0111.shape = coloring(^.layer_0.shape, red)
0.189	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.176	OUT ADD ^.layer_010 = ^.layer_01
0.170	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.164	OUT ADD ^.layer_0110 = ^.layer_011
0.157	OUT ADD ^.layer_01111 = ^.layer_011.shape at (?,?)
0.151	OUT ADD ^.layer_01110 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.145	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.140	OUT SPE ^.size = ^.size
0.137	OUT SPE ^.layer_01111 = ^.layer_0111
0.135	OUT SPE ^.layer_01110.shape.color = red
0.134	IN  SPE ^.layer_0.shape.color = grey
0.133	IN  SPE ^.layer_01.shape.color = grey
0.131	IN  SPE ^.layer_011.shape.color = grey
0.130	IN  SPE ^.layer_0111.shape.color = grey
0.129	OUT SPE ^.layer_0.shape.color = red
0.127	OUT SPE ^.layer_011.shape.color = red
0.126	OUT SPE ^.layer_01110.pos.i = ^.layer_0111.pos.i
0.121	OUT SPE ^.layer_0.pos.j = ^.layer_0.pos.j
0.119	OUT SPE ^.layer_0111.pos.j = ^.layer_0.pos.j
0.118	OUT SPE ^.layer_011.pos.j = ^.layer_01.pos.i + 3
0.117	OUT SPE ^.layer_011.shape.mask.size.i = area(^.layer_01.shape)
0.116	OUT SPE ^.layer_01110.shape.mask.size.i = 1
0.115	OUT SPE ^.layer_011.pos.i = span(^.layer_011.pos.i, ^.layer_0111.pos.i) - 1
0.114	OUT SPE ^.layer_0111.pos.i = center(^.layer_011) - area(^.layer_01.shape)
0.114	OUT SPE ^.layer_0.shape.mask.size.i = area(^.layer_01.shape)
0.074	
0.074	IN  GEN ^.layer_0111.shape.color = ?
0.074	IN  GEN ^.layer_011.shape.color = ?
0.074	IN  GEN ^.layer_01.shape.color = ?
0.074	IN  GEN ^.layer_0.shape.color = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (area(^.layer_01.shape),?) with model ? with color red at (?,^.layer_0.pos.j)
  _010: ^.layer_01
  _01: ^.layer_0
  _0110: ^.layer_011
  _011: rectangle with size (area(^.layer_01.shape),?) with model ? with color red at (span(^.layer_011.pos.i, ^.layer_0111.pos.i) - 1,^.layer_01.pos.i + 3)
  _01110: rectangle with size (1,?) with model ? with color red at (^.layer_0111.pos.i,?)
  _0111: coloring(^.layer_0.shape, red) at (center(^.layer_011) - area(^.layer_01.shape),^.layer_0.pos.j)
  _01111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)
  _01: rectangle with size (?,?) with model ? with color grey at (?,?)
  _011: point with color grey at (?,?)
  _0111: point with color grey at (?,?)

DL input  with Mi: L = 119.4 + 4770.7 = 4890.1
DL output with Mo: L = 305.8 + 8400.1 = 8705.9
DL input+output M: L = 425.3 + 13170.8 = 13596.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (area(^.layer_01.shape),?) with model ? with color red at (?,^.layer_0.pos.j)
  _010: ^.layer_01
  _01: ^.layer_0
  _0110: ^.layer_011
  _011: rectangle with size (area(^.layer_01.shape),?) with model ? with color red at (span(^.layer_011.pos.i, ^.layer_0111.pos.i) - 1,^.layer_01.pos.i + 3)
  _01110: rectangle with size (1,?) with model ? with color red at (^.layer_0111.pos.i,?)
  _0111: coloring(^.layer_0.shape, red) at (center(^.layer_011) - area(^.layer_01.shape),^.layer_0.pos.j)
  _01111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 106.2 + 20.0 = 126.2
DL output with Mo: L = 305.8 + 8400.1 = 8705.9
DL input+output M: L = 412.0 + 8420.1 = 8832.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color grey at (0,0)
  _01: rectangle with size (1,1) with model Full with color grey at (0,3)
  _011: point with color grey at (0,7)
  _0111: point with color grey at (3,9)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (3,0)
  _010: 
5#
 at (0,3)
  _01: 
5#
 at (0,0)
  _0110: 
5#
 at (0,7)
  _011: rectangle with size (1,1) with model Full with color red at (3,3)
  _01110: rectangle with size (1,1) with model Full with color red at (3,7)
  _0111: 
2 
 at (7,0)
  _01111: 
5#
 at (3,9)
  + 3 delta pixels
diff: 
   (154.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color grey at (0,0)
  _01: rectangle with size (1,1) with model Full with color grey at (0,3)
  _011: point with color grey at (0,7)
  _0111: point with color grey at (3,9)
  + 1 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color grey at (0,0)
  _01: rectangle with size (1,1) with model Full with color grey at (0,3)
  _011: point with color grey at (0,7)
  _0111: point with color grey at (7,9)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color grey at (0,0)
  _01: rectangle with size (1,1) with model Full with color grey at (0,3)
  _011: point with color grey at (3,9)
  _0111: point with color grey at (0,7)
  + 1 delta pixels
diff: 
! 10 wrong pixels (generated / expected)

TRAIN 2281f1f4.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,2) with model Full with color grey at (0,3)
  _01: rectangle with size (1,1) with model Full with color grey at (0,1)
  _011: point with color grey at (0,7)
  _0111: point with color grey at (2,9)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (4,3)
  _010: 
5#
 at (0,1)
  _01: 
5#5#
 at (0,3)
  _0110: 
5#
 at (0,7)
  _011: rectangle with size (1,2) with model Full with color red at (2,3)
  _01110: rectangle with size (1,1) with model Full with color red at (2,1)
  _0111: 
2 2 
 at (7,3)
  _01111: 
5#
 at (2,9)
  + 7 delta pixels
diff: 
   (318.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,2) with model Full with color grey at (0,3)
  _01: rectangle with size (1,1) with model Full with color grey at (0,1)
  _011: point with color grey at (0,7)
  _0111: point with color grey at (2,9)
  + 2 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,2) with model Full with color grey at (0,3)
  _01: rectangle with size (1,1) with model Full with color grey at (0,1)
  _011: point with color grey at (0,7)
  _0111: point with color grey at (4,9)
  + 2 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,2) with model Full with color grey at (0,3)
  _01: rectangle with size (1,1) with model Full with color grey at (0,1)
  _011: point with color grey at (2,9)
  _0111: point with color grey at (0,7)
  + 2 delta pixels
diff: 
! 17 wrong pixels (generated / expected)

TRAIN 2281f1f4.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,7) with model Full with color grey at (0,2)
  _01: rectangle with size (2,1) with model Full with color grey at (2,9)
  _011: point with color grey at (8,9)
  _0111: point with color grey at (6,9)
  + 2 delta pixels
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color red at (2,2)
  _010: 
5#
5#
 at (2,9)
  _01: 
5#5#5#5#5#5#5#
 at (0,2)
  _0110: 
5#
 at (8,9)
  _011: rectangle with size (2,4) with model Full with color red at (2,5)
  _01110: rectangle with size (1,7) with model Full with color red at (6,2)
  _0111: 
2 2 2 2 2 2 2 
 at (8,2)
  _01111: 
5#
 at (6,9)
  + 8 delta pixels
diff: 
   (366.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,7) with model Full with color grey at (0,2)
  _01: rectangle with size (2,1) with model Full with color grey at (2,9)
  _011: point with color grey at (6,9)
  _0111: point with color grey at (8,9)
  + 2 delta pixels
diff: 
! 25 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,7) with model Full with color grey at (0,2)
  _01: rectangle with size (2,1) with model Full with color grey at (2,9)
  _011: point with color grey at (8,9)
  _0111: point with color grey at (6,9)
  + 2 delta pixels
diff: 
! 25 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,1) with model Full with color grey at (2,9)
  _01: rectangle with size (1,7) with model Full with color grey at (0,2)
  _011: point with color grey at (6,9)
  _0111: point with color grey at (8,9)
  + 2 delta pixels
diff: 
! 37 wrong pixels (generated / expected)

TRAIN 2281f1f4.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
undefined expression: Span: same int

TEST 2281f1f4.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 59.4 sec (59.4 sec/task)
bits-train-error = 8400.1 bits (8400.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-357] Checking task 228f6490.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.513	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.027	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.750	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.536	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.428	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.350	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.302	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.269	OUT ADD ^.layer_010 = ^.layer_01.shape at (?,?)
0.234	IN  ADD ^.layer_010 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.208	OUT ADD ^.layer_00 = ^.layer_0
0.177	OUT ADD ^.layer_001 = ^.layer_010
0.155	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.135	OUT ADD ^.layer_011 = ^.layer_0111
0.122	IN  ADD ^.layer_01110 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.114	OUT ADD ^.layer_0111 = ^.layer_011.shape at (?,?)
0.108	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.101	OUT SPE ^.layer_01 = ^.layer_01111
0.096	OUT SPE ^.size = ^.size
0.091	OUT SPE ^.layer_0.shape = ^.layer_01110.shape
0.089	OUT SPE ^.layer_0.pos = max(^.layer_01.pos, ^.layer_01110.pos)
0.088	IN  SPE ^.layer_0.shape.color = grey
0.086	IN  SPE ^.layer_010.shape.color = grey
0.085	OUT SPE ^.layer_010.pos.j = ^.layer_01.pos.j + 1
0.084	OUT SPE ^.layer_010.pos.i = center(^.layer_0) + ^.layer_01111.pos.i - ^.layer_010.pos.i
0.083	OUT SPE ^.layer_0111.pos.j = bottom(^.layer_0) - ^.layer_01111.pos.i - ^.layer_01.pos.i
0.082	IN  SPE ^.color = black
0.082	OUT SPE ^.color = black
0.013	
0.013	IN  GEN ^.layer_010.shape.color = ?
0.013	IN  GEN ^.layer_0.shape.color = ?
0.013	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _001: ^.layer_010
  _0: ^.layer_01110.shape at max(^.layer_01.pos, ^.layer_01110.pos)
  _010: ^.layer_01.shape at (center(^.layer_0) + ^.layer_01111.pos.i - ^.layer_010.pos.i,^.layer_01.pos.j + 1)
  _01: ^.layer_01111
  _011: ^.layer_0111
  _0111: ^.layer_011.shape at (?,bottom(^.layer_0) - ^.layer_01111.pos.i - ^.layer_01.pos.i)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)
  _010: rectangle with size (?,?) with model ? with color grey at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01110: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 205.3 + 8293.3 = 8498.6
DL output with Mo: L = 289.0 + 999.8 = 1288.8
DL input+output M: L = 494.3 + 9293.0 = 9787.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _001: ^.layer_010
  _0: ^.layer_01110.shape at max(^.layer_01.pos, ^.layer_01110.pos)
  _010: ^.layer_01.shape at (center(^.layer_0) + ^.layer_01111.pos.i - ^.layer_010.pos.i,^.layer_01.pos.j + 1)
  _01: ^.layer_01111
  _011: ^.layer_0111
  _0111: ^.layer_011.shape at (?,bottom(^.layer_0) - ^.layer_01111.pos.i - ^.layer_01.pos.i)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01110: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 198.5 + 31.7 = 230.2
DL output with Mo: L = 289.0 + 999.8 = 1288.8
DL input+output M: L = 487.5 + 1031.5 = 1519.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 . . 0 0 
0 . . 0 0 
0 0 0 0 0 
0 0 0 0 0 
 with color grey at (1,1)
  _010: rectangle with size (3,5) with mask 
0 0 0 0 0 
0 0 . . 0 
0 0 0 0 0 
 with color grey at (7,5)
  _01: rectangle with size (2,2) with model Full with color cyan at (8,1)
  _011: rectangle with size (1,2) with model Full with color orange at (0,8)
  _01110: rectangle with size (1,2) with model Full with color pink at (2,7)
  _0111: rectangle with size (1,1) with model Full with color orange at (0,0)
  _01111: point with color orange at (5,8)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
5#5#5#5#5#
5#. . 5#5#
5#. . 5#5#
5#5#5#5#5#
5#5#5#5#5#
 at (1,1)
  _001: 
5#5#5#5#5#
5#5#. . 5#
5#5#5#5#5#
 at (7,5)
  _0: 
6 6 
 at (8,7)
  _010: 
8 8 
8 8 
 at (2,2)
  _01: 
7#
 at (5,8)
  _011: 
7#
 at (0,0)
  _0111: 
7#7#
 at (0,8)
  + 1 delta pixels
diff: 
   (47.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 . . 0 0 
0 . . 0 0 
0 0 0 0 0 
0 0 0 0 0 
 with color grey at (1,1)
  _010: rectangle with size (3,5) with mask 
0 0 0 0 0 
0 0 . . 0 
0 0 0 0 0 
 with color grey at (7,5)
  _01: rectangle with size (2,2) with model Full with color cyan at (8,1)
  _011: rectangle with size (1,2) with model Full with color orange at (0,8)
  _01110: rectangle with size (1,2) with model Full with color pink at (2,7)
  _0111: rectangle with size (1,1) with model Full with color orange at (0,0)
  _01111: point with color orange at (5,8)
  + 1 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 . . 0 0 
0 . . 0 0 
0 0 0 0 0 
0 0 0 0 0 
 with color grey at (1,1)
  _010: rectangle with size (3,5) with mask 
0 0 0 0 0 
0 0 . . 0 
0 0 0 0 0 
 with color grey at (7,5)
  _01: rectangle with size (2,2) with model Full with color cyan at (8,1)
  _011: rectangle with size (1,2) with model Full with color orange at (0,8)
  _01110: rectangle with size (1,2) with model Full with color pink at (2,7)
  _0111: rectangle with size (1,1) with model Full with color orange at (0,0)
  _01111: point with color orange at (7,4)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 . . 0 0 
0 . . 0 0 
0 0 0 0 0 
0 0 0 0 0 
 with color grey at (1,1)
  _010: rectangle with size (3,5) with mask 
0 0 0 0 0 
0 0 . . 0 
0 0 0 0 0 
 with color grey at (7,5)
  _01: rectangle with size (2,2) with model Full with color cyan at (8,1)
  _011: rectangle with size (1,2) with model Full with color orange at (0,8)
  _01110: rectangle with size (1,2) with model Full with color pink at (2,7)
  _0111: rectangle with size (1,1) with model Full with color orange at (5,8)
  _01111: point with color orange at (0,0)
  + 1 delta pixels
diff: 
! 7 wrong pixels (generated / expected)

TRAIN 228f6490.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,5) with mask 
0 0 0 0 0 
0 . . . 0 
0 0 0 . 0 
0 0 0 0 0 
 with color grey at (0,0)
  _010: rectangle with size (4,6) with model Border with color grey at (6,3)
  _01: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color green at (5,0)
  _011: rectangle with size (2,4) with model Full with color brown at (1,6)
  _01110: rectangle with size (2,2) with model Full with color pink at (8,0)
  _0111: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color pink at (4,6)
  _01111: point with color pink at (4,9)
diff: 
   (3.2 bits)
data: a background with size (10,10) and color black and layers
  _00: 
5#5#5#5#5#
5#. . . 5#
5#5#5#. 5#
5#5#5#5#5#
 at (0,0)
  _001: 
5#5#5#5#5#5#
5#. . . . 5#
5#. . . . 5#
5#5#5#5#5#5#
 at (6,3)
  _0: 
6 6 
6 6 
 at (8,0)
  _010: 
3 3 3 
. . 3 
 at (1,1)
  _01: 
6 
 at (4,9)
  _011: 
. 6 
6 6 
 at (4,6)
  _0111: 
9#9#9#9#
9#9#9#9#
 at (7,4)
diff: 
   (5.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,5) with mask 
0 0 0 0 0 
0 . . . 0 
0 0 0 . 0 
0 0 0 0 0 
 with color grey at (0,0)
  _010: rectangle with size (4,6) with model Border with color grey at (6,3)
  _01: rectangle with size (2,4) with model Full with color brown at (1,6)
  _011: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color green at (5,0)
  _01110: rectangle with size (2,2) with model Full with color pink at (8,0)
  _0111: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color pink at (4,6)
  _01111: point with color pink at (4,9)
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,5) with mask 
0 0 0 0 0 
0 . . . 0 
0 0 0 . 0 
0 0 0 0 0 
 with color grey at (0,0)
  _010: rectangle with size (4,6) with model Border with color grey at (6,3)
  _01: rectangle with size (2,4) with model Full with color brown at (1,6)
  _011: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color green at (5,0)
  _01110: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color pink at (4,6)
  _0111: rectangle with size (2,2) with model Full with color pink at (8,0)
  _01111: point with color pink at (4,9)
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,5) with mask 
0 0 0 0 0 
0 . . . 0 
0 0 0 . 0 
0 0 0 0 0 
 with color grey at (0,0)
  _010: rectangle with size (4,6) with model Border with color grey at (6,3)
  _01: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color green at (5,0)
  _011: rectangle with size (2,4) with model Full with color brown at (1,6)
  _01110: rectangle with size (2,2) with model Full with color pink at (8,0)
  _0111: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color pink at (4,6)
  _01111: point with color pink at (4,9)
diff: 
! 14 wrong pixels (generated / expected)

TRAIN 228f6490.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 . . 0 0 
0 . . . 0 
0 0 0 0 0 
 with color grey at (5,0)
  _010: rectangle with size (4,6) with mask 
0 0 0 0 0 0 
0 . . . 0 0 
0 0 0 . . 0 
0 0 0 0 0 0 
 with color grey at (0,4)
  _01: rectangle with size (2,3) with mask 
0 0 . 
0 0 0 
 with color red at (0,0)
  _011: rectangle with size (2,4) with mask 
0 0 0 . 
. . 0 0 
 with color cyan at (8,6)
  _01110: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color yellow at (3,1)
  _0111: rectangle with size (1,2) with model Full with color yellow at (5,7)
  _01111: point with color yellow at (4,5)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
5#5#5#5#5#
5#5#5#5#5#
5#. . 5#5#
5#. . . 5#
5#5#5#5#5#
 at (5,0)
  _001: 
5#5#5#5#5#5#
5#. . . 5#5#
5#5#5#. . 5#
5#5#5#5#5#5#
 at (0,4)
  _0: 
4 4 
. 4 
 at (3,1)
  _010: 
2 2 . 
2 2 2 
 at (7,1)
  _01: 
4 
 at (4,5)
  _011: 
4 4 
 at (5,7)
  _0111: 
8 8 8 . 
. . 8 8 
 at (1,5)
  + 1 delta pixels
diff: 
   (47.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 . . 0 0 
0 . . . 0 
0 0 0 0 0 
 with color grey at (5,0)
  _010: rectangle with size (4,6) with mask 
0 0 0 0 0 0 
0 . . . 0 0 
0 0 0 . . 0 
0 0 0 0 0 0 
 with color grey at (0,4)
  _01: rectangle with size (2,3) with mask 
0 0 . 
0 0 0 
 with color red at (0,0)
  _011: rectangle with size (2,4) with mask 
0 0 0 . 
. . 0 0 
 with color cyan at (8,6)
  _01110: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color yellow at (3,1)
  _0111: rectangle with size (1,2) with model Full with color yellow at (5,7)
  _01111: point with color yellow at (4,5)
  + 1 delta pixels
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 . . 0 0 
0 . . . 0 
0 0 0 0 0 
 with color grey at (5,0)
  _010: rectangle with size (4,6) with mask 
0 0 0 0 0 0 
0 . . . 0 0 
0 0 0 . . 0 
0 0 0 0 0 0 
 with color grey at (0,4)
  _01: rectangle with size (2,3) with mask 
0 0 . 
0 0 0 
 with color red at (0,0)
  _011: rectangle with size (2,4) with mask 
0 0 0 . 
. . 0 0 
 with color cyan at (8,6)
  _01110: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color yellow at (3,1)
  _0111: rectangle with size (1,2) with model Full with color yellow at (5,7)
  _01111: point with color yellow at (7,9)
  + 1 delta pixels
diff: 
! 12 wrong pixels (generated / expected)

TRAIN 228f6490.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 . . . 0 
0 0 . 0 0 
0 0 0 0 0 
0 0 0 0 0 
 with color grey at (0,2)
  _010: rectangle with size (3,7) with mask 
0 0 0 0 0 0 0 
0 . . . 0 0 0 
0 0 0 0 0 0 0 
 with color grey at (7,3)
  _01: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color orange at (5,0)
  _011: rectangle with size (1,3) with model Full with color yellow at (2,7)
  _01110: rectangle with size (1,3) with model Full with color red at (5,5)
  _0111: rectangle with size (2,2) with model Odd Checkboard with color red at (8,0)
  _01111: point with color red at (0,9)
  + 3 delta pixels
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 . . . 0 
0 0 . 0 0 
0 0 0 0 0 
0 0 0 0 0 
 with color grey at (0,2)
  _010: rectangle with size (3,7) with mask 
0 0 0 0 0 0 0 
0 . . . 0 0 0 
0 0 0 0 0 0 0 
 with color grey at (7,3)
  _01: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color orange at (5,0)
  _011: rectangle with size (1,3) with model Full with color red at (5,5)
  _01110: rectangle with size (1,3) with model Full with color yellow at (2,7)
  _0111: rectangle with size (2,2) with model Odd Checkboard with color red at (8,0)
  _01111: point with color red at (0,9)
  + 3 delta pixels
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 . . . 0 
0 0 . 0 0 
0 0 0 0 0 
0 0 0 0 0 
 with color grey at (0,2)
  _010: rectangle with size (3,7) with mask 
0 0 0 0 0 0 0 
0 . . . 0 0 0 
0 0 0 0 0 0 0 
 with color grey at (7,3)
  _01: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color orange at (5,0)
  _011: rectangle with size (1,3) with model Full with color red at (5,5)
  _01110: rectangle with size (2,2) with model Odd Checkboard with color red at (8,0)
  _0111: rectangle with size (1,3) with model Full with color yellow at (2,7)
  _01111: point with color red at (0,9)
  + 3 delta pixels
diff: 
! 14 wrong pixels (generated / expected)

TEST 228f6490.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 38.3 sec (38.3 sec/task)
bits-train-error = 999.8 bits (999.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-356] Checking task 22eb0ac0.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.093	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.266	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.204	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.172	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.166	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.160	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.155	OUT ADD ^.layer_01111 = point with color ? at (?,?)
0.149	OUT ADD ^.layer_011111 = point with color ? at (?,?)
0.143	OUT ADD ^.layer_0111111 = point with color ? at (?,?)
0.138	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.132	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.126	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.121	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.115	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.109	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.051	
0.050	IN  GEN ^ = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)

DL input  with Mi: L = 122.1 + 6988.4 = 7110.4
DL output with Mo: L = 159.3 + 5822.9 = 5982.2
DL input+output M: L = 281.4 + 12811.2 = 13092.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 159.3 + 5822.9 = 5982.2
DL input+output M: L = 161.6 + 5822.9 = 5984.5

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 
9#0 0 0 0 0 0 0 0 6 
0 0 0 0 0 0 0 0 0 0 
8 0 0 0 0 0 0 0 0 9#
0 0 0 0 0 0 0 0 0 0 
4 0 0 0 0 0 0 0 0 4 
0 0 0 0 0 0 0 0 0 0 
6 0 0 0 0 0 0 0 0 8 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color yellow at (5,0)
  _01: rectangle with size (1,1) with model Full with color brown at (1,0)
  _011: point with color pink at (1,9)
  _0111: point with color cyan at (3,0)
  _01111: point with color brown at (3,9)
  _011111: point with color pink at (7,0)
  _0111111: point with color cyan at (7,9)
diff: 
   (166.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 
9#0 0 0 0 0 0 0 0 6 
0 0 0 0 0 0 0 0 0 0 
8 0 0 0 0 0 0 0 0 9#
0 0 0 0 0 0 0 0 0 0 
4 0 0 0 0 0 0 0 0 4 
0 0 0 0 0 0 0 0 0 0 
6 0 0 0 0 0 0 0 0 8 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 

diff: 
! 19 wrong pixels (generated / expected)

TRAIN 22eb0ac0.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 
8 0 0 0 0 0 0 0 0 8 
0 0 0 0 0 0 0 0 0 0 
4 0 0 0 0 0 0 0 0 2 
0 0 0 0 0 0 0 0 0 0 
3 0 0 0 0 0 0 0 0 4 
0 0 0 0 0 0 0 0 0 0 
1 0 0 0 0 0 0 0 0 1 
0 0 0 0 0 0 0 0 0 0 
2 0 0 0 0 0 0 0 0 3 

diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color cyan at (1,0)
  _01: rectangle with size (1,10) with model Full with color blue at (7,0)
  _011: point with color yellow at (3,0)
  _0111: point with color red at (3,9)
  _01111: point with color green at (5,0)
  _011111: point with color yellow at (5,9)
  _0111111: point with color red at (9,0)
  + 1 delta pixels
diff: 
   (214.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 
8 0 0 0 0 0 0 0 0 8 
0 0 0 0 0 0 0 0 0 0 
4 0 0 0 0 0 0 0 0 2 
0 0 0 0 0 0 0 0 0 0 
3 0 0 0 0 0 0 0 0 4 
0 0 0 0 0 0 0 0 0 0 
1 0 0 0 0 0 0 0 0 1 
0 0 0 0 0 0 0 0 0 0 
2 0 0 0 0 0 0 0 0 3 

diff: 
! 28 wrong pixels (generated / expected)

TRAIN 22eb0ac0.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 
2 0 0 0 0 0 0 0 0 8 
0 0 0 0 0 0 0 0 0 0 
3 0 0 0 0 0 0 0 0 4 
0 0 0 0 0 0 0 0 0 0 
5#0 0 0 0 0 0 0 0 3 
0 0 0 0 0 0 0 0 0 0 
8 0 0 0 0 0 0 0 0 2 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (1,0)
  _01: rectangle with size (1,1) with model Full with color cyan at (1,9)
  _011: point with color green at (3,0)
  _0111: point with color yellow at (3,9)
  _01111: point with color grey at (5,0)
  _011111: point with color green at (5,9)
  _0111111: point with color cyan at (7,0)
  + 1 delta pixels
diff: 
   (201.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 
2 0 0 0 0 0 0 0 0 8 
0 0 0 0 0 0 0 0 0 0 
3 0 0 0 0 0 0 0 0 4 
0 0 0 0 0 0 0 0 0 0 
5#0 0 0 0 0 0 0 0 3 
0 0 0 0 0 0 0 0 0 0 
8 0 0 0 0 0 0 0 0 2 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 

diff: 
! 11 wrong pixels (generated / expected)

TRAIN 22eb0ac0.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 
4 0 0 0 0 0 0 0 0 2 
0 0 0 0 0 0 0 0 0 0 
3 0 0 0 0 0 0 0 0 3 
0 0 0 0 0 0 0 0 0 0 
2 0 0 0 0 0 0 0 0 9#
0 0 0 0 0 0 0 0 0 0 
6 0 0 0 0 0 0 0 0 6 
0 0 0 0 0 0 0 0 0 0 
9#0 0 0 0 0 0 0 0 4 

diff: 
! 29 wrong pixels (generated / expected)

TEST 22eb0ac0.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.9 sec (59.9 sec/task)
bits-train-error = 5822.9 bits (5822.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-355] Checking task 234bbc79.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 49052.9 = 49055.3
DL output with Mo: L = 2.3 + 38433.5 = 38435.8
DL input+output M: L = 4.6 + 87486.4 = 87491.1

# learning a model for train pairs
2.000	
1.346	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.782	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.623	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.516	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.448	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.395	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.348	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.310	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.292	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.273	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.253	IN  ADD ^.layer_0110 = point with color ? at (?,?)
0.244	OUT SPE ^.size.j = ^.size.j - area(^.layer_01.shape)
0.237	OUT SPE ^.size.i = ^.size.i
0.232	OUT SPE ^.layer_0.shape.color = red
0.226	OUT SPE ^.layer_01.shape.mask.size.j = ^.layer_0.shape.mask.size.j
0.218	OUT SPE ^.layer_0.pos = projI(^.layer_0.pos) + translationOnto(^.layer_0, ^.layer_01111)
0.213	OUT SPE ^.layer_01.pos.j = ^.layer_0110.pos.j / '2
0.208	IN  SPE ^.layer_0111.shape.color = grey
0.203	OUT SPE ^.layer_011.shape.mask.size.j = ^.layer_011.shape.mask.size.j - ^.layer_0110.pos.i - ^.layer_01.pos.i
0.200	OUT SPE ^.layer_01.shape.mask.size.i = ^.size.i - ^.layer_0.shape.mask.size.i
0.196	OUT SPE ^.layer_011.pos.i = middle(^.layer_0111) / '2
0.193	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_011.shape.mask.size.i - ^.layer_0110.pos.i - ^.layer_0.pos.i
0.190	OUT SPE ^.layer_011.shape.mask.size.i = ^.layer_011.shape.mask.size.j - ^.layer_01111.pos.i - ^.layer_01.pos.i
0.187	OUT SPE ^.layer_01.pos.i = middle(^.layer_0111) - ^.layer_011.shape.mask.size.i
0.185	OUT SPE ^.color = black
0.183	IN  SPE ^.color = black
0.057	
0.057	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (^.size.i,^.size.j - area(^.layer_01.shape)) and color black and layers
  _0: rectangle with size (^.layer_011.shape.mask.size.i - ^.layer_0110.pos.i - ^.layer_0.pos.i,?) with model ? with color red at projI(^.layer_0.pos) + translationOnto(^.layer_0, ^.layer_01111)
  _01: rectangle with size (^.size.i - ^.layer_0.shape.mask.size.i,^.layer_0.shape.mask.size.j) with model ? with color ? at (middle(^.layer_0111) - ^.layer_011.shape.mask.size.i,^.layer_0110.pos.j / '2)
  _011: rectangle with size (^.layer_011.shape.mask.size.j - ^.layer_01111.pos.i - ^.layer_01.pos.i,^.layer_011.shape.mask.size.j - ^.layer_0110.pos.i - ^.layer_01.pos.i) with model ? with color ? at (middle(^.layer_0111) / '2,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: point with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: point with color grey at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 154.9 + 6185.7 = 6340.6
DL output with Mo: L = 505.1 + 1556.9 = 2062.0
DL input+output M: L = 660.0 + 7742.7 = 8402.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (^.size.i,^.size.j - area(^.layer_01.shape)) and color black and layers
  _0: rectangle with size (^.layer_011.shape.mask.size.i - ^.layer_0110.pos.i - ^.layer_0.pos.i,?) with model ? with color red at projI(^.layer_0.pos) + translationOnto(^.layer_0, ^.layer_01111)
  _01: rectangle with size (^.size.i - ^.layer_0.shape.mask.size.i,^.layer_0.shape.mask.size.j) with model ? with color ? at (middle(^.layer_0111) - ^.layer_011.shape.mask.size.i,^.layer_0110.pos.j / '2)
  _011: rectangle with size (^.layer_011.shape.mask.size.j - ^.layer_01111.pos.i - ^.layer_01.pos.i,^.layer_011.shape.mask.size.j - ^.layer_0110.pos.i - ^.layer_01.pos.i) with model ? with color ? at (middle(^.layer_0111) / '2,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: point with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: point with color grey at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 154.8 + 20.0 = 174.8
DL output with Mo: L = 505.1 + 1556.9 = 2062.0
DL input+output M: L = 659.9 + 1576.9 = 2236.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,9) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (1,0)
  _01: rectangle with size (2,2) with model Even Checkboard with color grey at (1,3)
  _0110: point with color blue at (1,4)
  _011: rectangle with size (1,2) with model Full with color red at (1,7)
  _0111: point with color grey at (0,1)
  _01111: point with color grey at (1,6)
diff: 
   (2.0 bits)
data: a background with size (3,7) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (1,4)
  _01: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color blue at (0,2)
  _011: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color red at (0,0)
diff: 
   (35.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,9) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (1,0)
  _01: rectangle with size (2,2) with model Even Checkboard with color grey at (1,3)
  _0110: point with color grey at (0,1)
  _011: rectangle with size (1,2) with model Full with color red at (1,7)
  _0111: point with color grey at (1,6)
  _01111: point with color blue at (1,4)
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,9) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (1,0)
  _01: rectangle with size (2,2) with model Even Checkboard with color grey at (1,3)
  _0110: point with color blue at (1,4)
  _011: rectangle with size (1,2) with model Full with color red at (1,7)
  _0111: point with color grey at (0,1)
  _01111: point with color grey at (1,6)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,9) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (1,0)
  _01: rectangle with size (1,2) with model Full with color red at (1,7)
  _0110: point with color grey at (0,1)
  _011: rectangle with size (2,2) with model Even Checkboard with color grey at (1,3)
  _0111: point with color grey at (1,6)
  _01111: point with color blue at (1,4)
diff: 
! 15 wrong pixels (generated / expected)

TRAIN 234bbc79.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,11) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . . 
 with color green at (1,8)
  _01: rectangle with size (1,2) with model Full with color red at (1,0)
  _0110: point with color blue at (0,4)
  _011: rectangle with size (1,3) with model Full with color grey at (0,3)
  _0111: point with color grey at (2,1)
  _01111: point with color grey at (2,7)
diff: 
   (0.0 bits)
data: a background with size (3,9) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color red at (1,0)
  _01: rectangle with size (1,3) with model Full with color blue at (2,2)
  _011: rectangle with size (2,4) with mask 
. 0 0 0 
0 0 . . 
 with color green at (1,5)
diff: 
   (39.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . . 
 with color green at (1,8)
  _01: rectangle with size (1,2) with model Full with color red at (1,0)
  _0110: point with color blue at (0,4)
  _011: rectangle with size (1,3) with model Full with color grey at (0,3)
  _0111: point with color grey at (2,1)
  _01111: point with color grey at (2,7)
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . . 
 with color green at (1,8)
  _01: rectangle with size (1,2) with model Full with color red at (1,0)
  _0110: point with color blue at (0,4)
  _011: rectangle with size (1,3) with model Full with color grey at (0,3)
  _0111: point with color grey at (2,7)
  _01111: point with color grey at (2,1)
diff: 
! 14 wrong pixels (generated / expected)

TRAIN 234bbc79.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,11) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (1,0)
  _01: rectangle with size (1,2) with model Full with color cyan at (1,5)
  _0110: point with color grey at (0,6)
  _011: rectangle with size (1,2) with model Full with color pink at (2,9)
  _0111: point with color grey at (1,4)
  _01111: point with color grey at (2,2)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,9) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color red at (1,0)
  _01: rectangle with size (2,3) with mask 
. . 0 
0 0 0 
 with color cyan at (1,3)
  _011: rectangle with size (1,3) with model Full with color pink at (1,6)
diff: 
   (40.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (1,0)
  _01: rectangle with size (1,2) with model Full with color cyan at (1,5)
  _0110: point with color grey at (0,6)
  _011: rectangle with size (1,2) with model Full with color pink at (2,9)
  _0111: point with color grey at (1,4)
  _01111: point with color grey at (2,2)
  + 1 delta pixels
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (1,0)
  _01: rectangle with size (1,2) with model Full with color cyan at (1,5)
  _0110: point with color grey at (0,6)
  _011: rectangle with size (1,2) with model Full with color pink at (2,9)
  _0111: point with color grey at (1,4)
  _01111: point with color grey at (2,8)
  + 1 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (1,0)
  _01: rectangle with size (1,2) with model Full with color cyan at (1,5)
  _0110: point with color grey at (0,6)
  _011: rectangle with size (1,2) with model Full with color pink at (2,9)
  _0111: point with color grey at (2,2)
  _01111: point with color grey at (1,4)
  + 1 delta pixels
diff: 
! 10 wrong pixels (generated / expected)

TRAIN 234bbc79.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (3,11) and color black and layers
  _0: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color blue at (0,0)
  _01: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color red at (0,8)
  _0110: point with color grey at (0,2)
  _011: rectangle with size (2,2) with model Even Checkboard with color grey at (1,4)
  _0111: point with color grey at (1,7)
  _01111: point with color red at (1,5)
diff: 
   (0.0 bits)
data: a background with size (3,8) and color black and layers
  _0: rectangle with size (2,5) with mask 
0 0 . 0 0 
. 0 0 0 . 
 with color red at (0,3)
  _01: rectangle with size (1,2) with model Full with color blue at (0,1)
  _011: rectangle with size (1,2) with model Full with color blue at (1,0)
diff: 
   (41.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color blue at (0,0)
  _01: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color red at (0,8)
  _0110: point with color grey at (0,2)
  _011: rectangle with size (2,2) with model Even Checkboard with color grey at (1,4)
  _0111: point with color grey at (1,7)
  _01111: point with color red at (1,5)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color blue at (0,0)
  _01: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color red at (0,8)
  _0110: point with color red at (1,5)
  _011: rectangle with size (2,2) with model Even Checkboard with color grey at (1,4)
  _0111: point with color grey at (0,2)
  _01111: point with color grey at (1,7)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color blue at (0,0)
  _01: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color red at (0,8)
  _0110: point with color grey at (1,7)
  _011: rectangle with size (2,2) with model Even Checkboard with color grey at (1,4)
  _0111: point with color grey at (0,2)
  _01111: point with color red at (1,5)
diff: 
! 10 wrong pixels (generated / expected)

TRAIN 234bbc79.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (2,1) with model Full with color blue at (0,4)
  _01: rectangle with size (2,2) with model Odd Checkboard with color grey at (0,6)
  _0110: point with color grey at (0,1)
  _011: rectangle with size (2,1) with model Full with color cyan at (0,10)
  _0111: point with color grey at (0,3)
  _01111: point with color grey at (0,9)
  + 4 delta pixels
diff: 
! size mismatch, 3x9 instead of 3x8
>> Trial 2
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (2,2) with model Odd Checkboard with color grey at (0,6)
  _01: rectangle with size (2,1) with model Full with color blue at (0,4)
  _0110: point with color grey at (0,1)
  _011: rectangle with size (2,1) with model Full with color cyan at (0,10)
  _0111: point with color grey at (0,3)
  _01111: point with color grey at (0,9)
  + 4 delta pixels
diff: 
! size mismatch, 3x9 instead of 3x8

TEST 234bbc79.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 31.7 sec (31.7 sec/task)
bits-train-error = 1556.9 bits (1556.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-354] Checking task 23581191.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 64315.6 = 64317.9
DL output with Mo: L = 2.3 + 64315.6 = 64317.9
DL input+output M: L = 4.6 + 128631.2 = 128635.9

# learning a model for train pairs
2.000	
1.032	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.433	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.315	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.201	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.152	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.107	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.100	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.092	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.086	OUT SPE ^.layer_0.shape = scaleTo(^.layer_0.shape, projI(^.size) + (0, 1))
0.079	OUT ADD ^.layer_0110 = point with color ? at (?,?)
0.072	OUT SPE ^.layer_01.shape = scaleTo(^.layer_01.shape, projJ(^.size) + (1, 0))
0.066	OUT ADD ^.layer_00 = point with color ? at (?,?)
0.059	OUT SPE ^.layer_011.shape = scaleTo(^.layer_01.shape, projI(^.size) + (0, 1))
0.052	OUT SPE ^.layer_0111.shape = scaleTo(^.layer_0.shape, projJ(^.size) + (1, 0))
0.046	OUT SPE ^.size = ^.size
0.043	OUT SPE ^.layer_01.pos = projI(^.layer_01.pos)
0.040	OUT SPE ^.layer_0.pos = projJ(^.layer_0.pos)
0.036	OUT SPE ^.layer_011.pos = projJ(^.layer_01.pos)
0.033	OUT SPE ^.layer_0111.pos = projI(^.layer_0.pos)
0.030	OUT SPE ^.layer_0110.pos = corner(^.layer_0.pos, ^.layer_01.pos)
0.027	OUT SPE ^.layer_00.pos = corner(^.layer_01.pos, ^.layer_0.pos)
0.025	IN  SPE ^.layer_0.shape.color = cyan
0.023	IN  SPE ^.layer_01.shape.color = orange
0.022	OUT SPE ^.layer_00.shape.color = red
0.020	OUT SPE ^.layer_0110.shape.color = red
0.019	IN  SPE ^.color = black
0.018	OUT SPE ^.color = black
0.006	
0.006	IN  GEN ^.layer_01.shape.color = ?
0.006	IN  GEN ^.layer_0.shape.color = ?
0.006	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: point with color red at corner(^.layer_01.pos, ^.layer_0.pos)
  _0: scaleTo(^.layer_0.shape, projI(^.size) + (0, 1)) at projJ(^.layer_0.pos)
  _01: scaleTo(^.layer_01.shape, projJ(^.size) + (1, 0)) at projI(^.layer_01.pos)
  _0110: point with color red at corner(^.layer_0.pos, ^.layer_01.pos)
  _011: scaleTo(^.layer_01.shape, projI(^.size) + (0, 1)) at projJ(^.layer_01.pos)
  _0111: scaleTo(^.layer_0.shape, projJ(^.size) + (1, 0)) at projI(^.layer_0.pos)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color cyan at (?,?)
  _01: point with color orange at (?,?)

DL input  with Mi: L = 57.4 + 825.8 = 883.2
DL output with Mo: L = 306.2 + 0.0 = 306.2
DL input+output M: L = 363.5 + 825.8 = 1189.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: point with color red at corner(^.layer_01.pos, ^.layer_0.pos)
  _0: scaleTo(^.layer_0.shape, projI(^.size) + (0, 1)) at projJ(^.layer_0.pos)
  _01: scaleTo(^.layer_01.shape, projJ(^.size) + (1, 0)) at projI(^.layer_01.pos)
  _0110: point with color red at corner(^.layer_0.pos, ^.layer_01.pos)
  _011: scaleTo(^.layer_01.shape, projI(^.size) + (0, 1)) at projJ(^.layer_01.pos)
  _0111: scaleTo(^.layer_0.shape, projJ(^.size) + (1, 0)) at projI(^.layer_0.pos)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.6 + 0.0 = 50.6
DL output with Mo: L = 306.2 + 0.0 = 306.2
DL input+output M: L = 356.8 + 0.0 = 356.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: point with color cyan at (2,2)
  _01: point with color orange at (6,6)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _00: point with color red at (6,2)
  _0: 
8 
8 
8 
8 
8 
8 
8 
8 
8 
 at (0,2)
  _01: 
7#7#7#7#7#7#7#7#7#
 at (6,0)
  _0110: point with color red at (2,6)
  _011: 
7#
7#
7#
7#
7#
7#
7#
7#
7#
 at (0,6)
  _0111: 
8 8 8 8 8 8 8 8 8 
 at (2,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color cyan at (2,2)
  _01: point with color orange at (6,6)
diff: 
correct output grid

TRAIN 23581191.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: point with color cyan at (1,3)
  _01: point with color orange at (7,6)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _00: point with color red at (7,3)
  _0: 
8 
8 
8 
8 
8 
8 
8 
8 
8 
 at (0,3)
  _01: 
7#7#7#7#7#7#7#7#7#
 at (7,0)
  _0110: point with color red at (1,6)
  _011: 
7#
7#
7#
7#
7#
7#
7#
7#
7#
 at (0,6)
  _0111: 
8 8 8 8 8 8 8 8 8 
 at (1,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color cyan at (1,3)
  _01: point with color orange at (7,6)
diff: 
correct output grid

TRAIN 23581191.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color cyan at (1,4)
  _01: point with color orange at (6,1)
diff: 
correct output grid

TEST 23581191.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 10.4 sec (10.4 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-353] Checking task 239be575.json: 6 train, 2 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 86675.0 = 86677.3
DL output with Mo: L = 2.3 + 2917.4 = 2919.7
DL input+output M: L = 4.6 + 89592.4 = 89597.1

# learning a model for train pairs
2.000	
1.258	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.766	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.608	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.473	OUT SPE ^.size = '(1, 1)
0.379	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.306	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.274	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.265	IN  SPE ^.layer_01.shape.mask = 
0 0 
0 0 

0.261	IN  SPE ^.layer_01.shape.color = red
0.259	IN  SPE ^.layer_0111.shape.mask.model = Full
0.125	
0.124	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(1, 1) and color ? and layers
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: 
0 0 
0 0 
 with color red at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 126.7 + 11624.3 = 11751.0
DL output with Mo: L = 18.5 + 342.7 = 361.2
DL input+output M: L = 145.1 + 11967.0 = 12112.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(1, 1) and color ? and layers
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 18.5 + 342.7 = 361.2
DL input+output M: L = 20.8 + 342.7 = 363.5

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 8 0 8 
2 2 8 0 0 
2 2 0 0 8 
0 0 0 2 2 
8 8 0 2 2 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color black and layers
diff: 
   (2.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 8 0 8 
2 2 8 0 0 
2 2 0 0 8 
0 0 0 2 2 
8 8 0 2 2 

diff: 
correct output grid

TRAIN 239be575.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 8 0 0 0 0 0 
2 2 0 8 8 8 0 
2 2 8 8 0 2 2 
0 0 8 0 0 2 2 
0 8 0 0 8 0 0 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color cyan and layers
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 8 0 0 0 0 0 
2 2 0 8 8 8 0 
2 2 8 8 0 2 2 
0 0 8 0 0 2 2 
0 8 0 0 8 0 0 

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 239be575.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
8 2 2 8 8 0 0 
0 2 2 0 0 0 8 
0 8 8 0 0 8 0 
0 0 8 0 0 0 8 
8 0 8 8 8 2 2 
8 0 0 0 0 2 2 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color cyan and layers
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 2 2 8 8 0 0 
0 2 2 0 0 0 8 
0 8 8 0 0 8 0 
0 0 8 0 0 0 8 
8 0 8 8 8 2 2 
8 0 0 0 0 2 2 

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 239be575.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: 
8 8 0 0 2 2 0 
0 8 8 0 2 2 8 
0 0 0 8 0 8 0 
8 0 0 0 0 0 0 
0 2 2 0 8 0 8 
0 2 2 8 8 0 8 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color black and layers
diff: 
   (2.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 8 0 0 2 2 0 
0 8 8 0 2 2 8 
0 0 0 8 0 8 0 
8 0 0 0 0 0 0 
0 2 2 0 8 0 8 
0 2 2 8 8 0 8 

diff: 
correct output grid

TRAIN 239be575.json/4: 1 1st (SUCCESS)

## instance 5

> Input and output best reading:

data: 
8 0 0 0 0 8 0 
0 0 2 2 0 8 0 
8 0 2 2 0 0 0 
0 0 8 0 0 8 0 
0 0 8 2 2 0 8 
8 0 0 2 2 8 0 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color cyan and layers
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 0 0 0 0 8 0 
0 0 2 2 0 8 0 
8 0 2 2 0 0 0 
0 0 8 0 0 8 0 
0 0 8 2 2 0 8 
8 0 0 2 2 8 0 

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 239be575.json/5: 0 - (FAILURE)

## instance 6

> Input and output best reading:

data: 
8 0 0 2 2 8 
8 0 8 2 2 0 
0 0 0 0 8 0 
2 2 8 0 8 0 
2 2 0 0 0 8 
0 8 8 0 8 0 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color black and layers
diff: 
   (2.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 0 0 2 2 8 
8 0 8 2 2 0 
0 0 0 0 8 0 
2 2 8 0 8 0 
2 2 0 0 0 8 
0 8 8 0 8 0 

diff: 
correct output grid

TRAIN 239be575.json/6: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 2 8 8 0 8 
2 2 0 8 0 0 
8 8 0 0 0 8 
0 8 8 8 0 0 
8 0 8 0 0 8 
0 0 8 2 2 0 
8 0 0 2 2 0 
0 8 0 0 0 8 

diff: 
! 1 wrong pixels (generated / expected)

TEST 239be575.json/1: 0 - (FAILURE)

## instance 2

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 8 0 0 0 0 
0 0 0 8 2 2 
0 8 8 8 2 2 
0 8 0 0 0 8 
0 0 0 8 0 0 
8 2 2 0 0 8 
0 2 2 0 0 0 
0 8 0 8 8 0 

diff: 
correct output grid

TEST 239be575.json/2: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 2.7 sec (2.7 sec/task)
bits-train-error = 342.7 bits (342.7 bits/task)
acc-train-micro = 0.50 tasks (50.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.50
acc-test-micro = 0.50 tasks (50.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.50

=====================================
[-352] Checking task 23b5c85d.json: 5 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 457509.2 = 457511.5
DL output with Mo: L = 2.3 + 14535.5 = 14537.8
DL input+output M: L = 4.6 + 472044.7 = 472049.3

# learning a model for train pairs
2.000	
1.074	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.473	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.254	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.159	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.119	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.102	OUT SPE ^.size.j = max(^.layer_0.shape.mask.size.i, ^.layer_011.shape.mask.size.i) / '2
0.100	IN  SPE ^.layer_011.shape.mask.model = Full
0.100	IN  SPE ^.layer_01.shape.mask.model = Full
0.100	IN  SPE ^.color = black
0.057	
0.057	IN  GEN ^.layer_01.shape.mask.model = ?
0.057	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,max(^.layer_0.shape.mask.size.i, ^.layer_011.shape.mask.size.i) / '2) and color ? and layers
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 99.3 + 19604.0 = 19703.3
DL output with Mo: L = 76.2 + 749.5 = 825.7
DL input+output M: L = 175.4 + 20353.5 = 20529.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,max(^.layer_0.shape.mask.size.i, ^.layer_011.shape.mask.size.i) / '2) and color ? and layers
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 98.6 + 31.7 = 130.3
DL output with Mo: L = 76.2 + 749.5 = 825.7
DL input+output M: L = 174.8 + 781.2 = 956.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,6) with model Full with color red at (1,1)
  _01: rectangle with size (3,3) with model Full with color cyan at (5,3)
  _011: rectangle with size (6,6) with model Full with color red at (1,1)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color cyan and layers
diff: 
   (15.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,6) with model Full with color red at (1,1)
  _01: rectangle with size (3,3) with model Full with color cyan at (5,3)
  _011: rectangle with size (6,6) with model Full with color red at (1,1)
diff: 
! size mismatch, 10x3 instead of 3x3

TRAIN 23b5c85d.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (5,6) with model Full with color red at (10,4)
  _01: rectangle with size (9,8) with model Full with color green at (3,1)
  _011: rectangle with size (7,7) with model Full with color cyan at (2,12)
  + 30 delta pixels
diff: 
   (0.0 bits)
data: a background with size (2,3) and color blue and layers
diff: 
   (14.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (5,6) with model Full with color red at (10,4)
  _01: rectangle with size (9,8) with model Full with color green at (3,1)
  _011: rectangle with size (7,7) with model Full with color cyan at (2,12)
  + 30 delta pixels
diff: 
! size mismatch, 10x3 instead of 2x3
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (9,8) with mask 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 . . . . . 
0 0 0 . . . . . 
 with color green at (3,1)
  _01: rectangle with size (7,7) with model Full with color cyan at (2,12)
  _011: rectangle with size (5,6) with model Full with color red at (10,4)
  + 30 delta pixels
diff: 
! size mismatch, 10x4 instead of 2x3

TRAIN 23b5c85d.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,15) and color black and layers
  _0: rectangle with size (3,2) with model Full with color pink at (5,5)
  _01: rectangle with size (9,4) with model Full with color green at (1,2)
  _011: rectangle with size (4,3) with model Full with color red at (0,9)
diff: 
   (0.0 bits)
data: a background with size (3,2) and color pink and layers
diff: 
   (15.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,15) and color black and layers
  _0: rectangle with size (3,2) with model Full with color pink at (5,5)
  _01: rectangle with size (9,4) with model Full with color green at (1,2)
  _011: rectangle with size (4,3) with model Full with color red at (0,9)
diff: 
! size mismatch, 10x2 instead of 3x2
>> Trial 2
data: a background with size (10,15) and color black and layers
  _0: rectangle with size (9,4) with mask 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 . 
0 0 0 . 
0 0 0 . 
0 0 0 0 
0 0 0 0 
 with color green at (1,2)
  _01: rectangle with size (4,3) with model Full with color red at (0,9)
  _011: rectangle with size (3,2) with model Full with color pink at (5,5)
diff: 
! size mismatch, 10x4 instead of 3x2

TRAIN 23b5c85d.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (13,15) and color black and layers
  _0: rectangle with size (8,13) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . 0 0 0 0 0 0 0 
0 0 . . . . 0 0 0 0 0 0 0 
0 0 . . . . 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 . . . . . . . 0 
 with color red at (2,1)
  _01: rectangle with size (4,7) with model Full with color green at (9,6)
  _011: rectangle with size (3,4) with model Full with color orange at (4,3)
diff: 
   (0.0 bits)
data: a background with size (3,4) and color orange and layers
diff: 
   (15.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,15) and color black and layers
  _0: rectangle with size (8,13) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . 0 0 0 0 0 0 0 
0 0 . . . . 0 0 0 0 0 0 0 
0 0 . . . . 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 . . . . . . . 0 
 with color red at (2,1)
  _01: rectangle with size (4,7) with model Full with color green at (9,6)
  _011: rectangle with size (3,4) with model Full with color orange at (4,3)
diff: 
! size mismatch, 10x4 instead of 3x4
>> Trial 2
data: a background with size (13,15) and color black and layers
  _0: rectangle with size (4,7) with model Full with color green at (9,6)
  _01: rectangle with size (8,13) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . 0 0 0 0 0 0 0 
0 0 . . . . 0 0 0 0 0 0 0 
0 0 . . . . 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 . . . . . . . 0 
 with color red at (2,1)
  _011: rectangle with size (3,4) with model Full with color orange at (4,3)
diff: 
! size mismatch, 10x2 instead of 3x4

TRAIN 23b5c85d.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: a background with size (18,15) and color black and layers
  _0: rectangle with size (4,7) with model Full with color pink at (11,4)
  _01: rectangle with size (7,8) with model Full with color blue at (2,1)
  _011: rectangle with size (2,2) with model Full with color yellow at (3,11)
diff: 
   (3.2 bits)
data: a background with size (2,2) and color yellow and layers
diff: 
   (14.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,15) and color black and layers
  _0: rectangle with size (7,8) with model Full with color blue at (2,1)
  _01: rectangle with size (4,7) with model Full with color pink at (11,4)
  _011: rectangle with size (2,2) with model Full with color yellow at (3,11)
diff: 
! size mismatch, 10x3 instead of 2x2
>> Trial 2
data: a background with size (18,15) and color black and layers
  _0: rectangle with size (4,7) with model Full with color pink at (11,4)
  _01: rectangle with size (7,8) with model Full with color blue at (2,1)
  _011: rectangle with size (2,2) with model Full with color yellow at (3,11)
diff: 
! size mismatch, 10x2 instead of 2x2

TRAIN 23b5c85d.json/5: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,18) and color black and layers
  _0: rectangle with size (11,8) with model Full with color yellow at (3,9)
  _01: rectangle with size (6,6) with model Full with color blue at (2,2)
  _011: rectangle with size (4,5) with model Full with color green at (13,2)
  + 9 delta pixels
diff: 
! size mismatch, 10x5 instead of 3x3
>> Trial 2
data: a background with size (18,18) and color black and layers
  _0: rectangle with size (6,6) with model Full with color blue at (2,2)
  _01: rectangle with size (11,8) with model Full with color yellow at (3,9)
  _011: rectangle with size (4,5) with model Full with color green at (13,2)
  + 9 delta pixels
diff: 
! size mismatch, 10x3 instead of 3x3

TEST 23b5c85d.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 2.8 sec (2.8 sec/task)
bits-train-error = 749.5 bits (749.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-351] Checking task 253bf280.json: 8 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 239346.1 = 239348.4
DL output with Mo: L = 2.3 + 239346.1 = 239348.4
DL input+output M: L = 4.6 + 478692.1 = 478696.8

# learning a model for train pairs
2.000	
1.046	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.165	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.115	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.107	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.101	OUT SPE ^.size = ^.size
0.099	IN  SPE ^.layer_0.shape.color = cyan
0.098	OUT SPE ^.layer_0.shape.mask.model = Full
0.098	IN  SPE ^.color = black
0.097	OUT SPE ^.color = black
0.062	
0.061	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color cyan at (?,?)

DL input  with Mi: L = 35.6 + 8427.0 = 8462.6
DL output with Mo: L = 39.4 + 14676.5 = 14715.9
DL input+output M: L = 75.0 + 23103.5 = 23178.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 39.4 + 14676.5 = 14715.9
DL input+output M: L = 41.7 + 14676.5 = 14718.2

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 8 0 0 0 0 0 0 8 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (7,13) and color black and layers
  _0: rectangle with size (1,6) with model Full with color green at (3,3)
  + 2 delta pixels
diff: 
   (110.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 8 0 0 0 0 0 0 8 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
! 12 wrong pixels (generated / expected)

TRAIN 253bf280.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 8 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 8 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 8 0 0 
0 0 0 0 8 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (10,11) and color black and layers
  _0: rectangle with size (5,1) with model Full with color green at (2,4)
  + 7 delta pixels
diff: 
   (312.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 8 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 8 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 8 0 0 
0 0 0 0 8 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 

diff: 
! 16 wrong pixels (generated / expected)

TRAIN 253bf280.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 
0 8 0 0 0 0 0 0 0 8 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 8 0 0 0 0 8 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (12,11) and color black and layers
  _0: rectangle with size (1,7) with model Full with color green at (1,2)
  + 8 delta pixels
diff: 
   (355.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 
0 8 0 0 0 0 0 0 0 8 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 8 0 0 0 0 8 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 

diff: 
! 18 wrong pixels (generated / expected)

TRAIN 253bf280.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: 
0 0 0 0 0 0 
0 0 8 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 8 0 0 0 
0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (9,6) and color black and layers
  _0: rectangle with size (5,1) with model Full with color green at (2,2)
  + 2 delta pixels
diff: 
   (107.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 
0 0 8 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 8 0 0 0 
0 0 0 0 0 0 

diff: 
! 11 wrong pixels (generated / expected)

TRAIN 253bf280.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: 
0 0 0 
0 8 0 
0 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (1,1)
diff: 
   (20.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 
0 8 0 
0 0 0 

diff: 
! 4 wrong pixels (generated / expected)

TRAIN 253bf280.json/5: 0 - (FAILURE)

## instance 6

> Input and output best reading:

data: 
0 0 0 0 0 0 
0 8 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 8 0 
0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (5,6) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (1,1)
  + 1 delta pixels
diff: 
   (61.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 
0 8 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 8 0 
0 0 0 0 0 0 

diff: 
! 5 wrong pixels (generated / expected)

TRAIN 253bf280.json/6: 0 - (FAILURE)

## instance 7

> Input and output best reading:

data: 
0 0 0 0 0 0 
0 0 0 8 0 0 
0 0 0 0 0 0 
0 8 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 8 0 0 

diff: 
   (0.0 bits)
data: a background with size (7,6) and color black and layers
  _0: rectangle with size (4,1) with model Full with color green at (2,3)
  + 3 delta pixels
diff: 
   (145.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 
0 0 0 8 0 0 
0 0 0 0 0 0 
0 8 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 8 0 0 

diff: 
! 11 wrong pixels (generated / expected)

TRAIN 253bf280.json/7: 0 - (FAILURE)

## instance 8

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 8 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 8 0 0 0 8 
0 8 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 8 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (12,11) and color black and layers
  _0: rectangle with size (7,1) with model Full with color green at (2,3)
  + 8 delta pixels
diff: 
   (355.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 8 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 8 0 0 0 8 
0 8 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 8 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 

diff: 
! 19 wrong pixels (generated / expected)

TRAIN 253bf280.json/8: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 8 0 0 0 0 0 0 0 8 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 8 0 0 0 0 0 8 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 8 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 8 0 0 0 0 
0 8 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
! 25 wrong pixels (generated / expected)

TEST 253bf280.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 9.2 sec (9.2 sec/task)
bits-train-error = 14676.5 bits (14676.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-350] Checking task 25d487eb.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 191783.2 = 191785.5
DL output with Mo: L = 2.3 + 191783.2 = 191785.5
DL input+output M: L = 4.6 + 383566.4 = 383571.0

# learning a model for train pairs
2.000	
1.076	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.203	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.134	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.077	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.028	OUT ADD ^.layer_00 = ^.layer_0
0.025	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.021	OUT SPE ^.size = ^.size
0.020	OUT SPE ^.layer_0.pos.j = ^.layer_01.pos.j
0.020	OUT SPE ^.layer_0.shape.color = ^.layer_01.shape.color
0.019	OUT SPE ^.layer_0.shape.mask.model = Full
0.019	IN  SPE ^.color = black
0.018	OUT SPE ^.color = black
0.004	
0.004	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model Full with color ^.layer_01.shape.color at (?,^.layer_01.pos.j)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 60.5 + 2794.6 = 2855.1
DL output with Mo: L = 74.8 + 586.2 = 661.1
DL input+output M: L = 135.4 + 3380.8 = 3516.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model Full with color ^.layer_01.shape.color at (?,^.layer_01.pos.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 60.4 + 0.0 = 60.4
DL output with Mo: L = 74.8 + 586.2 = 661.1
DL input+output M: L = 135.2 + 586.2 = 721.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,15) and color black and layers
  _0: rectangle with size (5,3) with mask 
0 . . 
0 0 . 
. 0 0 
0 0 . 
0 . . 
 with color red at (2,3)
  _01: point with color blue at (4,3)
diff: 
   (0.0 bits)
data: a background with size (10,15) and color black and layers
  _00: 
2 . . 
2 2 . 
. 2 2 
2 2 . 
2 . . 
 at (2,3)
  _0: rectangle with size (1,12) with model Full with color blue at (4,3)
diff: 
   (19.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,15) and color black and layers
  _0: rectangle with size (5,3) with mask 
0 . . 
0 0 . 
. 0 0 
0 0 . 
0 . . 
 with color red at (2,3)
  _01: point with color blue at (4,3)
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,15) and color black and layers
  _0: rectangle with size (5,1) with model Full with color red at (2,3)
  _01: point with color red at (3,4)
  + 4 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TRAIN 25d487eb.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (4,7) with mask 
. . . 0 . . . 
. . 0 0 0 . . 
. 0 0 0 0 0 . 
0 0 0 . 0 0 0 
 with color cyan at (5,3)
  _01: point with color green at (8,6)
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _00: 
. . . 8 . . . 
. . 8 8 8 . . 
. 8 8 8 8 8 . 
8 8 8 . 8 8 8 
 at (5,3)
  _0: rectangle with size (9,1) with model Full with color green at (0,6)
diff: 
   (18.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (4,7) with mask 
. . . 0 . . . 
. . 0 0 0 . . 
. 0 0 0 0 0 . 
0 0 0 . 0 0 0 
 with color cyan at (5,3)
  _01: point with color green at (8,6)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (2,5) with model Full with color cyan at (7,4)
  _01: point with color cyan at (5,6)
  + 7 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (2,5) with model Full with color cyan at (7,4)
  _01: point with color cyan at (6,5)
  + 7 delta pixels
diff: 
! 14 wrong pixels (generated / expected)

TRAIN 25d487eb.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (15,12) and color black and layers
  _0: rectangle with size (3,5) with mask 
0 0 . 0 0 
. 0 0 0 . 
. . 0 . . 
 with color green at (2,2)
  _01: point with color red at (2,4)
diff: 
   (0.0 bits)
data: a background with size (15,12) and color black and layers
  _00: 
3 3 . 3 3 
. 3 3 3 . 
. . 3 . . 
 at (2,2)
  _0: rectangle with size (13,1) with model Full with color red at (2,4)
diff: 
   (20.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,12) and color black and layers
  _0: rectangle with size (3,5) with mask 
0 0 . 0 0 
. 0 0 0 . 
. . 0 . . 
 with color green at (2,2)
  _01: point with color red at (2,4)
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,12) and color black and layers
  _0: rectangle with size (1,5) with model Full with color green at (2,2)
  _01: point with color green at (3,3)
  + 4 delta pixels
diff: 
! 19 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,12) and color black and layers
  _0: rectangle with size (1,5) with model Full with color green at (2,2)
  _01: point with color green at (3,4)
  + 4 delta pixels
diff: 
! 19 wrong pixels (generated / expected)

TRAIN 25d487eb.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,11) and color black and layers
  _0: rectangle with size (4,7) with mask 
. . . 0 . . . 
. . 0 0 0 . . 
. 0 0 0 0 0 . 
0 0 0 . 0 0 0 
 with color yellow at (11,1)
  _01: point with color cyan at (14,4)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (16,11) and color black and layers
  _0: rectangle with size (2,5) with model Full with color yellow at (13,2)
  _01: point with color yellow at (11,4)
  + 7 delta pixels
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (16,11) and color black and layers
  _0: rectangle with size (2,5) with model Full with color yellow at (13,2)
  _01: point with color yellow at (12,3)
  + 7 delta pixels
diff: 
! 20 wrong pixels (generated / expected)

TEST 25d487eb.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 12.0 sec (12.0 sec/task)
bits-train-error = 586.2 bits (586.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-349] Checking task 25d8a9c8.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 14046.4 = 14048.7
DL output with Mo: L = 2.3 + 14046.4 = 14048.7
DL input+output M: L = 4.6 + 28092.8 = 28097.5

# learning a model for train pairs
2.000	
1.369	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.012	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.766	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.529	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.391	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.354	OUT SPE ^.size = ^.size
0.317	IN  SPE ^.layer_0.shape.mask = 
0 0 0 

0.284	OUT SPE ^.layer_0.shape.mask = ^.layer_0.shape.mask
0.273	OUT SPE ^.layer_0.pos.j = ^.layer_0.pos.j
0.046	
0.044	IN  DEL ^.layer_01

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: ^.layer_0.shape.mask with color ? at (?,^.layer_0.pos.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 0 0 
 with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 66.3 + 3192.0 = 3258.3
DL output with Mo: L = 30.8 + 546.4 = 577.1
DL input+output M: L = 97.0 + 3738.4 = 3835.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: ^.layer_0.shape.mask with color ? at (?,^.layer_0.pos.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 0 0 
 with color ? at (?,?)

DL input  with Mi: L = 38.0 + 0.0 = 38.0
DL output with Mo: L = 30.8 + 546.4 = 577.1
DL input+output M: L = 68.8 + 546.4 = 615.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color red and layers
  _0: 
0 0 0 
 with color yellow at (0,0)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
0 0 0 
 with color grey at (0,0)
diff: 
   (12.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color red and layers
  _0: 
0 0 0 
 with color yellow at (0,0)
  + 3 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color red and layers
  _0: 
0 . 
0 0 
 with color green at (1,1)
  + 3 delta pixels
diff:   ^.layer_0.shape.mask
! 5 wrong pixels (generated / expected)

TRAIN 25d8a9c8.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,3) and color green and layers
  _0: 
0 0 0 
 with color pink at (1,0)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
0 0 0 
 with color grey at (1,0)
diff: 
   (12.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color green and layers
  _0: 
0 0 0 
 with color pink at (1,0)
  + 3 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color pink and layers
  _0: 
0 0 
 with color green at (0,1)
  + 4 delta pixels
diff:   ^.layer_0.shape.mask
! 5 wrong pixels (generated / expected)

TRAIN 25d8a9c8.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,3) and color brown and layers
  _0: 
0 0 0 
 with color yellow at (1,0)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color grey and layers
  _0: 
0 0 0 
 with color black at (0,0)
diff: 
   (18.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color brown and layers
  _0: 
0 0 0 
 with color yellow at (1,0)
  + 2 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 25d8a9c8.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (3,3) and color red and layers
  _0: 
0 0 0 
 with color blue at (2,0)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
0 0 0 
 with color grey at (2,0)
diff: 
   (12.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color red and layers
  _0: 
0 0 0 
 with color blue at (2,0)
  + 2 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color blue and layers
  _0: 
0 0 
0 0 
 with color red at (0,0)
  + 2 delta pixels
diff:   ^.layer_0.shape.mask
! 7 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,3) and color red and layers
  _0: 
0 
0 
 with color yellow at (0,2)
  + 3 delta pixels
diff:   ^.layer_0.shape.mask
! 5 wrong pixels (generated / expected)

TRAIN 25d8a9c8.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color yellow and layers
  _0: 
0 0 0 
 with color cyan at (2,0)
  + 3 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TEST 25d8a9c8.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.9 sec (3.9 sec/task)
bits-train-error = 546.4 bits (546.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-348] Checking task 25ff71a9.json: 4 train, 2 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 14046.4 = 14048.7
DL output with Mo: L = 2.3 + 14046.4 = 14048.7
DL input+output M: L = 4.6 + 28092.8 = 28097.5

# learning a model for train pairs
2.000	
1.364	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.728	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.489	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.193	OUT ADD ^.layer_0 = ^.layer_0.shape at (?,?)
0.156	OUT SPE ^.size = ^.size
0.134	OUT SPE ^.layer_0.pos = ^.layer_0.pos + (1, 0)
0.127	IN  SPE ^.color = black
0.120	OUT SPE ^.color = black
0.005	
0.005	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0.shape at ^.layer_0.pos + (1, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.1 + 1616.5 = 1658.6
DL output with Mo: L = 31.1 + 0.0 = 31.1
DL input+output M: L = 73.2 + 1616.5 = 1689.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0.shape at ^.layer_0.pos + (1, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 31.1 + 0.0 = 31.1
DL input+output M: L = 73.1 + 0.0 = 73.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color blue at (0,0)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
1 1 1 
 at (1,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color blue at (0,0)
diff: 
correct output grid

TRAIN 25ff71a9.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color blue at (1,0)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
1 1 1 
 at (2,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color blue at (1,0)
diff: 
correct output grid

TRAIN 25ff71a9.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color blue at (0,0)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
. 1 
1 1 
 at (1,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color blue at (0,0)
diff: 
correct output grid

TRAIN 25ff71a9.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color red at (0,1)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
2 2 
. 2 
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color red at (0,1)
diff: 
correct output grid

TRAIN 25ff71a9.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,1) with model Full with color red at (0,0)
diff: 
correct output grid

TEST 25ff71a9.json/1: 1 1st (SUCCESS)

## instance 2

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color blue at (1,1)
diff: 
correct output grid

TEST 25ff71a9.json/2: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.2 sec (1.2 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-347] Checking task 264363fd.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 1154266.3 = 1154268.6
DL output with Mo: L = 2.3 + 1154266.3 = 1154268.6
DL input+output M: L = 4.6 + 2308532.5 = 2308537.2

# learning a model for train pairs
2.000	
1.451	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.915	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.493	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.147	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.117	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.095	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.054	
0.054	IN  GEN ^ = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 47641.2 = 47683.2
DL output with Mo: L = 98.1 + 62346.5 = 62444.6
DL input+output M: L = 140.1 + 109987.6 = 110127.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 98.1 + 62346.5 = 62444.6
DL input+output M: L = 100.4 + 62346.5 = 62446.9

# train input/output grids

## instance 1

> Input and output best reading:

data: 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 2 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 3 2 3 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 2 2 3 2 2 8 8 
8 8 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 3 2 3 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 2 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 

diff: 
   (0.0 bits)
data: a background with size (30,30) and color blue and layers
  _0: rectangle with size (30,30) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 
0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 
0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 
0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 
0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 
0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 
0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 
0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 
0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color cyan at (0,0)
  _01: rectangle with size (15,17) with mask 
. . . 0 . . . . . . . . . . . . . 
. . . 0 . . . . . . . . . . . . . 
. . . 0 . . . . . . . . . . . . . 
. . . 0 . . . . . . . . . . . . . 
0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . . . . . . . . . . . 
. . . 0 . . . . . . . . . . . . . 
. . . 0 . . . . . . . . . . . . . 
. . . 0 . . . . . . . . . . . . . 
. . . 0 . . . . . . . . . . . . . 
. . . 0 . . . . . . . . . . . . . 
. . . 0 . . . . . . . . . . . . . 
. . . 0 . . . . . . . . . . . . . 
. . . 0 . . . . . . . . . . . . . 
. . . 0 . . . . . . . . . . . . . 
 with color red at (1,2)
  _011: rectangle with size (9,18) with mask 
. . . . . . . . . 0 . . . . . . . . 
. . . . . . . . . 0 . . . . . . . . 
. . . . . . . . . 0 . . . . . . . . 
. . . . . . . . . 0 . . . . . . . . 
. . . . . . . . . 0 . . . . . . . . 
. . . . . . . . . 0 . . . . . . . . 
. . . . . . . . . 0 . . . . . . . . 
0 0 0 0 0 0 0 0 0 . 0 0 0 0 0 0 0 0 
. . . . . . . . . 0 . . . . . . . . 
 with color red at (18,8)
  + 10 delta pixels
diff: 
   (1743.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 2 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 3 2 3 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 2 2 3 2 2 8 8 
8 8 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 3 2 3 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 2 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 

diff: 
! size mismatch, 10x10 instead of 30x30

TRAIN 264363fd.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 
1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 3 3 4 3 3 1 1 1 
1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 3 1 1 1 1 1 
1 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 1 1 1 1 1 1 3 1 1 1 1 1 
1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 

diff: 
   (0.0 bits)
data: a background with size (30,30) and color red and layers
  _0: rectangle with size (30,30) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color blue at (0,0)
  _01: rectangle with size (9,17) with mask 
. . . . 0 . . . . . . . . 0 . . . 
. . . . 0 . . . . . . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 0 
. . . . 0 . . . . . . . . 0 . . . 
. . . . 0 . . . . . . . . 0 . . . 
0 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . . . . . 0 . . . 
. . . . 0 . . . . . . . . 0 . . . 
. . . . 0 . . . . . . . . 0 . . . 
 with color green at (5,1)
  _011: rectangle with size (13,18) with mask 
. . . . . . . . . . 0 . . . . . . . 
. . . . . . . . . . 0 . . . . . . . 
. . . . . . . . . . 0 . . . . . . . 
. . . . . . . . . . 0 . . . . . . . 
. . . . . . . . . . 0 . . . . . . . 
. . . . . . . . . . 0 . . . . . . . 
. . . . . . . . . . 0 . . . . . . . 
. . . . . . . . . . 0 . . . . . . . 
. . . . . . . . . . 0 . . . . . . . 
0 0 0 0 0 0 0 0 0 0 . 0 0 0 0 0 0 0 
. . . . . . . . . . 0 . . . . . . . 
. . . . . . . . . . 0 . . . . . . . 
. . . . . . . . . . 0 . . . . . . . 
 with color green at (15,6)
  + 3 delta pixels
diff: 
   (1459.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 
1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 3 3 4 3 3 1 1 1 
1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 3 1 1 1 1 1 
1 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 1 1 1 1 1 1 3 1 1 1 1 1 
1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 

diff: 
! size mismatch, 10x10 instead of 30x30

TRAIN 264363fd.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 3 3 3 4 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 3 3 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 3 3 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 3 3 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 3 3 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 3 3 3 3 3 3 4 3 3 3 8 8 8 8 8 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 3 3 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 3 3 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5#8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 6 5#6 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 6 4 6 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 6 5#6 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5#8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 

diff: 
   (0.0 bits)
data: a background with size (30,30) and color green and layers
  _0: rectangle with size (30,30) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . 0 0 0 
0 . . . . . . . . . 0 . . . . . . . . . . . . . . . . 0 0 0 
0 . . . . . . . . . 0 . . . . . . . . . . . . . . . . 0 0 0 
0 . . . . . . . . . 0 . . . . . . . . . . . . . . . . 0 0 0 
0 . . . . . . . . . 0 . . . . . . . . . . . . . . . . 0 0 0 
0 . . . . . . . . . 0 . . . . . . . . . . . . . . . . 0 0 0 
0 . . . . . . . . . 0 . . . . . . . . . . . . . . . . 0 0 0 
0 . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . . 0 0 . . . . . . . . . . 0 0 0 0 0 0 0 0 
0 . . . . . . . . . 0 0 . . . . . . . . . . 0 0 0 0 0 0 0 0 
0 . . . . . . . . . 0 0 . . . . . . . . . . 0 0 0 0 0 0 0 0 
0 . . . . . . . . . 0 0 . . . . . . . . . . 0 0 0 0 0 0 0 0 
0 . . . . . . . . . 0 0 . . . . . . . . . . 0 0 0 0 0 0 0 0 
0 . . . . . . . . . 0 0 . . . . . . . . . . 0 0 0 0 0 0 0 0 
0 . . . . . . . . . 0 0 . . . . . . . . . . 0 0 0 0 0 0 0 0 
0 . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color cyan at (0,0)
  _01: rectangle with size (15,1) with model Full with color grey at (9,4)
  _011: rectangle with size (13,1) with model Full with color grey at (2,15)
  + 46 delta pixels
diff: 
   (3031.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 3 3 3 4 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 3 3 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 3 3 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 3 3 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 3 3 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 3 3 3 3 3 3 4 3 3 3 8 8 8 8 8 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 3 3 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 3 3 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 
8 3 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5#8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 6 5#6 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 6 4 6 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 6 5#6 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5#8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 

diff: 
! size mismatch, 10x10 instead of 30x30

TRAIN 264363fd.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 1 1 1 2 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 
4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 
4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 
4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 4 
4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 
4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 
4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 
4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 
4 4 3 3 3 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 
4 8 8 2 8 8 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 
4 4 3 3 3 4 4 4 4 4 4 4 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 4 
4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 
4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 
4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 

diff: 
! size mismatch, 10x10 instead of 30x30

TEST 264363fd.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 60.3 sec (60.3 sec/task)
bits-train-error = 62346.5 bits (62346.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-346] Checking task 272f95fa.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 209793.2 = 209795.5
DL output with Mo: L = 2.3 + 209793.2 = 209795.5
DL input+output M: L = 4.6 + 419586.3 = 419591.0

# learning a model for train pairs
2.000	
1.233	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.881	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.673	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.443	OUT ADD ^.layer_0 = ^.layer_0
0.283	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.185	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.118	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.074	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.046	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.044	OUT SPE ^.size = ^.size
0.042	OUT SPE ^.layer_0111.shape.mask = 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 

0.041	OUT SPE ^.layer_011111.pos.j = '0
0.040	OUT SPE ^.layer_011.shape.mask = 
0 0 0 0 0 0 
0 0 0 0 0 0 

0.039	IN  SPE ^.layer_0.shape.color = cyan
0.039	OUT SPE ^.layer_01111.shape.mask.size.j = ^.size.i / '3
0.038	OUT SPE ^.layer_011111.shape.color = yellow
0.038	OUT SPE ^.layer_011.pos.j = bottom(^.layer_0) / '3
0.037	OUT SPE ^.layer_0111.pos.j = bottom(^.layer_0) / '3
0.037	OUT SPE ^.layer_01111.pos.i = bottom(^.layer_0) / '2
0.036	OUT SPE ^.layer_01.shape.mask.model = Full
0.036	OUT SPE ^.layer_01111.shape.mask.model = Full
0.036	OUT SPE ^.layer_011111.shape.mask.model = Full
0.036	IN  SPE ^.color = black
0.035	OUT SPE ^.color = black
0.011	
0.011	IN  GEN ^.layer_0.shape.color = ?
0.011	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: 
0 0 0 0 0 0 
0 0 0 0 0 0 
 with color ? at (?,bottom(^.layer_0) / '3)
  _0111: 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
 with color ? at (?,bottom(^.layer_0) / '3)
  _01111: rectangle with size (?,^.size.i / '3) with model Full with color ? at (bottom(^.layer_0) / '2,?)
  _011111: rectangle with size (?,?) with model Full with color yellow at (?,'0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color cyan at (?,?)

DL input  with Mi: L = 45.4 + 5185.4 = 5230.9
DL output with Mo: L = 282.0 + 1926.8 = 2208.8
DL input+output M: L = 327.4 + 7112.2 = 7439.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: 
0 0 0 0 0 0 
0 0 0 0 0 0 
 with color ? at (?,bottom(^.layer_0) / '3)
  _0111: 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
 with color ? at (?,bottom(^.layer_0) / '3)
  _01111: rectangle with size (?,^.size.i / '3) with model Full with color ? at (bottom(^.layer_0) / '2,?)
  _011111: rectangle with size (?,?) with model Full with color yellow at (?,'0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 282.0 + 1926.8 = 2208.8
DL input+output M: L = 324.0 + 1926.8 = 2250.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (18,19) and color black and layers
  _0: rectangle with size (18,19) with mask 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
 with color cyan at (0,0)
diff: 
   (0.0 bits)
data: a background with size (18,19) and color black and layers
  _0: 
. . . . 8 . . . . . . 8 . . . . . . . 
. . . . 8 . . . . . . 8 . . . . . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . . . 8 . . . . . . 8 . . . . . . . 
. . . . 8 . . . . . . 8 . . . . . . . 
. . . . 8 . . . . . . 8 . . . . . . . 
. . . . 8 . . . . . . 8 . . . . . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . . . 8 . . . . . . 8 . . . . . . . 
. . . . 8 . . . . . . 8 . . . . . . . 
. . . . 8 . . . . . . 8 . . . . . . . 
. . . . 8 . . . . . . 8 . . . . . . . 
. . . . 8 . . . . . . 8 . . . . . . . 
. . . . 8 . . . . . . 8 . . . . . . . 
. . . . 8 . . . . . . 8 . . . . . . . 
. . . . 8 . . . . . . 8 . . . . . . . 
. . . . 8 . . . . . . 8 . . . . . . . 
. . . . 8 . . . . . . 8 . . . . . . . 
 at (0,0)
  _01: rectangle with size (4,7) with model Full with color green at (3,12)
  _011: 
0 0 0 0 0 0 
0 0 0 0 0 0 
 with color red at (0,5)
  _0111: 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
 with color pink at (3,5)
  _01111: rectangle with size (10,6) with model Full with color blue at (8,5)
  _011111: rectangle with size (4,4) with model Full with color yellow at (3,0)
diff: 
   (102.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,19) and color black and layers
  _0: rectangle with size (18,19) with mask 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
. . . . 0 . . . . . . 0 . . . . . . . 
 with color cyan at (0,0)
diff: 
! 152 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (18,19) and color black and layers
  _0: rectangle with size (1,19) with model Full with color cyan at (2,0)
  + 51 delta pixels
diff: 
! 199 wrong pixels (generated / expected)

TRAIN 272f95fa.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (12,14) and color black and layers
  _0: rectangle with size (12,14) with mask 
. . 0 . . . . . . 0 . . . . 
. . 0 . . . . . . 0 . . . . 
. . 0 . . . . . . 0 . . . . 
. . 0 . . . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . . . . . 0 . . . . 
. . 0 . . . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . . . . . 0 . . . . 
. . 0 . . . . . . 0 . . . . 
. . 0 . . . . . . 0 . . . . 
. . 0 . . . . . . 0 . . . . 
 with color cyan at (0,0)
diff: 
   (0.0 bits)
data: a background with size (12,14) and color black and layers
  _0: 
. . 8 . . . . . . 8 . . . . 
. . 8 . . . . . . 8 . . . . 
. . 8 . . . . . . 8 . . . . 
. . 8 . . . . . . 8 . . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . 8 . . . . . . 8 . . . . 
. . 8 . . . . . . 8 . . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . 8 . . . . . . 8 . . . . 
. . 8 . . . . . . 8 . . . . 
. . 8 . . . . . . 8 . . . . 
. . 8 . . . . . . 8 . . . . 
 at (0,0)
  _01: rectangle with size (4,6) with model Full with color red at (0,3)
  _011: 
0 0 0 0 0 0 
0 0 0 0 0 0 
 with color pink at (5,3)
  _0111: 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
 with color blue at (8,3)
  _01111: rectangle with size (2,4) with model Full with color green at (5,10)
  _011111: rectangle with size (2,2) with model Full with color yellow at (5,0)
diff: 
   (90.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,14) and color black and layers
  _0: rectangle with size (12,14) with mask 
. . 0 . . . . . . 0 . . . . 
. . 0 . . . . . . 0 . . . . 
. . 0 . . . . . . 0 . . . . 
. . 0 . . . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . . . . . 0 . . . . 
. . 0 . . . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . . . . . 0 . . . . 
. . 0 . . . . . . 0 . . . . 
. . 0 . . . . . . 0 . . . . 
. . 0 . . . . . . 0 . . . . 
 with color cyan at (0,0)
diff: 
! 76 wrong pixels (generated / expected)

TRAIN 272f95fa.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
undefined expression: ScaleDown: not an integer

TEST 272f95fa.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 17.0 sec (17.0 sec/task)
bits-train-error = 1926.8 bits (1926.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-345] Checking task 27a28665.json: 7 train, 3 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 24581.2 = 24583.5
DL output with Mo: L = 2.3 + 3403.7 = 3406.0
DL input+output M: L = 4.6 + 27984.9 = 27989.5

# learning a model for train pairs
2.000	
1.325	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.811	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.471	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.336	OUT SPE ^.size = '(1, 1)
0.329	IN  SPE ^.color = black
0.191	
0.190	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(1, 1) and color ? and layers
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.1 + 3392.9 = 3435.0
DL output with Mo: L = 18.5 + 627.6 = 646.1
DL input+output M: L = 60.6 + 4020.5 = 4081.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(1, 1) and color ? and layers
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 18.5 + 627.6 = 646.1
DL input+output M: L = 20.8 + 627.6 = 648.4

# train input/output grids

## instance 1

> Input and output best reading:

data: 
5#5#0 
5#0 5#
0 5#0 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color blue and layers
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#5#0 
5#0 5#
0 5#0 

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 27a28665.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
8 0 8 
0 8 0 
8 0 8 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color red and layers
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 0 8 
0 8 0 
8 0 8 

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 27a28665.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
5#0 5#
0 5#0 
5#0 5#

diff: 
   (0.0 bits)
data: a background with size (1,1) and color red and layers
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#0 5#
0 5#0 
5#0 5#

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 27a28665.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: 
0 1 1 
0 1 1 
1 0 0 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color green and layers
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 1 1 
0 1 1 
1 0 0 

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 27a28665.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: 
0 8 8 
0 8 8 
8 0 0 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color green and layers
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 8 8 
0 8 8 
8 0 0 

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 27a28665.json/5: 0 - (FAILURE)

## instance 6

> Input and output best reading:

data: 
4 4 0 
4 0 4 
0 4 0 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color blue and layers
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 4 0 
4 0 4 
0 4 0 

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 27a28665.json/6: 0 - (FAILURE)

## instance 7

> Input and output best reading:

data: 
0 5#0 
5#5#5#
0 5#0 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color pink and layers
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 5#0 
5#5#5#
0 5#0 

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 27a28665.json/7: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 8 0 
8 8 8 
0 8 0 

diff: 
! 1 wrong pixels (generated / expected)

TEST 27a28665.json/1: 0 - (FAILURE)

## instance 2

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
7#7#0 
7#0 7#
0 7#0 

diff: 
! 1 wrong pixels (generated / expected)

TEST 27a28665.json/2: 0 - (FAILURE)

## instance 3

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 0 2 
0 2 0 
2 0 2 

diff: 
! 1 wrong pixels (generated / expected)

TEST 27a28665.json/3: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 1.4 sec (1.4 sec/task)
bits-train-error = 627.6 bits (627.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-344] Checking task 28bf18c6.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 75779.3 = 75781.7
DL output with Mo: L = 2.3 + 20923.3 = 20925.6
DL input+output M: L = 4.6 + 96702.6 = 96707.3

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = tiling(strip(^), 1, 2)
0.094	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.026	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.025	IN  SPE ^.color = black
0.001	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
tiling(strip(^), 1, 2)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.1 + 1750.1 = 1792.2
DL output with Mo: L = 18.9 + 0.0 = 18.9
DL input+output M: L = 61.0 + 1750.1 = 1811.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
tiling(strip(^), 1, 2)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 18.9 + 0.0 = 18.9
DL input+output M: L = 21.2 + 0.0 = 21.2

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 
0 8 8 0 0 0 0 0 
0 0 8 0 0 0 0 0 
0 8 8 8 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
8 8 0 8 8 0 
0 8 0 0 8 0 
8 8 8 8 8 8 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 
0 8 8 0 0 0 0 0 
0 0 8 0 0 0 0 0 
0 8 8 8 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 28bf18c6.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 2 0 0 0 0 
0 0 2 2 2 0 0 0 
0 0 2 2 0 0 0 0 

diff: 
   (0.0 bits)
data: 
0 2 0 0 2 0 
2 2 2 2 2 2 
2 2 0 2 2 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 2 0 0 0 0 
0 0 2 2 2 0 0 0 
0 0 2 2 0 0 0 0 

diff: 
correct output grid

TRAIN 28bf18c6.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 
0 0 0 0 0 1 1 0 
0 0 0 0 1 0 0 0 
0 0 0 0 0 1 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
0 1 1 0 1 1 
1 0 0 1 0 0 
0 1 0 0 1 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 
0 0 0 0 0 1 1 0 
0 0 0 0 1 0 0 0 
0 0 0 0 0 1 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 28bf18c6.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 3 0 0 0 0 
0 3 3 3 0 0 0 0 
0 3 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 

diff: 
correct output grid

TEST 28bf18c6.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 0.7 sec (0.7 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-343] Checking task 28e73c20.json: 5 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 239738.7 = 239741.0
DL output with Mo: L = 2.3 + 239738.7 = 239741.0
DL input+output M: L = 4.6 + 479477.3 = 479482.0

# learning a model for train pairs
2.000	
1.005	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.424	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.038	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.033	OUT SPE ^.size = ^.size
0.030	OUT SPE ^.layer_0.shape.mask.size = ^.size - (2, 1)
0.027	OUT SPE ^.layer_0.pos = '(1, 0)
0.025	OUT SPE ^.color = green
0.024	OUT SPE ^.layer_0.shape.color = black
0.024	IN  SPE ^.color = black
0.020	
0.020	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color green and layers
  _0: rectangle with size ^.size - (2, 1) with model ? with color black at '(1, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers

DL input  with Mi: L = 13.1 + 992.8 = 1005.8
DL output with Mo: L = 66.3 + 4614.7 = 4681.0
DL input+output M: L = 79.4 + 5607.5 = 5686.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color green and layers
  _0: rectangle with size ^.size - (2, 1) with model ? with color black at '(1, 0)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 66.3 + 4614.7 = 4681.0
DL input+output M: L = 68.6 + 4614.7 = 4683.4

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (6,6) and color green and layers
  _0: rectangle with size (4,5) with mask 
0 0 0 0 0 
. . . . 0 
. 0 . . 0 
. 0 0 0 0 
 with color black at (1,0)
diff: 
   (21.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 

diff: 
! 8 wrong pixels (generated / expected)

TRAIN 28e73c20.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (8,8) and color green and layers
  _0: rectangle with size (6,7) with mask 
0 0 0 0 0 0 0 
. . . . . . 0 
. 0 0 0 0 . 0 
. 0 . . 0 . 0 
. 0 . . . . 0 
. 0 0 0 0 0 0 
 with color black at (1,0)
diff: 
   (44.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 

diff: 
! 18 wrong pixels (generated / expected)

TRAIN 28e73c20.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (15,15) and color green and layers
  _0: rectangle with size (13,14) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . . . 0 
. 0 0 0 0 0 0 0 0 0 0 0 . 0 
. 0 . . . . . . . . . 0 . 0 
. 0 . 0 0 0 0 0 0 0 . 0 . 0 
. 0 . 0 . . . . . 0 . 0 . 0 
. 0 . 0 . 0 0 0 . 0 . 0 . 0 
. 0 . 0 . 0 . . . 0 . 0 . 0 
. 0 . 0 . 0 0 0 0 0 . 0 . 0 
. 0 . 0 . . . . . . . 0 . 0 
. 0 . 0 0 0 0 0 0 0 0 0 . 0 
. 0 . . . . . . . . . . . 0 
. 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color black at (1,0)
diff: 
   (185.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
! 84 wrong pixels (generated / expected)

TRAIN 28e73c20.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (13,13) and color green and layers
  _0: rectangle with size (11,12) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . 0 
. 0 0 0 0 0 0 0 0 0 . 0 
. 0 . . . . . . . 0 . 0 
. 0 . 0 0 0 0 0 . 0 . 0 
. 0 . 0 . . . 0 . 0 . 0 
. 0 . 0 . 0 0 0 . 0 . 0 
. 0 . 0 . . . . . 0 . 0 
. 0 . 0 0 0 0 0 0 0 . 0 
. 0 . . . . . . . . . 0 
. 0 0 0 0 0 0 0 0 0 0 0 
 with color black at (1,0)
diff: 
   (135.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
! 60 wrong pixels (generated / expected)

TRAIN 28e73c20.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (10,10) and color green and layers
  _0: rectangle with size (8,9) with mask 
0 0 0 0 0 0 0 0 0 
. . . . . . . . 0 
. 0 0 0 0 0 0 . 0 
. 0 . . . . 0 . 0 
. 0 . 0 . . 0 . 0 
. 0 . 0 0 0 0 . 0 
. 0 . . . . . . 0 
. 0 0 0 0 0 0 0 0 
 with color black at (1,0)
diff: 
   (74.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 

diff: 
! 32 wrong pixels (generated / expected)

TRAIN 28e73c20.json/5: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
! 128 wrong pixels (generated / expected)

TEST 28e73c20.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 1.9 sec (1.9 sec/task)
bits-train-error = 4614.7 bits (4614.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-342] Checking task 29623171.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 145705.7 = 145708.0
DL output with Mo: L = 2.3 + 145705.7 = 145708.0
DL input+output M: L = 4.6 + 291411.4 = 291416.0

# learning a model for train pairs
2.000	
1.417	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.850	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.553	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.224	OUT ADD ^.layer_0 = ^.layer_0
0.157	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.130	IN  SPE ^.layer_0.shape.mask = 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 

0.117	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.112	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.107	IN  ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.102	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.098	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.093	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.088	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.084	OUT SPE ^.layer_01.shape = ^.layer_0111.shape * '3
0.080	OUT SPE ^.size = ^.size
0.079	IN  SPE ^.layer_0.shape.color = grey
0.078	OUT SPE ^.layer_01.pos.j = right(^.layer_0) - 2
0.077	OUT SPE ^.layer_01.pos.i = ^.layer_0111111.pos.i - ^.layer_011111.pos.j - ^.layer_0.pos.j
0.076	IN  SPE ^.layer_01.shape.mask.model = Full
0.076	IN  SPE ^.color = black
0.075	OUT SPE ^.color = black
0.028	
0.028	IN  GEN ^.layer_0.shape.color = ?
0.028	IN  GEN ^.layer_01.shape.mask.model = ?
0.028	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_0111.shape * '3 at (^.layer_0111111.pos.i - ^.layer_011111.pos.j - ^.layer_0.pos.j,right(^.layer_0) - 2)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)

DL input  with Mi: L = 320.1 + 6863.6 = 7183.7
DL output with Mo: L = 143.0 + 3648.1 = 3791.1
DL input+output M: L = 463.0 + 10511.8 = 10974.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_0111.shape * '3 at (^.layer_0111111.pos.i - ^.layer_011111.pos.j - ^.layer_0.pos.j,right(^.layer_0) - 2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)

DL input  with Mi: L = 316.1 + 0.0 = 316.1
DL output with Mo: L = 143.0 + 3648.1 = 3791.1
DL input+output M: L = 459.1 + 3648.1 = 4107.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _00: rectangle with size (1,1) with model Full with color blue at (1,9)
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (3,1) with model Full with color blue at (2,6)
  _011: rectangle with size (1,1) with model Full with color blue at (1,0)
  _0111: point with color blue at (5,9)
  _01111: point with color blue at (8,8)
  _011111: point with color blue at (9,1)
  _0111111: point with color blue at (9,10)
diff: 
   (0.0 bits)
data: a background with size (11,11) and color black and layers
  _0: 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
5#5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
5#5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
 at (0,0)
  _01: 
1 1 1 
1 1 1 
1 1 1 
 at (8,8)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _00: rectangle with size (1,1) with model Full with color blue at (1,9)
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (3,1) with model Full with color blue at (2,6)
  _011: rectangle with size (1,1) with model Full with color blue at (1,0)
  _0111: point with color blue at (5,9)
  _01111: point with color blue at (8,8)
  _011111: point with color blue at (9,1)
  _0111111: point with color blue at (9,10)
diff: 
correct output grid

TRAIN 29623171.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _00: rectangle with size (2,1) with model Full with color red at (4,0)
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,4) with model Full with color red at (0,5)
  _011: rectangle with size (1,1) with model Full with color red at (1,0)
  _0111: point with color red at (1,10)
  _01111: point with color red at (5,6)
  _011111: point with color red at (6,9)
  _0111111: point with color red at (9,0)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (11,11) and color black and layers
  _0: 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
5#5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
5#5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
 at (0,0)
  _01: 
2 2 2 
2 2 2 
2 2 2 
 at (0,8)
  + 9 delta pixels
diff: 
   (364.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _00: rectangle with size (2,1) with model Full with color red at (4,0)
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,4) with model Full with color red at (0,5)
  _011: rectangle with size (1,1) with model Full with color red at (1,0)
  _0111: point with color red at (1,10)
  _01111: point with color red at (5,6)
  _011111: point with color red at (6,9)
  _0111111: point with color red at (9,0)
  + 3 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,11) and color black and layers
  _00: rectangle with size (2,1) with model Full with color red at (4,0)
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,4) with model Full with color red at (0,5)
  _011: rectangle with size (1,1) with model Full with color red at (1,0)
  _0111: point with color red at (1,10)
  _01111: point with color red at (5,6)
  _011111: point with color red at (9,0)
  _0111111: point with color red at (6,9)
  + 3 delta pixels
diff: 
! 24 wrong pixels (generated / expected)

TRAIN 29623171.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _00: rectangle with size (2,3) with mask 
0 0 . 
. . 0 
 with color green at (9,8)
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,2) with model Full with color green at (0,0)
  _011: rectangle with size (2,2) with model Odd Checkboard with color green at (5,4)
  _0111: point with color green at (1,9)
  _01111: point with color green at (5,1)
  _011111: point with color green at (9,1)
  _0111111: point with color green at (9,4)
diff: 
   (0.0 bits)
data: a background with size (11,11) and color black and layers
  _0: 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
5#5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
5#5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
. . . 5#. . . 5#. . . 
 at (0,0)
  _01: 
3 3 3 
3 3 3 
3 3 3 
 at (8,8)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _00: rectangle with size (2,3) with mask 
0 0 . 
. . 0 
 with color green at (9,8)
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,2) with model Full with color green at (0,0)
  _011: rectangle with size (2,2) with model Odd Checkboard with color green at (5,4)
  _0111: point with color green at (1,9)
  _01111: point with color green at (5,1)
  _011111: point with color green at (9,1)
  _0111111: point with color green at (9,4)
diff: 
correct output grid

TRAIN 29623171.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _00: rectangle with size (3,2) with mask 
0 0 
. 0 
0 . 
 with color yellow at (0,0)
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (9,1) with model Full with color yellow at (1,9)
  _011: rectangle with size (3,3) with mask 
. 0 . 
. . 0 
0 0 . 
 with color yellow at (8,4)
  _0111: point with color yellow at (1,6)
  _01111: point with color yellow at (1,8)
  _011111: point with color yellow at (5,0)
  _0111111: point with color yellow at (5,5)
  + 7 delta pixels
diff: 
! 24 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,11) and color black and layers
  _00: rectangle with size (3,2) with mask 
0 0 
. 0 
0 . 
 with color yellow at (0,0)
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (9,1) with model Full with color yellow at (1,9)
  _011: rectangle with size (3,3) with mask 
. 0 . 
. . 0 
0 0 . 
 with color yellow at (8,4)
  _0111: point with color yellow at (1,6)
  _01111: point with color yellow at (1,8)
  _011111: point with color yellow at (5,5)
  _0111111: point with color yellow at (5,0)
  + 7 delta pixels
diff: 
! 27 wrong pixels (generated / expected)

TEST 29623171.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 9.8 sec (9.8 sec/task)
bits-train-error = 3648.1 bits (3648.1 bits/task)
acc-train-micro = 0.67 tasks (66.67%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.67
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-341] Checking task 29c11459.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 43263.7 = 43266.0
DL output with Mo: L = 2.3 + 43263.7 = 43266.0
DL input+output M: L = 4.6 + 86527.4 = 86532.0

# learning a model for train pairs
2.000	
1.047	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.257	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.181	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.105	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.094	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.083	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.072	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.064	OUT SPE ^.size = ^.size
0.057	OUT SPE ^.layer_0.shape.mask = 
0 0 0 0 0 

0.051	OUT SPE ^.layer_01.shape.mask = 
0 0 0 0 0 

0.046	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.042	OUT SPE ^.layer_011.pos = average(^.layer_0.pos, ^.layer_01.pos)
0.037	OUT SPE ^.layer_01.pos = average(^.layer_0.pos, ^.layer_01.pos) + (0, 1)
0.035	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.032	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.030	OUT SPE ^.layer_011.shape.color = grey
0.029	IN  SPE ^.color = black
0.027	OUT SPE ^.color = black
0.004	
0.004	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 0 0 0 0 
 with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: 
0 0 0 0 0 
 with color ^.layer_01.shape.color at average(^.layer_0.pos, ^.layer_01.pos) + (0, 1)
  _011: point with color grey at average(^.layer_0.pos, ^.layer_01.pos)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.7 + 1006.3 = 1057.1
DL output with Mo: L = 128.4 + 0.0 = 128.4
DL input+output M: L = 179.2 + 1006.3 = 1185.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 0 0 0 0 
 with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: 
0 0 0 0 0 
 with color ^.layer_01.shape.color at average(^.layer_0.pos, ^.layer_01.pos) + (0, 1)
  _011: point with color grey at average(^.layer_0.pos, ^.layer_01.pos)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.6 + 0.0 = 50.6
DL output with Mo: L = 128.4 + 0.0 = 128.4
DL input+output M: L = 179.0 + 0.0 = 179.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (5,11) and color black and layers
  _0: point with color blue at (1,0)
  _01: point with color red at (1,10)
diff: 
   (0.0 bits)
data: a background with size (5,11) and color black and layers
  _0: 
0 0 0 0 0 
 with color blue at (1,0)
  _01: 
0 0 0 0 0 
 with color red at (1,6)
  _011: point with color grey at (1,5)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,11) and color black and layers
  _0: point with color blue at (1,0)
  _01: point with color red at (1,10)
diff: 
correct output grid

TRAIN 29c11459.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (5,11) and color black and layers
  _0: point with color green at (3,0)
  _01: point with color orange at (3,10)
diff: 
   (0.0 bits)
data: a background with size (5,11) and color black and layers
  _0: 
0 0 0 0 0 
 with color green at (3,0)
  _01: 
0 0 0 0 0 
 with color orange at (3,6)
  _011: point with color grey at (3,5)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,11) and color black and layers
  _0: point with color green at (3,0)
  _01: point with color orange at (3,10)
diff: 
correct output grid

TRAIN 29c11459.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,11) and color black and layers
  _0: point with color yellow at (1,0)
  _01: point with color cyan at (1,10)
  + 2 delta pixels
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,11) and color black and layers
  _0: point with color cyan at (1,10)
  _01: point with color yellow at (1,0)
  + 2 delta pixels
diff: 
! 20 wrong pixels (generated / expected)

TEST 29c11459.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 2.8 sec (2.8 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-340] Checking task 29ec7d0e.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 536067.0 = 536069.3
DL output with Mo: L = 2.3 + 536067.0 = 536069.3
DL input+output M: L = 4.6 + 1072133.9 = 1072138.6

# learning a model for train pairs
2.000	
1.630	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.307	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.676	OUT SPE ^ = fillResizeAlike(black, ^.size, ^)
0.602	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.584	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.572	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.565	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.561	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.551	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.549	IN  ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.541	IN  ADD ^.layer_01111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.540	IN  SPE ^.layer_0111.shape.mask.model = Full
0.540	IN  SPE ^.layer_01111.shape.mask.model = Full
0.540	IN  SPE ^.layer_011111.shape.mask.model = Full
0.540	IN  SPE ^.layer_0111111.shape.mask.model = Full
0.539	IN  SPE ^.layer_01111111.shape.mask.model = Full
0.539	IN  SPE ^.layer_01.shape.mask.model = Full
0.539	IN  SPE ^.layer_011.shape.mask.model = Full
0.000	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
fillResizeAlike(black, ^.size, ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 239.3 + 288828.8 = 289068.2
DL output with Mo: L = 20.8 + 0.0 = 20.8
DL input+output M: L = 260.2 + 288828.8 = 289089.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
fillResizeAlike(black, ^.size, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 20.8 + 0.0 = 20.8
DL input+output M: L = 23.2 + 0.0 = 23.2

# train input/output grids

## instance 1

> Input and output best reading:

data: 
1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 0 0 1 2 3 4 5#1 2 3 4 5#1 2 3 
1 3 5#0 0 1 3 5#2 4 0 0 5#2 4 1 3 5#
1 4 2 5#3 1 4 2 5#3 0 0 2 5#3 1 4 2 
1 5#4 3 2 1 0 0 3 2 1 5#4 3 2 1 5#4 
1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 1 1 
1 2 3 4 5#1 2 3 4 5#1 0 0 0 5#1 2 3 
1 3 5#2 4 1 3 5#2 4 1 3 5#2 4 1 3 5#
1 4 2 5#3 1 4 2 5#3 1 4 2 5#3 1 4 2 
1 5#4 3 2 1 5#4 3 2 1 5#4 3 2 1 5#4 
0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
0 0 0 0 5#1 2 3 4 5#1 2 3 4 5#1 2 3 
0 0 0 0 4 1 3 5#2 4 1 3 5#2 4 1 3 5#
1 4 2 5#3 1 4 2 5#3 1 4 2 5#3 1 4 2 
1 5#4 3 2 1 5#4 3 2 1 5#4 3 2 1 5#4 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#1 2 3 4 5#1 2 3 4 5#1 2 3 
1 3 5#2 4 1 3 5#2 4 1 3 5#2 4 1 3 5#

diff: 
   (0.0 bits)
data: 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#1 2 3 4 5#1 2 3 4 5#1 2 3 
1 3 5#2 4 1 3 5#2 4 1 3 5#2 4 1 3 5#
1 4 2 5#3 1 4 2 5#3 1 4 2 5#3 1 4 2 
1 5#4 3 2 1 5#4 3 2 1 5#4 3 2 1 5#4 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#1 2 3 4 5#1 2 3 4 5#1 2 3 
1 3 5#2 4 1 3 5#2 4 1 3 5#2 4 1 3 5#
1 4 2 5#3 1 4 2 5#3 1 4 2 5#3 1 4 2 
1 5#4 3 2 1 5#4 3 2 1 5#4 3 2 1 5#4 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#1 2 3 4 5#1 2 3 4 5#1 2 3 
1 3 5#2 4 1 3 5#2 4 1 3 5#2 4 1 3 5#
1 4 2 5#3 1 4 2 5#3 1 4 2 5#3 1 4 2 
1 5#4 3 2 1 5#4 3 2 1 5#4 3 2 1 5#4 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#1 2 3 4 5#1 2 3 4 5#1 2 3 
1 3 5#2 4 1 3 5#2 4 1 3 5#2 4 1 3 5#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 0 0 1 2 3 4 5#1 2 3 4 5#1 2 3 
1 3 5#0 0 1 3 5#2 4 0 0 5#2 4 1 3 5#
1 4 2 5#3 1 4 2 5#3 0 0 2 5#3 1 4 2 
1 5#4 3 2 1 0 0 3 2 1 5#4 3 2 1 5#4 
1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 1 1 
1 2 3 4 5#1 2 3 4 5#1 0 0 0 5#1 2 3 
1 3 5#2 4 1 3 5#2 4 1 3 5#2 4 1 3 5#
1 4 2 5#3 1 4 2 5#3 1 4 2 5#3 1 4 2 
1 5#4 3 2 1 5#4 3 2 1 5#4 3 2 1 5#4 
0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
0 0 0 0 5#1 2 3 4 5#1 2 3 4 5#1 2 3 
0 0 0 0 4 1 3 5#2 4 1 3 5#2 4 1 3 5#
1 4 2 5#3 1 4 2 5#3 1 4 2 5#3 1 4 2 
1 5#4 3 2 1 5#4 3 2 1 5#4 3 2 1 5#4 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#1 2 3 4 5#1 2 3 4 5#1 2 3 
1 3 5#2 4 1 3 5#2 4 1 3 5#2 4 1 3 5#

diff: 
correct output grid

TRAIN 29ec7d0e.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 1 0 0 0 5#6 1 2 3 4 5#6 
1 3 5#1 3 5#1 0 0 0 3 5#1 3 5#1 3 5#
1 4 1 4 1 4 1 0 0 0 1 4 1 4 1 4 1 4 
1 5#3 1 5#3 1 5#3 1 5#0 0 0 3 1 5#3 
1 6 5#0 0 0 0 6 5#4 3 0 0 0 5#4 3 2 
1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 0 0 0 0 2 3 4 5#6 1 2 3 4 5#6 
1 3 5#1 3 5#1 3 5#1 3 5#1 3 5#1 3 5#
1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 
1 5#3 1 5#3 1 5#3 1 5#3 1 5#3 1 5#3 
1 6 5#4 3 2 1 0 0 0 3 2 0 0 0 0 3 2 
1 1 1 1 1 1 1 0 0 0 1 1 0 0 0 0 1 1 
1 2 3 4 5#6 1 0 0 0 5#6 0 0 0 0 5#6 
1 3 5#1 3 5#1 3 5#1 3 5#1 3 5#1 3 5#
1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 
1 5#3 1 5#3 1 5#3 1 5#3 1 5#3 1 5#3 
1 6 5#4 3 2 1 6 5#4 3 2 1 6 5#4 3 2 

diff: 
   (0.0 bits)
data: 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 1 2 3 4 5#6 1 2 3 4 5#6 
1 3 5#1 3 5#1 3 5#1 3 5#1 3 5#1 3 5#
1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 
1 5#3 1 5#3 1 5#3 1 5#3 1 5#3 1 5#3 
1 6 5#4 3 2 1 6 5#4 3 2 1 6 5#4 3 2 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 1 2 3 4 5#6 1 2 3 4 5#6 
1 3 5#1 3 5#1 3 5#1 3 5#1 3 5#1 3 5#
1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 
1 5#3 1 5#3 1 5#3 1 5#3 1 5#3 1 5#3 
1 6 5#4 3 2 1 6 5#4 3 2 1 6 5#4 3 2 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 1 2 3 4 5#6 1 2 3 4 5#6 
1 3 5#1 3 5#1 3 5#1 3 5#1 3 5#1 3 5#
1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 
1 5#3 1 5#3 1 5#3 1 5#3 1 5#3 1 5#3 
1 6 5#4 3 2 1 6 5#4 3 2 1 6 5#4 3 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 1 0 0 0 5#6 1 2 3 4 5#6 
1 3 5#1 3 5#1 0 0 0 3 5#1 3 5#1 3 5#
1 4 1 4 1 4 1 0 0 0 1 4 1 4 1 4 1 4 
1 5#3 1 5#3 1 5#3 1 5#0 0 0 3 1 5#3 
1 6 5#0 0 0 0 6 5#4 3 0 0 0 5#4 3 2 
1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 0 0 0 0 2 3 4 5#6 1 2 3 4 5#6 
1 3 5#1 3 5#1 3 5#1 3 5#1 3 5#1 3 5#
1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 
1 5#3 1 5#3 1 5#3 1 5#3 1 5#3 1 5#3 
1 6 5#4 3 2 1 0 0 0 3 2 0 0 0 0 3 2 
1 1 1 1 1 1 1 0 0 0 1 1 0 0 0 0 1 1 
1 2 3 4 5#6 1 0 0 0 5#6 0 0 0 0 5#6 
1 3 5#1 3 5#1 3 5#1 3 5#1 3 5#1 3 5#
1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 
1 5#3 1 5#3 1 5#3 1 5#3 1 5#3 1 5#3 
1 6 5#4 3 2 1 6 5#4 3 2 1 6 5#4 3 2 

diff: 
correct output grid

TRAIN 29ec7d0e.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 3 4 
1 3 5#7#2 4 6 1 3 5#7#2 0 0 0 0 5#7#
1 4 7#3 6 2 0 0 0 0 0 0 0 0 0 0 7#3 
1 5#2 6 3 7#0 0 0 0 0 0 0 0 0 0 2 6 
1 0 0 2 7#5#0 0 0 0 2 7#0 0 0 0 4 2 
1 0 0 5#4 3 0 0 0 0 5#4 3 0 0 0 6 5#
1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 
1 0 0 4 5#6 7#1 2 3 4 5#6 7#1 2 3 4 
1 3 5#7#2 4 6 1 3 5#7#2 4 6 1 3 5#7#
1 4 7#3 6 2 5#1 4 7#3 6 2 5#1 4 7#3 
1 5#2 6 3 7#4 1 5#2 6 3 7#4 1 5#2 6 
1 6 4 2 7#5#3 1 6 4 2 7#5#3 1 6 4 2 
1 7#6 5#4 3 2 1 7#6 5#4 3 2 1 7#6 5#
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 3 4 
1 3 5#7#2 4 6 1 3 5#7#2 4 6 1 3 5#7#
1 4 7#3 6 2 5#1 4 7#3 6 2 5#1 4 7#3 

diff: 
   (0.0 bits)
data: 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 3 4 
1 3 5#7#2 4 6 1 3 5#7#2 4 6 1 3 5#7#
1 4 7#3 6 2 5#1 4 7#3 6 2 5#1 4 7#3 
1 5#2 6 3 7#4 1 5#2 6 3 7#4 1 5#2 6 
1 6 4 2 7#5#3 1 6 4 2 7#5#3 1 6 4 2 
1 7#6 5#4 3 2 1 7#6 5#4 3 2 1 7#6 5#
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 3 4 
1 3 5#7#2 4 6 1 3 5#7#2 4 6 1 3 5#7#
1 4 7#3 6 2 5#1 4 7#3 6 2 5#1 4 7#3 
1 5#2 6 3 7#4 1 5#2 6 3 7#4 1 5#2 6 
1 6 4 2 7#5#3 1 6 4 2 7#5#3 1 6 4 2 
1 7#6 5#4 3 2 1 7#6 5#4 3 2 1 7#6 5#
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 3 4 
1 3 5#7#2 4 6 1 3 5#7#2 4 6 1 3 5#7#
1 4 7#3 6 2 5#1 4 7#3 6 2 5#1 4 7#3 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 3 4 
1 3 5#7#2 4 6 1 3 5#7#2 0 0 0 0 5#7#
1 4 7#3 6 2 0 0 0 0 0 0 0 0 0 0 7#3 
1 5#2 6 3 7#0 0 0 0 0 0 0 0 0 0 2 6 
1 0 0 2 7#5#0 0 0 0 2 7#0 0 0 0 4 2 
1 0 0 5#4 3 0 0 0 0 5#4 3 0 0 0 6 5#
1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 
1 0 0 4 5#6 7#1 2 3 4 5#6 7#1 2 3 4 
1 3 5#7#2 4 6 1 3 5#7#2 4 6 1 3 5#7#
1 4 7#3 6 2 5#1 4 7#3 6 2 5#1 4 7#3 
1 5#2 6 3 7#4 1 5#2 6 3 7#4 1 5#2 6 
1 6 4 2 7#5#3 1 6 4 2 7#5#3 1 6 4 2 
1 7#6 5#4 3 2 1 7#6 5#4 3 2 1 7#6 5#
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 3 4 
1 3 5#7#2 4 6 1 3 5#7#2 4 6 1 3 5#7#
1 4 7#3 6 2 5#1 4 7#3 6 2 5#1 4 7#3 

diff: 
correct output grid

TRAIN 29ec7d0e.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 7#8 1 2 3 4 5#6 7#8 1 2 
1 3 5#7#1 3 5#7#1 3 5#7#1 3 5#7#1 3 
1 4 7#2 5#8 3 6 1 4 7#2 5#8 0 0 1 4 
1 5#1 5#1 5#1 5#1 5#1 5#1 5#0 0 1 5#
1 6 3 8 5#2 7#4 1 6 3 8 5#2 0 0 1 6 
1 7#5#3 1 7#5#3 1 7#5#3 1 7#5#3 1 7#
1 8 7#6 5#4 3 2 1 8 7#6 5#4 3 2 1 8 
1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 
1 2 3 0 0 0 0 0 1 2 3 4 5#6 7#8 1 2 
1 3 5#7#0 0 0 0 1 3 5#7#1 3 5#7#1 3 
1 4 7#2 5#8 3 6 1 4 7#2 5#8 3 6 1 4 
1 5#1 5#1 5#1 5#1 5#1 5#1 5#1 5#1 5#
1 6 3 8 5#2 0 0 1 6 3 8 5#2 7#4 1 6 
1 7#5#3 1 7#0 0 1 7#5#3 1 7#5#3 1 7#
1 8 7#6 0 0 3 2 1 8 7#6 5#4 3 2 1 8 
1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 7#8 1 2 3 4 5#6 7#8 1 2 

diff: 
   (0.0 bits)
data: 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 7#8 1 2 3 4 5#6 7#8 1 2 
1 3 5#7#1 3 5#7#1 3 5#7#1 3 5#7#1 3 
1 4 7#2 5#8 3 6 1 4 7#2 5#8 3 6 1 4 
1 5#1 5#1 5#1 5#1 5#1 5#1 5#1 5#1 5#
1 6 3 8 5#2 7#4 1 6 3 8 5#2 7#4 1 6 
1 7#5#3 1 7#5#3 1 7#5#3 1 7#5#3 1 7#
1 8 7#6 5#4 3 2 1 8 7#6 5#4 3 2 1 8 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 7#8 1 2 3 4 5#6 7#8 1 2 
1 3 5#7#1 3 5#7#1 3 5#7#1 3 5#7#1 3 
1 4 7#2 5#8 3 6 1 4 7#2 5#8 3 6 1 4 
1 5#1 5#1 5#1 5#1 5#1 5#1 5#1 5#1 5#
1 6 3 8 5#2 7#4 1 6 3 8 5#2 7#4 1 6 
1 7#5#3 1 7#5#3 1 7#5#3 1 7#5#3 1 7#
1 8 7#6 5#4 3 2 1 8 7#6 5#4 3 2 1 8 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 7#8 1 2 3 4 5#6 7#8 1 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 7#8 1 2 3 4 5#6 7#8 1 2 
1 3 5#7#1 3 5#7#1 3 5#7#1 3 5#7#1 3 
1 4 7#2 5#8 3 6 1 4 7#2 5#8 0 0 1 4 
1 5#1 5#1 5#1 5#1 5#1 5#1 5#0 0 1 5#
1 6 3 8 5#2 7#4 1 6 3 8 5#2 0 0 1 6 
1 7#5#3 1 7#5#3 1 7#5#3 1 7#5#3 1 7#
1 8 7#6 5#4 3 2 1 8 7#6 5#4 3 2 1 8 
1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 
1 2 3 0 0 0 0 0 1 2 3 4 5#6 7#8 1 2 
1 3 5#7#0 0 0 0 1 3 5#7#1 3 5#7#1 3 
1 4 7#2 5#8 3 6 1 4 7#2 5#8 3 6 1 4 
1 5#1 5#1 5#1 5#1 5#1 5#1 5#1 5#1 5#
1 6 3 8 5#2 0 0 1 6 3 8 5#2 7#4 1 6 
1 7#5#3 1 7#0 0 1 7#5#3 1 7#5#3 1 7#
1 8 7#6 0 0 3 2 1 8 7#6 5#4 3 2 1 8 
1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 7#8 1 2 3 4 5#6 7#8 1 2 

diff: 
correct output grid

TRAIN 29ec7d0e.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 
1 2 3 4 5#6 7#8 9#1 2 3 4 0 0 0 8 9#
1 3 5#7#9#2 4 6 8 1 3 5#7#0 0 0 6 8 
1 4 7#1 4 7#1 4 7#1 4 7#1 4 7#1 4 7#
1 5#9#4 8 3 7#2 6 1 5#9#4 8 3 7#2 6 
1 6 2 0 0 0 4 9#5#1 6 2 7#0 0 0 9#5#
1 7#4 0 0 0 1 7#4 0 0 0 0 0 0 0 7#4 
1 8 6 0 0 0 7#5#3 0 0 0 0 2 9#7#5#3 
1 9#8 0 0 0 4 3 2 0 0 0 0 6 5#4 3 2 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 2 3 4 5#6 7#8 9#1 2 3 4 5#6 7#8 9#
1 3 5#7#9#2 4 6 8 1 3 5#7#9#2 4 6 8 
1 4 7#1 4 7#1 4 7#1 4 7#1 4 7#1 4 7#
1 0 0 0 8 3 7#2 6 1 5#9#4 8 3 7#2 6 
1 0 0 0 3 8 4 9#5#1 6 2 7#3 8 4 9#5#
1 0 0 0 7#4 1 7#4 1 7#4 1 7#4 1 7#4 
1 0 0 0 2 9#7#5#3 1 8 6 4 2 9#7#5#3 
1 9#8 7#6 5#4 3 2 1 9#8 7#6 5#4 3 2 

diff: 
correct output grid

TEST 29ec7d0e.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 10.9 sec (10.9 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-339] Checking task 2bcee788.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 159701.1 = 159703.5
DL output with Mo: L = 2.3 + 159701.1 = 159703.5
DL input+output M: L = 4.6 + 319402.3 = 319406.9

# learning a model for train pairs
2.000	
1.069	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.162	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.087	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.054	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.041	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.036	OUT SPE ^.size = ^.size
0.034	OUT SPE ^.color = green
0.032	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.031	IN  SPE ^.layer_01.shape.color = red
0.030	IN  SPE ^.layer_01.shape.mask.model = Full
0.029	IN  SPE ^.color = black
0.010	
0.010	IN  DEL ^.layer_01
0.010	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color green and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color red at (?,?)

DL input  with Mi: L = 74.2 + 3083.3 = 3157.5
DL output with Mo: L = 44.5 + 1500.3 = 1544.8
DL input+output M: L = 118.7 + 4583.6 = 4702.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color green and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 44.5 + 1500.3 = 1544.8
DL input+output M: L = 86.5 + 1500.3 = 1586.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. . 0 
 with color yellow at (3,2)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color green and layers
  _0: rectangle with size (3,6) with model +-cross with color yellow at (3,2)
diff: 
   (32.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. . 0 
 with color yellow at (3,2)
  + 3 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,1) with model Full with color red at (3,5)
  + 5 delta pixels
diff: 
! 14 wrong pixels (generated / expected)

TRAIN 2bcee788.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 . 
. 0 0 
 with color pink at (4,3)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color green and layers
  _0: rectangle with size (6,3) with mask 
. 0 0 
. 0 . 
0 0 . 
0 0 . 
. 0 . 
. 0 0 
 with color pink at (1,3)
diff: 
   (46.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 . 
. 0 0 
 with color pink at (4,3)
  + 2 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (3,3)
  + 5 delta pixels
diff: 
! 14 wrong pixels (generated / expected)

TRAIN 2bcee788.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color orange at (4,4)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color green and layers
  _0: rectangle with size (2,4) with mask 
. 0 0 . 
0 0 0 0 
 with color orange at (4,2)
diff: 
   (32.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color orange at (4,4)
  + 2 delta pixels
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,1) with model Full with color red at (4,3)
  + 3 delta pixels
diff: 
! 10 wrong pixels (generated / expected)

TRAIN 2bcee788.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color cyan at (4,3)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color green and layers
  _0: rectangle with size (4,3) with mask 
0 0 0 
. . 0 
. . 0 
0 0 0 
 with color cyan at (4,3)
diff: 
   (38.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color cyan at (4,3)
  + 1 delta pixels
diff: 
! 12 wrong pixels (generated / expected)

TRAIN 2bcee788.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 . 
0 0 
. 0 
 with color blue at (3,4)
  + 2 delta pixels
diff: 
! 12 wrong pixels (generated / expected)

TEST 2bcee788.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 6.0 sec (6.0 sec/task)
bits-train-error = 1500.3 bits (1500.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-338] Checking task 2bee17df.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 156112.0 = 156114.3
DL output with Mo: L = 2.3 + 156112.0 = 156114.3
DL input+output M: L = 4.6 + 312224.0 = 312228.7

# learning a model for train pairs
2.000	
1.462	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.113	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.891	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.647	OUT ADD ^.layer_0 = ^.layer_0
0.445	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.259	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.084	OUT ADD ^.layer_011 = ^.layer_01
0.080	OUT SPE ^.size = ^.size
0.076	OUT SPE ^.layer_01.shape.mask.size = ^.size - (2, 2)
0.074	OUT SPE ^.layer_01.pos = '(1, 1)
0.073	IN  SPE ^.layer_0.shape.color = red
0.072	IN  SPE ^.layer_01.shape.color = cyan
0.071	OUT SPE ^.layer_01.shape.color = green
0.070	IN  SPE ^.color = black
0.070	OUT SPE ^.color = black
0.018	
0.018	IN  GEN ^.layer_01.shape.color = ?
0.018	IN  GEN ^.layer_0.shape.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size ^.size - (2, 2) with model ? with color green at '(1, 1)
  _011: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at (?,?)
  _01: rectangle with size (?,?) with model ? with color cyan at (?,?)

DL input  with Mi: L = 77.0 + 8170.5 = 8247.4
DL output with Mo: L = 78.3 + 2585.9 = 2664.2
DL input+output M: L = 155.3 + 10756.3 = 10911.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size ^.size - (2, 2) with model ? with color green at '(1, 1)
  _011: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.3 + 0.0 = 70.3
DL output with Mo: L = 78.3 + 2585.9 = 2664.2
DL input+output M: L = 148.6 + 2585.9 = 2734.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (11,12) with mask 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . 0 
0 . . . . . . . . . . 0 
0 0 . . . . 0 0 . . . 0 
0 0 0 . . 0 0 0 . . 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color cyan at (1,0)
  _01: rectangle with size (7,12) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 0 . 0 0 0 0 0 
. . . . . 0 . . 0 0 . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
 with color red at (0,0)
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _0: 
8 . . . . . . . . . . . 
8 . . . . . . . . . . . 
8 . . . . . . . . . . . 
8 . . . . . . . . . . . 
8 . . . . . . . . . . . 
8 . . . . . . . . . . . 
8 . . . . . . . . . . 8 
8 . . . . . . . . . . 8 
8 8 . . . . 8 8 . . . 8 
8 8 8 . . 8 8 8 . . 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 
 at (1,0)
  _01: rectangle with size (10,10) with mask 
. . 0 . . . . . . . 
. . 0 . . . . . . . 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
. . 0 . . . . . . . 
. . 0 . . . . . . . 
 with color green at (1,1)
  _011: 
2 2 2 2 2 2 2 2 2 2 2 2 
. . . . 2 2 . 2 2 2 2 2 
. . . . . 2 . . 2 2 . 2 
. . . . . . . . . . . 2 
. . . . . . . . . . . 2 
. . . . . . . . . . . 2 
. . . . . . . . . . . 2 
 at (0,0)
diff: 
   (97.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (11,12) with mask 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . 0 
0 . . . . . . . . . . 0 
0 0 . . . . 0 0 . . . 0 
0 0 0 . . 0 0 0 . . 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color cyan at (1,0)
  _01: rectangle with size (7,12) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 0 . 0 0 0 0 0 
. . . . . 0 . . 0 0 . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
 with color red at (0,0)
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (7,12) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 0 . 0 0 0 0 0 
. . . . . 0 . . 0 0 . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
 with color red at (0,0)
  _01: rectangle with size (11,12) with mask 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . 0 
0 . . . . . . . . . . 0 
0 0 . . . . 0 0 . . . 0 
0 0 0 . . 0 0 0 . . 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color cyan at (1,0)
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (11,12) with mask 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . 0 
0 . . . . . . . . . . 0 
0 0 . . . . 0 0 . . . 0 
0 0 0 . . 0 0 0 . . 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color cyan at (1,0)
  _01: rectangle with size (2,8) with model Full with color red at (0,4)
  + 14 delta pixels
diff: 
! 36 wrong pixels (generated / expected)

TRAIN 2bee17df.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (11,12) with mask 
0 . . . . . . . . . . . 
0 0 . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 0 0 . . . . . . . . . 
0 0 . . . . . . . . . . 
0 0 . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . 0 0 
0 0 . 0 . . 0 . . 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color red at (1,0)
  _01: rectangle with size (9,12) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . 0 0 0 0 0 0 
. . . . . . . 0 0 . . 0 
. . . . . . . 0 . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
 with color cyan at (0,0)
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _0: 
2 . . . . . . . . . . . 
2 2 . . . . . . . . . . 
2 . . . . . . . . . . . 
2 . . . . . . . . . . . 
2 2 2 . . . . . . . . . 
2 2 . . . . . . . . . . 
2 2 . . . . . . . . . . 
2 . . . . . . . . . . . 
2 . . . . . . . . . 2 2 
2 2 . 2 . . 2 . . 2 2 2 
2 2 2 2 2 2 2 2 2 2 2 2 
 at (1,0)
  _01: rectangle with size (10,10) with mask 
. . . 0 0 . . . . . 
. . . 0 0 . . . . . 
. . . 0 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 
. . . 0 0 . . . . . 
. . . 0 0 . . . . . 
. . . 0 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 
. . . 0 0 . . . . . 
. . . 0 0 . . . . . 
 with color green at (1,1)
  _011: 
8 8 8 8 8 8 8 8 8 8 8 8 
. . . . . . 8 8 8 8 8 8 
. . . . . . . 8 8 . . 8 
. . . . . . . 8 . . . 8 
. . . . . . . . . . . 8 
. . . . . . . . . . . 8 
. . . . . . . . . . . 8 
. . . . . . . . . . . 8 
. . . . . . . . . . . 8 
 at (0,0)
diff: 
   (97.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (11,12) with mask 
0 . . . . . . . . . . . 
0 0 . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 0 0 . . . . . . . . . 
0 0 . . . . . . . . . . 
0 0 . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . 0 0 
0 0 . 0 . . 0 . . 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color red at (1,0)
  _01: rectangle with size (9,12) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . 0 0 0 0 0 0 
. . . . . . . 0 0 . . 0 
. . . . . . . 0 . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
 with color cyan at (0,0)
diff: 
! 53 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (9,12) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . 0 0 0 0 0 0 
. . . . . . . 0 0 . . 0 
. . . . . . . 0 . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
. . . . . . . . . . . 0 
 with color cyan at (0,0)
  _01: rectangle with size (11,12) with mask 
0 . . . . . . . . . . . 
0 0 . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 0 0 . . . . . . . . . 
0 0 . . . . . . . . . . 
0 0 . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . 0 0 
0 0 . 0 . . 0 . . 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color red at (1,0)
diff: 
! 56 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (11,12) with mask 
0 . . . . . . . . . . . 
0 0 . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . . . 
0 0 0 . . . . . . . . . 
0 0 . . . . . . . . . . 
0 0 . . . . . . . . . . 
0 . . . . . . . . . . . 
0 . . . . . . . . . 0 0 
0 0 . 0 . . 0 . . 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color red at (1,0)
  _01: rectangle with size (1,12) with model Full with color cyan at (0,0)
  + 16 delta pixels
diff: 
! 61 wrong pixels (generated / expected)

TRAIN 2bee17df.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,9) with mask 
. . . . . . . . 0 
. . . . . . . . 0 
. . . . . . . . 0 
. . . . . . . 0 0 
. . . . . . . 0 0 
. . . . . . . . 0 
. . . . . . . . 0 
. . . . . 0 0 . 0 
0 . . . 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color red at (0,1)
  _01: rectangle with size (10,9) with mask 
0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 . 0 . 
0 0 . . 0 . . . . 
0 0 . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
 with color cyan at (0,0)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
. . . . . . . . 2 
. . . . . . . . 2 
. . . . . . . . 2 
. . . . . . . 2 2 
. . . . . . . 2 2 
. . . . . . . . 2 
. . . . . . . . 2 
. . . . . 2 2 . 2 
2 . . . 2 2 2 2 2 
2 2 2 2 2 2 2 2 2 
 at (0,1)
  _01: rectangle with size (8,8) with mask 
. . 0 . . . . . 
. . 0 . . . . . 
. . 0 . . . . . 
. . 0 . . . . . 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
. . 0 . . . . . 
. . 0 . . . . . 
 with color green at (1,1)
  _011: 
8 8 8 8 8 8 8 8 8 
8 8 8 . 8 8 . 8 . 
8 8 . . 8 . . . . 
8 8 . . . . . . . 
8 . . . . . . . . 
8 . . . . . . . . 
8 . . . . . . . . 
8 . . . . . . . . 
8 . . . . . . . . 
8 . . . . . . . . 
 at (0,0)
diff: 
   (62.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,9) with mask 
. . . . . . . . 0 
. . . . . . . . 0 
. . . . . . . . 0 
. . . . . . . 0 0 
. . . . . . . 0 0 
. . . . . . . . 0 
. . . . . . . . 0 
. . . . . 0 0 . 0 
0 . . . 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color red at (0,1)
  _01: rectangle with size (10,9) with mask 
0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 . 0 . 
0 0 . . 0 . . . . 
0 0 . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
 with color cyan at (0,0)
diff: 
! 33 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,9) with mask 
0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 . 0 . 
0 0 . . 0 . . . . 
0 0 . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (10,9) with mask 
. . . . . . . . 0 
. . . . . . . . 0 
. . . . . . . . 0 
. . . . . . . 0 0 
. . . . . . . 0 0 
. . . . . . . . 0 
. . . . . . . . 0 
. . . . . 0 0 . 0 
0 . . . 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color red at (0,1)
diff: 
! 34 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,9) with mask 
. . . . . . . . 0 
. . . . . . . . 0 
. . . . . . . . 0 
. . . . . . . 0 0 
. . . . . . . 0 0 
. . . . . . . . 0 
. . . . . . . . 0 
. . . . . 0 0 . 0 
0 . . . 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color red at (0,1)
  _01: rectangle with size (10,1) with model Full with color cyan at (0,0)
  + 16 delta pixels
diff: 
! 41 wrong pixels (generated / expected)

TRAIN 2bee17df.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (14,14) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . . 0 0 0 . . 0 . . 
0 0 0 . . . . . . . . . . . 
0 . . . . . . . . . . . . . 
0 0 0 . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 . . . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 . . . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 . . . . . . . . . . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (13,13) with mask 
. . . . . . . . . . . 0 0 
. . . . . . . . . . . . 0 
. . . . . . . . . . . . 0 
. . . . . . . . . . . 0 0 
. . . . . . . . . . 0 0 0 
. . . . . . . . . . . . 0 
. . . . . . . . . . . . 0 
. . . . . . . . . . . . 0 
. . . . . . . . . . . . 0 
. . . . . . . . . . . . 0 
. . . . . . . . . . . 0 0 
. . 0 . 0 0 . . . . 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color red at (1,1)
diff: 
! 64 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (13,13) with mask 
. . . . . . . . . . . 0 0 
. . . . . . . . . . . . 0 
. . . . . . . . . . . . 0 
. . . . . . . . . . . 0 0 
. . . . . . . . . . 0 0 0 
. . . . . . . . . . . . 0 
. . . . . . . . . . . . 0 
. . . . . . . . . . . . 0 
. . . . . . . . . . . . 0 
. . . . . . . . . . . . 0 
. . . . . . . . . . . 0 0 
. . 0 . 0 0 . . . . 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color red at (1,1)
  _01: rectangle with size (14,14) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . . 0 0 0 . . 0 . . 
0 0 0 . . . . . . . . . . . 
0 . . . . . . . . . . . . . 
0 0 0 . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 . . . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 . . . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 . . . . . . . . . . . . . 
 with color cyan at (0,0)
diff: 
! 71 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (14,14) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . . 0 0 0 . . 0 . . 
0 0 0 . . . . . . . . . . . 
0 . . . . . . . . . . . . . 
0 0 0 . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 . . . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 . . . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 0 . . . . . . . . . . . . 
0 . . . . . . . . . . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (13,1) with model Full with color red at (1,13)
  + 22 delta pixels
diff: 
! 76 wrong pixels (generated / expected)

TEST 2bee17df.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 11.9 sec (11.9 sec/task)
bits-train-error = 2585.9 bits (2585.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-337] Checking task 2c608aff.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 262866.2 = 262868.6
DL output with Mo: L = 2.3 + 262866.2 = 262868.6
DL input+output M: L = 4.6 + 525732.5 = 525737.1

# learning a model for train pairs
2.000	
1.110	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.252	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.170	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.082	OUT ADD ^.layer_0 = ^.layer_0
0.059	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.050	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.046	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.043	OUT SPE ^.size = ^.size
0.042	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.041	OUT SPE ^.layer_01.pos.j = ^.layer_01.pos.j
0.041	OUT SPE ^.layer_01.shape.mask.size.j = 1
0.040	IN  SPE ^.layer_0.shape.mask.model = Full
0.040	OUT SPE ^.layer_01.shape.mask.model = Full
0.040	OUT SPE ^.layer_011.shape.mask.model = Full
0.039	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.038	OUT SPE ^.color = ^.color
0.037	OUT SPE ^.layer_011.shape.color = ^.layer_011.shape.color
0.037	OUT SPE ^.layer_011.shape.mask.size.i = ^.layer_011.shape.mask.size.i
0.036	IN  SPE ^.layer_011.shape.mask.model = Full
0.014	
0.014	IN  GEN ^.layer_011.shape.mask.model = ?
0.014	IN  GEN ^.layer_0.shape.mask.model = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.color and layers
  _0: ^.layer_0
  _01: rectangle with size (?,1) with model Full with color ^.layer_01.shape.color at (?,^.layer_01.pos.j)
  _011: rectangle with size (^.layer_011.shape.mask.size.i,?) with model Full with color ^.layer_011.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 89.3 + 5923.2 = 6012.5
DL output with Mo: L = 80.7 + 3403.7 = 3484.3
DL input+output M: L = 170.0 + 9326.9 = 9496.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.color and layers
  _0: ^.layer_0
  _01: rectangle with size (?,1) with model Full with color ^.layer_01.shape.color at (?,^.layer_01.pos.j)
  _011: rectangle with size (^.layer_011.shape.mask.size.i,?) with model Full with color ^.layer_011.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 88.3 + 20.0 = 108.3
DL output with Mo: L = 80.7 + 3403.7 = 3484.3
DL input+output M: L = 169.0 + 3423.7 = 3592.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,12) and color cyan and layers
  _0: rectangle with size (4,3) with model Full with color green at (1,2)
  _01: point with color yellow at (7,7)
  _011: rectangle with size (1,1) with model Full with color yellow at (3,9)
diff: 
   (2.0 bits)
data: a background with size (9,12) and color cyan and layers
  _0: 
3 3 3 
3 3 3 
3 3 3 
3 3 3 
 at (1,2)
  _01: rectangle with size (1,1) with model Full with color yellow at (7,7)
  _011: rectangle with size (1,5) with model Full with color yellow at (3,5)
diff: 
   (28.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,12) and color cyan and layers
  _0: rectangle with size (4,3) with model Full with color green at (1,2)
  _01: point with color yellow at (3,9)
  _011: rectangle with size (1,1) with model Full with color yellow at (7,7)
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,12) and color cyan and layers
  _0: rectangle with size (4,3) with model Full with color green at (1,2)
  _01: point with color yellow at (7,7)
  _011: rectangle with size (1,1) with model Full with color yellow at (3,9)
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,12) and color cyan and layers
  _0: rectangle with size (1,1) with model Full with color yellow at (3,9)
  _01: point with color yellow at (7,7)
  _011: rectangle with size (4,3) with model Full with color green at (1,2)
diff: 
! 27 wrong pixels (generated / expected)

TRAIN 2c608aff.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,12) and color black and layers
  _0: rectangle with size (3,3) with model Full with color blue at (2,3)
  _01: point with color cyan at (8,3)
  _011: rectangle with size (10,12) with model Full with color red at (0,0)
diff: 
   (0.0 bits)
data: a background with size (10,12) and color black and layers
  _0: 
1 1 1 
1 1 1 
1 1 1 
 at (2,3)
  _01: rectangle with size (4,1) with model Full with color cyan at (5,3)
  _011: rectangle with size (10,12) with model Full with color red at (0,0)
diff: 
   (35.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,12) and color black and layers
  _0: rectangle with size (3,3) with model Full with color blue at (2,3)
  _01: point with color cyan at (8,3)
  _011: rectangle with size (10,12) with model Full with color red at (0,0)
diff: 
! 91 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,12) and color black and layers
  _0: rectangle with size (10,12) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 . . . 0 0 0 0 0 0 
0 0 0 . . . 0 0 0 0 0 0 
0 0 0 . . . 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color red at (0,0)
  _01: point with color cyan at (8,3)
  _011: rectangle with size (3,3) with model Full with color blue at (2,3)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,12) and color black and layers
  _0: rectangle with size (5,8) with model Full with color red at (5,4)
  _01: point with color cyan at (8,3)
  _011: rectangle with size (10,12) with model Full with color red at (0,0)
  + 19 delta pixels
diff: 
! 60 wrong pixels (generated / expected)

TRAIN 2c608aff.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (14,12) and color blue and layers
  _0: rectangle with size (4,4) with model Full with color yellow at (4,3)
  _01: point with color red at (0,4)
  _011: rectangle with size (1,1) with model Full with color red at (6,10)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (14,12) and color blue and layers
  _0: 
4 4 4 4 
4 4 4 4 
4 4 4 4 
4 4 4 4 
 at (4,3)
  _01: rectangle with size (4,1) with model Full with color red at (0,4)
  _011: rectangle with size (1,4) with model Full with color red at (6,7)
  + 1 delta pixels
diff: 
   (75.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,12) and color blue and layers
  _0: rectangle with size (4,4) with model Full with color yellow at (4,3)
  _01: point with color red at (0,4)
  _011: rectangle with size (1,1) with model Full with color red at (6,10)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,12) and color blue and layers
  _0: rectangle with size (4,4) with model Full with color yellow at (4,3)
  _01: point with color red at (6,10)
  _011: rectangle with size (1,1) with model Full with color red at (0,4)
  + 1 delta pixels
diff: 
! 13 wrong pixels (generated / expected)

TRAIN 2c608aff.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (14,18) and color blue and layers
  _0: rectangle with size (4,5) with model Full with color grey at (5,7)
  _01: point with color yellow at (1,8)
  _011: rectangle with size (1,1) with model Full with color yellow at (3,11)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (14,18) and color blue and layers
  _0: 
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
 at (5,7)
  _01: rectangle with size (4,1) with model Full with color yellow at (1,8)
  _011: rectangle with size (1,5) with model Full with color yellow at (5,2)
  + 4 delta pixels
diff: 
   (202.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,18) and color blue and layers
  _0: rectangle with size (4,5) with model Full with color grey at (5,7)
  _01: point with color yellow at (1,8)
  _011: rectangle with size (1,1) with model Full with color yellow at (3,11)
  + 3 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,18) and color blue and layers
  _0: rectangle with size (4,5) with model Full with color grey at (5,7)
  _01: point with color yellow at (3,11)
  _011: rectangle with size (1,1) with model Full with color yellow at (1,8)
  + 3 delta pixels
diff: 
! 17 wrong pixels (generated / expected)

TRAIN 2c608aff.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,21) and color red and layers
  _0: rectangle with size (6,8) with model Full with color cyan at (5,7)
  _01: point with color blue at (1,9)
  _011: rectangle with size (1,1) with model Full with color blue at (2,2)
  + 7 delta pixels
diff: 
! 29 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (19,21) and color red and layers
  _0: rectangle with size (6,8) with model Full with color cyan at (5,7)
  _01: point with color blue at (2,2)
  _011: rectangle with size (1,1) with model Full with color blue at (1,9)
  + 7 delta pixels
diff: 
! 31 wrong pixels (generated / expected)

TEST 2c608aff.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 8.5 sec (8.5 sec/task)
bits-train-error = 3403.7 bits (3403.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-336] Checking task 2dc579da.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 77497.4 = 77499.7
DL output with Mo: L = 2.3 + 14835.4 = 14837.7
DL input+output M: L = 4.6 + 92332.8 = 92337.4

# learning a model for train pairs
2.000	
1.123	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.367	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.165	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.117	OUT ADD ^.layer_0 = point with color ? at (?,?)
0.091	OUT SPE ^.size = ^.size / '2
0.073	OUT SPE ^.color = ^.color
0.064	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.053	OUT SPE ^.layer_0.shape = ^.layer_01.shape
0.050	IN  SPE ^.layer_0.shape.mask.model = +-cross
0.020	
0.020	IN  DEL ^.layer_0

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size / '2 and color ^.color and layers
  _0: ^.layer_01.shape at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model +-cross with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 64.7 + 2314.7 = 2379.4
DL output with Mo: L = 51.5 + 237.5 = 289.0
DL input+output M: L = 116.3 + 2552.1 = 2668.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size / '2 and color ^.color and layers
  _0: ^.layer_01.shape at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _01: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 0.0 = 32.2
DL output with Mo: L = 51.5 + 237.5 = 289.0
DL input+output M: L = 83.7 + 237.5 = 321.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (5,5) and color cyan and layers
  _01: point with color yellow at (4,0)
  + 9 delta pixels
diff: 
   (0.0 bits)
data: a background with size (2,2) and color cyan and layers
  _0: 
4 
 at (1,0)
diff: 
   (6.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color cyan and layers
  _01: point with color yellow at (4,0)
  + 9 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,5) and color green and layers
  _01: point with color cyan at (0,0)
  + 15 delta pixels
diff: 
! 3 wrong pixels (generated / expected)

TRAIN 2dc579da.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (7,7) and color yellow and layers
  _01: point with color blue at (1,5)
  + 13 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color yellow and layers
  _0: 
1 
 at (1,1)
diff: 
   (7.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color yellow and layers
  _01: point with color blue at (1,5)
  + 13 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,7) and color red and layers
  _01: point with color yellow at (0,4)
  + 35 delta pixels
diff: 
! 8 wrong pixels (generated / expected)

TRAIN 2dc579da.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (11,11) and color green and layers
  _01: point with color cyan at (2,1)
  + 21 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,5) and color green and layers
  _0: 
8 
 at (2,1)
diff: 
   (9.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color green and layers
  _01: point with color cyan at (2,1)
  + 21 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,11) and color black and layers
  _01: point with color cyan at (2,1)
  + 120 delta pixels
diff: 
! 25 wrong pixels (generated / expected)

TRAIN 2dc579da.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color blue and layers
  _01: point with color red at (3,8)
  + 25 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,13) and color black and layers
  _01: point with color red at (3,8)
  + 143 delta pixels
diff: 
! 36 wrong pixels (generated / expected)

TEST 2dc579da.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 4.0 sec (4.0 sec/task)
bits-train-error = 237.5 bits (237.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-335] Checking task 2dd70a9a.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 298502.2 = 298504.5
DL output with Mo: L = 2.3 + 298502.2 = 298504.5
DL input+output M: L = 4.6 + 597004.4 = 597009.0

# learning a model for train pairs
2.000	
1.287	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.635	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.516	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.399	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.331	OUT ADD ^.layer_01 = ^.layer_0
0.298	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.265	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.233	OUT ADD ^.layer_010 = ^.layer_01
0.206	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.188	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.168	OUT ADD ^.layer_0111 = ^.layer_0111
0.152	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.137	IN  ADD ^.layer_010 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.129	OUT ADD ^.layer_0110 = ^.layer_011
0.125	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.122	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.048	
0.048	IN  DEL ^.layer_01111
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _01: ^.layer_0
  _0110: ^.layer_011
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: ^.layer_0111
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 180.9 + 22060.5 = 22241.3
DL output with Mo: L = 152.0 + 13925.4 = 14077.4
DL input+output M: L = 332.8 + 35985.9 = 36318.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _01: ^.layer_0
  _0110: ^.layer_011
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: ^.layer_0111
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 153.4 + 51.7 = 205.1
DL output with Mo: L = 152.0 + 13925.4 = 14077.4
DL input+output M: L = 305.3 + 13977.1 = 14282.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (12,17) with mask 
. . . . . . . . . 0 . . . . . . . 
. . . . . . 0 . . 0 . . . . . . . 
. . . 0 0 0 . 0 . . 0 . 0 0 . . . 
. . 0 . . . . 0 0 0 0 0 0 0 0 0 0 
. . . 0 0 0 . . 0 0 0 . 0 . . 0 0 
. . . 0 0 . . . . 0 . . . 0 . . 0 
. . . . 0 . 0 . 0 . . 0 . . 0 . 0 
. . . 0 0 0 . . . 0 0 0 0 . . . . 
. . . . 0 . 0 0 . 0 . 0 . 0 . . . 
. . . . 0 . . . 0 . . . . . 0 0 . 
0 . . . 0 . . . . 0 0 0 . . . . 0 
. 0 0 0 0 . . . . . . . 0 0 0 . . 
 with color cyan at (8,3)
  _010: rectangle with size (5,5) with mask 
. 0 . . . 
0 0 0 0 0 
0 . 0 0 . 
0 . . 0 0 
. . . 0 . 
 with color cyan at (1,0)
  _01: rectangle with size (6,6) with mask 
. . . 0 0 0 
. . . 0 . 0 
. . 0 0 0 . 
0 0 0 0 0 0 
. 0 . 0 . . 
. . . 0 . . 
 with color cyan at (0,10)
  _011: rectangle with size (3,5) with mask 
0 0 0 0 0 
. . . 0 . 
. . 0 . 0 
 with color cyan at (0,4)
  _0111: rectangle with size (4,2) with mask 
0 . 
0 0 
0 0 
0 0 
 with color cyan at (6,18)
  + 15 delta pixels
diff: 
   (2.0 bits)
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (12,15) with mask 
. . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . 
 with color green at (4,3)
  _010: 
. . . 8 8 8 
. . . 8 . 8 
. . 8 8 8 . 
8 8 8 8 8 8 
. 8 . 8 . . 
. . . 8 . . 
 at (0,10)
  _01: 
. . . . . . . . . 8 . . . . . . . 
. . . . . . 8 . . 8 . . . . . . . 
. . . 8 8 8 . 8 . . 8 . 8 8 . . . 
. . 8 . . . . 8 8 8 8 8 8 8 8 8 8 
. . . 8 8 8 . . 8 8 8 . 8 . . 8 8 
. . . 8 8 . . . . 8 . . . 8 . . 8 
. . . . 8 . 8 . 8 . . 8 . . 8 . 8 
. . . 8 8 8 . . . 8 8 8 8 . . . . 
. . . . 8 . 8 8 . 8 . 8 . 8 . . . 
. . . . 8 . . . 8 . . . . . 8 8 . 
8 . . . 8 . . . . 8 8 8 . . . . 8 
. 8 8 8 8 . . . . . . . 8 8 8 . . 
 at (8,3)
  _0110: 
8 8 8 8 8 
. . . 8 . 
. . 8 . 8 
 at (0,4)
  _011: rectangle with size (5,5) with mask 
. 0 . . . 
0 0 0 0 0 
0 . 0 0 . 
0 . . 0 0 
. . . 0 . 
 with color cyan at (1,0)
  _0111: 
8 . 
8 8 
8 8 
8 8 
 at (6,18)
  _01111: rectangle with size (2,1) with model Full with color red at (2,17)
  _011111: rectangle with size (2,2) with model Odd Checkboard with color cyan at (10,0)
  + 9 delta pixels
diff: 
   (687.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (12,17) with mask 
. . . . . . . . . 0 . . . . . . . 
. . . . . . 0 . . 0 . . . . . . . 
. . . 0 0 0 . 0 . . 0 . 0 0 . . . 
. . 0 . . . . 0 0 0 0 0 0 0 0 0 0 
. . . 0 0 0 . . 0 0 0 . 0 . . 0 0 
. . . 0 0 . . . . 0 . . . 0 . . 0 
. . . . 0 . 0 . 0 . . 0 . . 0 . 0 
. . . 0 0 0 . . . 0 0 0 0 . . . . 
. . . . 0 . 0 0 . 0 . 0 . 0 . . . 
. . . . 0 . . . 0 . . . . . 0 0 . 
0 . . . 0 . . . . 0 0 0 . . . . 0 
. 0 0 0 0 . . . . . . . 0 0 0 . . 
 with color cyan at (8,3)
  _010: rectangle with size (6,6) with mask 
. . . 0 0 0 
. . . 0 . 0 
. . 0 0 0 . 
0 0 0 0 0 0 
. 0 . 0 . . 
. . . 0 . . 
 with color cyan at (0,10)
  _01: rectangle with size (5,5) with mask 
. 0 . . . 
0 0 0 0 0 
0 . 0 0 . 
0 . . 0 0 
. . . 0 . 
 with color cyan at (1,0)
  _011: rectangle with size (3,5) with mask 
0 0 0 0 0 
. . . 0 . 
. . 0 . 0 
 with color cyan at (0,4)
  _0111: rectangle with size (4,2) with mask 
0 . 
0 0 
0 0 
0 0 
 with color cyan at (6,18)
  + 15 delta pixels
diff: 
! size mismatch, 10x10 instead of 20x20
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (12,17) with mask 
. . . . . . . . . 0 . . . . . . . 
. . . . . . 0 . . 0 . . . . . . . 
. . . 0 0 0 . 0 . . 0 . 0 0 . . . 
. . 0 . . . . 0 0 0 0 0 0 0 0 0 0 
. . . 0 0 0 . . 0 0 0 . 0 . . 0 0 
. . . 0 0 . . . . 0 . . . 0 . . 0 
. . . . 0 . 0 . 0 . . 0 . . 0 . 0 
. . . 0 0 0 . . . 0 0 0 0 . . . . 
. . . . 0 . 0 0 . 0 . 0 . 0 . . . 
. . . . 0 . . . 0 . . . . . 0 0 . 
0 . . . 0 . . . . 0 0 0 . . . . 0 
. 0 0 0 0 . . . . . . . 0 0 0 . . 
 with color cyan at (8,3)
  _010: rectangle with size (5,5) with mask 
. 0 . . . 
0 0 0 0 0 
0 . 0 0 . 
0 . . 0 0 
. . . 0 . 
 with color cyan at (1,0)
  _01: rectangle with size (6,6) with mask 
. . . 0 0 0 
. . . 0 . 0 
. . 0 0 0 . 
0 0 0 0 0 0 
. 0 . 0 . . 
. . . 0 . . 
 with color cyan at (0,10)
  _011: rectangle with size (3,5) with mask 
0 0 0 0 0 
. . . 0 . 
. . 0 . 0 
 with color cyan at (0,4)
  _0111: rectangle with size (4,2) with mask 
0 . 
0 0 
0 0 
0 0 
 with color cyan at (6,18)
  + 15 delta pixels
diff: 
! size mismatch, 10x10 instead of 20x20
>> Trial 3
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (6,6) with mask 
. . . 0 0 0 
. . . 0 . 0 
. . 0 0 0 . 
0 0 0 0 0 0 
. 0 . 0 . . 
. . . 0 . . 
 with color cyan at (0,10)
  _010: rectangle with size (12,17) with mask 
. . . . . . . . . 0 . . . . . . . 
. . . . . . 0 . . 0 . . . . . . . 
. . . 0 0 0 . 0 . . 0 . 0 0 . . . 
. . 0 . . . . 0 0 0 0 0 0 0 0 0 0 
. . . 0 0 0 . . 0 0 0 . 0 . . 0 0 
. . . 0 0 . . . . 0 . . . 0 . . 0 
. . . . 0 . 0 . 0 . . 0 . . 0 . 0 
. . . 0 0 0 . . . 0 0 0 0 . . . . 
. . . . 0 . 0 0 . 0 . 0 . 0 . . . 
. . . . 0 . . . 0 . . . . . 0 0 . 
0 . . . 0 . . . . 0 0 0 . . . . 0 
. 0 0 0 0 . . . . . . . 0 0 0 . . 
 with color cyan at (8,3)
  _01: rectangle with size (5,5) with mask 
. 0 . . . 
0 0 0 0 0 
0 . 0 0 . 
0 . . 0 0 
. . . 0 . 
 with color cyan at (1,0)
  _011: rectangle with size (3,5) with mask 
0 0 0 0 0 
. . . 0 . 
. . 0 . 0 
 with color cyan at (0,4)
  _0111: rectangle with size (4,2) with mask 
0 . 
0 0 
0 0 
0 0 
 with color cyan at (6,18)
  + 15 delta pixels
diff: 
! size mismatch, 10x10 instead of 20x20

TRAIN 2dd70a9a.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,3) with mask 
. . 0 
. . 0 
0 0 . 
. 0 . 
. 0 . 
 with color cyan at (4,1)
  _010: rectangle with size (2,1) with model Full with color green at (1,1)
  _01: rectangle with size (2,2) with model Odd Checkboard with color cyan at (2,6)
  _011: rectangle with size (2,1) with model Full with color red at (6,5)
  _0111: rectangle with size (1,1) with model Full with color cyan at (0,9)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 . . . . 
0 . . . . 
0 0 0 0 0 
. . . . 0 
. . . . 0 
 with color green at (1,1)
  _010: 
. 8 
8 . 
 at (2,6)
  _01: 
. . 8 
. . 8 
8 8 . 
. 8 . 
. 8 . 
 at (4,1)
  _0110: 
2 
2 
 at (6,5)
  _011: rectangle with size (1,1) with model Full with color cyan at (1,2)
  _0111: 
8 
 at (0,9)
  _01111: rectangle with size (1,1) with model Full with color cyan at (3,9)
  _011111: rectangle with size (1,1) with model Full with color cyan at (4,1)
  + 1 delta pixels
diff: 
   (202.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,3) with mask 
. . 0 
. . 0 
0 0 . 
. 0 . 
. 0 . 
 with color cyan at (4,1)
  _010: rectangle with size (2,1) with model Full with color green at (1,1)
  _01: rectangle with size (2,2) with model Odd Checkboard with color cyan at (2,6)
  _011: rectangle with size (2,1) with model Full with color red at (6,5)
  _0111: rectangle with size (1,1) with model Full with color cyan at (0,9)
  + 4 delta pixels
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,3) with mask 
. . 0 
. . 0 
0 0 . 
. 0 . 
. 0 . 
 with color cyan at (4,1)
  _010: rectangle with size (2,1) with model Full with color green at (1,1)
  _01: rectangle with size (2,2) with model Odd Checkboard with color cyan at (2,6)
  _011: rectangle with size (2,1) with model Full with color red at (6,5)
  _0111: rectangle with size (1,1) with model Full with color cyan at (1,2)
  + 4 delta pixels
diff: 
! 16 wrong pixels (generated / expected)

TRAIN 2dd70a9a.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (5,10) with mask 
. . . 0 0 0 . . . . 
0 . 0 . . . 0 0 0 0 
. 0 . 0 . . . . . . 
. 0 0 . 0 . . . . . 
0 0 . . . . . . . . 
 with color cyan at (10,4)
  _010: rectangle with size (3,5) with mask 
0 . . 0 . 
. 0 . 0 0 
. 0 0 0 . 
 with color cyan at (0,10)
  _01: rectangle with size (4,5) with mask 
. . 0 . 0 
0 . . 0 . 
. 0 0 0 . 
. . 0 . 0 
 with color cyan at (0,3)
  _011: rectangle with size (4,4) with mask 
. . . 0 
. . 0 . 
. 0 . 0 
0 0 . . 
 with color cyan at (4,10)
  _0111: rectangle with size (5,3) with mask 
. 0 0 
. 0 . 
0 . . 
0 . . 
. 0 . 
 with color cyan at (7,0)
  + 13 delta pixels
diff: 
   (3.2 bits)
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (5,7) with mask 
0 0 0 0 0 0 0 
. . . . . . 0 
. . . . . . 0 
. . . . . . 0 
. . 0 0 0 0 0 
 with color green at (5,1)
  _010: 
. . 8 . 8 
8 . . 8 . 
. 8 8 8 . 
. . 8 . 8 
 at (0,3)
  _01: 
. . . 8 8 8 . . . . 
8 . 8 . . . 8 8 8 8 
. 8 . 8 . . . . . . 
. 8 8 . 8 . . . . . 
8 8 . . . . . . . . 
 at (10,4)
  _0110: 
. . . 8 
. . 8 . 
. 8 . 8 
8 8 . . 
 at (4,10)
  _011: rectangle with size (3,5) with mask 
0 . . 0 . 
. 0 . 0 0 
. 0 0 0 . 
 with color cyan at (0,10)
  _0111: 
. 8 8 
. 8 . 
8 . . 
8 . . 
. 8 . 
 at (7,0)
  _01111: rectangle with size (2,2) with model Odd Checkboard with color cyan at (4,8)
  _011111: rectangle with size (1,2) with model Full with color red at (9,1)
  + 7 delta pixels
diff: 
   (502.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (5,10) with mask 
. . . 0 0 0 . . . . 
0 . 0 . . . 0 0 0 0 
. 0 . 0 . . . . . . 
. 0 0 . 0 . . . . . 
0 0 . . . . . . . . 
 with color cyan at (10,4)
  _010: rectangle with size (4,5) with mask 
. . 0 . 0 
0 . . 0 . 
. 0 0 0 . 
. . 0 . 0 
 with color cyan at (0,3)
  _01: rectangle with size (3,5) with mask 
0 . . 0 . 
. 0 . 0 0 
. 0 0 0 . 
 with color cyan at (0,10)
  _011: rectangle with size (4,4) with mask 
. . . 0 
. . 0 . 
. 0 . 0 
0 0 . . 
 with color cyan at (4,10)
  _0111: rectangle with size (5,3) with mask 
. 0 0 
. 0 . 
0 . . 
0 . . 
. 0 . 
 with color cyan at (7,0)
  + 13 delta pixels
diff: 
! size mismatch, 10x10 instead of 15x15
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (5,10) with mask 
. . . 0 0 0 . . . . 
0 . 0 . . . 0 0 0 0 
. 0 . 0 . . . . . . 
. 0 0 . 0 . . . . . 
0 0 . . . . . . . . 
 with color cyan at (10,4)
  _010: rectangle with size (3,5) with mask 
0 . . 0 . 
. 0 . 0 0 
. 0 0 0 . 
 with color cyan at (0,10)
  _01: rectangle with size (4,5) with mask 
. . 0 . 0 
0 . . 0 . 
. 0 0 0 . 
. . 0 . 0 
 with color cyan at (0,3)
  _011: rectangle with size (4,4) with mask 
. . . 0 
. . 0 . 
. 0 . 0 
0 0 . . 
 with color cyan at (4,10)
  _0111: rectangle with size (5,3) with mask 
. 0 0 
. 0 . 
0 . . 
0 . . 
. 0 . 
 with color cyan at (7,0)
  + 13 delta pixels
diff: 
! size mismatch, 10x10 instead of 15x15

TRAIN 2dd70a9a.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (6,4) with mask 
0 0 0 0 
0 . . . 
. 0 . . 
. . 0 . 
. . 0 . 
. . . 0 
 with color cyan at (0,0)
  _010: rectangle with size (4,1) with model Full with color cyan at (5,10)
  _01: rectangle with size (2,3) with mask 
0 . 0 
. 0 0 
 with color cyan at (7,0)
  _011: rectangle with size (3,3) with mask 
0 . . 
. 0 0 
. 0 . 
 with color cyan at (8,5)
  _0111: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color cyan at (1,4)
  + 15 delta pixels
diff: 
! size mismatch, 10x10 instead of 13x13
>> Trial 2
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (6,4) with mask 
0 0 0 0 
0 . . . 
. 0 . . 
. . 0 . 
. . 0 . 
. . . 0 
 with color cyan at (0,0)
  _010: rectangle with size (2,3) with mask 
0 . 0 
. 0 0 
 with color cyan at (7,0)
  _01: rectangle with size (4,1) with model Full with color cyan at (5,10)
  _011: rectangle with size (3,3) with mask 
0 . . 
. 0 0 
. 0 . 
 with color cyan at (8,5)
  _0111: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color cyan at (1,4)
  + 15 delta pixels
diff: 
! size mismatch, 10x10 instead of 13x13

TEST 2dd70a9a.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.7 sec (59.7 sec/task)
bits-train-error = 13925.4 bits (13925.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-334] Checking task 2dee498d.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 33971.9 = 33974.2
DL output with Mo: L = 2.3 + 11330.3 = 11332.6
DL input+output M: L = 4.6 + 45302.2 = 45306.8

# learning a model for train pairs
2.000	
1.632	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.278	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.140	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
1.011	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.913	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.824	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.685	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.624	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.592	OUT SPE ^.layer_011.shape = scaleTo(^.layer_011.shape, min(^.layer_01.shape.mask.size, ^.layer_011.shape.mask.size))
0.571	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.551	OUT SPE ^.layer_011.pos = ^.layer_011.pos
0.531	IN  ADD ^.layer_0110 = point with color ? at (?,?)
0.514	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_0.shape.mask.size.i
0.497	OUT SPE ^.size.i = ^.size.i
0.481	OUT SPE ^.size.j = ^.size.i
0.466	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.455	OUT SPE ^.layer_01.shape.mask.model = ^.layer_01.shape.mask.model
0.445	OUT SPE ^.layer_01.shape.mask.size.i = area(^.layer_01.shape.mask) / '2
0.435	OUT SPE ^.layer_01.shape.mask.size.j = area(^.layer_01.shape.mask) / '2
0.426	OUT SPE ^.layer_01.pos.j = ^.layer_01.pos.j / '2
0.416	OUT SPE ^.layer_0.shape.mask.size.j = max(^.layer_0.shape.mask.size.j, ^.layer_011.shape.mask.size.j) / '3
0.407	OUT SPE ^.layer_01.pos.i = ^.layer_0110.pos.i
0.404	IN  SPE ^.layer_011.shape.mask.model = Full
0.076	
0.076	IN  GEN ^.layer_011.shape.mask.model = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (^.size.i,^.size.i) and color ? and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i,max(^.layer_0.shape.mask.size.j, ^.layer_011.shape.mask.size.j) / '3) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: rectangle with size (area(^.layer_01.shape.mask) / '2,area(^.layer_01.shape.mask) / '2) with model ^.layer_01.shape.mask.model with color ? at (^.layer_0110.pos.i,^.layer_01.pos.j / '2)
  _011: scaleTo(^.layer_011.shape, min(^.layer_01.shape.mask.size, ^.layer_011.shape.mask.size)) at ^.layer_011.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: point with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 116.5 + 11172.4 = 11288.9
DL output with Mo: L = 261.3 + 555.8 = 817.2
DL input+output M: L = 377.9 + 11728.3 = 12106.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (^.size.i,^.size.i) and color ? and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i,max(^.layer_0.shape.mask.size.j, ^.layer_011.shape.mask.size.j) / '3) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: rectangle with size (area(^.layer_01.shape.mask) / '2,area(^.layer_01.shape.mask) / '2) with model ^.layer_01.shape.mask.model with color ? at (^.layer_0110.pos.i,^.layer_01.pos.j / '2)
  _011: scaleTo(^.layer_011.shape, min(^.layer_01.shape.mask.size, ^.layer_011.shape.mask.size)) at ^.layer_011.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: point with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 116.0 + 31.7 = 147.7
DL output with Mo: L = 261.3 + 555.8 = 817.2
DL input+output M: L = 377.3 + 587.5 = 964.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,9) and color blue and layers
  _0: rectangle with size (3,9) with mask 
. 0 . . 0 . . 0 . 
0 0 0 0 0 0 0 0 0 
. 0 . . 0 . . 0 . 
 with color grey at (0,0)
  _01: rectangle with size (1,2) with model Full with color yellow at (0,5)
  _0110: point with color yellow at (2,2)
  _011: rectangle with size (1,1) with model Full with color yellow at (0,0)
  + 2 delta pixels
diff: 
   (3.2 bits)
data: a background with size (3,3) and color blue and layers
  _0: rectangle with size (3,3) with model +-cross with color grey at (0,0)
  _01: rectangle with size (1,1) with model Full with color yellow at (2,2)
  _011: 
4 
 at (0,0)
diff: 
   (21.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,9) and color blue and layers
  _0: rectangle with size (3,9) with mask 
. 0 . . 0 . . 0 . 
0 0 0 0 0 0 0 0 0 
. 0 . . 0 . . 0 . 
 with color grey at (0,0)
  _01: rectangle with size (1,2) with model Full with color yellow at (0,5)
  _0110: point with color yellow at (0,0)
  _011: rectangle with size (1,2) with model Full with color yellow at (2,2)
  + 1 delta pixels
diff: 
! 4 wrong pixels (generated / expected)

TRAIN 2dee498d.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (4,12) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . 0 . 
. 0 . . 
0 . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with model x-cross with color red at (0,0)
  _0110: point with color red at (0,4)
  _011: rectangle with size (2,12) with model Full with color yellow at (1,0)
  + 15 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . 0 . 
. 0 . . 
0 . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with model x-cross with color red at (0,0)
  _011: 
4 4 4 4 
4 4 4 4 
 at (1,0)
diff: 
   (23.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,12) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . 0 . 
. 0 . . 
0 . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with model x-cross with color red at (0,0)
  _0110: point with color red at (0,4)
  _011: rectangle with size (2,12) with model Full with color yellow at (1,0)
  + 15 delta pixels
diff: 
! 12 wrong pixels (generated / expected)

TRAIN 2dee498d.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (2,6) and color blue and layers
  _0: rectangle with size (2,1) with model Full with color red at (0,0)
  _01: rectangle with size (2,1) with model Full with color red at (0,2)
  _0110: point with color red at (0,4)
  _011: rectangle with size (1,5) with model Full with color green at (1,1)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (2,2) and color black and layers
  _0: rectangle with size (2,1) with model Full with color red at (0,0)
  _01: rectangle with size (1,1) with model Full with color blue at (0,1)
  _011: 
3 
 at (1,1)
diff: 
   (10.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (2,6) and color blue and layers
  _0: rectangle with size (2,1) with model Full with color red at (0,0)
  _01: rectangle with size (2,1) with model Full with color red at (0,2)
  _0110: point with color red at (0,4)
  _011: rectangle with size (1,5) with model Full with color green at (1,1)
  + 1 delta pixels
diff: 
! 1 wrong pixels (generated / expected)

TRAIN 2dee498d.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
Arc_common.Undefined_result("Grid.Transf.scale_to: invalid scaling factor")

TEST 2dee498d.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 12.7 sec (12.7 sec/task)
bits-train-error = 555.8 bits (555.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-333] Checking task 31aa019c.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.096	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.309	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.237	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.225	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.212	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.206	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.200	OUT ADD ^.layer_00 = point with color ? at (?,?)
0.195	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.189	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.183	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.178	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.172	IN  ADD ^.layer_01111111 = point with color ? at (?,?)
0.167	OUT SPE ^.size = ^.size
0.163	OUT SPE ^.layer_0.shape.mask = 
0 0 0 
0 0 0 
0 0 0 

0.162	OUT SPE ^.layer_0.shape.color = red
0.161	OUT SPE ^.layer_0.pos.j = ^.layer_01111111.pos.j - ^.layer_01.shape.mask.size.j
0.160	OUT SPE ^.layer_00.pos.j = center(^.layer_01111111) - ^.layer_01.shape.mask.size.j
0.159	IN  SPE ^.layer_0.shape.mask.model = Full
0.159	IN  SPE ^.layer_0111.shape.mask.model = Full
0.158	IN  SPE ^.color = black
0.157	OUT SPE ^.color = black
0.007	
0.007	IN  GEN ^.layer_0111.shape.mask.model = ?
0.007	IN  GEN ^.layer_0.shape.mask.model = ?
0.007	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: point with color ? at (?,center(^.layer_01111111) - ^.layer_01.shape.mask.size.j)
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color red at (?,^.layer_01111111.pos.j - ^.layer_01.shape.mask.size.j)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)

DL input  with Mi: L = 197.7 + 17971.7 = 18169.3
DL output with Mo: L = 167.1 + 507.5 = 674.6
DL input+output M: L = 364.8 + 18479.2 = 18843.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: point with color ? at (?,center(^.layer_01111111) - ^.layer_01.shape.mask.size.j)
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color red at (?,^.layer_01111111.pos.j - ^.layer_01.shape.mask.size.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)

DL input  with Mi: L = 196.5 + 0.0 = 196.5
DL output with Mo: L = 167.1 + 507.5 = 674.6
DL input+output M: L = 363.6 + 507.5 = 871.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,1) with model Full with color blue at (7,2)
  _01: rectangle with size (2,2) with model Odd Checkboard with color green at (8,7)
  _011: rectangle with size (1,1) with model Full with color blue at (0,3)
  _0111: rectangle with size (1,1) with model Full with color grey at (0,7)
  _01111: point with color red at (2,0)
  _011111: point with color red at (2,5)
  _0111111: point with color blue at (2,9)
  _01111111: point with color blue at (3,2)
  + 7 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: point with color yellow at (6,1)
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color red at (5,0)
diff: 
   (16.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,1) with model Full with color blue at (7,2)
  _01: rectangle with size (2,2) with model Odd Checkboard with color green at (8,7)
  _011: rectangle with size (1,1) with model Full with color blue at (0,3)
  _0111: rectangle with size (1,1) with model Full with color grey at (0,7)
  _01111: point with color red at (2,0)
  _011111: point with color red at (2,5)
  _0111111: point with color blue at (2,9)
  _01111111: point with color blue at (3,2)
  + 7 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,1) with model Full with color blue at (7,2)
  _01: rectangle with size (2,2) with model Odd Checkboard with color green at (8,7)
  _011: rectangle with size (1,1) with model Full with color blue at (0,3)
  _0111: rectangle with size (1,1) with model Full with color grey at (0,7)
  _01111: point with color red at (2,0)
  _011111: point with color red at (2,5)
  _0111111: point with color blue at (2,9)
  _01111111: point with color grey at (3,9)
  + 7 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TRAIN 31aa019c.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,2) with model Full with color orange at (0,1)
  _01: rectangle with size (3,1) with model Full with color blue at (0,3)
  _011: rectangle with size (2,2) with model Odd Checkboard with color green at (0,8)
  _0111: rectangle with size (1,2) with model Full with color yellow at (7,0)
  _01111: point with color red at (0,0)
  _011111: point with color green at (0,5)
  _0111111: point with color orange at (1,9)
  _01111111: point with color pink at (2,7)
  + 16 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: point with color pink at (2,7)
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color red at (1,6)
diff: 
   (16.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,2) with model Full with color orange at (0,1)
  _01: rectangle with size (3,1) with model Full with color blue at (0,3)
  _011: rectangle with size (2,2) with model Odd Checkboard with color green at (0,8)
  _0111: rectangle with size (1,2) with model Full with color yellow at (7,0)
  _01111: point with color red at (0,0)
  _011111: point with color green at (0,5)
  _0111111: point with color orange at (1,9)
  _01111111: point with color pink at (2,7)
  + 16 delta pixels
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,2) with model Full with color orange at (0,1)
  _01: rectangle with size (3,1) with model Full with color blue at (0,3)
  _011: rectangle with size (2,2) with model Odd Checkboard with color green at (0,8)
  _0111: rectangle with size (1,2) with model Full with color yellow at (7,0)
  _01111: point with color red at (0,0)
  _011111: point with color green at (0,5)
  _0111111: point with color orange at (1,9)
  _01111111: point with color brown at (2,9)
  + 16 delta pixels
diff: 
! 11 wrong pixels (generated / expected)

TRAIN 31aa019c.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,1) with model Full with color red at (1,8)
  _01: rectangle with size (2,1) with model Full with color brown at (3,1)
  _011: rectangle with size (1,1) with model Full with color pink at (0,0)
  _0111: rectangle with size (1,1) with model Full with color cyan at (0,4)
  _01111: point with color cyan at (1,9)
  _011111: point with color orange at (2,1)
  _0111111: point with color red at (2,4)
  _01111111: point with color grey at (2,6)
  + 7 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: point with color green at (8,6)
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color red at (7,5)
diff: 
   (16.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,1) with model Full with color red at (1,8)
  _01: rectangle with size (2,1) with model Full with color brown at (3,1)
  _011: rectangle with size (1,1) with model Full with color pink at (0,0)
  _0111: rectangle with size (1,1) with model Full with color cyan at (0,4)
  _01111: point with color cyan at (1,9)
  _011111: point with color orange at (2,1)
  _0111111: point with color red at (2,4)
  _01111111: point with color grey at (2,6)
  + 7 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,1) with model Full with color red at (1,8)
  _01: rectangle with size (2,1) with model Full with color brown at (3,1)
  _011: rectangle with size (1,1) with model Full with color pink at (0,0)
  _0111: rectangle with size (1,1) with model Full with color cyan at (0,4)
  _01111: point with color cyan at (1,9)
  _011111: point with color orange at (2,1)
  _0111111: point with color red at (2,4)
  _01111111: point with color blue at (3,3)
  + 7 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,1) with model Full with color red at (1,8)
  _01: rectangle with size (2,1) with model Full with color brown at (3,1)
  _011: rectangle with size (1,1) with model Full with color pink at (0,0)
  _0111: rectangle with size (1,1) with model Full with color cyan at (0,4)
  _01111: point with color cyan at (1,9)
  _011111: point with color orange at (2,1)
  _0111111: point with color grey at (2,6)
  _01111111: point with color red at (2,4)
  + 7 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TRAIN 31aa019c.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,4) with model Full with color orange at (4,0)
  _01: rectangle with size (1,2) with model Full with color grey at (7,0)
  _011: rectangle with size (2,2) with model Odd Checkboard with color green at (7,2)
  _0111: rectangle with size (3,1) with model Full with color orange at (7,9)
  _01111: point with color red at (0,4)
  _011111: point with color grey at (0,5)
  _0111111: point with color orange at (0,6)
  _01111111: point with color grey at (1,3)
  + 19 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,4) with model Full with color orange at (4,0)
  _01: rectangle with size (1,2) with model Full with color grey at (7,0)
  _011: rectangle with size (2,2) with model Odd Checkboard with color green at (7,2)
  _0111: rectangle with size (3,1) with model Full with color orange at (7,9)
  _01111: point with color red at (0,4)
  _011111: point with color grey at (0,5)
  _0111111: point with color orange at (0,6)
  _01111111: point with color pink at (1,4)
  + 19 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,4) with model Full with color orange at (4,0)
  _01: rectangle with size (1,2) with model Full with color grey at (7,0)
  _011: rectangle with size (2,2) with model Odd Checkboard with color green at (7,2)
  _0111: rectangle with size (3,1) with model Full with color orange at (7,9)
  _01111: point with color red at (0,4)
  _011111: point with color grey at (0,5)
  _0111111: point with color grey at (1,3)
  _01111111: point with color orange at (0,6)
  + 19 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TEST 31aa019c.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 19.3 sec (19.3 sec/task)
bits-train-error = 507.5 bits (507.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-332] Checking task 321b1fc6.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79850.6 = 79852.9
DL output with Mo: L = 2.3 + 79850.6 = 79852.9
DL input+output M: L = 4.6 + 159701.1 = 159705.8

# learning a model for train pairs
2.000	
1.141	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.327	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.291	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.255	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.218	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.205	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.189	OUT ADD ^.layer_0 = ^.layer_0111.shape at (?,?)
0.172	OUT ADD ^.layer_01 = ^.layer_0111.shape at (?,?)
0.155	OUT ADD ^.layer_011 = ^.layer_0111.shape at (?,?)
0.147	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.135	OUT ADD ^.layer_0111 = ^.layer_01111.shape at (?,?)
0.123	OUT ADD ^.layer_01111 = ^.layer_01111.shape at (?,?)
0.111	OUT ADD ^.layer_011111 = ^.layer_01111.shape at (?,?)
0.106	OUT SPE ^.size = ^.size
0.103	OUT SPE ^.layer_011.pos = ^.layer_011.pos
0.100	OUT SPE ^.layer_01.pos = ^.layer_01.pos
0.097	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.095	OUT SPE ^.layer_01111.pos = ^.layer_011.pos + (1, 0)
0.092	OUT SPE ^.layer_0111.pos = ^.layer_0.pos + (1, 0)
0.090	OUT SPE ^.layer_011111.pos = ^.layer_01.pos + (1, 0)
0.088	IN  SPE ^.layer_0111.shape.color = orange
0.087	IN  ADD ^.layer_011110 = point with color ? at (?,?)
0.083	IN  SPE ^.layer_011.shape.mask = 
0 0 
0 0 

0.082	IN  SPE ^.layer_0.shape.color = cyan
0.081	IN  SPE ^.layer_01.shape.color = cyan
0.079	IN  SPE ^.layer_011.shape.color = cyan
0.078	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.075	IN  SPE ^.layer_01.shape.mask = 
0 0 
0 0 

0.074	IN  SPE ^.layer_0111.shape.mask.model = Full
0.073	IN  SPE ^.layer_01111.shape.mask.model = Full
0.073	IN  SPE ^.color = black
0.072	OUT SPE ^.color = black
0.035	
0.035	IN  DEL ^.layer_011111
0.035	IN  GEN ^.layer_011.shape.color = ?
0.035	IN  GEN ^.layer_01.shape.color = ?
0.035	IN  GEN ^.layer_0.shape.color = ?
0.035	IN  GEN ^.layer_01111.shape.mask.model = ?
0.035	IN  GEN ^.layer_0111.shape.mask.model = ?
0.035	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0111.shape at ^.layer_0.pos
  _01: ^.layer_0111.shape at ^.layer_01.pos
  _011: ^.layer_0111.shape at ^.layer_011.pos
  _0111: ^.layer_01111.shape at ^.layer_0.pos + (1, 0)
  _01111: ^.layer_01111.shape at ^.layer_011.pos + (1, 0)
  _011111: ^.layer_01111.shape at ^.layer_01.pos + (1, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color cyan at (?,?)
  _01: 
0 0 
0 0 
 with color cyan at (?,?)
  _011: 
0 0 
0 0 
 with color cyan at (?,?)
  _0111: rectangle with size (?,?) with model Full with color orange at (?,?)
  _011110: point with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011111: point with color ? at (?,?)

DL input  with Mi: L = 197.2 + 2943.2 = 3140.4
DL output with Mo: L = 178.3 + 2427.5 = 2605.7
DL input+output M: L = 375.5 + 5370.6 = 5746.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0111.shape at ^.layer_0.pos
  _01: ^.layer_0111.shape at ^.layer_01.pos
  _011: ^.layer_0111.shape at ^.layer_011.pos
  _0111: ^.layer_01111.shape at ^.layer_0.pos + (1, 0)
  _01111: ^.layer_01111.shape at ^.layer_011.pos + (1, 0)
  _011111: ^.layer_01111.shape at ^.layer_01.pos + (1, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: 
0 0 
0 0 
 with color ? at (?,?)
  _011: 
0 0 
0 0 
 with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color orange at (?,?)
  _011110: point with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 168.5 + 0.0 = 168.5
DL output with Mo: L = 178.3 + 2427.5 = 2605.7
DL input+output M: L = 346.8 + 2427.5 = 2774.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color cyan at (4,5)
  _01: 
0 0 
0 0 
 with color cyan at (7,2)
  _011: 
0 0 
0 0 
 with color cyan at (8,8)
  _0111: rectangle with size (1,1) with model Full with color orange at (1,1)
  _011110: point with color pink at (1,2)
  _01111: rectangle with size (1,1) with model Full with color brown at (2,1)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
7#
 at (4,5)
  _01: 
7#
 at (7,2)
  _011: 
7#
 at (8,8)
  _0111: 
9#
 at (5,5)
  _01111: 
9#
 at (9,8)
  _011111: 
9#
 at (8,2)
  + 6 delta pixels
diff: 
   (242.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color cyan at (4,5)
  _01: 
0 0 
0 0 
 with color cyan at (7,2)
  _011: 
0 0 
0 0 
 with color cyan at (8,8)
  _0111: rectangle with size (1,1) with model Full with color orange at (1,1)
  _011110: point with color pink at (1,2)
  _01111: rectangle with size (1,1) with model Full with color brown at (2,1)
  + 1 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color cyan at (4,5)
  _01: 
0 0 
0 0 
 with color cyan at (7,2)
  _011: 
0 0 
0 0 
 with color cyan at (8,8)
  _0111: rectangle with size (1,1) with model Full with color orange at (1,1)
  _011110: point with color pink at (1,2)
  _01111: rectangle with size (1,1) with model Full with color yellow at (2,2)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color cyan at (4,5)
  _01: 
0 0 
0 0 
 with color cyan at (7,2)
  _011: 
0 0 
0 0 
 with color cyan at (8,8)
  _0111: rectangle with size (1,1) with model Full with color orange at (1,1)
  _011110: point with color brown at (2,1)
  _01111: rectangle with size (1,1) with model Full with color pink at (1,2)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 321b1fc6.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 . 
0 0 0 
 with color cyan at (1,1)
  _01: 
0 0 
0 0 
 with color cyan at (2,6)
  _011: 
0 0 
0 0 
 with color cyan at (7,3)
  _0111: rectangle with size (1,2) with model Full with color orange at (5,5)
  _011110: point with color cyan at (3,8)
  _01111: rectangle with size (1,3) with model Full with color pink at (6,5)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
7#7#
 at (1,1)
  _01: 
7#7#
 at (2,6)
  _011: 
7#7#
 at (7,3)
  _0111: 
6 6 6 
 at (2,1)
  _01111: 
6 6 6 
 at (8,3)
  _011111: 
6 6 6 
 at (3,6)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 . 
0 0 0 
 with color cyan at (1,1)
  _01: 
0 0 
0 0 
 with color cyan at (2,6)
  _011: 
0 0 
0 0 
 with color cyan at (7,3)
  _0111: rectangle with size (1,2) with model Full with color orange at (5,5)
  _011110: point with color cyan at (3,8)
  _01111: rectangle with size (1,3) with model Full with color pink at (6,5)
  + 1 delta pixels
diff: 
correct output grid

TRAIN 321b1fc6.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,7) with model Full with color cyan at (1,1)
  _01: 
0 0 
0 0 
 with color cyan at (6,6)
  _011: 
0 0 
0 0 
 with color yellow at (5,1)
  _0111: rectangle with size (3,4) with mask 
. 0 0 . 
0 0 0 0 
. . 0 . 
 with color cyan at (1,0)
  _011110: point with color cyan at (3,7)
  _01111: rectangle with size (1,4) with model Full with color green at (6,0)
  + 12 delta pixels
diff:   ^.layer_0111.shape.color
! 34 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,7) with model Full with color cyan at (1,1)
  _01: 
0 0 
0 0 
 with color cyan at (6,6)
  _011: 
0 0 
0 0 
 with color yellow at (5,1)
  _0111: rectangle with size (3,4) with mask 
. 0 0 . 
0 0 0 0 
. . 0 . 
 with color cyan at (1,0)
  _011110: point with color cyan at (3,7)
  _01111: rectangle with size (2,2) with model Odd Checkboard with color green at (6,2)
  + 12 delta pixels
diff:   ^.layer_0111.shape.color
! 37 wrong pixels (generated / expected)

TEST 321b1fc6.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 37.1 sec (37.1 sec/task)
bits-train-error = 2427.5 bits (2427.5 bits/task)
acc-train-micro = 0.50 tasks (50.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.50
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-331] Checking task 32597951.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 357321.9 = 357324.2
DL output with Mo: L = 2.3 + 357321.9 = 357324.2
DL input+output M: L = 4.6 + 714643.8 = 714648.5

# learning a model for train pairs
2.000	
1.450	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.909	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.705	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.494	OUT ADD ^.layer_0 = ^.layer_0
0.433	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.379	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.345	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.325	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.307	OUT ADD ^.layer_0110 = ^.layer_011.shape at (?,?)
0.296	OUT ADD ^.layer_01100 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.285	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.270	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.262	IN  ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.113	
0.104	IN  DEL ^.layer_00
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01100: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: ^.layer_011.shape at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 53297.8 = 53423.6
DL output with Mo: L = 177.3 + 40031.7 = 40209.0
DL input+output M: L = 303.1 + 93329.5 = 93632.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01100: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: ^.layer_011.shape at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 0.0 = 98.1
DL output with Mo: L = 177.3 + 36957.7 = 37135.0
DL input+output M: L = 275.4 + 36957.7 = 37233.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (17,17) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 0 0 
. . 0 . . 
0 0 0 0 0 
. 0 . . . 
0 0 0 0 0 
 with color cyan at (2,5)
  _01: rectangle with size (1,17) with model Full with color blue at (3,0)
  _011: rectangle with size (1,17) with model Full with color blue at (5,0)
  + 84 delta pixels
diff: 
   (0.0 bits)
data: a background with size (17,17) and color black and layers
  _0: 
8 8 8 8 8 
. . 8 . . 
8 8 8 8 8 
. 8 . . . 
8 8 8 8 8 
 at (2,5)
  _01: rectangle with size (1,17) with model Full with color blue at (1,0)
  _01100: rectangle with size (1,17) with model Full with color blue at (7,0)
  _0110: 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
 at (9,0)
  _011: rectangle with size (1,17) with model Full with color blue at (11,0)
  _0111: rectangle with size (1,17) with model Full with color blue at (13,0)
  _01111: rectangle with size (1,17) with model Full with color blue at (15,0)
  + 50 delta pixels
diff: 
   (2282.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 0 0 
. . 0 . . 
0 0 0 0 0 
. 0 . . . 
0 0 0 0 0 
 with color cyan at (2,5)
  _01: rectangle with size (1,17) with model Full with color blue at (3,0)
  _011: rectangle with size (1,17) with model Full with color blue at (5,0)
  + 84 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x17

TRAIN 32597951.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (17,17) and color black and layers
  _0: rectangle with size (10,13) with mask 
. 0 . . . . . . . 0 . . . 
0 . 0 . 0 0 0 0 0 . . . . 
0 . . . 0 . . 0 0 . . . . 
. 0 . 0 . 0 . 0 0 . . . . 
. . 0 0 . . . . . 0 0 . . 
. . 0 0 0 . . . . 0 0 . . 
. . . 0 0 . . . . . 0 . . 
. . . . . . 0 . . 0 . 0 0 
. . . . . . . 0 0 . . . . 
. . . . . . . . 0 0 . . . 
 with color blue at (0,3)
  _01: rectangle with size (9,14) with mask 
. . . 0 0 0 . . . . . . . . 
. . . 0 0 . 0 . . . . . . . 
. . . 0 . . . 0 . . . . . . 
. . . . . 0 . 0 . 0 . . . . 
. . . 0 . . 0 . . . 0 . 0 . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 
. 0 0 . 0 0 0 0 0 0 . . . . 
0 0 . 0 0 . . . . . 0 . . . 
. 0 . . . . . . . . 0 . . . 
 with color blue at (8,1)
  _011: rectangle with size (3,6) with model Full with color cyan at (7,3)
  + 34 delta pixels
diff: 
   (0.0 bits)
data: a background with size (17,17) and color black and layers
  _0: 
. 1 . . . . . . . 1 . . . 
1 . 1 . 1 1 1 1 1 . . . . 
1 . . . 1 . . 1 1 . . . . 
. 1 . 1 . 1 . 1 1 . . . . 
. . 1 1 . . . . . 1 1 . . 
. . 1 1 1 . . . . 1 1 . . 
. . . 1 1 . . . . . 1 . . 
. . . . . . 1 . . 1 . 1 1 
. . . . . . . 1 1 . . . . 
. . . . . . . . 1 1 . . . 
 at (0,3)
  _01: rectangle with size (7,14) with mask 
. . . . . . . 0 . . . . . . 
. . . . . 0 . 0 . 0 . . . . 
. . . 0 . . 0 . . . 0 . 0 . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 
. 0 0 . 0 0 0 0 0 0 . . . . 
0 0 . 0 0 . . . . . 0 . . . 
. 0 . . . . . . . . 0 . . . 
 with color blue at (10,1)
  _01100: rectangle with size (2,4) with mask 
0 0 0 . 
0 0 . 0 
 with color green at (8,4)
  _0110: 
8 8 8 8 8 8 
8 8 8 8 8 8 
8 8 8 8 8 8 
 at (7,3)
  _011: rectangle with size (5,3) with mask 
0 . 0 
0 0 . 
. . 0 
. 0 . 
. 0 0 
 with color blue at (0,14)
  _0111: rectangle with size (3,2) with mask 
. 0 
. 0 
0 0 
 with color green at (7,1)
  _01111: rectangle with size (3,2) with mask 
0 . 
0 0 
. 0 
 with color blue at (10,15)
  + 19 delta pixels
diff: 
   (1120.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (10,13) with mask 
. 0 . . . . . . . 0 . . . 
0 . 0 . 0 0 0 0 0 . . . . 
0 . . . 0 . . 0 0 . . . . 
. 0 . 0 . 0 . 0 0 . . . . 
. . 0 0 . . . . . 0 0 . . 
. . 0 0 0 . . . . 0 0 . . 
. . . 0 0 . . . . . 0 . . 
. . . . . . 0 . . 0 . 0 0 
. . . . . . . 0 0 . . . . 
. . . . . . . . 0 0 . . . 
 with color blue at (0,3)
  _01: rectangle with size (9,14) with mask 
. . . 0 0 0 . . . . . . . . 
. . . 0 0 . 0 . . . . . . . 
. . . 0 . . . 0 . . . . . . 
. . . . . 0 . 0 . 0 . . . . 
. . . 0 . . 0 . . . 0 . 0 . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 
. 0 0 . 0 0 0 0 0 0 . . . . 
0 0 . 0 0 . . . . . 0 . . . 
. 0 . . . . . . . . 0 . . . 
 with color blue at (8,1)
  _011: rectangle with size (3,6) with model Full with color cyan at (7,3)
  + 34 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x17
>> Trial 2
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (9,14) with mask 
. . . 0 0 0 . . . . . . . . 
. . . 0 0 . 0 . . . . . . . 
. . . 0 . . . 0 . . . . . . 
. . . . . 0 . 0 . 0 . . . . 
. . . 0 . . 0 . . . 0 . 0 . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 
. 0 0 . 0 0 0 0 0 0 . . . . 
0 0 . 0 0 . . . . . 0 . . . 
. 0 . . . . . . . . 0 . . . 
 with color blue at (8,1)
  _01: rectangle with size (10,13) with mask 
. 0 . . . . . . . 0 . . . 
0 . 0 . 0 0 0 0 0 . . . . 
0 . . . 0 . . 0 0 . . . . 
. 0 . 0 . 0 . 0 0 . . . . 
. . 0 0 . . . . . 0 0 . . 
. . 0 0 0 . . . . 0 0 . . 
. . . 0 0 . . . . . 0 . . 
. . . . . . 0 . . 0 . 0 0 
. . . . . . . 0 0 . . . . 
. . . . . . . . 0 0 . . . 
 with color blue at (0,3)
  _011: rectangle with size (3,6) with model Full with color cyan at (7,3)
  + 34 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x17
>> Trial 3
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (9,14) with mask 
. . . 0 0 0 . . . . . . . . 
. . . 0 0 . 0 . . . . . . . 
. . . 0 . . . 0 . . . . . . 
. . . . . 0 . 0 . 0 . . . . 
. . . 0 . . 0 . . . 0 . 0 . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 
. 0 0 . 0 0 0 0 0 0 . . . . 
0 0 . 0 0 . . . . . 0 . . . 
. 0 . . . . . . . . 0 . . . 
 with color blue at (8,1)
  _01: rectangle with size (3,6) with model Full with color cyan at (7,3)
  _011: rectangle with size (10,13) with mask 
. 0 . . . . . . . 0 . . . 
0 . 0 . 0 0 0 0 0 . . . . 
0 . . . 0 . . 0 0 . . . . 
. 0 . 0 . 0 . 0 0 . . . . 
. . 0 0 . . . . . 0 0 . . 
. . 0 0 0 . . . . 0 0 . . 
. . . 0 0 . . . . . 0 . . 
. . . . . . 0 . . 0 . 0 0 
. . . . . . . 0 0 . . . . 
. . . . . . . . 0 0 . . . 
 with color blue at (0,3)
  + 34 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x17

TRAIN 32597951.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (17,17) and color blue and layers
  _0: rectangle with size (17,17) with mask 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . 0 . . 0 . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . . . . . . . 0 . . 0 . . 0 
0 . 0 0 . . . . . 0 . 0 0 . 0 0 . 
. 0 . . . . . . . . 0 . . 0 . . 0 
0 . 0 0 . . . . . 0 . 0 0 . 0 0 . 
. 0 . . . . . . . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . 0 . . 0 . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . 0 . . 0 . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . 0 . . 0 . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . 0 . . 0 . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
 with color black at (0,0)
  _01: rectangle with size (5,1) with model Full with color cyan at (3,4)
  _011: rectangle with size (5,5) with mask 
0 . . 0 . 
. 0 0 . 0 
0 . . 0 . 
. 0 0 . 0 
0 . . 0 . 
 with color cyan at (3,4)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (17,17) and color blue and layers
  _0: 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . 0 . . 0 . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . . . . . . . 0 . . 0 . . 0 
0 . 0 0 . . . . . 0 . 0 0 . 0 0 . 
. 0 . . . . . . . . 0 . . 0 . . 0 
0 . 0 0 . . . . . 0 . 0 0 . 0 0 . 
. 0 . . . . . . . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . 0 . . 0 . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . 0 . . 0 . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . 0 . . 0 . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . 0 . . 0 . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
 at (0,0)
  _01: rectangle with size (3,2) with model Full with color cyan at (4,5)
  _01100: rectangle with size (5,2) with model Full with color green at (3,5)
  _0110: 
8 . . 8 . 
. 8 8 . 8 
8 . . 8 . 
. 8 8 . 8 
8 . . 8 . 
 at (3,4)
  _011: rectangle with size (5,1) with model Full with color green at (3,8)
  _0111: rectangle with size (3,1) with model Full with color green at (4,4)
  _01111: rectangle with size (3,1) with model Full with color green at (4,7)
  + 2 delta pixels
diff: 
   (292.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,17) and color blue and layers
  _0: rectangle with size (17,17) with mask 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . 0 . . 0 . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . . . . . . . 0 . . 0 . . 0 
0 . 0 0 . . . . . 0 . 0 0 . 0 0 . 
. 0 . . . . . . . . 0 . . 0 . . 0 
0 . 0 0 . . . . . 0 . 0 0 . 0 0 . 
. 0 . . . . . . . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . 0 . . 0 . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . 0 . . 0 . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . 0 . . 0 . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
. 0 . . 0 . . 0 . . 0 . . 0 . . 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 . 0 0 . 
 with color black at (0,0)
  _01: rectangle with size (5,1) with model Full with color cyan at (3,4)
  _011: rectangle with size (5,5) with mask 
0 . . 0 . 
. 0 0 . 0 
0 . . 0 . 
. 0 0 . 0 
0 . . 0 . 
 with color cyan at (3,4)
  + 2 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x17

TRAIN 32597951.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (17,17) with mask 
0 . . . . . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . . . . 
. . 0 . . . . . . . . . . . . . . 
. . . 0 . . . . . . . . . . . . . 
. . . . 0 . . . . . . . . . . . . 
. . . . . 0 . . . . . . . . . . . 
. . . . . . 0 . . . . . . . . . . 
. . . . . . . 0 . . . . . . . . . 
. . . . . . . . 0 . . . . . . . . 
. . . . . . . . . 0 . . . . . . . 
. . . . . . . . . . 0 . . . . . . 
. . . . . . . . . . . 0 . . . . . 
. . . . . . . . . . . . 0 . . . . 
. . . . . . . . . . . . . 0 . . . 
. . . . . . . . . . . . . . 0 . . 
. . . . . . . . . . . . . . . 0 . 
. . . . . . . . . . . . . . . . 0 
 with color blue at (0,0)
  _01: rectangle with size (4,6) with model Full with color cyan at (11,7)
  _011: rectangle with size (14,14) with mask 
0 . . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . 
. . 0 . . . . . . . . . . . 
. . . 0 . . . . . . . . . . 
. . . . 0 . . . . . . . . . 
. . . . . 0 . . . . . . . . 
. . . . . . 0 . . . . . . . 
. . . . . . . 0 . . . . . . 
. . . . . . . . 0 . . . . . 
. . . . . . . . . 0 . . . . 
. . . . . . . . . . 0 . . . 
. . . . . . . . . . . 0 . . 
. . . . . . . . . . . . 0 . 
. . . . . . . . . . . . . 0 
 with color blue at (0,3)
  + 66 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x17
>> Trial 2
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (17,17) with mask 
0 . . . . . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . . . . 
. . 0 . . . . . . . . . . . . . . 
. . . 0 . . . . . . . . . . . . . 
. . . . 0 . . . . . . . . . . . . 
. . . . . 0 . . . . . . . . . . . 
. . . . . . 0 . . . . . . . . . . 
. . . . . . . 0 . . . . . . . . . 
. . . . . . . . 0 . . . . . . . . 
. . . . . . . . . 0 . . . . . . . 
. . . . . . . . . . 0 . . . . . . 
. . . . . . . . . . . 0 . . . . . 
. . . . . . . . . . . . 0 . . . . 
. . . . . . . . . . . . . 0 . . . 
. . . . . . . . . . . . . . 0 . . 
. . . . . . . . . . . . . . . 0 . 
. . . . . . . . . . . . . . . . 0 
 with color blue at (0,0)
  _01: rectangle with size (14,14) with mask 
0 . . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . 
. . 0 . . . . . . . . . . . 
. . . 0 . . . . . . . . . . 
. . . . 0 . . . . . . . . . 
. . . . . 0 . . . . . . . . 
. . . . . . 0 . . . . . . . 
. . . . . . . 0 . . . . . . 
. . . . . . . . 0 . . . . . 
. . . . . . . . . 0 . . . . 
. . . . . . . . . . 0 . . . 
. . . . . . . . . . . 0 . . 
. . . . . . . . . . . . 0 . 
. . . . . . . . . . . . . 0 
 with color blue at (0,3)
  _011: rectangle with size (4,6) with model Full with color cyan at (11,7)
  + 66 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x17

TEST 32597951.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.7 sec (59.7 sec/task)
bits-train-error = 36957.7 bits (36957.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-330] Checking task 3345333e.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 210210.1 = 210212.5
DL output with Mo: L = 2.3 + 210210.1 = 210212.5
DL input+output M: L = 4.6 + 420420.3 = 420424.9

# learning a model for train pairs
2.000	
1.132	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.295	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.175	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.083	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.031	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.029	OUT SPE ^.size = ^.size
0.028	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.027	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_0.shape.mask.size.i
0.026	OUT SPE ^.layer_0.shape.mask.size.j = area(^.layer_01.shape) / '2
0.025	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.025	IN  SPE ^.layer_01.shape.mask.model = Full
0.025	IN  SPE ^.color = black
0.025	OUT SPE ^.color = black
0.007	
0.007	IN  GEN ^.layer_01.shape.mask.model = ?
0.007	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i,area(^.layer_01.shape) / '2) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 70.9 + 3832.6 = 3903.4
DL output with Mo: L = 73.3 + 1228.6 = 1301.8
DL input+output M: L = 144.1 + 5061.1 = 5205.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i,area(^.layer_01.shape) / '2) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 73.3 + 1228.6 = 1301.8
DL input+output M: L = 143.5 + 1228.6 = 1372.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (16,16) and color black and layers
  _0: rectangle with size (9,5) with mask 
0 0 . . . 
0 0 . . . 
. 0 0 . . 
. . 0 . . 
. . 0 0 . 
. 0 0 0 0 
. 0 . . 0 
. 0 0 0 0 
. . 0 0 . 
 with color pink at (2,3)
  _01: rectangle with size (3,4) with model Full with color blue at (3,6)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (9,6) with mask 
0 0 . . 0 0 
0 0 . . 0 0 
. 0 0 0 0 . 
. . 0 0 . . 
. . 0 0 . . 
. 0 0 0 0 . 
. 0 . . 0 . 
. 0 0 0 0 . 
. . 0 0 . . 
 with color pink at (2,3)
diff: 
   (57.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (9,5) with mask 
0 0 . . . 
0 0 . . . 
. 0 0 . . 
. . 0 . . 
. . 0 0 . 
. 0 0 0 0 
. 0 . . 0 
. 0 0 0 0 
. . 0 0 . 
 with color pink at (2,3)
  _01: rectangle with size (3,4) with model Full with color blue at (3,6)
  + 2 delta pixels
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (3,4) with model Full with color blue at (3,6)
  _01: rectangle with size (9,5) with mask 
0 0 . . . 
0 0 . . . 
. 0 0 . . 
. . 0 . . 
. . 0 0 . 
. 0 0 0 0 
. 0 . . 0 
. 0 0 0 0 
. . 0 0 . 
 with color pink at (2,3)
  + 2 delta pixels
diff: 
! 53 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (9,5) with mask 
0 0 . . . 
0 0 . . . 
. 0 0 . . 
. . 0 . . 
. . 0 0 . 
. 0 0 0 0 
. 0 . . 0 
. 0 0 0 0 
. . 0 0 . 
 with color pink at (2,3)
  _01: rectangle with size (1,2) with model Full with color pink at (2,7)
  + 12 delta pixels
diff: 
! 33 wrong pixels (generated / expected)

TRAIN 3345333e.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (16,16) and color black and layers
  _0: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . . 0 0 0 0 . 
. . . 0 0 0 0 0 
. . . 0 0 . 0 . 
. . . . . . 0 . 
. 0 0 0 0 0 0 . 
0 0 . 0 0 . 0 0 
0 0 . . . . 0 0 
 with color red at (3,1)
  _01: rectangle with size (4,4) with model Full with color green at (4,0)
diff: 
   (0.0 bits)
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. 0 0 0 0 0 0 . 
0 0 0 0 0 0 0 0 
. 0 . 0 0 . 0 . 
. 0 . . . . 0 . 
. 0 0 0 0 0 0 . 
0 0 . 0 0 . 0 0 
0 0 . . . . 0 0 
 with color red at (3,1)
diff: 
   (65.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . . 0 0 0 0 . 
. . . 0 0 0 0 0 
. . . 0 0 . 0 . 
. . . . . . 0 . 
. 0 0 0 0 0 0 . 
0 0 . 0 0 . 0 0 
0 0 . . . . 0 0 
 with color red at (3,1)
  _01: rectangle with size (4,4) with model Full with color green at (4,0)
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (4,4) with model Full with color green at (4,0)
  _01: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . . 0 0 0 0 . 
. . . 0 0 0 0 0 
. . . 0 0 . 0 . 
. . . . . . 0 . 
. 0 0 0 0 0 0 . 
0 0 . 0 0 . 0 0 
0 0 . . . . 0 0 
 with color red at (3,1)
diff: 
! 78 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (6,2) with model Full with color red at (4,4)
  _01: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . . 0 0 0 0 . 
. . . 0 0 0 0 0 
. . . 0 0 . 0 . 
. . . . . . 0 . 
. 0 0 0 0 0 0 . 
0 0 . 0 0 . 0 0 
0 0 . . . . 0 0 
 with color red at (3,1)
  + 18 delta pixels
diff: 
! 68 wrong pixels (generated / expected)

TRAIN 3345333e.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (8,8) with mask 
. 0 . . . 0 . . 
. . 0 0 0 . 0 . 
. . . . . . 0 0 
. . 0 0 0 0 0 0 
. . . 0 . . . . 
. . 0 0 0 0 0 0 
0 0 . 0 . 0 0 . 
. 0 . . . 0 . . 
 with color grey at (5,6)
  _01: rectangle with size (5,4) with model Full with color cyan at (6,4)
diff: 
! 49 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (5,4) with model Full with color cyan at (6,4)
  _01: rectangle with size (8,8) with mask 
. 0 . . . 0 . . 
. . 0 0 0 . 0 . 
. . . . . . 0 0 
. . 0 0 0 0 0 0 
. . . 0 . . . . 
. . 0 0 0 0 0 0 
0 0 . 0 . 0 0 . 
. 0 . . . 0 . . 
 with color grey at (5,6)
diff: 
! 69 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (3,6) with model Full with color grey at (8,8)
  _01: rectangle with size (5,4) with model Full with color cyan at (6,4)
  + 21 delta pixels
diff: 
! 35 wrong pixels (generated / expected)

TEST 3345333e.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 4.6 sec (4.6 sec/task)
bits-train-error = 1228.6 bits (1228.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-329] Checking task 3428a4f5.json: 4 train, 2 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 102655.9 = 102658.3
DL output with Mo: L = 2.3 + 46680.5 = 46682.8
DL input+output M: L = 4.6 + 149336.4 = 149341.1

# learning a model for train pairs
2.000	
1.430	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.906	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.588	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.408	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.268	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.203	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.183	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.169	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.161	OUT SPE ^.layer_0.pos = ^.layer_0.pos + translationOnto(^.layer_0, ^.layer_011)
0.159	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.073	
0.072	IN  DEL ^.layer_0111

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at ^.layer_0.pos + translationOnto(^.layer_0, ^.layer_011)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 8899.2 = 9025.0
DL output with Mo: L = 105.2 + 3193.6 = 3298.8
DL input+output M: L = 231.0 + 12092.8 = 12323.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at ^.layer_0.pos + translationOnto(^.layer_0, ^.layer_011)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 40.0 = 138.1
DL output with Mo: L = 105.2 + 3190.8 = 3296.0
DL input+output M: L = 203.3 + 3230.8 = 3434.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (13,5) and color red and layers
  _0: rectangle with size (6,5) with mask 
0 0 0 . . 
0 0 . 0 . 
. 0 0 . . 
. . 0 0 . 
0 0 0 0 . 
0 . 0 0 0 
 with color black at (0,0)
  _01: rectangle with size (6,5) with mask 
. 0 0 0 0 
. . 0 0 0 
. 0 . 0 0 
0 0 . 0 0 
0 0 0 . . 
. 0 0 . . 
 with color black at (7,0)
  _011: rectangle with size (1,5) with model Full with color yellow at (6,0)
  + 1 delta pixels
diff: 
   (2.0 bits)
data: a background with size (6,5) and color black and layers
  _0: rectangle with size (6,5) with mask 
0 . . 0 0 
0 0 0 . 0 
. . 0 0 0 
0 0 0 . 0 
. . . 0 . 
. . . 0 . 
 with color green at (0,0)
  _01: rectangle with size (1,2) with model Full with color green at (5,0)
diff: 
   (83.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,5) and color red and layers
  _0: rectangle with size (6,5) with mask 
. 0 0 0 0 
. . 0 0 0 
. 0 . 0 0 
0 0 . 0 0 
0 0 0 . . 
. 0 0 . . 
 with color black at (7,0)
  _01: rectangle with size (6,5) with mask 
0 0 0 . . 
0 0 . 0 . 
. 0 0 . . 
. . 0 0 . 
0 0 0 0 . 
0 . 0 0 0 
 with color black at (0,0)
  _011: rectangle with size (1,5) with model Full with color yellow at (6,0)
  + 1 delta pixels
diff: 
! 19 wrong pixels (generated / expected)

TRAIN 3428a4f5.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (13,5) and color black and layers
  _0: rectangle with size (6,5) with mask 
. 0 0 0 0 
. . . . 0 
. . 0 0 0 
. . 0 0 . 
0 0 0 0 . 
0 0 . . 0 
 with color red at (0,0)
  _01: rectangle with size (4,4) with mask 
. . . 0 
. . 0 . 
0 . 0 . 
0 0 0 . 
 with color red at (9,1)
  _011: rectangle with size (1,5) with model Full with color yellow at (6,0)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,5) and color green and layers
  _0: rectangle with size (6,2) with mask 
0 . 
0 0 
0 0 
0 0 
. 0 
. 0 
 with color black at (0,0)
  _01: rectangle with size (4,2) with mask 
0 . 
. 0 
0 0 
0 0 
 with color black at (1,3)
diff: 
   (76.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,5) and color black and layers
  _0: rectangle with size (6,5) with mask 
. 0 0 0 0 
. . . . 0 
. . 0 0 0 
. . 0 0 . 
0 0 0 0 . 
0 0 . . 0 
 with color red at (0,0)
  _01: rectangle with size (4,4) with mask 
. . . 0 
. . 0 . 
0 . 0 . 
0 0 0 . 
 with color red at (9,1)
  _011: rectangle with size (1,5) with model Full with color yellow at (6,0)
  + 3 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,5) and color black and layers
  _0: rectangle with size (6,5) with mask 
. 0 0 0 0 
. . . . 0 
. . 0 0 0 
. . 0 0 . 
0 0 0 0 . 
0 0 . . 0 
 with color red at (0,0)
  _01: rectangle with size (1,5) with model Full with color yellow at (6,0)
  _011: rectangle with size (4,4) with mask 
. . . 0 
. . 0 . 
0 . 0 . 
0 0 0 . 
 with color red at (9,1)
  + 3 delta pixels
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (13,5) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . 0 . 
0 . 0 . 
0 0 0 . 
 with color red at (9,1)
  _01: rectangle with size (6,5) with mask 
. 0 0 0 0 
. . . . 0 
. . 0 0 0 
. . 0 0 . 
0 0 0 0 . 
0 0 . . 0 
 with color red at (0,0)
  _011: rectangle with size (1,5) with model Full with color yellow at (6,0)
  + 3 delta pixels
diff: 
! size mismatch, 4x4 instead of 6x5

TRAIN 3428a4f5.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (13,5) and color black and layers
  _0: rectangle with size (6,5) with mask 
0 0 . 0 0 
0 . 0 0 0 
0 . . . . 
. 0 . 0 . 
0 0 0 . 0 
0 . 0 . . 
 with color red at (0,0)
  _01: rectangle with size (6,5) with mask 
. . . 0 0 
. . 0 . 0 
0 0 . . . 
. . 0 . 0 
. 0 . 0 0 
. 0 0 . 0 
 with color red at (7,0)
  _011: rectangle with size (1,5) with model Full with color yellow at (6,0)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,5) and color black and layers
  _0: rectangle with size (6,5) with mask 
. 0 . . . 
0 . . . . 
. 0 . . . 
. 0 0 0 0 
0 . 0 0 . 
0 0 . . 0 
 with color green at (0,0)
  _01: rectangle with size (1,1) with model Full with color green at (1,3)
diff: 
   (81.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,5) and color black and layers
  _0: rectangle with size (6,5) with mask 
0 0 . 0 0 
0 . 0 0 0 
0 . . . . 
. 0 . 0 . 
0 0 0 . 0 
0 . 0 . . 
 with color red at (0,0)
  _01: rectangle with size (6,5) with mask 
. . . 0 0 
. . 0 . 0 
0 0 . . . 
. . 0 . 0 
. 0 . 0 0 
. 0 0 . 0 
 with color red at (7,0)
  _011: rectangle with size (1,5) with model Full with color yellow at (6,0)
  + 1 delta pixels
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,5) and color black and layers
  _0: rectangle with size (6,5) with mask 
0 0 . 0 0 
0 . 0 0 0 
0 . . . . 
. 0 . 0 . 
0 0 0 . 0 
0 . 0 . . 
 with color red at (0,0)
  _01: rectangle with size (1,5) with model Full with color yellow at (6,0)
  _011: rectangle with size (6,5) with mask 
. . . 0 0 
. . 0 . 0 
0 0 . . . 
. . 0 . 0 
. 0 . 0 0 
. 0 0 . 0 
 with color red at (7,0)
  + 1 delta pixels
diff: 
! 17 wrong pixels (generated / expected)

TRAIN 3428a4f5.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (13,5) and color black and layers
  _0: rectangle with size (6,5) with mask 
. 0 . 0 . 
0 0 . 0 0 
. 0 0 0 . 
. 0 0 . . 
. 0 0 0 0 
0 . 0 . 0 
 with color red at (0,0)
  _01: rectangle with size (1,5) with model Full with color yellow at (6,0)
  _011: rectangle with size (6,5) with mask 
0 . 0 0 0 
. 0 0 . . 
0 . 0 . 0 
0 . . . 0 
0 0 . 0 . 
0 . 0 0 . 
 with color red at (7,0)
diff: 
   (2.0 bits)
data: a background with size (6,5) and color green and layers
  _0: rectangle with size (5,4) with mask 
. 0 . . 
. . 0 . 
. . . 0 
. 0 . 0 
0 0 0 . 
 with color black at (1,0)
  _01: rectangle with size (1,1) with model Full with color black at (0,3)
diff: 
   (76.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,5) and color black and layers
  _0: rectangle with size (6,5) with mask 
. 0 . 0 . 
0 0 . 0 0 
. 0 0 0 . 
. 0 0 . . 
. 0 0 0 0 
0 . 0 . 0 
 with color red at (0,0)
  _01: rectangle with size (6,5) with mask 
0 . 0 0 0 
. 0 0 . . 
0 . 0 . 0 
0 . . . 0 
0 0 . 0 . 
0 . 0 0 . 
 with color red at (7,0)
  _011: rectangle with size (1,5) with model Full with color yellow at (6,0)
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,5) and color black and layers
  _0: rectangle with size (6,5) with mask 
. 0 . 0 . 
0 0 . 0 0 
. 0 0 0 . 
. 0 0 . . 
. 0 0 0 0 
0 . 0 . 0 
 with color red at (0,0)
  _01: rectangle with size (1,5) with model Full with color yellow at (6,0)
  _011: rectangle with size (6,5) with mask 
0 . 0 0 0 
. 0 0 . . 
0 . 0 . 0 
0 . . . 0 
0 0 . 0 . 
0 . 0 0 . 
 with color red at (7,0)
diff: 
! 22 wrong pixels (generated / expected)

TRAIN 3428a4f5.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,5) and color black and layers
  _0: rectangle with size (6,5) with mask 
0 . 0 0 . 
0 . . 0 0 
0 0 0 . . 
0 0 0 0 0 
. 0 0 . . 
0 0 0 0 0 
 with color red at (0,0)
  _01: rectangle with size (5,5) with mask 
0 . . . . 
0 0 0 . . 
. 0 0 . . 
0 . 0 0 . 
0 . 0 0 0 
 with color red at (8,0)
  _011: rectangle with size (1,5) with model Full with color yellow at (6,0)
  + 4 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,5) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 . . . . 
0 0 0 . . 
. 0 0 . . 
0 . 0 0 . 
0 . 0 0 0 
 with color red at (8,0)
  _01: rectangle with size (6,5) with mask 
0 . 0 0 . 
0 . . 0 0 
0 0 0 . . 
0 0 0 0 0 
. 0 0 . . 
0 0 0 0 0 
 with color red at (0,0)
  _011: rectangle with size (1,5) with model Full with color yellow at (6,0)
  + 4 delta pixels
diff: 
! size mismatch, 5x5 instead of 6x5
>> Trial 3
data: a background with size (13,5) and color black and layers
  _0: rectangle with size (6,5) with mask 
0 . 0 0 . 
0 . . 0 0 
0 0 0 . . 
0 0 0 0 0 
. 0 0 . . 
0 0 0 0 0 
 with color red at (0,0)
  _01: rectangle with size (1,5) with model Full with color yellow at (6,0)
  _011: rectangle with size (5,5) with mask 
0 . . . . 
0 0 0 . . 
. 0 0 . . 
0 . 0 0 . 
0 . 0 0 0 
 with color red at (8,0)
  + 4 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TEST 3428a4f5.json/1: 0 - (FAILURE)

## instance 2

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,5) and color black and layers
  _0: rectangle with size (6,5) with mask 
. . 0 . 0 
. . 0 . 0 
. . . 0 . 
. 0 0 0 . 
0 . 0 0 . 
0 0 0 . 0 
 with color red at (0,0)
  _01: rectangle with size (6,5) with mask 
0 0 . . . 
. 0 0 0 0 
. . 0 0 . 
. 0 . . . 
. 0 0 . . 
0 . . . . 
 with color red at (7,0)
  _011: rectangle with size (1,5) with model Full with color yellow at (6,0)
  + 3 delta pixels
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,5) and color black and layers
  _0: rectangle with size (6,5) with mask 
. . 0 . 0 
. . 0 . 0 
. . . 0 . 
. 0 0 0 . 
0 . 0 0 . 
0 0 0 . 0 
 with color red at (0,0)
  _01: rectangle with size (1,5) with model Full with color yellow at (6,0)
  _011: rectangle with size (6,5) with mask 
0 0 . . . 
. 0 0 0 0 
. . 0 0 . 
. 0 . . . 
. 0 0 . . 
0 . . . . 
 with color red at (7,0)
  + 3 delta pixels
diff: 
! 19 wrong pixels (generated / expected)

TEST 3428a4f5.json/2: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 16.0 sec (16.0 sec/task)
bits-train-error = 3190.8 bits (3190.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-328] Checking task 3618c87e.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 29114.4 = 29116.7
DL output with Mo: L = 2.3 + 29114.4 = 29116.7
DL input+output M: L = 4.6 + 58228.7 = 58233.4

# learning a model for train pairs
2.000	
1.283	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.631	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.411	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.256	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.217	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.188	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.170	OUT SPE ^.layer_01.shape = ^.layer_01.shape
0.153	OUT SPE ^.size = ^.size
0.140	OUT SPE ^.layer_0.shape.mask.size = projJ(^.layer_0.shape.mask.size) + (2, 0)
0.131	OUT SPE ^.layer_0.pos = '(3, 0)
0.121	OUT SPE ^.layer_01.pos = ^.layer_01.pos + (2, 0)
0.115	IN  SPE ^.color = grey
0.109	IN  SPE ^.layer_0.shape.color = black
0.104	IN  SPE ^.layer_01.shape.color = blue
0.098	OUT SPE ^.layer_0.shape.color = grey
0.095	IN  SPE ^.layer_01.shape.mask.model = Full
0.093	OUT SPE ^.color = black
0.016	
0.016	IN  GEN ^.color = ?
0.016	IN  GEN ^.layer_0.shape.color = ?
0.016	IN  GEN ^.layer_01.shape.color = ?
0.016	IN  GEN ^.layer_01.shape.mask.model = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size projJ(^.layer_0.shape.mask.size) + (2, 0) with model ? with color grey at '(3, 0)
  _01: ^.layer_01.shape at ^.layer_01.pos + (2, 0)
WHERE (Mi)
a background with size (?,?) and color grey and layers
  _0: rectangle with size (?,?) with model ? with color black at (?,?)
  _01: rectangle with size (?,?) with model Full with color blue at (?,?)

DL input  with Mi: L = 84.1 + 2222.9 = 2307.0
DL output with Mo: L = 82.3 + 306.9 = 389.2
DL input+output M: L = 166.4 + 2529.8 = 2696.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size projJ(^.layer_0.shape.mask.size) + (2, 0) with model ? with color grey at '(3, 0)
  _01: ^.layer_01.shape at ^.layer_01.pos + (2, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 82.3 + 306.9 = 389.2
DL input+output M: L = 152.5 + 306.9 = 459.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,5) with mask 
. . 0 . . 
0 0 0 0 0 
 with color grey at (3,0)
  _01: rectangle with size (1,1) with model Full with color blue at (2,2)
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,5) with mask 
. . 0 . . 
0 0 . 0 0 
 with color grey at (3,0)
  _01: 
1 
 at (4,2)
diff: 
   (12.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,5) with mask 
. . 0 . . 
0 0 0 0 0 
 with color grey at (3,0)
  _01: rectangle with size (1,1) with model Full with color blue at (2,2)
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (1,1) with model Full with color blue at (2,2)
  _01: rectangle with size (2,5) with mask 
. . 0 . . 
0 0 0 0 0 
 with color grey at (3,0)
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 3618c87e.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (5,5) and color grey and layers
  _0: rectangle with size (4,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 . 0 . 0 
0 . 0 . 0 
 with color black at (0,0)
  _01: rectangle with size (1,3) with model Full with color blue at (2,1)
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,5) with model Odd Checkboard with color grey at (3,0)
  _01: 
1 1 1 
 at (4,1)
diff: 
   (6.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color grey and layers
  _0: rectangle with size (4,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 . 0 . 0 
0 . 0 . 0 
 with color black at (0,0)
  _01: rectangle with size (1,3) with model Full with color blue at (2,1)
diff: 
! 5 wrong pixels (generated / expected)

TRAIN 3618c87e.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (5,5) and color grey and layers
  _0: rectangle with size (4,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 . 0 0 . 
0 . 0 0 . 
 with color black at (0,0)
  _01: rectangle with size (1,4) with model Full with color blue at (2,1)
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,5) with mask 
. 0 . . 0 
0 . 0 0 . 
 with color grey at (3,0)
  _01: 
1 1 1 1 
 at (4,1)
diff: 
   (12.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color grey and layers
  _0: rectangle with size (4,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 . 0 0 . 
0 . 0 0 . 
 with color black at (0,0)
  _01: rectangle with size (1,4) with model Full with color blue at (2,1)
diff: 
! 5 wrong pixels (generated / expected)

TRAIN 3618c87e.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color grey and layers
  _0: rectangle with size (4,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 0 . 0 . 
0 0 . 0 . 
 with color black at (0,0)
  _01: rectangle with size (1,3) with model Full with color blue at (2,2)
diff: 
! 5 wrong pixels (generated / expected)

TEST 3618c87e.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 6.4 sec (6.4 sec/task)
bits-train-error = 306.9 bits (306.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-327] Checking task 3631a71a.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 1539021.7 = 1539024.0
DL output with Mo: L = 2.3 + 1539021.7 = 1539024.0
DL input+output M: L = 4.6 + 3078043.4 = 3078048.0

# learning a model for train pairs
2.000	
1.468	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.979	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.931	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.893	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.860	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.839	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.820	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.802	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.789	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.777	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.763	OUT ADD ^.layer_011 = ^.layer_01111
0.395	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: ^.layer_01111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 180.9 + 565982.3 = 566163.2
DL output with Mo: L = 84.4 + 607655.9 = 607740.3
DL input+output M: L = 265.2 + 1173638.3 = 1173903.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: ^.layer_01111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 180.9 + 0.0 = 180.9
DL output with Mo: L = 84.4 + 607655.9 = 607740.3
DL input+output M: L = 265.2 + 607655.9 = 607921.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (30,30) and color black and layers
  _0: rectangle with size (8,8) with mask 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 . . 
0 0 0 0 0 0 . . 
 with color brown at (5,22)
  _01: rectangle with size (6,7) with model Full with color brown at (9,12)
  _011: rectangle with size (5,8) with mask 
0 0 . 0 0 . 0 0 
0 0 . 0 0 . 0 0 
. 0 0 . . 0 0 . 
. . 0 0 0 0 . . 
. . . 0 0 . . . 
 with color blue at (15,12)
  _0111: rectangle with size (3,7) with model Full with color brown at (8,0)
  _01111: rectangle with size (4,4) with mask 
. . 0 0 
. . 0 . 
0 0 . . 
0 . . . 
 with color grey at (0,8)
  _011111: rectangle with size (4,4) with mask 
0 0 . . 
. 0 . . 
. . 0 0 
. . . 0 
 with color grey at (0,20)
  + 209 delta pixels
diff: 
   (0.0 bits)
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (8,8) with mask 
. . . 0 0 . . . 
. . 0 0 0 0 . . 
. 0 0 . . 0 0 . 
0 0 . 0 0 . 0 0 
0 0 . 0 0 . 0 0 
. 0 0 . . 0 0 . 
. . 0 0 0 0 . . 
. . . 0 0 . . . 
 with color blue at (12,12)
  _01: rectangle with size (4,4) with mask 
0 0 . . 
. 0 . . 
. . 0 0 
. . . 0 
 with color grey at (0,20)
  _011: 
. . 5#5#
. . 5#. 
5#5#. . 
5#. . . 
 at (0,8)
  + 244 delta pixels
diff: 
   (10619.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (8,8) with mask 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 . . 
0 0 0 0 0 0 . . 
 with color brown at (5,22)
  _01: rectangle with size (6,7) with model Full with color brown at (9,12)
  _011: rectangle with size (5,8) with mask 
0 0 . 0 0 . 0 0 
0 0 . 0 0 . 0 0 
. 0 0 . . 0 0 . 
. . 0 0 0 0 . . 
. . . 0 0 . . . 
 with color blue at (15,12)
  _0111: rectangle with size (3,7) with model Full with color brown at (8,0)
  _01111: rectangle with size (4,4) with mask 
. . 0 0 
. . 0 . 
0 0 . . 
0 . . . 
 with color grey at (0,8)
  _011111: rectangle with size (4,4) with mask 
0 0 . . 
. 0 . . 
. . 0 0 
. . . 0 
 with color grey at (0,20)
  + 209 delta pixels
diff: 
! size mismatch, 10x10 instead of 30x30
>> Trial 2
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (8,8) with mask 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 . . 
0 0 0 0 0 0 . . 
 with color brown at (5,22)
  _01: rectangle with size (6,7) with model Full with color brown at (9,12)
  _011: rectangle with size (5,8) with mask 
0 0 . 0 0 . 0 0 
0 0 . 0 0 . 0 0 
. 0 0 . . 0 0 . 
. . 0 0 0 0 . . 
. . . 0 0 . . . 
 with color blue at (15,12)
  _0111: rectangle with size (3,7) with model Full with color brown at (8,0)
  _01111: rectangle with size (4,4) with mask 
0 0 . . 
. 0 . . 
. . 0 0 
. . . 0 
 with color grey at (0,20)
  _011111: rectangle with size (4,4) with mask 
. . 0 0 
. . 0 . 
0 0 . . 
0 . . . 
 with color grey at (0,8)
  + 209 delta pixels
diff: 
! size mismatch, 10x10 instead of 30x30

TRAIN 3631a71a.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (30,30) and color black and layers
  _0: rectangle with size (4,5) with model Full with color brown at (1,21)
  _01: rectangle with size (2,7) with model Full with color brown at (28,17)
  _011: rectangle with size (6,6) with mask 
. . 0 0 0 . 
. . 0 0 . 0 
0 0 . . . . 
0 0 . . . . 
0 . . . . . 
. 0 . . . . 
 with color blue at (4,4)
  _0111: rectangle with size (4,8) with mask 
. . 0 . . 0 . . 
. . . 0 0 . . . 
0 . . 0 0 . . 0 
. 0 0 . . 0 0 . 
 with color orange at (8,12)
  _01111: rectangle with size (4,8) with mask 
. 0 0 . . 0 0 . 
0 . . 0 0 . . 0 
. . . 0 0 . . . 
. . 0 . . 0 . . 
 with color orange at (20,12)
  _011111: rectangle with size (2,6) with model Full with color brown at (25,20)
  + 361 delta pixels
diff: 
   (0.0 bits)
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (4,8) with mask 
. . 0 . . 0 . . 
. . . 0 0 . . . 
0 . . 0 0 . . 0 
. 0 0 . . 0 0 . 
 with color orange at (8,12)
  _01: rectangle with size (8,4) with mask 
. . 0 . 
. . . 0 
0 . . 0 
. 0 0 . 
. 0 0 . 
0 . . 0 
. . . 0 
. . 0 . 
 with color orange at (12,8)
  _011: 
. 7#7#. . 7#7#. 
7#. . 7#7#. . 7#
. . . 7#7#. . . 
. . 7#. . 7#. . 
 at (20,12)
  + 385 delta pixels
diff: 
   (16622.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (4,5) with model Full with color brown at (1,21)
  _01: rectangle with size (2,7) with model Full with color brown at (28,17)
  _011: rectangle with size (6,6) with mask 
. . 0 0 0 . 
. . 0 0 . 0 
0 0 . . . . 
0 0 . . . . 
0 . . . . . 
. 0 . . . . 
 with color blue at (4,4)
  _0111: rectangle with size (4,8) with mask 
. . 0 . . 0 . . 
. . . 0 0 . . . 
0 . . 0 0 . . 0 
. 0 0 . . 0 0 . 
 with color orange at (8,12)
  _01111: rectangle with size (4,8) with mask 
. 0 0 . . 0 0 . 
0 . . 0 0 . . 0 
. . . 0 0 . . . 
. . 0 . . 0 . . 
 with color orange at (20,12)
  _011111: rectangle with size (2,6) with model Full with color brown at (25,20)
  + 361 delta pixels
diff: 
! size mismatch, 10x10 instead of 30x30

TRAIN 3631a71a.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (30,30) and color black and layers
  _0: rectangle with size (7,4) with model Full with color brown at (0,17)
  _01: rectangle with size (12,12) with mask 
. . . . . 0 0 . . . . . 
. . . . 0 . . 0 . . . . 
. . . 0 . . . . 0 . . . 
. . 0 0 . . . . 0 0 . . 
. 0 . . . . . . . . 0 . 
0 . . . . . . . . . . 0 
0 . . . . . . . . . . 0 
. 0 . . . . . . . . 0 . 
. . 0 0 . . . . 0 0 . . 
. . . 0 . . . . 0 . . . 
. . . . 0 . . 0 . . . . 
. . . . . 0 0 . . . . . 
 with color pink at (10,10)
  _011: rectangle with size (7,3) with model Full with color brown at (7,0)
  _0111: rectangle with size (12,6) with mask 
. . . . 0 0 
. . . . 0 . 
. . 0 0 . . 
. . 0 0 . . 
0 0 . . . . 
0 . . . . . 
0 . . . . . 
0 0 . . . . 
. . 0 0 . . 
. . 0 0 . . 
. . . . 0 . 
. . . . 0 0 
 with color cyan at (10,2)
  _01111: rectangle with size (12,6) with mask 
0 0 . . . . 
. 0 . . . . 
. . 0 0 . . 
. . 0 0 . . 
. . . . 0 0 
. . . . . 0 
. . . . . 0 
. . . . 0 0 
. . 0 0 . . 
. . 0 0 . . 
. 0 . . . . 
0 0 . . . . 
 with color cyan at (10,24)
  _011111: rectangle with size (6,12) with mask 
0 . . . . . . . . . . 0 
0 0 . . . . . . . . 0 0 
. . 0 0 . . . . 0 0 . . 
. . 0 0 . . . . 0 0 . . 
. . . . 0 . . 0 . . . . 
. . . . 0 0 0 0 . . . . 
 with color cyan at (24,10)
  + 340 delta pixels
diff: 
   (0.0 bits)
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (12,12) with mask 
. . . . . 0 0 . . . . . 
. . . . 0 . . 0 . . . . 
. . . 0 . . . . 0 . . . 
. . 0 0 . . . . 0 0 . . 
. 0 . . . . . . . . 0 . 
0 . . . . . . . . . . 0 
0 . . . . . . . . . . 0 
. 0 . . . . . . . . 0 . 
. . 0 0 . . . . 0 0 . . 
. . . 0 . . . . 0 . . . 
. . . . 0 . . 0 . . . . 
. . . . . 0 0 . . . . . 
 with color pink at (10,10)
  _01: rectangle with size (6,12) with mask 
. . . . 0 0 0 0 . . . . 
. . . . 0 . . 0 . . . . 
. . 0 0 . . . . 0 0 . . 
. . 0 0 . . . . 0 0 . . 
0 0 . . . . . . . . 0 0 
0 . . . . . . . . . . 0 
 with color cyan at (2,10)
  _011: 
8 8 . . . . 
. 8 . . . . 
. . 8 8 . . 
. . 8 8 . . 
. . . . 8 8 
. . . . . 8 
. . . . . 8 
. . . . 8 8 
. . 8 8 . . 
. . 8 8 . . 
. 8 . . . . 
8 8 . . . . 
 at (10,24)
  + 390 delta pixels
diff: 
   (16946.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (7,4) with model Full with color brown at (0,17)
  _01: rectangle with size (12,12) with mask 
. . . . . 0 0 . . . . . 
. . . . 0 . . 0 . . . . 
. . . 0 . . . . 0 . . . 
. . 0 0 . . . . 0 0 . . 
. 0 . . . . . . . . 0 . 
0 . . . . . . . . . . 0 
0 . . . . . . . . . . 0 
. 0 . . . . . . . . 0 . 
. . 0 0 . . . . 0 0 . . 
. . . 0 . . . . 0 . . . 
. . . . 0 . . 0 . . . . 
. . . . . 0 0 . . . . . 
 with color pink at (10,10)
  _011: rectangle with size (7,3) with model Full with color brown at (7,0)
  _0111: rectangle with size (12,6) with mask 
. . . . 0 0 
. . . . 0 . 
. . 0 0 . . 
. . 0 0 . . 
0 0 . . . . 
0 . . . . . 
0 . . . . . 
0 0 . . . . 
. . 0 0 . . 
. . 0 0 . . 
. . . . 0 . 
. . . . 0 0 
 with color cyan at (10,2)
  _01111: rectangle with size (12,6) with mask 
0 0 . . . . 
. 0 . . . . 
. . 0 0 . . 
. . 0 0 . . 
. . . . 0 0 
. . . . . 0 
. . . . . 0 
. . . . 0 0 
. . 0 0 . . 
. . 0 0 . . 
. 0 . . . . 
0 0 . . . . 
 with color cyan at (10,24)
  _011111: rectangle with size (6,12) with mask 
0 . . . . . . . . . . 0 
0 0 . . . . . . . . 0 0 
. . 0 0 . . . . 0 0 . . 
. . 0 0 . . . . 0 0 . . 
. . . . 0 . . 0 . . . . 
. . . . 0 0 0 0 . . . . 
 with color cyan at (24,10)
  + 340 delta pixels
diff: 
! size mismatch, 10x10 instead of 30x30

TRAIN 3631a71a.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (30,30) and color black and layers
  _0: rectangle with size (16,16) with mask 
. . . . . . . 0 0 . . . . . . . 
. . . . . . 0 0 0 0 . . . . . . 
. . . . . 0 . . . . 0 . . . . . 
. . . . . 0 . . . . 0 0 . . . . 
. . . . . 0 . 0 0 . 0 . 0 . . . 
. . . . . . 0 0 0 0 . 0 0 0 . . 
. . . . . 0 . . . . 0 . . . 0 . 
0 0 . . 0 0 . . . . 0 0 . . 0 0 
0 0 . . 0 0 . . . . 0 0 . . 0 0 
. 0 . . . 0 . . . . 0 . . . 0 . 
. . 0 0 0 . 0 0 0 0 . 0 0 0 . . 
. . . 0 . 0 . 0 0 . 0 . 0 . . . 
. . . . 0 0 . . . . 0 0 . . . . 
. . . . . 0 . . . . 0 . . . . . 
. . . . . . 0 0 0 0 . . . . . . 
. . . . . . . 0 0 . . . . . . . 
 with color red at (8,8)
  _01: rectangle with size (7,8) with mask 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 . . . . . 
0 0 0 . . . . . 
0 0 0 . . . . . 
 with color brown at (11,5)
  _011: rectangle with size (20,9) with mask 
. . . . . . 0 . . 
. . . . . . . 0 0 
. . . . . . . 0 . 
. . . . . . 0 . . 
. . . . . 0 . . . 
. . . . 0 . . . . 
. . . 0 . . . . . 
. . 0 . . . . . . 
. 0 . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
. 0 . . . . . . . 
. . 0 . . . . . . 
. . . 0 . . . . . 
. . . . 0 . . . . 
. . . . . 0 . . . 
. . . . . . 0 . . 
. . . . . . . 0 . 
. . . . . . . 0 0 
. . . . . . 0 . . 
 with color red at (6,0)
  _0111: rectangle with size (14,18) with mask 
. . . 0 0 . . . . . . . . . . . . . 
. . 0 . . 0 . . . . . . . . . . . . 
. 0 . . . . 0 . . . . . . . . . . . 
0 . . . . . . 0 . . . . . . . . . . 
. . . . . . . . 0 . . . . . . . . . 
. . . . . . . . . 0 . . . . . . . . 
. . . . . . . . . . 0 . . 0 . . . . 
. . . . . . . . . . . 0 0 . . . . . 
. . . . . . . . . . . . 0 . . . . . 
. . . . . . . . . . . . . 0 . . . . 
. . . . . . . . . . . . . . 0 . . . 
. . . . . . . . . . . . . . . 0 . . 
. . . . . . . . . . . . . . . . 0 . 
. . . . . . . . . . . . . . . . . 0 
 with color red at (0,12)
  _01111: rectangle with size (12,12) with mask 
. . . . . . . . . . . 0 
. . . . . . . . . . 0 . 
. . . . . . . . . 0 . . 
. . . . . . . . 0 . . . 
. . . . . . . 0 . . . . 
. . . . . . 0 . . . . . 
. . . . . 0 0 . . . . . 
. . . . 0 . . 0 . . . . 
. . . 0 . . . . . . . . 
. . 0 . . . . . . . . . 
. 0 . . . . . . . . . . 
0 . . . . . . . . . . . 
 with color red at (18,18)
  _011111: rectangle with size (7,2) with model Full with color brown at (23,9)
  + 365 delta pixels
diff: 
   (0.0 bits)
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (16,16) with mask 
. . . . . . . 0 0 . . . . . . . 
. . . . . . 0 0 0 0 . . . . . . 
. . . . . 0 . . . . 0 . . . . . 
. . . . 0 0 . . . . 0 0 . . . . 
. . . 0 . 0 . 0 0 . 0 . 0 . . . 
. . 0 0 0 . 0 0 0 0 . 0 0 0 . . 
. 0 . . . 0 . . . . 0 . . . 0 . 
0 0 . . 0 0 . . . . 0 0 . . 0 0 
0 0 . . 0 0 . . . . 0 0 . . 0 0 
. 0 . . . 0 . . . . 0 . . . 0 . 
. . 0 0 0 . 0 0 0 0 . 0 0 0 . . 
. . . 0 . 0 . 0 0 . 0 . 0 . . . 
. . . . 0 0 . . . . 0 0 . . . . 
. . . . . 0 . . . . 0 . . . . . 
. . . . . . 0 0 0 0 . . . . . . 
. . . . . . . 0 0 . . . . . . . 
 with color red at (8,8)
  _01: rectangle with size (30,30) with mask 
. . . . . . . . . . . . . . . 0 0 . . . . . . . . . . . . . 
. . . . . . . . . . . . . . 0 . . 0 . . . . . . . . . . . . 
. . . . . . . . . . . . . 0 . . . . 0 . . . . . . . . . . . 
. . . . . . . . . . . . 0 . . . . . . 0 . . . . . . . . . . 
. . . . . . . . . . . 0 . . . . . . . . 0 . . . . . . . . . 
. . . . . . . . . . 0 . . . . . . . . . . 0 . . . . . . . . 
. . . . . . 0 . . 0 . . . . . . . . . . . . 0 . . 0 . . . . 
. . . . . . . 0 0 . . . . . . . . . . . . . . 0 0 . . . . . 
. . . . . . . 0 . . . . . . . . . . . . . . . . 0 . . . . . 
. . . . . . 0 . . . . . . . . . . . . . . . . . . 0 . . . . 
. . . . . 0 . . . . . . . . . . . . . . . . . . . . 0 . . . 
. . . . 0 . . . . . . . . . . . . . . . . . . . . . . 0 . . 
. . . 0 . . . . . . . . . . . . . . . . . . . . . . . . 0 . 
. . 0 . . . . . . . . . . . . . . . . . . . . . . . . . . 0 
. 0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. . 0 . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. . . 0 . . . . . . . . . . . . . . . . . . . . . . . . . . 
. . . . 0 . . . . . . . . . . . . . . . . . . . . . . . . . 
. . . . . 0 . . . . . . . . . . . . . . . . . . . . . . . . 
. . . . . . 0 . . . . . . . . . . . . . . . . . . . . . . . 
. . . . . . . 0 . . . . . . . . . . . . . . . . . . . . . . 
. . . . . . . 0 0 . . . . . . . . . . . . . . . . . . . . . 
. . . . . . 0 . . 0 . . . . . . . . . . . . . . . . . . . . 
. . . . . . . . . . 0 . . . . . . . . . . . . . . . . . . . 
. . . . . . . . . . . 0 . . . . . . . . . . . . . . . . . . 
. . . . . . . . . . . . 0 . . . . . . . . . . . . . . . . . 
. . . . . . . . . . . . . 0 . . . . . . . . . . . . . . . . 
 with color red at (0,0)
  _011: 
. . . . . . . . . . . 2 
. . . . . . . . . . 2 . 
. . . . . . . . . 2 . . 
. . . . . . . . 2 . . . 
. . . . . . . 2 . . . . 
. . . . . . 2 . . . . . 
. . . . . 2 2 . . . . . 
. . . . 2 . . 2 . . . . 
. . . 2 . . . . . . . . 
. . 2 . . . . . . . . . 
. 2 . . . . . . . . . . 
2 . . . . . . . . . . . 
 at (18,18)
  + 373 delta pixels
diff: 
   (16576.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (16,16) with mask 
. . . . . . . 0 0 . . . . . . . 
. . . . . . 0 0 0 0 . . . . . . 
. . . . . 0 . . . . 0 . . . . . 
. . . . . 0 . . . . 0 0 . . . . 
. . . . . 0 . 0 0 . 0 . 0 . . . 
. . . . . . 0 0 0 0 . 0 0 0 . . 
. . . . . 0 . . . . 0 . . . 0 . 
0 0 . . 0 0 . . . . 0 0 . . 0 0 
0 0 . . 0 0 . . . . 0 0 . . 0 0 
. 0 . . . 0 . . . . 0 . . . 0 . 
. . 0 0 0 . 0 0 0 0 . 0 0 0 . . 
. . . 0 . 0 . 0 0 . 0 . 0 . . . 
. . . . 0 0 . . . . 0 0 . . . . 
. . . . . 0 . . . . 0 . . . . . 
. . . . . . 0 0 0 0 . . . . . . 
. . . . . . . 0 0 . . . . . . . 
 with color red at (8,8)
  _01: rectangle with size (7,8) with mask 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 . . . . . 
0 0 0 . . . . . 
0 0 0 . . . . . 
 with color brown at (11,5)
  _011: rectangle with size (20,9) with mask 
. . . . . . 0 . . 
. . . . . . . 0 0 
. . . . . . . 0 . 
. . . . . . 0 . . 
. . . . . 0 . . . 
. . . . 0 . . . . 
. . . 0 . . . . . 
. . 0 . . . . . . 
. 0 . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
. 0 . . . . . . . 
. . 0 . . . . . . 
. . . 0 . . . . . 
. . . . 0 . . . . 
. . . . . 0 . . . 
. . . . . . 0 . . 
. . . . . . . 0 . 
. . . . . . . 0 0 
. . . . . . 0 . . 
 with color red at (6,0)
  _0111: rectangle with size (14,18) with mask 
. . . 0 0 . . . . . . . . . . . . . 
. . 0 . . 0 . . . . . . . . . . . . 
. 0 . . . . 0 . . . . . . . . . . . 
0 . . . . . . 0 . . . . . . . . . . 
. . . . . . . . 0 . . . . . . . . . 
. . . . . . . . . 0 . . . . . . . . 
. . . . . . . . . . 0 . . 0 . . . . 
. . . . . . . . . . . 0 0 . . . . . 
. . . . . . . . . . . . 0 . . . . . 
. . . . . . . . . . . . . 0 . . . . 
. . . . . . . . . . . . . . 0 . . . 
. . . . . . . . . . . . . . . 0 . . 
. . . . . . . . . . . . . . . . 0 . 
. . . . . . . . . . . . . . . . . 0 
 with color red at (0,12)
  _01111: rectangle with size (12,12) with mask 
. . . . . . . . . . . 0 
. . . . . . . . . . 0 . 
. . . . . . . . . 0 . . 
. . . . . . . . 0 . . . 
. . . . . . . 0 . . . . 
. . . . . . 0 . . . . . 
. . . . . 0 0 . . . . . 
. . . . 0 . . 0 . . . . 
. . . 0 . . . . . . . . 
. . 0 . . . . . . . . . 
. 0 . . . . . . . . . . 
0 . . . . . . . . . . . 
 with color red at (18,18)
  _011111: rectangle with size (7,2) with model Full with color brown at (23,9)
  + 365 delta pixels
diff: 
! size mismatch, 10x10 instead of 30x30

TRAIN 3631a71a.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (9,7) with mask 
0 0 0 0 0 . . 
0 0 0 0 0 . . 
0 0 0 0 0 . . 
0 0 0 0 0 . . 
0 0 0 0 0 0 0 
. . 0 0 0 0 0 
. . 0 0 0 0 0 
. . 0 0 0 0 0 
. . 0 0 0 0 0 
 with color brown at (3,20)
  _01: rectangle with size (3,7) with model Full with color brown at (2,0)
  _011: rectangle with size (12,12) with mask 
. . . . . . . . . . . 0 
. . . . . . . . . . 0 0 
. . . . . . . . . 0 . . 
. . . . . . . . 0 0 . . 
. . . . . . . 0 . . . . 
. . . . . . 0 0 . . . . 
. . . . . 0 . . . . . . 
. . . . 0 0 . . . . . . 
. . . 0 . . . . . . . . 
. . 0 0 . . . . . . . . 
. 0 . . . . . . . . . . 
0 0 . . . . . . . . . . 
 with color pink at (0,0)
  _0111: rectangle with size (12,6) with mask 
. . . . . 0 
. . . . 0 . 
. . 0 0 . . 
. . 0 0 . . 
. 0 . . . . 
0 . . . . . 
0 . . . . . 
. 0 . . . . 
. . 0 0 . . 
. . 0 0 . . 
. . . . 0 . 
. . . . . 0 
 with color pink at (10,2)
  _01111: rectangle with size (10,10) with mask 
0 0 . . . . . . . . 
. 0 . . . . . . . . 
. . 0 0 . . . . . . 
. . . 0 . . . . . . 
. . . . 0 0 . . . . 
. . . . . 0 . . . . 
. . . . . . 0 0 . . 
. . . . . . . 0 . . 
. . . . . . . . 0 0 
. . . . . . . . . 0 
 with color pink at (20,0)
  _011111: rectangle with size (2,7) with model Full with color brown at (27,18)
  + 343 delta pixels
diff: 
! size mismatch, 10x10 instead of 30x30

TEST 3631a71a.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 61.9 sec (61.9 sec/task)
bits-train-error = 607655.9 bits (607655.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-326] Checking task 363442ee.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 140754.1 = 140756.4
DL output with Mo: L = 2.3 + 140754.1 = 140756.4
DL input+output M: L = 4.6 + 281508.1 = 281512.8

# learning a model for train pairs
2.000	
1.196	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.686	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.612	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.543	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.472	OUT ADD ^.layer_00 = ^.layer_0
0.420	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.390	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.363	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.338	OUT ADD ^.layer_001 = ^.layer_01.shape at (?,?)
0.312	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.306	IN  ADD ^.layer_010 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.289	OUT ADD ^.layer_000 = ^.layer_010
0.277	OUT ADD ^.layer_010 = ^.layer_010.shape at (?,?)
0.272	IN  SPE ^.layer_0.shape.mask = 
0 
0 
0 
0 
0 
0 
0 
0 
0 

0.264	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.260	OUT SPE ^.size = ^.size
0.256	OUT SPE ^.layer_0.pos.i = ^.layer_011.pos.i + 1
0.254	OUT SPE ^.layer_011.shape.mask.size.j = ^.layer_011.shape.mask.size.j * '3
0.252	OUT SPE ^.layer_0111.shape.mask = scaleTo(^.layer_011.shape.mask, min(^.layer_01.shape.mask.size, ^.layer_010.shape.mask.size) + (0, 3))
0.251	IN  SPE ^.layer_0.shape.color = grey
0.250	OUT SPE ^.layer_0.shape.color = ^.layer_01.shape.color
0.249	OUT SPE ^.layer_010.pos.i = ^.layer_010.pos.j * '3
0.248	OUT SPE ^.layer_01.shape.mask.size.i = area(^.layer_010.shape) - ^.layer_0.pos.i - ^.layer_011.pos.i
0.247	OUT SPE ^.layer_01.pos.i = bottom(^.layer_010) + area(^.layer_01.shape)
0.246	OUT SPE ^.layer_010.pos.j = span(^.layer_01.pos.i, ^.layer_011.pos.i) + area(^.layer_01.shape)
0.169	
0.169	IN  GEN ^.layer_0.shape.color = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _000: ^.layer_010
  _00: ^.layer_0
  _001: ^.layer_01.shape at (?,?)
  _0: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at (^.layer_011.pos.i + 1,?)
  _010: ^.layer_010.shape at (^.layer_010.pos.j * '3,span(^.layer_01.pos.i, ^.layer_011.pos.i) + area(^.layer_01.shape))
  _01: rectangle with size (area(^.layer_010.shape) - ^.layer_0.pos.i - ^.layer_011.pos.i,?) with model ? with color ? at (bottom(^.layer_010) + area(^.layer_01.shape),?)
  _011: rectangle with size (?,^.layer_011.shape.mask.size.j * '3) with model ? with color ? at (?,?)
  _0111: scaleTo(^.layer_011.shape.mask, min(^.layer_01.shape.mask.size, ^.layer_010.shape.mask.size) + (0, 3)) with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 129.1 + 10789.1 = 10918.1
DL output with Mo: L = 484.0 + 23185.2 = 23669.2
DL input+output M: L = 613.0 + 33974.3 = 34587.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _000: ^.layer_010
  _00: ^.layer_0
  _001: ^.layer_01.shape at (?,?)
  _0: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at (^.layer_011.pos.i + 1,?)
  _010: ^.layer_010.shape at (^.layer_010.pos.j * '3,span(^.layer_01.pos.i, ^.layer_011.pos.i) + area(^.layer_01.shape))
  _01: rectangle with size (area(^.layer_010.shape) - ^.layer_0.pos.i - ^.layer_011.pos.i,?) with model ? with color ? at (bottom(^.layer_010) + area(^.layer_01.shape),?)
  _011: rectangle with size (?,^.layer_011.shape.mask.size.j * '3) with model ? with color ? at (?,?)
  _0111: scaleTo(^.layer_011.shape.mask, min(^.layer_01.shape.mask.size, ^.layer_010.shape.mask.size) + (0, 3)) with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 31.7 = 157.5
DL output with Mo: L = 484.0 + 23185.2 = 23669.2
DL input+output M: L = 609.7 + 23216.9 = 23826.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,13) and color black and layers
  _0: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (0,3)
  _010: rectangle with size (2,3) with mask 
. 0 0 
0 . 0 
 with color red at (0,0)
  _01: rectangle with size (1,2) with model Full with color yellow at (2,1)
  _011: rectangle with size (2,2) with model Full with color pink at (1,0)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (9,13) and color black and layers
  _000: 
. 2 2 
2 . 2 
 at (0,0)
  _00: 
5#
5#
5#
5#
5#
5#
5#
5#
5#
 at (0,3)
  _001: 
4 4 
 at (5,8)
  _0: rectangle with size (1,6) with model Full with color yellow at (2,1)
  _010: 
. 2 2 
2 . 2 
 at (0,4)
  _01: rectangle with size (5,3) with model Full with color red at (3,7)
  _011: rectangle with size (2,6) with model Full with color pink at (1,0)
  _0111: 
0 0 0 0 0 
 with color yellow at (0,0)
  + 9 delta pixels
diff: 
   (462.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,13) and color black and layers
  _0: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (0,3)
  _010: rectangle with size (2,3) with mask 
. 0 0 
0 . 0 
 with color red at (0,0)
  _01: rectangle with size (1,2) with model Full with color yellow at (2,1)
  _011: rectangle with size (2,2) with model Full with color pink at (1,0)
  + 4 delta pixels
diff: 
! 36 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,13) and color black and layers
  _0: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (0,3)
  _010: rectangle with size (2,3) with mask 
. 0 0 
0 . 0 
 with color red at (0,0)
  _01: rectangle with size (2,2) with model Odd Checkboard with color pink at (1,0)
  _011: rectangle with size (1,2) with model Full with color yellow at (2,1)
  + 4 delta pixels
diff: 
! 40 wrong pixels (generated / expected)

TRAIN 363442ee.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,13) and color black and layers
  _0: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (0,3)
  _010: rectangle with size (2,1) with model Full with color red at (0,0)
  _01: rectangle with size (3,3) with mask 
. . 0 
. 0 0 
0 . . 
 with color green at (0,0)
  _011: rectangle with size (1,2) with model Full with color orange at (2,1)
  + 6 delta pixels
diff: 
   (3.2 bits)
data: a background with size (9,13) and color black and layers
  _000: 
2 
2 
 at (0,0)
  _00: 
5#
5#
5#
5#
5#
5#
5#
5#
5#
 at (0,3)
  _001: 
. . 3 
. 3 3 
3 . . 
 at (0,0)
  _0: rectangle with size (6,9) with mask 
. . . . . . . . 0 
. . . . . . . 0 0 
. . . . . . 0 . . 
. . 0 . . 0 . . . 
. 0 0 . 0 0 . . . 
0 . . 0 . . . . . 
 with color green at (3,4)
  _010: 
2 
2 
 at (0,7)
  _01: rectangle with size (4,2) with model Full with color orange at (5,5)
  _011: rectangle with size (6,6) with mask 
. . . . . 0 
. . . . 0 0 
. . . 0 . . 
. . 0 . . . 
. 0 0 . . . 
0 . . . . . 
 with color green at (0,4)
  _0111: 
0 0 0 0 
0 0 0 0 
 with color red at (6,4)
  + 17 delta pixels
diff: 
   (859.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,13) and color black and layers
  _0: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (0,3)
  _010: rectangle with size (3,3) with mask 
. . 0 
. 0 0 
0 . . 
 with color green at (0,0)
  _01: rectangle with size (2,1) with model Full with color red at (0,0)
  _011: rectangle with size (1,2) with model Full with color orange at (2,1)
  + 6 delta pixels
diff: 
! 66 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,13) and color black and layers
  _0: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (0,3)
  _010: rectangle with size (3,3) with mask 
. . 0 
. 0 0 
0 . . 
 with color green at (0,0)
  _01: rectangle with size (1,2) with model Full with color orange at (2,1)
  _011: rectangle with size (2,1) with model Full with color red at (0,0)
  + 6 delta pixels
diff: 
! 59 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,13) and color black and layers
  _0: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (0,3)
  _010: rectangle with size (2,1) with model Full with color red at (0,0)
  _01: rectangle with size (3,3) with mask 
. . 0 
. 0 0 
0 . . 
 with color green at (0,0)
  _011: rectangle with size (1,2) with model Full with color orange at (2,1)
  + 6 delta pixels
diff: 
! 62 wrong pixels (generated / expected)

TRAIN 363442ee.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (9,13) and color black and layers
  _0: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (0,3)
  _010: rectangle with size (2,1) with model Full with color cyan at (0,1)
  _01: rectangle with size (2,3) with model Full with color brown at (1,0)
  _011: rectangle with size (1,1) with model Full with color green at (0,0)
  + 7 delta pixels
diff: 
   (0.0 bits)
data: a background with size (9,13) and color black and layers
  _000: 
8 
8 
 at (0,1)
  _00: 
5#
5#
5#
5#
5#
5#
5#
5#
5#
 at (0,3)
  _001: 
9#9#9#
9#9#9#
 at (1,10)
  _0: rectangle with size (2,7) with model Full with color brown at (1,0)
  _010: 
8 
8 
 at (3,8)
  _01: rectangle with size (2,6) with mask 
0 . . 0 . . 
0 0 0 0 0 0 
 with color brown at (7,7)
  _011: rectangle with size (2,3) with model Full with color brown at (4,7)
  _0111: 
0 0 0 0 
0 0 0 0 
 with color cyan at (6,8)
  + 22 delta pixels
diff: 
   (996.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,13) and color black and layers
  _0: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (0,3)
  _010: rectangle with size (2,1) with model Full with color cyan at (0,1)
  _01: rectangle with size (2,3) with model Full with color brown at (1,0)
  _011: rectangle with size (1,1) with model Full with color green at (0,0)
  + 7 delta pixels
diff: 
! 51 wrong pixels (generated / expected)

TRAIN 363442ee.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,13) and color black and layers
  _0: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (0,3)
  _010: rectangle with size (2,1) with model Full with color cyan at (1,0)
  _01: rectangle with size (1,2) with model Full with color green at (0,0)
  _011: rectangle with size (1,2) with model Full with color yellow at (1,1)
  + 9 delta pixels
diff: 
! 71 wrong pixels (generated / expected)

TEST 363442ee.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.3 sec (59.3 sec/task)
bits-train-error = 23185.2 bits (23185.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-325] Checking task 36d67576.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 205514.5 = 205516.9
DL output with Mo: L = 2.3 + 205514.5 = 205516.9
DL input+output M: L = 4.6 + 411029.1 = 411033.7

# learning a model for train pairs
2.000	
1.134	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.316	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.292	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.262	OUT ADD ^.layer_0 = ^.layer_0
0.238	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.209	OUT ADD ^.layer_01 = ^.layer_01
0.185	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.155	OUT ADD ^.layer_011 = ^.layer_011
0.150	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.140	OUT ADD ^.layer_0111 = ^.layer_0111
0.132	OUT ADD ^.layer_01111 = ^.layer_0111.shape at (?,?)
0.126	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.123	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.117	OUT ADD ^.layer_011110 = ^.layer_01111
0.113	OUT ADD ^.layer_0111110 = ^.layer_01111.shape at (?,?)
0.110	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.106	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.103	IN  ADD ^.layer_01111111 = point with color ? at (?,?)
0.100	OUT SPE ^.size = ^.size
0.098	OUT SPE ^.layer_011111.shape.mask = applySym(flipDiag1, ^.layer_0111.shape.mask)
0.097	OUT SPE ^.layer_0111110.pos.i = right(^.layer_0)
0.097	IN  SPE ^.layer_0.shape.color = yellow
0.096	IN  SPE ^.layer_01.shape.color = yellow
0.095	IN  SPE ^.layer_011.shape.color = yellow
0.094	OUT SPE ^.layer_011111.shape.color = green
0.093	OUT SPE ^.layer_011111.pos.j = bottom(^.layer_0) - 1
0.093	OUT SPE ^.layer_011111.pos.i = middle(^.layer_0111) + area(^.layer_0111.shape)
0.092	OUT SPE ^.layer_01111.pos.i = middle(^.layer_011111) + area(^.layer_0111.shape)
0.091	OUT SPE ^.layer_0111110.pos.j = right(^.layer_01) - ^.layer_01111111.pos.j - ^.layer_01111.pos.j
0.091	IN  SPE ^.layer_0111.shape.mask.model = Full
0.091	IN  SPE ^.color = black
0.090	OUT SPE ^.color = black
0.051	
0.051	IN  GEN ^.layer_011.shape.color = ?
0.051	IN  GEN ^.layer_01.shape.color = ?
0.051	IN  GEN ^.layer_0.shape.color = ?
0.051	IN  GEN ^.layer_0111.shape.mask.model = ?
0.051	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_01
  _011: ^.layer_011
  _0111: ^.layer_0111
  _011110: ^.layer_01111
  _01111: ^.layer_0111.shape at (middle(^.layer_011111) + area(^.layer_0111.shape),?)
  _0111110: ^.layer_01111.shape at (right(^.layer_0),right(^.layer_01) - ^.layer_01111111.pos.j - ^.layer_01111.pos.j)
  _011111: applySym(flipDiag1, ^.layer_0111.shape.mask) with color green at (middle(^.layer_0111) + area(^.layer_0111.shape),bottom(^.layer_0) - 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color yellow at (?,?)
  _01: rectangle with size (?,?) with model ? with color yellow at (?,?)
  _011: rectangle with size (?,?) with model ? with color yellow at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)

DL input  with Mi: L = 207.1 + 8017.2 = 8224.3
DL output with Mo: L = 277.0 + 10030.2 = 10307.2
DL input+output M: L = 484.1 + 18047.4 = 18531.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_01
  _011: ^.layer_011
  _0111: ^.layer_0111
  _011110: ^.layer_01111
  _01111: ^.layer_0111.shape at (middle(^.layer_011111) + area(^.layer_0111.shape),?)
  _0111110: ^.layer_01111.shape at (right(^.layer_0),right(^.layer_01) - ^.layer_01111111.pos.j - ^.layer_01111.pos.j)
  _011111: applySym(flipDiag1, ^.layer_0111.shape.mask) with color green at (middle(^.layer_0111) + area(^.layer_0111.shape),bottom(^.layer_0) - 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)

DL input  with Mi: L = 196.5 + 0.0 = 196.5
DL output with Mo: L = 277.0 + 10030.2 = 10307.2
DL input+output M: L = 473.5 + 10030.2 = 10503.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: rectangle with size (1,5) with model Full with color yellow at (2,1)
  _01: rectangle with size (5,1) with model Full with color yellow at (2,10)
  _011: rectangle with size (1,5) with model Full with color yellow at (8,3)
  _0111: rectangle with size (1,1) with model Full with color blue at (1,2)
  _01111: point with color blue at (1,4)
  _011111: point with color red at (1,5)
  _0111111: point with color green at (3,1)
  _01111111: point with color green at (3,3)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (13,13) and color black and layers
  _0: 
4 4 4 4 4 
 at (2,1)
  _01: 
4 
4 
4 
4 
4 
 at (2,10)
  _011: 
4 4 4 4 4 
 at (8,3)
  _0111: 
1 
 at (1,2)
  _011110: 
1 
 at (1,4)
  _01111: 
1 
 at (3,11)
  _0111110: 
1 
 at (5,11)
  _011111: 
0 
 with color green at (3,1)
  + 13 delta pixels
diff: 
   (537.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (1,5) with model Full with color yellow at (2,1)
  _01: rectangle with size (5,1) with model Full with color yellow at (2,10)
  _011: rectangle with size (1,5) with model Full with color yellow at (8,3)
  _0111: rectangle with size (1,1) with model Full with color blue at (1,2)
  _01111: point with color blue at (1,4)
  _011111: point with color red at (1,5)
  _0111111: point with color green at (3,1)
  _01111111: point with color green at (3,3)
  + 3 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (1,5) with model Full with color yellow at (2,1)
  _01: rectangle with size (5,1) with model Full with color yellow at (2,10)
  _011: rectangle with size (1,5) with model Full with color yellow at (8,3)
  _0111: rectangle with size (1,1) with model Full with color blue at (1,2)
  _01111: point with color blue at (1,4)
  _011111: point with color red at (1,5)
  _0111111: point with color green at (3,1)
  _01111111: point with color green at (3,5)
  + 3 delta pixels
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (1,5) with model Full with color yellow at (2,1)
  _01: rectangle with size (5,1) with model Full with color yellow at (2,10)
  _011: rectangle with size (1,5) with model Full with color yellow at (8,3)
  _0111: rectangle with size (1,3) with model Full with color blue at (1,2)
  _01111: point with color red at (1,5)
  _011111: point with color green at (3,1)
  _0111111: point with color green at (3,3)
  _01111111: point with color green at (3,5)
  + 3 delta pixels
diff: 
! 21 wrong pixels (generated / expected)

TRAIN 36d67576.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. . 0 
. . 0 
 with color yellow at (2,2)
  _01: rectangle with size (3,3) with mask 
0 0 0 
0 . . 
0 . . 
 with color yellow at (5,9)
  _011: rectangle with size (3,3) with mask 
. . 0 
. . 0 
0 0 0 
 with color yellow at (9,3)
  _0111: rectangle with size (1,4) with model Full with color green at (4,2)
  _01111: point with color red at (1,4)
  _011111: point with color blue at (2,5)
  _0111111: point with color red at (4,9)
  _01111111: point with color red at (11,6)
diff: 
   (0.0 bits)
data: a background with size (13,13) and color black and layers
  _0: 
4 4 4 
. . 4 
. . 4 
 at (2,2)
  _01: 
4 4 4 
4 . . 
4 . . 
 at (5,9)
  _011: 
. . 4 
. . 4 
4 4 4 
 at (9,3)
  _0111: 
3 3 3 3 
 at (4,2)
  _011110: 
2 
 at (1,4)
  _01111: 
3 3 3 3 
 at (7,8)
  _0111110: 
2 
 at (4,9)
  _011111: 
0 
0 
0 
0 
 with color green at (9,3)
  + 4 delta pixels
diff: 
   (171.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. . 0 
. . 0 
 with color yellow at (2,2)
  _01: rectangle with size (3,3) with mask 
0 0 0 
0 . . 
0 . . 
 with color yellow at (5,9)
  _011: rectangle with size (3,3) with mask 
. . 0 
. . 0 
0 0 0 
 with color yellow at (9,3)
  _0111: rectangle with size (1,4) with model Full with color green at (4,2)
  _01111: point with color red at (1,4)
  _011111: point with color blue at (2,5)
  _0111111: point with color red at (4,9)
  _01111111: point with color red at (11,6)
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. . 0 
. . 0 
 with color yellow at (2,2)
  _01: rectangle with size (3,3) with mask 
0 0 0 
0 . . 
0 . . 
 with color yellow at (5,9)
  _011: rectangle with size (3,3) with mask 
. . 0 
. . 0 
0 0 0 
 with color yellow at (9,3)
  _0111: rectangle with size (1,4) with model Full with color green at (4,2)
  _01111: point with color red at (1,4)
  _011111: point with color blue at (2,5)
  _0111111: point with color red at (11,6)
  _01111111: point with color red at (4,9)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. . 0 
. . 0 
 with color yellow at (2,2)
  _01: rectangle with size (3,3) with mask 
0 0 0 
0 . . 
0 . . 
 with color yellow at (5,9)
  _011: rectangle with size (3,3) with mask 
. . 0 
. . 0 
0 0 0 
 with color yellow at (9,3)
  _0111: rectangle with size (1,4) with model Full with color green at (4,2)
  _01111: point with color red at (1,4)
  _011111: point with color red at (4,9)
  _0111111: point with color blue at (2,5)
  _01111111: point with color red at (11,6)
diff: 
! 10 wrong pixels (generated / expected)

TRAIN 36d67576.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with model +-cross with color yellow at (1,2)
  _01: rectangle with size (3,3) with model +-cross with color yellow at (5,7)
  _011: rectangle with size (3,3) with model +-cross with color yellow at (9,3)
  _0111: rectangle with size (1,1) with model Full with color red at (1,4)
  _01111: point with color blue at (2,1)
  _011111: point with color green at (3,2)
  _0111111: point with color blue at (4,3)
  _01111111: point with color red at (5,7)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (13,13) and color black and layers
  _0: 
. 4 . 
4 4 4 
. 4 . 
 at (1,2)
  _01: 
. 4 . 
4 4 4 
. 4 . 
 at (5,7)
  _011: 
. 4 . 
4 4 4 
. 4 . 
 at (9,3)
  _0111: 
2 
 at (1,4)
  _011110: 
1 
 at (2,1)
  _01111: 
2 
 at (5,7)
  _0111110: 
1 
 at (4,3)
  _011111: 
0 
 with color green at (3,2)
  + 7 delta pixels
diff: 
   (294.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with model +-cross with color yellow at (1,2)
  _01: rectangle with size (3,3) with model +-cross with color yellow at (5,7)
  _011: rectangle with size (3,3) with model +-cross with color yellow at (9,3)
  _0111: rectangle with size (1,1) with model Full with color red at (1,4)
  _01111: point with color blue at (2,1)
  _011111: point with color green at (3,2)
  _0111111: point with color blue at (4,3)
  _01111111: point with color red at (5,7)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with model +-cross with color yellow at (1,2)
  _01: rectangle with size (3,3) with model +-cross with color yellow at (5,7)
  _011: rectangle with size (3,3) with model +-cross with color yellow at (9,3)
  _0111: rectangle with size (1,1) with model Full with color red at (1,4)
  _01111: point with color blue at (2,1)
  _011111: point with color green at (3,2)
  _0111111: point with color blue at (4,3)
  _01111111: point with color red at (11,3)
  + 1 delta pixels
diff: 
! 11 wrong pixels (generated / expected)

TRAIN 36d67576.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,15) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 0 
 with color yellow at (3,2)
  _01: rectangle with size (3,3) with mask 
. 0 0 
0 . 0 
0 0 . 
 with color yellow at (3,10)
  _011: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 0 
 with color yellow at (9,1)
  _0111: rectangle with size (3,3) with mask 
. 0 0 
0 . 0 
0 0 . 
 with color yellow at (9,8)
  _01111: point with color blue at (2,2)
  _011111: point with color green at (2,3)
  _0111111: point with color red at (3,4)
  _01111111: point with color green at (4,5)
  + 4 delta pixels
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,15) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 0 
 with color yellow at (3,2)
  _01: rectangle with size (3,3) with mask 
. 0 0 
0 . 0 
0 0 . 
 with color yellow at (3,10)
  _011: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 0 
 with color yellow at (9,1)
  _0111: rectangle with size (3,3) with mask 
. 0 0 
0 . 0 
0 0 . 
 with color yellow at (9,8)
  _01111: point with color blue at (2,2)
  _011111: point with color green at (2,3)
  _0111111: point with color green at (4,5)
  _01111111: point with color red at (3,4)
  + 4 delta pixels
diff: 
! 21 wrong pixels (generated / expected)

TEST 36d67576.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 26.2 sec (26.2 sec/task)
bits-train-error = 10030.2 bits (10030.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-324] Checking task 36fdfd69.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 310369.1 = 310371.4
DL output with Mo: L = 2.3 + 310369.1 = 310371.4
DL input+output M: L = 4.6 + 620738.1 = 620742.8

# learning a model for train pairs
2.000	
1.482	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.973	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.677	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.436	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.387	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.340	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.309	OUT ADD ^.layer_010 = ^.layer_01
0.279	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.252	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.235	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.223	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.110	
0.103	IN  DEL ^.layer_011
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 35103.4 = 35201.5
DL output with Mo: L = 160.7 + 33733.8 = 33894.5
DL input+output M: L = 258.8 + 68837.2 = 69096.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 51.7 = 121.9
DL output with Mo: L = 160.7 + 31538.5 = 31699.2
DL input+output M: L = 230.9 + 31590.2 = 31821.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (17,18) and color blue and layers
  _0: rectangle with size (17,18) with mask 
. . . . . . . 0 0 0 0 0 0 . . . . . 
. . . . . . . . . 0 0 . 0 . . . . . 
. . . . . . . . . 0 . . . 0 0 . . . 
. 0 . . . . . . . 0 . 0 0 0 . . . . 
0 . . . 0 0 . . . 0 0 0 . 0 . . 0 0 
. 0 . 0 0 . . 0 0 0 . . . . 0 0 0 0 
. 0 . 0 0 0 . 0 . 0 0 0 0 0 . . 0 . 
0 0 0 . 0 0 . 0 0 0 . 0 0 0 . . . 0 
0 . 0 . . 0 0 0 0 . 0 0 0 0 . . . . 
0 0 0 0 0 . 0 0 0 0 0 0 0 0 . . 0 0 
0 . . 0 . . . . . . . . 0 . 0 0 0 0 
0 0 0 0 0 0 . . . . . 0 0 . . 0 0 . 
0 0 0 0 0 . . . . . . 0 0 . 0 . . . 
0 . 0 0 0 0 0 0 . . 0 . 0 . . . . . 
0 0 . 0 0 0 . 0 0 . 0 0 0 0 0 . . . 
0 0 0 0 0 0 . . . 0 . 0 . 0 0 . . . 
. 0 0 . 0 0 . . . 0 . . 0 0 0 0 0 . 
 with color black at (0,0)
  _01: rectangle with size (3,7) with mask 
0 . . . . . . 
. 0 . 0 0 0 0 
0 . 0 0 0 0 0 
 with color red at (1,2)
  + 22 delta pixels
diff: 
   (0.0 bits)
data: a background with size (17,18) and color blue and layers
  _0: rectangle with size (17,18) with mask 
. . . . . . . 0 0 0 0 0 0 . . . . . 
. . . . . . . . . 0 0 . 0 . . . . . 
. . . . . . . . . 0 . . . 0 0 . . . 
. 0 . . . . . . . 0 . 0 0 0 . . . . 
0 . . . 0 0 . . . 0 0 0 . 0 . . 0 0 
. 0 . 0 0 . . 0 0 0 . . . . 0 0 0 0 
. 0 . 0 0 0 . 0 . 0 0 0 0 0 . . 0 . 
0 0 0 . 0 0 . 0 0 0 . 0 0 0 . . . 0 
0 . 0 . . 0 0 0 0 . 0 0 0 0 . . . . 
0 0 0 0 0 . 0 0 0 0 0 0 0 0 . . 0 0 
0 . . 0 . . . . . . . . 0 . 0 0 0 0 
0 0 0 0 0 0 . . . . . 0 0 . . 0 0 . 
0 0 0 0 0 . . . . . . 0 0 . 0 . . . 
0 . 0 0 0 0 0 0 . . 0 . 0 . . . . . 
0 0 . 0 0 0 . 0 0 . 0 0 0 0 0 . . . 
0 0 0 0 0 0 . . . 0 . 0 . 0 0 . . . 
. 0 0 . 0 0 . . . 0 . . 0 0 0 0 0 . 
 with color black at (0,0)
  _010: 
2 . . . . . . 
. 2 . 2 2 2 2 
2 . 2 2 2 2 2 
 at (1,2)
  _01: rectangle with size (3,7) with model Full with color yellow at (1,2)
  _011: rectangle with size (3,5) with model Full with color yellow at (10,6)
  _0111: rectangle with size (3,4) with mask 
0 0 0 . 
. . 0 0 
. . . 0 
 with color black at (0,14)
  _01111: rectangle with size (1,4) with model Full with color black at (0,1)
  + 13 delta pixels
diff: 
   (1078.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,18) and color blue and layers
  _0: rectangle with size (17,18) with mask 
. . . . . . . 0 0 0 0 0 0 . . . . . 
. . . . . . . . . 0 0 . 0 . . . . . 
. . . . . . . . . 0 . . . 0 0 . . . 
. 0 . . . . . . . 0 . 0 0 0 . . . . 
0 . . . 0 0 . . . 0 0 0 . 0 . . 0 0 
. 0 . 0 0 . . 0 0 0 . . . . 0 0 0 0 
. 0 . 0 0 0 . 0 . 0 0 0 0 0 . . 0 . 
0 0 0 . 0 0 . 0 0 0 . 0 0 0 . . . 0 
0 . 0 . . 0 0 0 0 . 0 0 0 0 . . . . 
0 0 0 0 0 . 0 0 0 0 0 0 0 0 . . 0 0 
0 . . 0 . . . . . . . . 0 . 0 0 0 0 
0 0 0 0 0 0 . . . . . 0 0 . . 0 0 . 
0 0 0 0 0 . . . . . . 0 0 . 0 . . . 
0 . 0 0 0 0 0 0 . . 0 . 0 . . . . . 
0 0 . 0 0 0 . 0 0 . 0 0 0 0 0 . . . 
0 0 0 0 0 0 . . . 0 . 0 . 0 0 . . . 
. 0 0 . 0 0 . . . 0 . . 0 0 0 0 0 . 
 with color black at (0,0)
  _01: rectangle with size (3,7) with mask 
0 . . . . . . 
. 0 . 0 0 0 0 
0 . 0 0 0 0 0 
 with color red at (1,2)
  + 22 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x18
>> Trial 2
data: a background with size (17,18) and color blue and layers
  _0: rectangle with size (17,18) with mask 
. . . . . . . 0 0 0 0 0 0 . . . . . 
. . . . . . . . . 0 0 . 0 . . . . . 
. . . . . . . . . 0 . . . 0 0 . . . 
. 0 . . . . . . . 0 . 0 0 0 . . . . 
0 . . . 0 0 . . . 0 0 0 . 0 . . 0 0 
. 0 . 0 0 . . 0 0 0 . . . . 0 0 0 0 
. 0 . 0 0 0 . 0 . 0 0 0 0 0 . . 0 . 
0 0 0 . 0 0 . 0 0 0 . 0 0 0 . . . 0 
0 . 0 . . 0 0 0 0 . 0 0 0 0 . . . . 
0 0 0 0 0 . 0 0 0 0 0 0 0 0 . . 0 0 
0 . . 0 . . . . . . . . 0 . 0 0 0 0 
0 0 0 0 0 0 . . . . . 0 0 . . 0 0 . 
0 0 0 0 0 . . . . . . 0 0 . 0 . . . 
0 . 0 0 0 0 0 0 . . 0 . 0 . . . . . 
0 0 . 0 0 0 . 0 0 . 0 0 0 0 0 . . . 
0 0 0 0 0 0 . . . 0 . 0 . 0 0 . . . 
. 0 0 . 0 0 . . . 0 . . 0 0 0 0 0 . 
 with color black at (0,0)
  _01: rectangle with size (2,4) with model Full with color red at (2,5)
  + 26 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x18

TRAIN 36fdfd69.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (15,16) and color cyan and layers
  _0: rectangle with size (5,4) with mask 
. 0 0 0 
0 . 0 0 
0 . 0 . 
. . . 0 
. . . 0 
 with color black at (0,12)
  _01: rectangle with size (15,16) with mask 
. 0 0 0 0 . 0 0 . . . . . . . . 
0 . 0 0 0 0 0 0 0 . . . . . . . 
0 0 . . . 0 . . . . . . . . . . 
0 0 . . . 0 0 0 0 . 0 . . . . . 
0 0 . . . . . . 0 0 0 . . . . . 
. 0 . . . . . . 0 0 0 . 0 0 . . 
. 0 0 . . 0 . . . . 0 . . 0 0 0 
. 0 . 0 . 0 . 0 . . 0 . . . 0 . 
. 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 
. 0 . . . . . . 0 . 0 0 0 . . . 
. 0 . . . . . . 0 . 0 0 . . . . 
0 . 0 0 0 . . 0 0 . . . 0 . . . 
. 0 0 . . . . 0 0 . . . 0 0 0 . 
0 . . 0 . . . 0 0 0 . 0 . . . . 
. . . 0 . . . 0 0 0 . . . . . . 
 with color black at (0,0)
  + 19 delta pixels
diff: 
   (2.0 bits)
data: a background with size (15,16) and color cyan and layers
  _0: rectangle with size (5,4) with mask 
. 0 0 0 
0 . 0 0 
0 . 0 . 
. . . 0 
. . . 0 
 with color black at (0,12)
  _010: 
. 0 0 0 0 . 0 0 . . . . . . . . 
0 . 0 0 0 0 0 0 0 . . . . . . . 
0 0 . . . 0 . . . . . . . . . . 
0 0 . . . 0 0 0 0 . 0 . . . . . 
0 0 . . . . . . 0 0 0 . . . . . 
. 0 . . . . . . 0 0 0 . 0 0 . . 
. 0 0 . . 0 . . . . 0 . . 0 0 0 
. 0 . 0 . 0 . 0 . . 0 . . . 0 . 
. 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 
. 0 . . . . . . 0 . 0 0 0 . . . 
. 0 . . . . . . 0 . 0 0 . . . . 
0 . 0 0 0 . . 0 0 . . . 0 . . . 
. 0 0 . . . . 0 0 . . . 0 0 0 . 
0 . . 0 . . . 0 0 0 . 0 . . . . 
. . . 0 . . . 0 0 0 . . . . . . 
 at (0,0)
  _01: rectangle with size (2,5) with model Full with color red at (4,2)
  _011: rectangle with size (2,4) with model Full with color yellow at (9,2)
  _0111: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color yellow at (3,11)
  _01111: rectangle with size (2,2) with model Full with color yellow at (11,10)
  + 17 delta pixels
diff: 
   (922.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,16) and color cyan and layers
  _0: rectangle with size (15,16) with mask 
. 0 0 0 0 . 0 0 . . . . . . . . 
0 . 0 0 0 0 0 0 0 . . . . . . . 
0 0 . . . 0 . . . . . . . . . . 
0 0 . . . 0 0 0 0 . 0 . . . . . 
0 0 . . . . . . 0 0 0 . . . . . 
. 0 . . . . . . 0 0 0 . 0 0 . . 
. 0 0 . . 0 . . . . 0 . . 0 0 0 
. 0 . 0 . 0 . 0 . . 0 . . . 0 . 
. 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 
. 0 . . . . . . 0 . 0 0 0 . . . 
. 0 . . . . . . 0 . 0 0 . . . . 
0 . 0 0 0 . . 0 0 . . . 0 . . . 
. 0 0 . . . . 0 0 . . . 0 0 0 . 
0 . . 0 . . . 0 0 0 . 0 . . . . 
. . . 0 . . . 0 0 0 . . . . . . 
 with color black at (0,0)
  _01: rectangle with size (5,4) with mask 
. 0 0 0 
0 . 0 0 
0 . 0 . 
. . . 0 
. . . 0 
 with color black at (0,12)
  + 19 delta pixels
diff: 
! size mismatch, 10x10 instead of 15x16

TRAIN 36fdfd69.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (15,14) and color black and layers
  _0: rectangle with size (15,9) with mask 
. . 0 . 0 0 . . . 
0 0 . 0 . . . . . 
. . 0 0 0 . . . . 
. . 0 0 0 . . . . 
. . 0 . . . . . . 
0 0 . . . . . . . 
. 0 . . . . . . . 
0 0 . . . . . . 0 
0 0 . . . . . 0 0 
0 0 . . . . . 0 . 
. . 0 0 . . . 0 . 
. . . 0 0 . 0 . 0 
. . . 0 . 0 0 . 0 
. . . 0 . . . . . 
. . . . 0 0 . . . 
 with color green at (0,5)
  _01: rectangle with size (3,5) with model Full with color red at (4,3)
  + 45 delta pixels
diff: 
   (3.2 bits)
data: a background with size (15,14) and color black and layers
  _0: rectangle with size (8,9) with mask 
0 0 . . . . . . 0 
0 0 . . . . . 0 0 
0 0 . . . . . 0 . 
. . 0 0 . . . 0 . 
. . . 0 0 . 0 . 0 
. . . 0 . 0 0 . 0 
. . . 0 . . . . . 
. . . . 0 0 . . . 
 with color green at (7,5)
  _010: 
2 2 2 2 2 
2 2 2 2 2 
2 2 2 2 2 
 at (4,3)
  _01: rectangle with size (7,7) with mask 
. . 0 0 . . . 
0 0 . . . . . 
. 0 . . . . . 
. 0 0 . 0 0 . 
. . 0 . 0 0 . 
. 0 0 . 0 . 0 
0 . . 0 . . . 
 with color green at (8,0)
  _011: rectangle with size (4,6) with mask 
. . 0 . 0 0 
0 0 . 0 . . 
. . 0 0 0 . 
. . 0 0 0 . 
 with color green at (0,5)
  _0111: rectangle with size (4,4) with mask 
. . 0 0 
. 0 . 0 
. 0 0 . 
0 . . . 
 with color green at (3,10)
  _01111: rectangle with size (3,4) with mask 
0 0 . . 
. . 0 . 
. . 0 0 
 with color green at (0,0)
  + 19 delta pixels
diff: 
   (1153.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,14) and color black and layers
  _0: rectangle with size (15,9) with mask 
. . 0 . 0 0 . . . 
0 0 . 0 . . . . . 
. . 0 0 0 . . . . 
. . 0 0 0 . . . . 
. . 0 . . . . . . 
0 0 . . . . . . . 
. 0 . . . . . . . 
0 0 . . . . . . 0 
0 0 . . . . . 0 0 
0 0 . . . . . 0 . 
. . 0 0 . . . 0 . 
. . . 0 0 . 0 . 0 
. . . 0 . 0 0 . 0 
. . . 0 . . . . . 
. . . . 0 0 . . . 
 with color green at (0,5)
  _01: rectangle with size (7,7) with mask 
. . 0 0 . . . 
0 0 0 . . . . 
. 0 . 0 . . . 
. 0 0 . 0 0 . 
. . 0 . 0 0 . 
. 0 0 . 0 . 0 
0 . . 0 . . . 
 with color green at (8,0)
  + 36 delta pixels
diff: 
! size mismatch, 10x10 instead of 15x14
>> Trial 2
data: a background with size (15,14) and color black and layers
  _0: rectangle with size (7,7) with mask 
. . 0 0 . . . 
0 0 0 . . . . 
. 0 . 0 . . . 
. 0 0 . 0 0 . 
. . 0 . 0 0 . 
. 0 0 . 0 . 0 
0 . . 0 . . . 
 with color green at (8,0)
  _01: rectangle with size (15,9) with mask 
. . 0 . 0 0 . . . 
0 0 . 0 . . . . . 
. . 0 0 0 . . . . 
. . 0 0 0 . . . . 
. . 0 . . . . . . 
0 0 . . . . . . . 
. 0 . . . . . . . 
0 0 . . . . . . 0 
0 0 . . . . . 0 0 
0 0 . . . . . 0 . 
. . 0 0 . . . 0 . 
. . . 0 0 . 0 . 0 
. . . 0 . 0 0 . 0 
. . . 0 . . . . . 
. . . . 0 0 . . . 
 with color green at (0,5)
  + 36 delta pixels
diff: 
! size mismatch, 10x10 instead of 15x14
>> Trial 3
data: a background with size (15,14) and color black and layers
  _0: rectangle with size (15,9) with mask 
. . 0 . 0 0 . . . 
0 0 . 0 . . . . . 
. . 0 0 0 . . . . 
. . 0 0 0 . . . . 
. . 0 . . . . . . 
0 0 . . . . . . . 
. 0 . . . . . . . 
0 0 . . . . . . 0 
0 0 . . . . . 0 0 
0 0 . . . . . 0 . 
. . 0 0 . . . 0 . 
. . . 0 0 . 0 . 0 
. . . 0 . 0 0 . 0 
. . . 0 . . . . . 
. . . . 0 0 . . . 
 with color green at (0,5)
  _01: rectangle with size (3,5) with model Full with color red at (4,3)
  + 45 delta pixels
diff: 
! size mismatch, 10x10 instead of 15x14

TRAIN 36fdfd69.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,18) and color black and layers
  _0: rectangle with size (17,18) with mask 
. . . . . . . . 0 0 . . . . . . . . 
. . . . . . . . . 0 . . 0 . . . . . 
. . . . . . . . 0 0 0 . . 0 . . 0 . 
. . . . . . . . . 0 0 0 0 0 0 . 0 . 
. . . . . . 0 . 0 0 . 0 . . 0 0 0 0 
. . . . . 0 . 0 . . 0 . . 0 . . . . 
. . . . . 0 . . . . 0 . 0 0 . . . . 
. . 0 0 . 0 . . 0 . 0 0 . 0 0 0 . . 
. . . 0 . . . 0 0 0 0 0 . 0 . . . . 
0 0 . 0 . 0 . 0 0 . . 0 0 . . . . . 
. 0 0 . 0 . 0 . 0 . . 0 . . . . . . 
. 0 0 . . 0 . 0 0 0 . . . . . . . . 
0 . 0 0 . 0 0 0 . . 0 . . . . . . . 
0 0 0 0 0 0 . . . . 0 . . . . . . . 
. 0 0 0 0 0 0 . 0 . . . . . . . . . 
. 0 . 0 . . 0 0 . 0 . . . . . . . . 
0 . . . . . . . . . . . . . . . . . 
 with color brown at (0,0)
  _01: rectangle with size (8,6) with mask 
. . . . . 0 
. . 0 0 0 0 
. 0 0 0 . 0 
. . 0 0 0 . 
. 0 . . 0 . 
0 . 0 0 . 0 
. 0 . . 0 . 
0 . 0 0 0 . 
 with color brown at (9,12)
  + 43 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x18
>> Trial 2
data: a background with size (17,18) and color black and layers
  _0: rectangle with size (8,6) with mask 
. . . . . 0 
. . 0 0 0 0 
. 0 0 0 . 0 
. . 0 0 0 . 
. 0 . . 0 . 
0 . 0 0 . 0 
. 0 . . 0 . 
0 . 0 0 0 . 
 with color brown at (9,12)
  _01: rectangle with size (17,18) with mask 
. . . . . . . . 0 0 . . . . . . . . 
. . . . . . . . . 0 . . 0 . . . . . 
. . . . . . . . 0 0 0 . . 0 . . 0 . 
. . . . . . . . . 0 0 0 0 0 0 . 0 . 
. . . . . . 0 . 0 0 . 0 . . 0 0 0 0 
. . . . . 0 . 0 . . 0 . . 0 . . . . 
. . . . . 0 . . . . 0 . 0 0 . . . . 
. . 0 0 . 0 . . 0 . 0 0 . 0 0 0 . . 
. . . 0 . . . 0 0 0 0 0 . 0 . . . . 
0 0 . 0 . 0 . 0 0 . . 0 0 . . . . . 
. 0 0 . 0 . 0 . 0 . . 0 . . . . . . 
. 0 0 . . 0 . 0 0 0 . . . . . . . . 
0 . 0 0 . 0 0 0 . . 0 . . . . . . . 
0 0 0 0 0 0 . . . . 0 . . . . . . . 
. 0 0 0 0 0 0 . 0 . . . . . . . . . 
. 0 . 0 . . 0 0 . 0 . . . . . . . . 
0 . . . . . . . . . . . . . . . . . 
 with color brown at (0,0)
  + 43 delta pixels
diff: 
! size mismatch, 10x10 instead of 17x18

TEST 36fdfd69.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.7 sec (59.7 sec/task)
bits-train-error = 31538.5 bits (31538.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-323] Checking task 3906de3d.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.312	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.623	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.397	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.173	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.129	OUT ADD ^.layer_01 = ^.layer_0
0.097	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.086	OUT ADD ^.layer_010 = ^.layer_01.shape at (?,?)
0.081	OUT SPE ^.size = ^.size
0.080	IN  SPE ^.layer_0.shape.color = blue
0.078	IN  SPE ^.layer_01.shape.color = red
0.077	OUT SPE ^.layer_010.pos.j = ^.layer_01.pos.j
0.076	OUT SPE ^.layer_010.pos.i = right(^.layer_0) / '3
0.075	IN  SPE ^.layer_01.shape.mask.model = Full
0.074	OUT SPE ^.layer_0.pos.i = span(^.layer_0.pos.j, ^.layer_01.pos.j) - average(^.layer_0.shape.mask.size.j, ^.layer_01.shape.mask.size.j)
0.074	IN  SPE ^.color = black
0.073	OUT SPE ^.color = black
0.019	
0.019	IN  GEN ^.layer_01.shape.color = ?
0.019	IN  GEN ^.layer_0.shape.color = ?
0.019	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (span(^.layer_0.pos.j, ^.layer_01.pos.j) - average(^.layer_0.shape.mask.size.j, ^.layer_01.shape.mask.size.j),?)
  _010: ^.layer_01.shape at (right(^.layer_0) / '3,^.layer_01.pos.j)
  _01: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color blue at (?,?)
  _01: rectangle with size (?,?) with model Full with color red at (?,?)

DL input  with Mi: L = 77.5 + 6453.6 = 6531.1
DL output with Mo: L = 192.1 + 2041.4 = 2233.5
DL input+output M: L = 269.6 + 8495.0 = 8764.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (span(^.layer_0.pos.j, ^.layer_01.pos.j) - average(^.layer_0.shape.mask.size.j, ^.layer_01.shape.mask.size.j),?)
  _010: ^.layer_01.shape at (right(^.layer_0) / '3,^.layer_01.pos.j)
  _01: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 70.7 + 0.0 = 70.7
DL output with Mo: L = 192.1 + 2041.4 = 2233.5
DL input+output M: L = 262.8 + 2041.4 = 2304.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 0 . 0 0 
0 0 . 0 0 
 with color blue at (0,2)
  _01: rectangle with size (3,1) with model Full with color red at (7,4)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,5) with model Full with color blue at (0,2)
  _010: 
2 
2 
2 
 at (2,4)
  _01: 
1 1 1 1 1 
1 1 1 1 1 
1 1 . 1 1 
1 1 . 1 1 
 at (0,2)
diff: 
   (27.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 0 . 0 0 
0 0 . 0 0 
 with color blue at (0,2)
  _01: rectangle with size (3,1) with model Full with color red at (7,4)
diff: 
! 4 wrong pixels (generated / expected)

TRAIN 3906de3d.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,7) with mask 
0 0 0 0 0 0 0 
0 0 . 0 0 0 0 
0 0 . 0 . 0 0 
0 0 . 0 . 0 0 
. . . . . 0 0 
 with color blue at (0,2)
  _01: rectangle with size (4,1) with model Full with color red at (6,6)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (1,4)
  _010: 
2 
2 
2 
2 
 at (2,6)
  _01: 
1 1 1 1 1 1 1 
1 1 . 1 1 1 1 
1 1 . 1 . 1 1 
1 1 . 1 . 1 1 
. . . . . 1 1 
 at (0,2)
diff: 
   (20.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,7) with mask 
0 0 0 0 0 0 0 
0 0 . 0 0 0 0 
0 0 . 0 . 0 0 
0 0 . 0 . 0 0 
. . . . . 0 0 
 with color blue at (0,2)
  _01: rectangle with size (4,1) with model Full with color red at (6,6)
  + 1 delta pixels
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,7) with mask 
0 0 0 0 0 0 0 
0 0 . 0 0 0 0 
0 0 . 0 . 0 0 
0 0 . 0 . 0 0 
. . . . . 0 0 
 with color blue at (0,2)
  _01: rectangle with size (1,1) with model Full with color red at (9,4)
  + 4 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,7) with model Full with color blue at (0,2)
  _01: rectangle with size (4,1) with model Full with color red at (6,6)
  + 11 delta pixels
diff: 
! 11 wrong pixels (generated / expected)

TRAIN 3906de3d.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,9) with mask 
0 0 0 0 0 0 0 0 0 
0 0 . 0 0 0 0 0 0 
0 0 . 0 0 0 0 . 0 
0 0 . . 0 . 0 . 0 
 with color blue at (0,1)
  _01: rectangle with size (4,1) with model Full with color red at (6,6)
  + 8 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,2) with mask 
0 . 
0 . 
0 0 
. 0 
 with color red at (1,3)
  _010: 
2 
2 
2 
2 
 at (3,6)
  _01: 
1 1 1 1 1 1 1 1 1 
1 1 . 1 1 1 1 1 1 
1 1 . 1 1 1 1 . 1 
1 1 . . 1 . 1 . 1 
 at (0,1)
  + 3 delta pixels
diff: 
   (156.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,9) with mask 
0 0 0 0 0 0 0 0 0 
0 0 . 0 0 0 0 0 0 
0 0 . 0 0 0 0 . 0 
0 0 . . 0 . 0 . 0 
 with color blue at (0,1)
  _01: rectangle with size (4,1) with model Full with color red at (6,6)
  + 8 delta pixels
diff: 
! 12 wrong pixels (generated / expected)

TRAIN 3906de3d.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,9) with mask 
0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 0 . 0 
0 . 0 . 0 . 0 . 0 
0 . 0 . . . 0 . 0 
. . 0 . . . . . 0 
 with color blue at (0,1)
  _01: rectangle with size (6,1) with model Full with color red at (4,8)
  + 10 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,9) with mask 
0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 0 . 0 
0 . 0 . 0 . 0 . 0 
0 . 0 . . . 0 . 0 
. . 0 . . . . . 0 
 with color blue at (0,1)
  _01: rectangle with size (4,1) with model Full with color red at (6,5)
  + 12 delta pixels
diff: 
! 16 wrong pixels (generated / expected)

TEST 3906de3d.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 7.0 sec (7.0 sec/task)
bits-train-error = 2041.4 bits (2041.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-322] Checking task 39a8645d.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 239423.3 = 239425.6
DL output with Mo: L = 2.3 + 10534.8 = 10537.1
DL input+output M: L = 4.6 + 249958.1 = 249962.7

# learning a model for train pairs
2.000	
1.138	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.619	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.284	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.248	OUT SPE ^.size = '(3, 3)
0.212	OUT SPE ^.layer_0.shape.mask.size = '(3, 3)
0.190	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.167	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.145	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.123	OUT SPE ^.layer_0.pos = '(0, 0)
0.110	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.099	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.092	OUT SPE ^.color = black
0.091	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.091	IN  SPE ^.color = black
0.046	
0.045	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: rectangle with size '(3, 3) with model ? with color ? at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 181.0 + 10765.8 = 10946.8
DL output with Mo: L = 62.7 + 410.5 = 473.2
DL input+output M: L = 243.7 + 11176.3 = 11420.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: rectangle with size '(3, 3) with model ? with color ? at '(0, 0)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 62.7 + 410.5 = 473.2
DL input+output M: L = 65.0 + 410.5 = 475.5

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 8 0 8 0 0 0 0 0 0 0 0 0 
0 0 0 8 0 0 0 0 0 0 8 0 8 0 
0 0 8 0 8 0 0 0 0 0 0 8 0 0 
0 0 0 0 0 0 0 0 0 0 8 0 8 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 8 0 8 0 0 0 2 0 2 0 0 
0 0 0 0 8 0 0 0 0 2 0 2 0 0 
0 0 0 8 0 8 0 0 0 0 2 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 2 0 2 0 0 0 0 0 0 0 0 0 0 
0 2 0 2 0 0 0 0 0 0 0 0 0 0 
0 0 2 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with model Even Checkboard with color cyan at (0,0)
diff: 
   (12.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 8 0 8 0 0 0 0 0 0 0 0 0 
0 0 0 8 0 0 0 0 0 0 8 0 8 0 
0 0 8 0 8 0 0 0 0 0 0 8 0 0 
0 0 0 0 0 0 0 0 0 0 8 0 8 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 8 0 8 0 0 0 2 0 2 0 0 
0 0 0 0 8 0 0 0 0 2 0 2 0 0 
0 0 0 8 0 8 0 0 0 0 2 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 2 0 2 0 0 0 0 0 0 0 0 0 0 
0 2 0 2 0 0 0 0 0 0 0 0 0 0 
0 0 2 0 0 0 0 0 0 0 0 0 0 0 

diff: 
! 9 wrong pixels (generated / expected)

TRAIN 39a8645d.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 0 0 1 0 1 0 0 0 0 
0 0 4 0 0 0 0 1 1 1 0 0 0 0 
0 0 0 4 4 0 0 0 1 0 0 0 0 0 
0 0 4 0 0 0 0 0 0 0 0 4 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 4 4 
0 0 0 0 0 0 2 0 2 0 0 4 0 0 
0 1 0 1 0 0 0 2 0 0 0 0 0 0 
0 1 1 1 0 0 2 0 2 0 0 0 0 0 
0 0 1 0 0 0 0 0 0 4 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 4 4 0 0 
0 0 4 0 0 0 0 0 0 4 0 0 0 0 
0 0 0 4 4 0 0 0 0 0 0 1 0 1 
0 0 4 0 0 0 0 0 0 0 0 1 1 1 
0 0 0 0 0 0 0 0 0 0 0 0 1 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
. 0 0 
0 . . 
 with color yellow at (0,0)
diff: 
   (16.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 1 0 1 0 0 0 0 
0 0 4 0 0 0 0 1 1 1 0 0 0 0 
0 0 0 4 4 0 0 0 1 0 0 0 0 0 
0 0 4 0 0 0 0 0 0 0 0 4 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 4 4 
0 0 0 0 0 0 2 0 2 0 0 4 0 0 
0 1 0 1 0 0 0 2 0 0 0 0 0 0 
0 1 1 1 0 0 2 0 2 0 0 0 0 0 
0 0 1 0 0 0 0 0 0 4 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 4 4 0 0 
0 0 4 0 0 0 0 0 0 4 0 0 0 0 
0 0 0 4 4 0 0 0 0 0 0 1 0 1 
0 0 4 0 0 0 0 0 0 0 0 1 1 1 
0 0 0 0 0 0 0 0 0 0 0 0 1 0 

diff: 
! 9 wrong pixels (generated / expected)

TRAIN 39a8645d.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 8 0 0 0 0 0 6 6 0 0 0 
0 0 8 8 8 0 0 0 0 6 6 0 0 0 
0 0 0 8 0 0 0 0 0 0 0 6 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 8 0 0 0 0 
0 0 0 0 0 0 0 0 8 8 8 0 0 0 
0 0 0 0 0 0 0 0 0 8 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with model +-cross with color cyan at (0,0)
diff: 
   (12.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 8 0 0 0 0 0 6 6 0 0 0 
0 0 8 8 8 0 0 0 0 6 6 0 0 0 
0 0 0 8 0 0 0 0 0 0 0 6 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 8 0 0 0 0 
0 0 0 0 0 0 0 0 8 8 8 0 0 0 
0 0 0 0 0 0 0 0 0 8 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
! 9 wrong pixels (generated / expected)

TRAIN 39a8645d.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 3 0 3 0 0 0 0 2 0 0 0 
0 0 0 0 3 3 0 0 0 2 2 2 0 0 
0 0 0 3 0 3 0 0 0 2 2 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 8 0 0 0 0 0 0 
0 2 0 0 0 0 8 0 8 0 0 0 0 0 
2 2 2 0 0 0 0 8 0 0 0 0 0 0 
2 2 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 2 0 0 0 3 0 3 0 0 
0 0 0 0 2 2 2 0 0 0 3 3 0 0 
0 0 0 0 2 2 0 0 0 3 0 3 0 0 

diff: 
! 9 wrong pixels (generated / expected)

TEST 39a8645d.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 8.0 sec (8.0 sec/task)
bits-train-error = 410.5 bits (410.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-321] Checking task 39e1d7f9.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 861748.4 = 861750.7
DL output with Mo: L = 2.3 + 861748.4 = 861750.7
DL input+output M: L = 4.6 + 1723496.9 = 1723501.5

# learning a model for train pairs
2.000	
1.497	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.071	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.726	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.379	OUT ADD ^.layer_0 = ^.layer_0
0.338	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.302	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.264	OUT ADD ^.layer_011 = ^.layer_01
0.227	OUT ADD ^.layer_010 = ^.layer_01.shape at (?,?)
0.190	IN  ADD ^.layer_010 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.161	OUT ADD ^.layer_0111 = ^.layer_010.shape at (?,?)
0.141	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.121	OUT ADD ^.layer_0100 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.101	IN  ADD ^.layer_0101 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.092	OUT ADD ^.layer_0101 = ^.layer_010
0.089	IN  ADD ^.layer_0100 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.087	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.047	
0.038	IN  DEL ^.layer_0101
0.037	IN  DEL ^.layer_011
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: ^.layer_0
  _0100: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01.shape at (?,?)
  _0101: ^.layer_010
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: ^.layer_01
  _0111: ^.layer_010.shape at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0100: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0101: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 180.9 + 34955.8 = 35136.7
DL output with Mo: L = 163.3 + 39735.8 = 39899.1
DL input+output M: L = 344.2 + 74691.6 = 75035.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: ^.layer_0
  _0100: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01.shape at (?,?)
  _0101: ^.layer_010
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: ^.layer_01
  _0111: ^.layer_010.shape at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0100: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 0.0 = 125.8
DL output with Mo: L = 163.3 + 31998.7 = 32162.1
DL input+output M: L = 289.1 + 31998.7 = 32287.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (24,24) and color black and layers
  _0: rectangle with size (24,24) with mask 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
 with color cyan at (0,0)
  _0100: rectangle with size (14,4) with model Full with color green at (0,5)
  _010: rectangle with size (4,14) with model Full with color green at (5,0)
  _01: rectangle with size (4,4) with model Full with color pink at (20,15)
  + 16 delta pixels
diff: 
   (0.0 bits)
data: a background with size (24,24) and color black and layers
  _0: 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
 at (0,0)
  _0100: rectangle with size (4,4) with model Full with color green at (0,5)
  _010: 
6 6 6 6 
6 6 6 6 
6 6 6 6 
6 6 6 6 
 at (5,5)
  _0101: 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 
 at (5,0)
  _01: rectangle with size (4,4) with model Full with color green at (10,5)
  _011: 
6 6 6 6 
6 6 6 6 
6 6 6 6 
6 6 6 6 
 at (20,15)
  _0111: 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 
 at (20,10)
  _01111: rectangle with size (4,4) with model Full with color green at (15,15)
diff: 
   (165.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (24,24) and color black and layers
  _0: rectangle with size (24,24) with mask 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
 with color cyan at (0,0)
  _0100: rectangle with size (14,4) with model Full with color green at (0,5)
  _010: rectangle with size (4,14) with model Full with color green at (5,0)
  _01: rectangle with size (4,4) with model Full with color pink at (20,15)
  + 16 delta pixels
diff: 
! size mismatch, 10x10 instead of 24x24
>> Trial 2
data: a background with size (24,24) and color black and layers
  _0: rectangle with size (24,24) with mask 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
 with color cyan at (0,0)
  _0100: rectangle with size (14,4) with model Full with color green at (0,5)
  _010: rectangle with size (4,4) with model Full with color pink at (20,15)
  _01: rectangle with size (4,14) with model Full with color green at (5,0)
  + 16 delta pixels
diff: 
! size mismatch, 10x10 instead of 24x24

TRAIN 39e1d7f9.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (27,27) and color black and layers
  _0: rectangle with size (27,27) with mask 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
 with color green at (0,0)
  _0100: rectangle with size (11,3) with model Full with color pink at (4,8)
  _010: rectangle with size (3,11) with model Full with color pink at (8,4)
  _01: rectangle with size (3,3) with model Full with color yellow at (0,24)
  + 18 delta pixels
diff: 
   (0.0 bits)
data: a background with size (27,27) and color black and layers
  _0: 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
. . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 3 . . . 
 at (0,0)
  _0100: rectangle with size (3,3) with model Full with color pink at (0,20)
  _010: 
4 4 4 
4 4 4 
4 4 4 
 at (8,8)
  _0101: 
6 6 6 6 6 6 6 6 6 6 6 
6 6 6 6 6 6 6 6 6 6 6 
6 6 6 6 6 6 6 6 6 6 6 
 at (8,4)
  _01: rectangle with size (11,3) with model Full with color pink at (16,12)
  _011: 
4 4 4 
4 4 4 
4 4 4 
 at (0,24)
  _0111: 
6 6 6 6 6 6 6 6 6 6 6 
6 6 6 6 6 6 6 6 6 6 6 
6 6 6 6 6 6 6 6 6 6 6 
 at (20,8)
  _01111: rectangle with size (11,3) with model Full with color pink at (4,8)
  + 18 delta pixels
diff: 
   (942.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (27,27) and color black and layers
  _0: rectangle with size (27,27) with mask 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
 with color green at (0,0)
  _0100: rectangle with size (11,3) with model Full with color pink at (4,8)
  _010: rectangle with size (3,11) with model Full with color pink at (8,4)
  _01: rectangle with size (3,3) with model Full with color yellow at (0,24)
  + 18 delta pixels
diff: 
! size mismatch, 10x10 instead of 27x27
>> Trial 2
data: a background with size (27,27) and color black and layers
  _0: rectangle with size (27,27) with mask 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
 with color green at (0,0)
  _0100: rectangle with size (11,3) with model Full with color pink at (4,8)
  _010: rectangle with size (3,3) with model Full with color yellow at (0,24)
  _01: rectangle with size (3,11) with model Full with color pink at (8,4)
  + 18 delta pixels
diff: 
! size mismatch, 10x10 instead of 27x27

TRAIN 39e1d7f9.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (27,27) and color black and layers
  _0: rectangle with size (27,27) with mask 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
 with color cyan at (0,0)
  _0100: rectangle with size (3,11) with model Full with color yellow at (12,12)
  _010: rectangle with size (3,11) with model Full with color yellow at (20,12)
  _01: rectangle with size (3,11) with model Full with color yellow at (16,12)
  + 27 delta pixels
diff: 
   (0.0 bits)
data: a background with size (27,27) and color black and layers
  _0: 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
. . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 8 . . . 
 at (0,0)
  _0100: rectangle with size (3,27) with model Full with color yellow at (4,0)
  _010: 
4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 
 at (8,0)
  _0101: 
4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 
 at (20,12)
  _01: rectangle with size (3,3) with model Full with color yellow at (0,20)
  _011: 
4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 
 at (16,12)
  _0111: 
4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 
 at (0,0)
  _01111: rectangle with size (3,11) with model Full with color yellow at (12,12)
  + 45 delta pixels
diff: 
   (2091.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (27,27) and color black and layers
  _0: rectangle with size (27,27) with mask 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
 with color cyan at (0,0)
  _0100: rectangle with size (3,11) with model Full with color yellow at (12,12)
  _010: rectangle with size (3,11) with model Full with color yellow at (20,12)
  _01: rectangle with size (3,11) with model Full with color yellow at (16,12)
  + 27 delta pixels
diff: 
! size mismatch, 10x10 instead of 27x27
>> Trial 2
data: a background with size (27,27) and color black and layers
  _0: rectangle with size (27,27) with mask 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
 with color cyan at (0,0)
  _0100: rectangle with size (11,3) with model Full with color yellow at (12,12)
  _010: rectangle with size (11,3) with model Full with color yellow at (12,20)
  _01: rectangle with size (11,3) with model Full with color yellow at (12,16)
  + 27 delta pixels
diff: 
! size mismatch, 10x10 instead of 27x27

TRAIN 39e1d7f9.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (29,29) and color black and layers
  _0: rectangle with size (29,29) with mask 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color yellow at (0,0)
  _0100: rectangle with size (2,8) with model Full with color cyan at (6,6)
  _010: rectangle with size (2,8) with model Full with color green at (9,6)
  _01: rectangle with size (2,8) with model Full with color cyan at (12,6)
  + 24 delta pixels
diff: 
! size mismatch, 10x10 instead of 29x29
>> Trial 2
data: a background with size (29,29) and color black and layers
  _0: rectangle with size (29,29) with mask 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color yellow at (0,0)
  _0100: rectangle with size (2,8) with model Full with color cyan at (6,6)
  _010: rectangle with size (2,8) with model Full with color cyan at (12,6)
  _01: rectangle with size (2,8) with model Full with color green at (9,6)
  + 24 delta pixels
diff: 
! size mismatch, 10x10 instead of 29x29
>> Trial 3
data: a background with size (29,29) and color black and layers
  _0: rectangle with size (29,29) with mask 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color yellow at (0,0)
  _0100: rectangle with size (8,2) with model Full with color cyan at (6,6)
  _010: rectangle with size (8,2) with model Full with color green at (6,9)
  _01: rectangle with size (8,2) with model Full with color cyan at (6,12)
  + 24 delta pixels
diff: 
! size mismatch, 10x10 instead of 29x29

TEST 39e1d7f9.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.8 sec (59.8 sec/task)
bits-train-error = 31998.7 bits (31998.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-320] Checking task 3aa6fb7a.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 38448.0 = 38450.4
DL output with Mo: L = 2.3 + 38448.0 = 38450.4
DL input+output M: L = 4.6 + 76896.1 = 76900.7

# learning a model for train pairs
2.000	
1.164	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.379	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.334	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.290	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.246	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.201	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.160	OUT ADD ^.layer_00 = ^.layer_0
0.129	OUT ADD ^.layer_011 = ^.layer_01
0.119	OUT SPE ^.size = ^.size
0.111	IN  SPE ^.layer_0.shape.mask = 
0 0 
. 0 

0.103	IN  SPE ^.layer_01.shape.mask = 
0 . 
0 0 

0.098	OUT SPE ^.layer_01.pos = projJ(^.layer_01.pos) + (1, 1)
0.094	OUT SPE ^.layer_0.pos = projI(^.layer_01.pos) + span(^.layer_0.pos, ^.layer_01.pos)
0.091	IN  SPE ^.layer_0.shape.color = cyan
0.088	IN  SPE ^.layer_01.shape.color = cyan
0.086	OUT SPE ^.layer_01.shape.color = blue
0.084	OUT SPE ^.layer_0.shape.mask.model = Full
0.083	IN  SPE ^.color = black
0.082	OUT SPE ^.color = black
0.031	
0.030	IN  GEN ^.layer_01.shape.color = ?
0.030	IN  GEN ^.layer_0.shape.color = ?
0.030	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model Full with color ? at projI(^.layer_01.pos) + span(^.layer_0.pos, ^.layer_01.pos)
  _01: rectangle with size (?,?) with model ? with color blue at projJ(^.layer_01.pos) + (1, 1)
  _011: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
0 0 
. 0 
 with color cyan at (?,?)
  _01: 
0 . 
0 0 
 with color cyan at (?,?)

DL input  with Mi: L = 76.7 + 1962.6 = 2039.3
DL output with Mo: L = 139.0 + 958.1 = 1097.1
DL input+output M: L = 215.7 + 2920.7 = 3136.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model Full with color ? at projI(^.layer_01.pos) + span(^.layer_0.pos, ^.layer_01.pos)
  _01: rectangle with size (?,?) with model ? with color blue at projJ(^.layer_01.pos) + (1, 1)
  _011: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 0 
. 0 
 with color ? at (?,?)
  _01: 
0 . 
0 0 
 with color ? at (?,?)

DL input  with Mi: L = 70.0 + 0.0 = 70.0
DL output with Mo: L = 139.0 + 958.1 = 1097.1
DL input+output M: L = 209.0 + 958.1 = 1167.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (7,7) and color black and layers
  _0: 
0 0 
. 0 
 with color cyan at (3,4)
  _01: 
0 . 
0 0 
 with color cyan at (1,1)
diff: 
   (0.0 bits)
data: a background with size (7,7) and color black and layers
  _00: 
8 8 
. 8 
 at (3,4)
  _0: rectangle with size (1,1) with model Full with color blue at (4,4)
  _01: rectangle with size (1,1) with model Full with color blue at (1,2)
  _011: 
8 . 
8 8 
 at (1,1)
diff: 
   (21.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: 
0 0 
. 0 
 with color cyan at (3,4)
  _01: 
0 . 
0 0 
 with color cyan at (1,1)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,7) and color black and layers
  _0: 
0 . 
0 0 
 with color cyan at (1,1)
  _01: 
0 0 
. 0 
 with color cyan at (3,4)
diff:   ^.layer_01.shape.mask  ^.layer_0.shape.mask
! 8 wrong pixels (generated / expected)

TRAIN 3aa6fb7a.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (7,7) and color black and layers
  _0: 
0 0 
. 0 
 with color cyan at (0,4)
  _01: 
0 . 
0 0 
 with color cyan at (2,2)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (7,7) and color black and layers
  _00: 
8 8 
. 8 
 at (0,4)
  _0: rectangle with size (2,2) with model Full with color cyan at (5,3)
  _01: rectangle with size (2,2) with model Odd Checkboard with color blue at (1,3)
  _011: 
8 . 
8 8 
 at (2,2)
  + 1 delta pixels
diff: 
   (74.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: 
0 0 
. 0 
 with color cyan at (0,4)
  _01: 
0 . 
0 0 
 with color cyan at (2,2)
  + 3 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,7) and color black and layers
  _0: 
0 0 
. 0 
 with color cyan at (0,4)
  _01: 
. 0 
0 0 
 with color cyan at (5,3)
  + 3 delta pixels
diff:   ^.layer_01.shape.mask
! 7 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (7,7) and color black and layers
  _0: 
. 0 
0 0 
 with color cyan at (5,3)
  _01: 
0 . 
0 0 
 with color cyan at (2,2)
  + 3 delta pixels
diff:   ^.layer_0.shape.mask
! 7 wrong pixels (generated / expected)

TRAIN 3aa6fb7a.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: 
0 0 
. 0 
 with color cyan at (0,5)
  _01: 
0 . 
0 0 
 with color cyan at (3,3)
  + 6 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,7) and color black and layers
  _0: 
0 0 
. 0 
 with color cyan at (0,5)
  _01: 
0 0 
0 . 
 with color cyan at (1,0)
  + 6 delta pixels
diff:   ^.layer_01.shape.mask
! 14 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (7,7) and color black and layers
  _0: 
0 0 
0 . 
 with color cyan at (1,0)
  _01: 
0 . 
0 0 
 with color cyan at (3,3)
  + 6 delta pixels
diff:   ^.layer_0.shape.mask
! 14 wrong pixels (generated / expected)

TEST 3aa6fb7a.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 8.7 sec (8.7 sec/task)
bits-train-error = 958.1 bits (958.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-319] Checking task 3ac3eb23.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 40072.4 = 40074.8
DL output with Mo: L = 2.3 + 40072.4 = 40074.8
DL input+output M: L = 4.6 + 80144.9 = 80149.5

# learning a model for train pairs
2.000	
1.041	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.315	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.159	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.098	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.086	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.076	OUT SPE ^.layer_01.shape.mask = 
. 0 . 
0 . 0 
. 0 . 
0 . 0 
. 0 . 
0 . 0 

0.067	OUT SPE ^.size = ^.size
0.062	OUT SPE ^.layer_01.pos = '(0, 0)
0.059	OUT SPE ^.layer_0.shape.mask.size.j = 3
0.056	OUT SPE ^.layer_01.shape.color = majorityColor(^)
0.054	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.051	OUT SPE ^.layer_0.pos.j = ^.layer_0.pos.j - 1
0.050	OUT SPE ^.layer_0.pos.i = middle(^.layer_0) / colorCount(^)
0.048	IN  SPE ^.color = black
0.047	OUT SPE ^.color = black
0.020	
0.020	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,3) with model ? with color ^.layer_0.shape.color at (middle(^.layer_0) / colorCount(^),^.layer_0.pos.j - 1)
  _01: 
. 0 . 
0 . 0 
. 0 . 
0 . 0 
. 0 . 
0 . 0 
 with color majorityColor(^) at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.3 + 1105.2 = 1137.5
DL output with Mo: L = 138.0 + 615.6 = 753.6
DL input+output M: L = 170.3 + 1720.8 = 1891.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,3) with model ? with color ^.layer_0.shape.color at (middle(^.layer_0) / colorCount(^),^.layer_0.pos.j - 1)
  _01: 
. 0 . 
0 . 0 
. 0 . 
0 . 0 
. 0 . 
0 . 0 
 with color majorityColor(^) at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 20.0 = 52.2
DL output with Mo: L = 138.0 + 615.6 = 753.6
DL input+output M: L = 170.1 + 635.6 = 805.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (6,10) and color black and layers
  _0: point with color cyan at (0,5)
  + 1 delta pixels
diff: 
   (2.0 bits)
data: a background with size (6,10) and color black and layers
  _0: rectangle with size (6,3) with model Odd Checkboard with color cyan at (0,4)
  _01: 
. 0 . 
0 . 0 
. 0 . 
0 . 0 
. 0 . 
0 . 0 
 with color red at (0,0)
diff: 
   (15.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,10) and color black and layers
  _0: point with color red at (0,1)
  + 1 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,10) and color black and layers
  _0: point with color cyan at (0,5)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 3ac3eb23.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (6,7) and color black and layers
  _0: point with color yellow at (0,1)
diff: 
   (0.0 bits)
data: a background with size (6,7) and color black and layers
  _0: rectangle with size (1,3) with model Full with color yellow at (1,0)
  _01: 
. 0 . 
0 . 0 
. 0 . 
0 . 0 
. 0 . 
0 . 0 
 with color yellow at (0,0)
  + 1 delta pixels
diff: 
   (46.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,7) and color black and layers
  _0: point with color yellow at (0,1)
diff: 
! 3 wrong pixels (generated / expected)

TRAIN 3ac3eb23.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
undefined expression: ScaleDown: not an integer

TEST 3ac3eb23.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 3.3 sec (3.3 sec/task)
bits-train-error = 615.6 bits (615.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-318] Checking task 3af2c5a8.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 13976.1 = 13978.5
DL output with Mo: L = 2.3 + 56470.9 = 56473.2
DL input+output M: L = 4.6 + 70447.0 = 70451.7

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = unfoldSym( [ id flipWidth ] [ flipHeight rotate180 ], ^)
0.443	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.117	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.116	IN  SPE ^.color = black
0.003	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
unfoldSym( [ id flipWidth ] [ flipHeight rotate180 ], ^)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.1 + 1583.3 = 1625.4
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 53.4 + 1583.3 = 1636.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
unfoldSym( [ id flipWidth ] [ flipHeight rotate180 ], ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 13.6 + 0.0 = 13.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 8 0 
0 8 0 8 
0 0 8 0 

diff: 
   (0.0 bits)
data: 
0 0 8 0 0 8 0 0 
0 8 0 8 8 0 8 0 
0 0 8 0 0 8 0 0 
0 0 8 0 0 8 0 0 
0 8 0 8 8 0 8 0 
0 0 8 0 0 8 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 8 0 
0 8 0 8 
0 0 8 0 

diff: 
correct output grid

TRAIN 3af2c5a8.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 0 3 3 
0 3 0 3 
3 3 3 0 

diff: 
   (0.0 bits)
data: 
0 0 3 3 3 3 0 0 
0 3 0 3 3 0 3 0 
3 3 3 0 0 3 3 3 
3 3 3 0 0 3 3 3 
0 3 0 3 3 0 3 0 
0 0 3 3 3 3 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 3 3 
0 3 0 3 
3 3 3 0 

diff: 
correct output grid

TRAIN 3af2c5a8.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
3 3 3 3 
3 0 0 0 
3 0 0 0 

diff: 
   (0.0 bits)
data: 
3 3 3 3 3 3 3 3 
3 0 0 0 0 0 0 3 
3 0 0 0 0 0 0 3 
3 0 0 0 0 0 0 3 
3 0 0 0 0 0 0 3 
3 3 3 3 3 3 3 3 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 3 3 3 
3 0 0 0 
3 0 0 0 

diff: 
correct output grid

TRAIN 3af2c5a8.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 0 0 0 
0 0 0 4 
4 4 0 0 

diff: 
correct output grid

TEST 3af2c5a8.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 0.5 sec (0.5 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-317] Checking task 3bd67248.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 114742.1 = 114744.4
DL output with Mo: L = 2.3 + 114742.1 = 114744.4
DL input+output M: L = 4.6 + 229484.2 = 229488.9

# learning a model for train pairs
2.000	
1.093	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.336	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.257	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.173	OUT ADD ^.layer_0 = ^.layer_0
0.105	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.046	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.041	OUT SPE ^.size = ^.size
0.037	OUT SPE ^.layer_01.shape.mask.size = ^.size - (1, 1)
0.034	OUT SPE ^.layer_01.pos = '(0, 1)
0.032	OUT SPE ^.layer_011.shape.mask.size.j = ^.size.j - 1
0.031	OUT SPE ^.layer_01.shape.color = red
0.029	OUT SPE ^.layer_011.shape.color = yellow
0.028	OUT SPE ^.layer_011.pos.j = 1
0.027	OUT SPE ^.layer_011.pos.i = bottom(^.layer_0)
0.026	OUT SPE ^.layer_011.shape.mask.size.i = 1
0.025	IN  SPE ^.layer_0.shape.mask.model = Full
0.024	OUT SPE ^.layer_011.shape.mask.model = Full
0.024	IN  SPE ^.color = black
0.023	OUT SPE ^.color = black
0.011	
0.011	IN  GEN ^.layer_0.shape.mask.model = ?
0.011	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size ^.size - (1, 1) with model ? with color red at '(0, 1)
  _011: rectangle with size (1,^.size.j - 1) with model Full with color yellow at (bottom(^.layer_0),1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 42.6 + 1370.8 = 1413.4
DL output with Mo: L = 133.4 + 1098.7 = 1232.1
DL input+output M: L = 176.0 + 2469.5 = 2645.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size ^.size - (1, 1) with model ? with color red at '(0, 1)
  _011: rectangle with size (1,^.size.j - 1) with model Full with color yellow at (bottom(^.layer_0),1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 133.4 + 1098.7 = 1232.1
DL input+output M: L = 175.4 + 1098.7 = 1274.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (15,1) with model Full with color pink at (0,0)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: 
6 
6 
6 
6 
6 
6 
6 
6 
6 
6 
6 
6 
6 
6 
6 
 at (0,0)
  _01: rectangle with size (14,14) with mask 
. . . . . . . . . . . . . 0 
. . . . . . . . . . . . 0 . 
. . . . . . . . . . . 0 . . 
. . . . . . . . . . 0 . . . 
. . . . . . . . . 0 . . . . 
. . . . . . . . 0 . . . . . 
. . . . . . . 0 . . . . . . 
. . . . . . 0 . . . . . . . 
. . . . . 0 . . . . . . . . 
. . . . 0 . . . . . . . . . 
. . . 0 . . . . . . . . . . 
. . 0 . . . . . . . . . . . 
. 0 . . . . . . . . . . . . 
0 . . . . . . . . . . . . . 
 with color red at (0,1)
  _011: rectangle with size (1,14) with model Full with color yellow at (14,1)
diff: 
   (76.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (15,1) with model Full with color pink at (0,0)
diff: 
! 182 wrong pixels (generated / expected)

TRAIN 3bd67248.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,1) with model Full with color grey at (0,0)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
5#
5#
5#
 at (0,0)
  _01: rectangle with size (2,2) with model Odd Checkboard with color red at (0,1)
  _011: rectangle with size (1,2) with model Full with color yellow at (2,1)
diff: 
   (6.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,1) with model Full with color grey at (0,0)
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color grey and layers
  _0: rectangle with size (3,2) with model Full with color black at (0,1)
diff: 
! 7 wrong pixels (generated / expected)

TRAIN 3bd67248.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (7,7) and color black and layers
  _0: rectangle with size (7,1) with model Full with color cyan at (0,0)
diff: 
   (0.0 bits)
data: a background with size (7,7) and color black and layers
  _0: 
8 
8 
8 
8 
8 
8 
8 
 at (0,0)
  _01: rectangle with size (6,6) with mask 
. . . . . 0 
. . . . 0 . 
. . . 0 . . 
. . 0 . . . 
. 0 . . . . 
0 . . . . . 
 with color red at (0,1)
  _011: rectangle with size (1,6) with model Full with color yellow at (6,1)
diff: 
   (26.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (7,1) with model Full with color cyan at (0,0)
diff: 
! 30 wrong pixels (generated / expected)

TRAIN 3bd67248.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color green at (0,0)
diff: 
! 72 wrong pixels (generated / expected)

TEST 3bd67248.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.6 sec (3.6 sec/task)
bits-train-error = 1098.7 bits (1098.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-316] Checking task 3bdb4ada.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 163087.7 = 163090.0
DL output with Mo: L = 2.3 + 163087.7 = 163090.0
DL input+output M: L = 4.6 + 326175.4 = 326180.0

# learning a model for train pairs
2.000	
1.395	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.863	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.569	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.326	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.166	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.033	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.030	OUT SPE ^.size = ^.size
0.028	OUT SPE ^.layer_0.shape.mask.size = ^.layer_0.shape.mask.size
0.026	OUT SPE ^.layer_01.shape.mask.size = ^.layer_01.shape.mask.size
0.024	OUT SPE ^.layer_01.pos = ^.layer_01.pos
0.023	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.022	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.021	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.021	IN  SPE ^.layer_0.shape.mask.model = Full
0.021	IN  SPE ^.layer_01.shape.mask.model = Full
0.020	IN  SPE ^.color = black
0.020	OUT SPE ^.color = black
0.009	
0.009	IN  GEN ^.layer_01.shape.mask.model = ?
0.009	IN  GEN ^.layer_0.shape.mask.model = ?
0.009	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size ^.layer_0.shape.mask.size with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: rectangle with size ^.layer_01.shape.mask.size with model ? with color ^.layer_01.shape.color at ^.layer_01.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 71.4 + 1849.3 = 1920.6
DL output with Mo: L = 57.0 + 1282.5 = 1339.5
DL input+output M: L = 128.4 + 3131.8 = 3260.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size ^.layer_0.shape.mask.size with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: rectangle with size ^.layer_01.shape.mask.size with model ? with color ^.layer_01.shape.color at ^.layer_01.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 57.0 + 1282.5 = 1339.5
DL input+output M: L = 127.2 + 1282.5 = 1409.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (8,30) and color black and layers
  _0: rectangle with size (3,29) with model Full with color yellow at (1,0)
  _01: rectangle with size (3,13) with model Full with color cyan at (5,12)
diff: 
   (0.0 bits)
data: a background with size (8,30) and color black and layers
  _0: rectangle with size (3,29) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color yellow at (1,0)
  _01: rectangle with size (3,13) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 . 0 . 0 . 0 . 0 . 0 . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color cyan at (5,12)
diff: 
   (86.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,30) and color black and layers
  _0: rectangle with size (3,29) with model Full with color yellow at (1,0)
  _01: rectangle with size (3,13) with model Full with color cyan at (5,12)
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,30) and color yellow and layers
  _0: rectangle with size (8,30) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . . . . . . . . . . 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . . . . . . . . . . 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . . . . . . . . . . 0 0 0 0 0 
 with color black at (0,0)
  _01: rectangle with size (3,13) with model Full with color cyan at (5,12)
diff: 
! 106 wrong pixels (generated / expected)

TRAIN 3bdb4ada.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (8,20) and color black and layers
  _0: rectangle with size (3,11) with model Full with color orange at (5,7)
  _01: rectangle with size (3,9) with model Full with color blue at (1,1)
diff: 
   (0.0 bits)
data: a background with size (8,20) and color black and layers
  _0: rectangle with size (3,11) with mask 
0 0 0 0 0 0 0 0 0 0 0 
0 . 0 . 0 . 0 . 0 . 0 
0 0 0 0 0 0 0 0 0 0 0 
 with color orange at (5,7)
  _01: rectangle with size (3,9) with mask 
0 0 0 0 0 0 0 0 0 
0 . 0 . 0 . 0 . 0 
0 0 0 0 0 0 0 0 0 
 with color blue at (1,1)
diff: 
   (42.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,20) and color black and layers
  _0: rectangle with size (3,11) with model Full with color orange at (5,7)
  _01: rectangle with size (3,9) with model Full with color blue at (1,1)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 3bdb4ada.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,20) and color black and layers
  _0: rectangle with size (3,13) with model Full with color yellow at (5,1)
  _01: rectangle with size (3,7) with model Full with color grey at (1,2)
  + 15 delta pixels
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,20) and color black and layers
  _0: rectangle with size (3,13) with model Full with color yellow at (5,1)
  _01: rectangle with size (3,5) with model Full with color cyan at (8,15)
  + 21 delta pixels
diff: 
! 26 wrong pixels (generated / expected)

TEST 3bdb4ada.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 19.8 sec (19.8 sec/task)
bits-train-error = 1282.5 bits (1282.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-315] Checking task 3befdf3e.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.143	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.537	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.308	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.210	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.113	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.089	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.066	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.058	OUT SPE ^.layer_01 = coloring(^.layer_01, ^.layer_0.shape.color)
0.050	OUT SPE ^.layer_0 = coloring(^.layer_0, majorityColor(^))
0.045	OUT SPE ^.size = ^.size
0.041	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.040	OUT SPE ^.layer_011.shape.mask.size.j = ^.layer_01.shape.mask.size.j
0.037	OUT SPE ^.layer_011.pos = ^.layer_01.pos - projI(^.layer_0.shape.mask.size)
0.035	OUT SPE ^.layer_0111.pos = ^.layer_01.pos - projJ(^.layer_0.shape.mask.size)
0.033	OUT SPE ^.layer_0111.shape.mask.size.i = ^.layer_01.shape.mask.size.i
0.032	OUT SPE ^.layer_011.shape.color = majorityColor(^)
0.030	OUT SPE ^.layer_0111.shape.color = majorityColor(^)
0.030	IN  SPE ^.layer_0.shape.mask.model = Full
0.029	IN  SPE ^.layer_01.shape.mask.model = Full
0.028	OUT SPE ^.layer_011.shape.mask.model = Full
0.027	OUT SPE ^.layer_0111.shape.mask.model = Full
0.027	IN  SPE ^.color = black
0.026	OUT SPE ^.color = black
0.007	
0.007	IN  GEN ^.layer_01.shape.mask.model = ?
0.007	IN  GEN ^.layer_0.shape.mask.model = ?
0.007	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, majorityColor(^))
  _01: coloring(^.layer_01, ^.layer_0.shape.color)
  _011: rectangle with size (?,^.layer_01.shape.mask.size.j) with model Full with color majorityColor(^) at ^.layer_01.pos - projI(^.layer_0.shape.mask.size)
  _0111: rectangle with size (^.layer_01.shape.mask.size.i,?) with model Full with color majorityColor(^) at ^.layer_01.pos - projJ(^.layer_0.shape.mask.size)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 71.4 + 2315.0 = 2386.4
DL output with Mo: L = 217.5 + 532.2 = 749.7
DL input+output M: L = 288.8 + 2847.2 = 3136.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, majorityColor(^))
  _01: coloring(^.layer_01, ^.layer_0.shape.color)
  _011: rectangle with size (?,^.layer_01.shape.mask.size.j) with model Full with color majorityColor(^) at ^.layer_01.pos - projI(^.layer_0.shape.mask.size)
  _0111: rectangle with size (^.layer_01.shape.mask.size.i,?) with model Full with color majorityColor(^) at ^.layer_01.pos - projJ(^.layer_0.shape.mask.size)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 217.5 + 532.2 = 749.7
DL input+output M: L = 287.7 + 532.2 = 819.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color pink at (4,4)
  _01: rectangle with size (3,3) with model Full with color yellow at (3,3)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
4 
 at (4,4)
  _01: 
6 6 6 
6 6 6 
6 6 6 
 at (3,3)
  _011: rectangle with size (5,3) with model Full with color yellow at (2,3)
  _0111: rectangle with size (3,5) with model Full with color yellow at (3,2)
diff: 
   (15.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color pink at (4,4)
  _01: rectangle with size (3,3) with model Full with color yellow at (3,3)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Border with color yellow at (3,3)
  _01: rectangle with size (1,1) with model Full with color pink at (4,4)
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,3) with model Full with color yellow at (3,3)
  _01: rectangle with size (3,3) with model Full with color yellow at (3,3)
  + 2 delta pixels
diff: 
! 23 wrong pixels (generated / expected)

TRAIN 3befdf3e.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color orange at (4,4)
  _01: rectangle with size (4,4) with model Full with color red at (3,3)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
2 2 
2 2 
 at (4,4)
  _01: 
7#7#7#7#
7#7#7#7#
7#7#7#7#
7#7#7#7#
 at (3,3)
  _011: rectangle with size (8,4) with model Full with color red at (1,3)
  _0111: rectangle with size (4,8) with model Full with color red at (3,1)
diff: 
   (18.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color orange at (4,4)
  _01: rectangle with size (4,4) with model Full with color red at (3,3)
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with model Border with color red at (3,3)
  _01: rectangle with size (2,2) with model Full with color orange at (4,4)
diff: 
! 44 wrong pixels (generated / expected)

TRAIN 3befdf3e.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color blue at (4,3)
  _01: rectangle with size (4,4) with model Full with color green at (3,2)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
3 3 
3 3 
 at (4,3)
  _01: 
1 1 1 1 
1 1 1 1 
1 1 1 1 
1 1 1 1 
 at (3,2)
  _011: rectangle with size (8,4) with model Full with color green at (1,2)
  _0111: rectangle with size (4,8) with model Full with color green at (3,0)
diff: 
   (18.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color blue at (4,3)
  _01: rectangle with size (4,4) with model Full with color green at (3,2)
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with model Border with color green at (3,2)
  _01: rectangle with size (2,2) with model Full with color blue at (4,3)
diff: 
! 42 wrong pixels (generated / expected)

TRAIN 3befdf3e.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (4,4) with model Full with color cyan at (6,6)
  _01: rectangle with size (3,3) with model Full with color cyan at (1,1)
  + 5 delta pixels
diff: 
! 64 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (3,3) with model Full with color cyan at (1,1)
  _01: rectangle with size (4,4) with model Full with color cyan at (6,6)
  + 5 delta pixels
diff: 
! 64 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (4,4) with model Border with color cyan at (6,6)
  _01: rectangle with size (3,3) with model Full with color cyan at (1,1)
  + 5 delta pixels
diff: 
! 68 wrong pixels (generated / expected)

TEST 3befdf3e.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 12.3 sec (12.3 sec/task)
bits-train-error = 532.2 bits (532.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-314] Checking task 3c9b0459.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 14046.4 = 14048.7
DL output with Mo: L = 2.3 + 14046.4 = 14048.7
DL input+output M: L = 4.6 + 28092.8 = 28097.5

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = applySym(rotate180, ^)
0.540	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.290	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.249	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.005	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
applySym(rotate180, ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 60.4 + 3432.3 = 3492.7
DL output with Mo: L = 12.3 + 0.0 = 12.3
DL input+output M: L = 72.7 + 3432.3 = 3505.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
applySym(rotate180, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 12.3 + 0.0 = 12.3
DL input+output M: L = 14.6 + 0.0 = 14.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
2 2 1 
2 1 2 
2 8 1 

diff: 
   (0.0 bits)
data: 
1 8 2 
2 1 2 
1 2 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 2 1 
2 1 2 
2 8 1 

diff: 
correct output grid

TRAIN 3c9b0459.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
9#2 4 
2 4 4 
2 9#2 

diff: 
   (0.0 bits)
data: 
2 9#2 
4 4 2 
4 2 9#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
9#2 4 
2 4 4 
2 9#2 

diff: 
correct output grid

TRAIN 3c9b0459.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
8 8 8 
5#5#8 
8 5#5#

diff: 
   (0.0 bits)
data: 
5#5#8 
8 5#5#
8 8 8 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 8 8 
5#5#8 
8 5#5#

diff: 
correct output grid

TRAIN 3c9b0459.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: 
3 2 9#
9#9#9#
2 3 3 

diff: 
   (0.0 bits)
data: 
3 3 2 
9#9#9#
9#2 3 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 2 9#
9#9#9#
2 3 3 

diff: 
correct output grid

TRAIN 3c9b0459.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
6 4 4 
6 6 4 
4 6 7#

diff: 
correct output grid

TEST 3c9b0459.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 0.6 sec (0.6 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-313] Checking task 3de23699.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 218737.4 = 218739.7
DL output with Mo: L = 2.3 + 27983.9 = 27986.2
DL input+output M: L = 4.6 + 246721.3 = 246725.9

# learning a model for train pairs
2.000	
1.084	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.437	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.209	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.172	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.136	OUT SPE ^.layer_0.shape.mask = ^.layer_0.shape.mask
0.130	OUT SPE ^.layer_0.pos.i = '0
0.126	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.120	OUT SPE ^.layer_0.shape.color = ^.layer_01.shape.color
0.115	OUT SPE ^.layer_0.pos.j = span(^.layer_0.pos.j, ^.layer_01.pos.j) - 2
0.111	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.107	OUT SPE ^.color = black
0.105	IN  ADD ^.layer_010 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.101	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.099	IN  SPE ^.layer_01.shape.mask = 
0 

0.092	OUT SPE ^.size.i = area(^.layer_01.shape.mask) - ^.layer_0.pos.i - ^.layer_0111.pos.i
0.090	IN  SPE ^.layer_011.shape.mask = 
0 

0.089	IN  SPE ^.layer_010.shape.mask.model = Full
0.089	IN  SPE ^.color = black
0.060	
0.060	IN  GEN ^.layer_010.shape.mask.model = ?
0.060	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (area(^.layer_01.shape.mask) - ^.layer_0.pos.i - ^.layer_0111.pos.i,?) and color black and layers
  _0: ^.layer_0.shape.mask with color ^.layer_01.shape.color at ('0,span(^.layer_0.pos.j, ^.layer_01.pos.j) - 2)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: 
0 
 with color ? at (?,?)
  _011: 
0 
 with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 128.6 + 6508.2 = 6636.9
DL output with Mo: L = 151.4 + 1487.4 = 1638.8
DL input+output M: L = 280.0 + 7995.6 = 8275.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (area(^.layer_01.shape.mask) - ^.layer_0.pos.i - ^.layer_0111.pos.i,?) and color black and layers
  _0: ^.layer_0.shape.mask with color ^.layer_01.shape.color at ('0,span(^.layer_0.pos.j, ^.layer_01.pos.j) - 2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: 
0 
 with color ? at (?,?)
  _011: 
0 
 with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 128.0 + 115.1 = 243.1
DL output with Mo: L = 151.4 + 1487.4 = 1638.8
DL input+output M: L = 279.4 + 1602.5 = 1881.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (7,7) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
. 0 0 
 with color red at (2,2)
  _010: rectangle with size (1,1) with model Full with color yellow at (1,1)
  _01: 
0 
 with color yellow at (5,1)
  _011: 
0 
 with color yellow at (1,5)
  _0111: point with color yellow at (5,5)
diff: 
   (3.2 bits)
data: a background with size (3,3) and color black and layers
  _0: 
. 0 . 
0 0 0 
. 0 0 
 with color yellow at (0,0)
diff: 
   (6.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
. 0 0 
 with color red at (2,2)
  _010: rectangle with size (1,1) with model Full with color yellow at (1,1)
  _01: 
0 
 with color yellow at (1,5)
  _011: 
0 
 with color yellow at (5,1)
  _0111: point with color yellow at (5,5)
diff: 
! size mismatch, 3x10 instead of 3x3
>> Trial 2
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
. 0 0 
 with color red at (2,2)
  _010: rectangle with size (1,1) with model Full with color yellow at (1,1)
  _01: 
0 
 with color yellow at (5,1)
  _011: 
0 
 with color yellow at (1,5)
  _0111: point with color yellow at (5,5)
diff: 
! size mismatch, 3x10 instead of 3x3

TRAIN 3de23699.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (12,9) and color black and layers
  _0: rectangle with size (3,5) with mask 
. 0 0 . . 
. 0 0 . 0 
0 . . 0 . 
 with color red at (2,2)
  _010: rectangle with size (1,1) with model Full with color green at (1,1)
  _01: 
0 
 with color green at (5,1)
  _011: 
0 
 with color green at (1,7)
  _0111: point with color green at (5,7)
diff: 
   (3.2 bits)
data: a background with size (3,5) and color black and layers
  _0: 
. 0 0 . . 
. 0 0 . 0 
0 . . 0 . 
 with color green at (0,0)
diff: 
   (8.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,9) and color black and layers
  _0: rectangle with size (3,5) with mask 
. 0 0 . . 
. 0 0 . 0 
0 . . 0 . 
 with color red at (2,2)
  _010: rectangle with size (1,1) with model Full with color green at (1,1)
  _01: 
0 
 with color green at (1,7)
  _011: 
0 
 with color green at (5,1)
  _0111: point with color green at (5,7)
diff: 
! size mismatch, 3x10 instead of 3x5
>> Trial 2
data: a background with size (12,9) and color black and layers
  _0: rectangle with size (3,5) with mask 
. 0 0 . . 
. 0 0 . 0 
0 . . 0 . 
 with color red at (2,2)
  _010: rectangle with size (1,1) with model Full with color green at (1,1)
  _01: 
0 
 with color green at (5,1)
  _011: 
0 
 with color green at (1,7)
  _0111: point with color green at (5,7)
diff: 
! size mismatch, 3x10 instead of 3x5

TRAIN 3de23699.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (12,14) and color black and layers
  _0: rectangle with size (4,3) with mask 
. 0 . 
. 0 . 
0 0 0 
. 0 0 
 with color cyan at (6,4)
  _010: rectangle with size (1,1) with model Full with color pink at (5,3)
  _01: 
0 
 with color pink at (10,3)
  _011: 
0 
 with color pink at (5,8)
  _0111: point with color pink at (10,8)
diff: 
   (3.2 bits)
data: a background with size (4,4) and color black and layers
  _0: 
. 0 . 
. 0 . 
0 0 0 
. 0 0 
 with color pink at (0,0)
diff: 
   (7.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,14) and color black and layers
  _0: rectangle with size (4,3) with mask 
. 0 . 
. 0 . 
0 0 0 
. 0 0 
 with color cyan at (6,4)
  _010: rectangle with size (1,1) with model Full with color pink at (5,3)
  _01: 
0 
 with color pink at (5,8)
  _011: 
0 
 with color pink at (10,3)
  _0111: point with color pink at (10,8)
diff: 
! size mismatch, 4x10 instead of 4x4
>> Trial 2
data: a background with size (12,14) and color black and layers
  _0: rectangle with size (4,3) with mask 
. 0 . 
. 0 . 
0 0 0 
. 0 0 
 with color cyan at (6,4)
  _010: rectangle with size (1,1) with model Full with color pink at (5,3)
  _01: 
0 
 with color pink at (10,3)
  _011: 
0 
 with color pink at (5,8)
  _0111: point with color pink at (10,8)
diff: 
! size mismatch, 4x10 instead of 4x4

TRAIN 3de23699.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (12,18) and color black and layers
  _0: rectangle with size (2,3) with mask 
. 0 0 
0 0 . 
 with color yellow at (2,5)
  _010: rectangle with size (2,1) with model Full with color yellow at (4,9)
  _01: 
0 
 with color cyan at (1,2)
  _011: 
0 
 with color cyan at (1,11)
  _0111: point with color cyan at (6,2)
  + 2 delta pixels
diff: 
   (2.0 bits)
data: a background with size (4,8) and color black and layers
  _0: 
. 0 0 
0 0 . 
 with color cyan at (0,2)
  + 3 delta pixels
diff: 
   (127.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,18) and color black and layers
  _0: rectangle with size (2,3) with mask 
. 0 0 
0 0 . 
 with color yellow at (2,5)
  _010: rectangle with size (2,1) with model Full with color yellow at (4,9)
  _01: 
0 
 with color cyan at (1,2)
  _011: 
0 
 with color cyan at (1,11)
  _0111: point with color yellow at (5,7)
  + 2 delta pixels
diff: 
! size mismatch, 3x10 instead of 4x8
>> Trial 2
data: a background with size (12,18) and color black and layers
  _0: rectangle with size (2,3) with mask 
. 0 0 
0 0 . 
 with color yellow at (2,5)
  _010: rectangle with size (2,1) with model Full with color yellow at (4,9)
  _01: 
0 
 with color cyan at (1,2)
  _011: 
0 
 with color cyan at (1,11)
  _0111: point with color cyan at (6,2)
  + 2 delta pixels
diff: 
! size mismatch, 4x10 instead of 4x8

TRAIN 3de23699.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
Invalid_argument("grid_background: negative or null grid size")

TEST 3de23699.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 4.3 sec (4.3 sec/task)
bits-train-error = 1487.4 bits (1487.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-312] Checking task 3e980e27.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 274019.4 = 274021.7
DL output with Mo: L = 2.3 + 274019.4 = 274021.7
DL input+output M: L = 4.6 + 548038.8 = 548043.4

# learning a model for train pairs
2.000	
1.060	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.171	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.152	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.127	OUT ADD ^.layer_0 = ^.layer_0
0.107	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.092	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.084	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.075	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.067	OUT ADD ^.layer_010 = ^.layer_01
0.062	OUT ADD ^.layer_00 = ^.layer_0.shape at (?,?)
0.058	IN  ADD ^.layer_00 = point with color ? at (?,?)
0.055	OUT SPE ^.size = ^.size
0.053	OUT SPE ^.layer_0111.shape.mask = 
0 

0.053	OUT SPE ^.layer_01.shape.color = majorityColor(^)
0.052	OUT SPE ^.layer_01.shape.mask.size.j = ^.layer_0.shape.mask.size.j
0.051	OUT SPE ^.layer_00.pos.j = span(^.layer_0.pos.i, ^.layer_00.pos.i) / '2
0.050	OUT SPE ^.layer_011.pos.j = average(^.layer_01.pos.j, ^.layer_00.pos.j) + 2
0.050	IN  SPE ^.color = black
0.050	OUT SPE ^.color = black
0.021	
0.021	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0.shape at (?,span(^.layer_0.pos.i, ^.layer_00.pos.i) / '2)
  _0: ^.layer_0
  _010: ^.layer_01
  _01: rectangle with size (?,^.layer_0.shape.mask.size.j) with model ? with color majorityColor(^) at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,average(^.layer_01.pos.j, ^.layer_00.pos.j) + 2)
  _0111: 
0 
 with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 88.4 + 7844.3 = 7932.7
DL output with Mo: L = 227.3 + 5472.4 = 5699.7
DL input+output M: L = 315.8 + 13316.7 = 13632.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0.shape at (?,span(^.layer_0.pos.i, ^.layer_00.pos.i) / '2)
  _0: ^.layer_0
  _010: ^.layer_01
  _01: rectangle with size (?,^.layer_0.shape.mask.size.j) with model ? with color majorityColor(^) at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,average(^.layer_01.pos.j, ^.layer_00.pos.j) + 2)
  _0111: 
0 
 with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 88.3 + 51.7 = 140.0
DL output with Mo: L = 227.3 + 5472.4 = 5699.7
DL input+output M: L = 315.6 + 5524.1 = 5839.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _00: point with color red at (3,3)
  _0: rectangle with size (1,1) with model Full with color red at (8,7)
  _01: rectangle with size (3,3) with mask 
. 0 . 
0 0 . 
. . 0 
 with color blue at (3,3)
diff: 
   (2.0 bits)
data: a background with size (13,13) and color black and layers
  _00: 
2 
 at (3,3)
  _0: 
2 
 at (8,7)
  _010: 
. 1 . 
1 1 . 
. . 1 
 at (3,3)
  _01: rectangle with size (2,1) with model Full with color blue at (8,6)
  _011: rectangle with size (1,1) with model Full with color blue at (10,5)
  _0111: 
0 
 with color blue at (9,7)
diff: 
   (65.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _00: point with color red at (3,3)
  _0: rectangle with size (1,1) with model Full with color red at (8,7)
  _01: rectangle with size (3,3) with mask 
. 0 . 
0 0 . 
. . 0 
 with color blue at (3,3)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,13) and color black and layers
  _00: point with color red at (8,7)
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 . 
. . 0 
 with color blue at (3,3)
  _01: rectangle with size (1,1) with model Full with color red at (3,3)
diff: 
! 19 wrong pixels (generated / expected)

TRAIN 3e980e27.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _00: point with color green at (2,6)
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 . 0 
0 0 . 
 with color yellow at (1,5)
  _01: rectangle with size (1,1) with model Full with color green at (6,2)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (13,13) and color black and layers
  _00: 
. 4 . 
4 . 4 
4 4 . 
 at (5,1)
  _0: 
. 4 . 
4 . 4 
4 4 . 
 at (1,5)
  _010: 
3 
 at (6,2)
  _01: rectangle with size (3,3) with mask 
. 0 . 
0 . 0 
0 0 . 
 with color yellow at (8,8)
  _011: rectangle with size (1,1) with model Full with color green at (2,6)
  _0111: 
0 
 with color green at (9,9)
diff: 
   (74.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _00: point with color green at (2,6)
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 . 0 
0 0 . 
 with color yellow at (1,5)
  _01: rectangle with size (1,1) with model Full with color green at (6,2)
  + 1 delta pixels
diff: 
! 24 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,13) and color black and layers
  _00: point with color yellow at (1,6)
  _0: rectangle with size (2,1) with model Full with color yellow at (2,5)
  _01: rectangle with size (1,1) with model Full with color green at (2,6)
  + 4 delta pixels
diff: 
! 23 wrong pixels (generated / expected)

TRAIN 3e980e27.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _00: point with color red at (1,10)
  _0: rectangle with size (2,3) with mask 
. 0 0 
0 . . 
 with color cyan at (2,2)
  _01: rectangle with size (2,3) with mask 
0 . . 
. 0 0 
 with color yellow at (7,6)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (13,13) and color black and layers
  _00: 
. 8 8 
8 . . 
 at (8,1)
  _0: 
. 8 8 
8 . . 
 at (2,2)
  _010: 
4 . . 
. 4 4 
 at (7,6)
  _01: rectangle with size (2,3) with mask 
. . 0 
0 0 . 
 with color yellow at (1,9)
  _011: rectangle with size (1,1) with model Full with color red at (1,10)
  _0111: 
0 
 with color green at (2,2)
  + 2 delta pixels
diff: 
   (153.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _00: point with color red at (1,10)
  _0: rectangle with size (2,3) with mask 
. 0 0 
0 . . 
 with color cyan at (2,2)
  _01: rectangle with size (2,3) with mask 
0 . . 
. 0 0 
 with color yellow at (7,6)
  + 3 delta pixels
diff: 
! 19 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,13) and color black and layers
  _00: point with color red at (1,10)
  _0: rectangle with size (2,3) with mask 
0 . . 
. 0 0 
 with color yellow at (7,6)
  _01: rectangle with size (2,3) with mask 
. 0 0 
0 . . 
 with color cyan at (2,2)
  + 3 delta pixels
diff: 
! 23 wrong pixels (generated / expected)

TRAIN 3e980e27.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _00: point with color red at (2,3)
  _0: rectangle with size (2,3) with mask 
. 0 0 
0 . 0 
 with color blue at (7,9)
  _01: rectangle with size (3,3) with mask 
0 0 0 
. . 0 
. . 0 
 with color yellow at (1,7)
  + 4 delta pixels
diff: 
   (3.2 bits)
data: a background with size (13,13) and color black and layers
  _00: 
. 1 1 
1 . 1 
 at (8,3)
  _0: 
. 1 1 
1 . 1 
 at (7,9)
  _010: 
4 4 4 
. . 4 
. . 4 
 at (1,7)
  _01: rectangle with size (3,3) with mask 
0 0 0 
0 . . 
0 . . 
 with color yellow at (1,2)
  _011: rectangle with size (3,3) with mask 
0 0 0 
0 . . 
0 . . 
 with color yellow at (10,7)
  _0111: 
0 
 with color red at (2,3)
  + 4 delta pixels
diff: 
   (254.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _00: point with color red at (2,3)
  _0: rectangle with size (3,3) with mask 
0 0 0 
. . 0 
. . 0 
 with color yellow at (1,7)
  _01: rectangle with size (2,3) with mask 
. 0 0 
0 . 0 
 with color blue at (7,9)
  + 4 delta pixels
diff: 
! 25 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,13) and color black and layers
  _00: point with color red at (2,3)
  _0: rectangle with size (2,3) with mask 
. 0 0 
0 . 0 
 with color blue at (7,9)
  _01: rectangle with size (3,3) with mask 
0 0 0 
. . 0 
. . 0 
 with color yellow at (1,7)
  + 4 delta pixels
diff: 
! 28 wrong pixels (generated / expected)

TRAIN 3e980e27.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _00: point with color green at (1,5)
  _0: rectangle with size (3,3) with mask 
0 0 0 
. . 0 
. 0 . 
 with color cyan at (5,8)
  _01: rectangle with size (3,2) with mask 
. 0 
0 . 
0 0 
 with color blue at (1,1)
  + 5 delta pixels
diff: 
! 31 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,13) and color black and layers
  _00: point with color red at (1,9)
  _0: rectangle with size (3,3) with mask 
0 0 0 
. . 0 
. 0 . 
 with color cyan at (5,8)
  _01: rectangle with size (3,2) with mask 
. 0 
0 . 
0 0 
 with color blue at (1,1)
  + 5 delta pixels
diff: 
! 35 wrong pixels (generated / expected)

TEST 3e980e27.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 16.2 sec (16.2 sec/task)
bits-train-error = 5472.4 bits (5472.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-311] Checking task 3eda0437.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 114962.4 = 114964.7
DL output with Mo: L = 2.3 + 114962.4 = 114964.7
DL input+output M: L = 4.6 + 229924.8 = 229929.4

# learning a model for train pairs
2.000	
1.430	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.946	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.706	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.494	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.393	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.323	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.259	OUT ADD ^.layer_011 = ^.layer_01
0.226	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.189	IN  ADD ^.layer_010 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.170	OUT ADD ^.layer_0110 = ^.layer_0
0.163	OUT SPE ^.size = ^.size
0.161	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.159	OUT SPE ^.layer_01.shape.mask.size.i = ^.layer_01.shape.mask.size.i
0.158	OUT SPE ^.color = ^.color
0.157	OUT SPE ^.layer_0.pos.i = ^.layer_0.pos.i
0.155	OUT SPE ^.layer_0111.pos.i = '0
0.154	OUT SPE ^.layer_01.pos.i = ^.layer_010.pos.i
0.153	OUT SPE ^.layer_0.shape.mask.model = Full
0.051	

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.color and layers
  _0: rectangle with size (?,?) with model Full with color ? at (^.layer_0.pos.i,?)
  _01: rectangle with size (^.layer_01.shape.mask.size.i,?) with model ? with color ^.layer_01.shape.color at (^.layer_010.pos.i,?)
  _0110: ^.layer_0
  _011: ^.layer_01
  _0111: rectangle with size (?,?) with model ? with color ? at ('0,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 11732.9 = 11831.0
DL output with Mo: L = 136.4 + 5622.5 = 5758.9
DL input+output M: L = 234.5 + 17355.4 = 17589.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.color and layers
  _0: rectangle with size (?,?) with model Full with color ? at (^.layer_0.pos.i,?)
  _01: rectangle with size (^.layer_01.shape.mask.size.i,?) with model ? with color ^.layer_01.shape.color at (^.layer_010.pos.i,?)
  _0110: ^.layer_0
  _011: ^.layer_01
  _0111: rectangle with size (?,?) with model ? with color ? at ('0,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 51.7 = 149.8
DL output with Mo: L = 136.4 + 5622.5 = 5758.9
DL input+output M: L = 234.5 + 5674.2 = 5908.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,30) and color black and layers
  _0: rectangle with size (2,8) with mask 
0 0 0 0 . 0 0 0 
0 . 0 0 0 . 0 0 
 with color blue at (1,7)
  _010: rectangle with size (3,6) with mask 
. 0 0 0 0 0 
. 0 . 0 . . 
0 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (3,7) with mask 
0 0 . 0 . . 0 
. . 0 0 0 . 0 
. . 0 . . 0 0 
 with color blue at (0,17)
  + 10 delta pixels
diff: 
   (3.2 bits)
data: a background with size (3,30) and color black and layers
  _0: rectangle with size (2,4) with model Full with color pink at (1,15)
  _01: rectangle with size (3,6) with mask 
. 0 0 0 0 0 
. 0 . 0 . . 
0 0 . . . . 
 with color blue at (0,0)
  _0110: 
1 1 1 1 . 1 1 1 
1 . 1 1 1 . 1 1 
 at (1,7)
  _011: 
1 1 . 1 . . 1 
. . 1 1 1 . 1 
. . 1 . . 1 1 
 at (0,17)
  _0111: rectangle with size (3,5) with mask 
. . . 0 . 
0 0 0 0 0 
. 0 . . . 
 with color blue at (0,25)
  + 3 delta pixels
diff: 
   (228.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,30) and color blue and layers
  _0: rectangle with size (3,18) with mask 
. . . . . 0 0 0 0 0 0 0 0 0 0 . . 0 
0 . 0 0 0 . . . . 0 . . . 0 0 0 0 . 
0 0 0 . 0 . . . . . 0 . . 0 0 0 0 . 
 with color black at (0,2)
  _010: rectangle with size (3,4) with mask 
0 0 0 0 
0 . . . 
0 0 . . 
 with color black at (0,24)
  _01: rectangle with size (3,3) with mask 
. 0 0 
. . 0 
0 0 . 
 with color black at (0,20)
  + 8 delta pixels
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,30) and color black and layers
  _0: rectangle with size (2,8) with mask 
0 0 0 0 . 0 0 0 
0 . 0 0 0 . 0 0 
 with color blue at (1,7)
  _010: rectangle with size (3,7) with mask 
0 0 . 0 . . 0 
. . 0 0 0 . 0 
. . 0 . . 0 0 
 with color blue at (0,17)
  _01: rectangle with size (3,6) with mask 
. 0 0 0 0 0 
. 0 . 0 . . 
0 0 . . . . 
 with color blue at (0,0)
  + 10 delta pixels
diff: 
! 33 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,30) and color black and layers
  _0: rectangle with size (2,8) with mask 
0 0 0 0 . 0 0 0 
0 . 0 0 0 . 0 0 
 with color blue at (1,7)
  _010: rectangle with size (3,6) with mask 
. 0 0 0 0 0 
. 0 . 0 . . 
0 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (3,7) with mask 
0 0 . 0 . . 0 
. . 0 0 0 . 0 
. . 0 . . 0 0 
 with color blue at (0,17)
  + 10 delta pixels
diff: 
! 27 wrong pixels (generated / expected)

TRAIN 3eda0437.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (4,20) and color black and layers
  _0: rectangle with size (4,8) with mask 
. 0 0 0 0 . . . 
. 0 . 0 . 0 0 . 
0 . 0 . 0 0 . 0 
0 0 . 0 0 0 . . 
 with color blue at (0,7)
  _010: rectangle with size (4,4) with mask 
. 0 . 0 
. 0 0 0 
0 0 0 . 
0 0 0 0 
 with color blue at (0,16)
  _01: rectangle with size (4,7) with mask 
0 0 0 . . 0 0 
0 0 0 . 0 0 . 
. . 0 0 0 . . 
. 0 . 0 . . . 
 with color blue at (0,0)
diff: 
   (2.0 bits)
data: a background with size (4,20) and color black and layers
  _0: rectangle with size (1,7) with model Full with color blue at (0,5)
  _01: rectangle with size (4,4) with mask 
. 0 . 0 
. 0 0 0 
0 0 0 . 
0 0 0 0 
 with color blue at (0,16)
  _0110: 
. 1 1 1 1 . . . 
. 1 . 1 . 1 1 . 
1 . 1 . 1 1 . 1 
1 1 . 1 1 1 . . 
 at (0,7)
  _011: 
1 1 1 . . 1 1 
1 1 1 . 1 1 . 
. . 1 1 1 . . 
. 1 . 1 . . . 
 at (0,0)
  _0111: rectangle with size (2,3) with model Full with color pink at (0,14)
  + 1 delta pixels
diff: 
   (122.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,20) and color black and layers
  _0: rectangle with size (4,8) with mask 
. 0 0 0 0 . . . 
. 0 . 0 . 0 0 . 
0 . 0 . 0 0 . 0 
0 0 . 0 0 0 . . 
 with color blue at (0,7)
  _010: rectangle with size (4,7) with mask 
0 0 0 . . 0 0 
0 0 0 . 0 0 . 
. . 0 0 0 . . 
. 0 . 0 . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
. 0 . 0 
. 0 0 0 
0 0 0 . 
0 0 0 0 
 with color blue at (0,16)
diff: 
! 23 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,20) and color black and layers
  _0: rectangle with size (4,8) with mask 
. 0 0 0 0 . . . 
. 0 . 0 . 0 0 . 
0 . 0 . 0 0 . 0 
0 0 . 0 0 0 . . 
 with color blue at (0,7)
  _010: rectangle with size (4,4) with mask 
. 0 . 0 
. 0 0 0 
0 0 0 . 
0 0 0 0 
 with color blue at (0,16)
  _01: rectangle with size (4,7) with mask 
0 0 0 . . 0 0 
0 0 0 . 0 0 . 
. . 0 0 0 . . 
. 0 . 0 . . . 
 with color blue at (0,0)
diff: 
! 25 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (4,20) and color black and layers
  _0: rectangle with size (4,7) with mask 
0 0 0 . . 0 0 
0 0 0 . 0 0 . 
. . 0 0 0 . . 
. 0 . 0 . . . 
 with color blue at (0,0)
  _010: rectangle with size (4,8) with mask 
. 0 0 0 0 . . . 
. 0 . 0 . 0 0 . 
0 . 0 . 0 0 . 0 
0 0 . 0 0 0 . . 
 with color blue at (0,7)
  _01: rectangle with size (4,4) with mask 
. 0 . 0 
. 0 0 0 
0 0 0 . 
0 0 0 0 
 with color blue at (0,16)
diff: 
! 31 wrong pixels (generated / expected)

TRAIN 3eda0437.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (2,20) and color blue and layers
  _0: rectangle with size (2,10) with mask 
0 0 . 0 0 . 0 . 0 . 
. 0 0 . . 0 0 0 0 0 
 with color black at (0,10)
  _010: rectangle with size (2,7) with mask 
0 0 0 0 0 0 0 
0 0 0 0 0 . . 
 with color black at (0,2)
  _01: rectangle with size (1,1) with model Full with color black at (1,0)
diff: 
   (0.0 bits)
data: a background with size (2,20) and color blue and layers
  _0: rectangle with size (1,2) with model Full with color black at (0,7)
  _01: rectangle with size (1,5) with model Full with color black at (0,10)
  _0110: 
0 0 . 0 0 . 0 . 0 . 
. 0 0 . . 0 0 0 0 0 
 at (0,10)
  _011: 
0 
 at (1,0)
  _0111: rectangle with size (2,5) with model Full with color pink at (0,2)
  + 1 delta pixels
diff: 
   (107.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (2,20) and color blue and layers
  _0: rectangle with size (2,10) with mask 
0 0 . 0 0 . 0 . 0 . 
. 0 0 . . 0 0 0 0 0 
 with color black at (0,10)
  _010: rectangle with size (2,7) with mask 
0 0 0 0 0 0 0 
0 0 0 0 0 . . 
 with color black at (0,2)
  _01: rectangle with size (1,1) with model Full with color black at (1,0)
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (2,20) and color blue and layers
  _0: rectangle with size (2,7) with mask 
0 0 0 0 0 0 0 
0 0 0 0 0 . . 
 with color black at (0,2)
  _010: rectangle with size (2,10) with mask 
0 0 . 0 0 . 0 . 0 . 
. 0 0 . . 0 0 0 0 0 
 with color black at (0,10)
  _01: rectangle with size (1,1) with model Full with color black at (1,0)
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (2,20) and color blue and layers
  _0: rectangle with size (2,10) with mask 
0 0 . 0 0 . 0 . 0 . 
. 0 0 . . 0 0 0 0 0 
 with color black at (0,10)
  _010: rectangle with size (1,1) with model Full with color black at (1,0)
  _01: rectangle with size (2,7) with mask 
0 0 0 0 0 0 0 
0 0 0 0 0 . . 
 with color black at (0,2)
diff: 
! 14 wrong pixels (generated / expected)

TRAIN 3eda0437.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (4,20) and color black and layers
  _0: rectangle with size (4,12) with mask 
0 . . . 0 0 0 0 0 . . . 
0 0 . . 0 . . . . . 0 . 
. 0 . 0 . 0 . 0 . . . 0 
. 0 0 . . 0 0 0 0 0 0 0 
 with color blue at (0,5)
  _010: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color blue at (2,2)
  _01: rectangle with size (2,1) with model Full with color blue at (1,0)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,20) and color black and layers
  _0: rectangle with size (3,3) with model Full with color pink at (0,17)
  _01: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color blue at (2,2)
  _0110: 
1 . . . 1 1 1 1 1 . . . 
1 1 . . 1 . . . . . 1 . 
. 1 . 1 . 1 . 1 . . . 1 
. 1 1 . . 1 1 1 1 1 1 1 
 at (0,5)
  _011: 
1 
1 
 at (1,0)
  _0111: rectangle with size (1,1) with model Full with color blue at (0,2)
  + 1 delta pixels
diff: 
   (104.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,20) and color black and layers
  _0: rectangle with size (4,12) with mask 
0 . . . 0 0 0 0 0 . . . 
0 0 . . 0 . . . . . 0 . 
. 0 . 0 . 0 . 0 . . . 0 
. 0 0 . . 0 0 0 0 0 0 0 
 with color blue at (0,5)
  _010: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color blue at (2,2)
  _01: rectangle with size (2,1) with model Full with color blue at (1,0)
  + 2 delta pixels
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,20) and color blue and layers
  _0: rectangle with size (4,14) with mask 
0 0 0 . . . . . 0 0 0 0 0 0 
. 0 0 . 0 0 0 0 0 . 0 0 0 0 
. 0 . 0 . 0 . 0 0 0 . 0 0 0 
. . 0 0 . . . . . . . 0 0 . 
 with color black at (0,6)
  _010: rectangle with size (1,6) with model Full with color black at (3,0)
  _01: rectangle with size (4,6) with mask 
0 0 . 0 0 . 
. 0 0 0 0 . 
. 0 . . 0 0 
0 0 . 0 0 0 
 with color black at (0,0)
  + 1 delta pixels
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (4,20) and color black and layers
  _0: rectangle with size (4,12) with mask 
0 . . . 0 0 0 0 0 . . . 
0 0 . . 0 . . . . . 0 . 
. 0 . 0 . 0 . 0 . . . 0 
. 0 0 . . 0 0 0 0 0 0 0 
 with color blue at (0,5)
  _010: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color blue at (2,2)
  _01: rectangle with size (1,1) with model Full with color blue at (0,2)
  + 3 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TRAIN 3eda0437.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,24) and color black and layers
  _0: rectangle with size (4,15) with mask 
. . . . . 0 . . . . 0 0 . 0 . 
. . . 0 0 . 0 0 . 0 0 0 0 0 . 
0 0 . 0 . . . 0 0 . . 0 0 0 0 
0 0 0 0 0 . 0 0 . 0 0 . . . 0 
 with color blue at (0,9)
  _010: rectangle with size (3,5) with mask 
0 . 0 . 0 
0 0 0 0 . 
. 0 0 0 . 
 with color blue at (0,4)
  _01: rectangle with size (1,2) with model Full with color blue at (3,2)
  + 1 delta pixels
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,24) and color black and layers
  _0: rectangle with size (3,5) with mask 
0 . 0 . 0 
0 0 0 0 . 
. 0 0 0 . 
 with color blue at (0,4)
  _010: rectangle with size (4,15) with mask 
. . . . . 0 . . . . 0 0 . 0 . 
. . . 0 0 . 0 0 . 0 0 0 0 0 . 
0 0 . 0 . . . 0 0 . . 0 0 0 0 
0 0 0 0 0 . 0 0 . 0 0 . . . 0 
 with color blue at (0,9)
  _01: rectangle with size (1,2) with model Full with color blue at (3,2)
  + 1 delta pixels
diff: 
! 43 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (4,24) and color blue and layers
  _0: rectangle with size (4,23) with mask 
0 0 0 0 . . . 0 . 0 0 0 0 0 . 0 0 0 0 . . . . 
. 0 0 0 . . . . 0 0 0 0 . . 0 . . 0 . . . . . 
0 0 0 0 0 . . . 0 . . 0 . 0 0 0 . . 0 0 . . . 
0 0 . . 0 0 0 0 0 . . . . . 0 . . 0 . . 0 0 0 
 with color black at (0,0)
  _010: rectangle with size (2,1) with model Full with color black at (0,23)
  _01: rectangle with size (1,1) with model Full with color black at (0,5)
  + 1 delta pixels
diff: 
! 14 wrong pixels (generated / expected)

TEST 3eda0437.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 55.8 sec (55.8 sec/task)
bits-train-error = 5622.5 bits (5622.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-310] Checking task 3f7978a0.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 129351.0 = 129353.4
DL output with Mo: L = 2.3 + 35020.9 = 35023.2
DL input+output M: L = 4.6 + 164371.9 = 164376.6

# learning a model for train pairs
2.000	
1.207	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.640	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.486	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.435	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.395	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.367	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.341	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.317	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.303	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.290	OUT ADD ^.layer_0110 = ^.layer_011.shape at (?,?)
0.272	OUT ADD ^.layer_010 = ^.layer_01.shape at (?,?)
0.263	OUT SPE ^.layer_0111.shape.mask = 
0 

0.255	OUT SPE ^.layer_01.pos = '(0, 0)
0.250	IN  ADD ^.layer_00 = point with color ? at (?,?)
0.239	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.234	OUT SPE ^.layer_0111.shape.color = ^.layer_0111.shape.color
0.229	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.224	OUT SPE ^.layer_01.shape.color = cyan
0.220	OUT SPE ^.layer_011.shape.color = cyan
0.216	OUT SPE ^.layer_010.pos.i = 1
0.213	OUT SPE ^.layer_01.shape.mask.size.j = 1
0.210	OUT SPE ^.layer_011.shape.mask.size.j = 1
0.206	OUT SPE ^.layer_0111.pos.j = 2
0.204	OUT SPE ^.layer_0.shape.mask.model = Full
0.197	OUT SPE ^.size.i = ^.layer_0.shape.mask.size.i + 2
0.194	OUT SPE ^.layer_0111.pos.i = span(^.layer_01.pos.i, ^.layer_0111.pos.i)
0.190	OUT SPE ^.layer_010.pos = '(1, 0)
0.186	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_011.shape.mask.size.i - 2
0.182	OUT SPE ^.layer_0.pos.i = ^.layer_01.pos.i / '2
0.179	OUT SPE ^.layer_0110.pos.j = span(^.layer_0.pos.j, ^.layer_01.pos.j) - 1
0.176	OUT SPE ^.layer_011.pos.j = ^.layer_0.pos.j - ^.layer_0111.shape.mask.size.j
0.173	OUT SPE ^.layer_0.pos.j = ^.layer_00.pos.i + ^.layer_0.shape.mask.size.i
0.171	OUT SPE ^.layer_0110.pos.i = average(^.layer_011.pos.i, ^.layer_00.pos.i) - 1
0.168	OUT SPE ^.layer_0.shape.mask.size.j = ^.layer_0111.shape.mask.size.j
0.042	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (^.layer_0.shape.mask.size.i + 2,?) and color ? and layers
  _0: rectangle with size (^.layer_011.shape.mask.size.i - 2,^.layer_0111.shape.mask.size.j) with model Full with color ^.layer_0.shape.color at (^.layer_01.pos.i / '2,^.layer_00.pos.i + ^.layer_0.shape.mask.size.i)
  _010: ^.layer_01.shape at '(1, 0)
  _01: rectangle with size (?,1) with model ? with color cyan at '(0, 0)
  _0110: ^.layer_011.shape at (average(^.layer_011.pos.i, ^.layer_00.pos.i) - 1,span(^.layer_0.pos.j, ^.layer_01.pos.j) - 1)
  _011: rectangle with size (?,1) with model ? with color cyan at (?,^.layer_0.pos.j - ^.layer_0111.shape.mask.size.j)
  _0111: 
0 
 with color ^.layer_0111.shape.color at (span(^.layer_01.pos.i, ^.layer_0111.pos.i),2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 143.6 + 16260.2 = 16403.8
DL output with Mo: L = 459.1 + 978.4 = 1437.6
DL input+output M: L = 602.7 + 17238.6 = 17841.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (^.layer_0.shape.mask.size.i + 2,?) and color ? and layers
  _0: rectangle with size (^.layer_011.shape.mask.size.i - 2,^.layer_0111.shape.mask.size.j) with model Full with color ^.layer_0.shape.color at (^.layer_01.pos.i / '2,^.layer_00.pos.i + ^.layer_0.shape.mask.size.i)
  _010: ^.layer_01.shape at '(1, 0)
  _01: rectangle with size (?,1) with model ? with color cyan at '(0, 0)
  _0110: ^.layer_011.shape at (average(^.layer_011.pos.i, ^.layer_00.pos.i) - 1,span(^.layer_0.pos.j, ^.layer_01.pos.j) - 1)
  _011: rectangle with size (?,1) with model ? with color cyan at (?,^.layer_0.pos.j - ^.layer_0111.shape.mask.size.j)
  _0111: 
0 
 with color ^.layer_0111.shape.color at (span(^.layer_01.pos.i, ^.layer_0111.pos.i),2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 143.6 + 20.0 = 163.6
DL output with Mo: L = 459.1 + 978.4 = 1437.6
DL input+output M: L = 602.7 + 998.4 = 1601.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _00: point with color cyan at (1,1)
  _0: rectangle with size (3,1) with model Full with color grey at (2,1)
  _01: rectangle with size (3,1) with model Full with color grey at (2,5)
  _011: rectangle with size (5,1) with model Full with color cyan at (1,5)
  _0111: rectangle with size (1,1) with model Full with color cyan at (1,8)
  + 6 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (3,1) with model Full with color grey at (1,4)
  _010: 
5#
5#
5#
 at (1,0)
  _01: rectangle with size (1,1) with model Full with color cyan at (0,0)
  _0110: 
8 
8 
8 
8 
8 
 at (0,4)
  _011: rectangle with size (1,1) with model Full with color cyan at (4,0)
  _0111: 
0 
 with color cyan at (2,2)
diff: 
   (27.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _00: point with color cyan at (1,1)
  _0: rectangle with size (3,1) with model Full with color grey at (2,1)
  _01: rectangle with size (3,1) with model Full with color grey at (2,5)
  _011: rectangle with size (5,1) with model Full with color cyan at (1,5)
  _0111: rectangle with size (1,1) with model Full with color cyan at (1,8)
  + 6 delta pixels
diff: 
! size mismatch, 5x10 instead of 5x5

TRAIN 3f7978a0.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,11) and color black and layers
  _00: point with color cyan at (0,1)
  _0: rectangle with size (3,3) with mask 
. . 0 
. 0 0 
0 . . 
 with color cyan at (1,8)
  _01: rectangle with size (3,1) with model Full with color grey at (4,2)
  _011: rectangle with size (3,1) with model Full with color grey at (4,8)
  _0111: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color cyan at (7,8)
  + 9 delta pixels
diff: 
   (2.0 bits)
data: a background with size (5,7) and color black and layers
  _0: rectangle with size (1,2) with model Full with color cyan at (2,3)
  _010: 
5#
5#
5#
 at (1,0)
  _01: rectangle with size (5,1) with model Full with color cyan at (0,0)
  _0110: 
5#
5#
5#
 at (1,6)
  _011: rectangle with size (5,1) with model Full with color cyan at (0,6)
  _0111: 
0 
 with color cyan at (4,2)
diff: 
   (37.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,11) and color black and layers
  _00: point with color cyan at (0,1)
  _0: rectangle with size (3,3) with mask 
. . 0 
. 0 0 
0 . . 
 with color cyan at (1,8)
  _01: rectangle with size (3,1) with model Full with color grey at (4,2)
  _011: rectangle with size (3,1) with model Full with color grey at (4,8)
  _0111: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color cyan at (7,8)
  + 9 delta pixels
diff: 
! size mismatch, 5x10 instead of 5x7

TRAIN 3f7978a0.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (11,13) and color black and layers
  _00: point with color cyan at (0,9)
  _0: rectangle with size (4,1) with model Full with color grey at (3,3)
  _01: rectangle with size (4,1) with model Full with color grey at (3,7)
  _011: rectangle with size (6,1) with model Full with color cyan at (2,3)
  _0111: rectangle with size (8,1) with model Full with color cyan at (2,7)
  + 13 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,5) and color black and layers
  _0: rectangle with size (4,1) with model Full with color grey at (1,4)
  _010: 
5#
5#
5#
5#
 at (1,0)
  _01: rectangle with size (6,1) with model Full with color cyan at (0,0)
  _0110: 
8 
8 
8 
8 
8 
8 
 at (0,4)
  _011: rectangle with size (1,1) with model Full with color cyan at (4,2)
  _0111: 
0 
 with color cyan at (2,2)
diff: 
   (32.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,13) and color black and layers
  _00: point with color cyan at (0,9)
  _0: rectangle with size (4,1) with model Full with color grey at (3,3)
  _01: rectangle with size (4,1) with model Full with color grey at (3,7)
  _011: rectangle with size (6,1) with model Full with color cyan at (2,3)
  _0111: rectangle with size (8,1) with model Full with color cyan at (2,7)
  + 13 delta pixels
diff: 
! size mismatch, 6x10 instead of 6x5
>> Trial 2
data: a background with size (11,13) and color black and layers
  _00: point with color cyan at (0,9)
  _0: rectangle with size (4,1) with model Full with color grey at (3,3)
  _01: rectangle with size (4,1) with model Full with color grey at (3,7)
  _011: rectangle with size (8,1) with model Full with color cyan at (2,7)
  _0111: rectangle with size (6,1) with model Full with color cyan at (2,3)
  + 13 delta pixels
diff: 
! size mismatch, 6x10 instead of 6x5

TRAIN 3f7978a0.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
undefined expression: Average: not an integer

TEST 3f7978a0.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 59.3 sec (59.3 sec/task)
bits-train-error = 978.4 bits (978.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-309] Checking task 40853293.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 334634.1 = 334636.4
DL output with Mo: L = 2.3 + 334634.1 = 334636.4
DL input+output M: L = 4.6 + 669268.1 = 669272.8

# learning a model for train pairs
2.000	
1.027	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.116	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.092	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.073	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.059	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.047	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.039	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.037	OUT SPE ^.size = ^.size
0.036	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.035	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.033	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.032	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.031	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.029	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.028	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.027	IN  ADD ^.layer_01111111 = point with color ? at (?,?)
0.026	OUT SPE ^.layer_0111.shape.mask = 
0 0 0 0 0 0 

0.025	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.024	OUT SPE ^.layer_01.pos = ^.layer_01.pos
0.024	OUT SPE ^.layer_01111.pos = ^.layer_0111.pos
0.023	OUT SPE ^.layer_0111.pos = ^.layer_01111111.pos
0.022	OUT SPE ^.layer_011.pos = ^.layer_0111111.pos
0.022	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.021	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.021	IN  SPE ^.layer_01.shape.color = green
0.021	IN  SPE ^.layer_011.shape.color = green
0.020	OUT SPE ^.layer_01111.shape.color = ^.layer_0111.shape.color
0.020	OUT SPE ^.layer_0.shape.mask.size.j = 1
0.020	OUT SPE ^.layer_01.shape.mask.size = span(^.layer_01.pos, ^.layer_011.pos)
0.019	OUT SPE ^.layer_0111.shape.color = ^.layer_01111111.shape.color
0.019	OUT SPE ^.layer_011.shape.color = ^.layer_0111111.shape.color
0.019	OUT SPE ^.layer_011.shape.mask.size.j = 1
0.018	OUT SPE ^.layer_011.shape.mask.size.i = area(^.layer_011.shape.mask) - ^.layer_01111111.pos.j - ^.layer_011.pos.j
0.018	OUT SPE ^.layer_0.shape.mask.model = Full
0.018	OUT SPE ^.layer_01.shape.mask.model = Full
0.018	OUT SPE ^.layer_011.shape.mask.model = Full
0.018	OUT SPE ^.layer_01111.shape.mask.model = Full
0.018	IN  SPE ^.color = black
0.018	OUT SPE ^.color = black
0.017	OUT SPE ^.layer_01111.shape.mask.size.j = area(^) - ^.layer_011.pos.j - ^.layer_01111111.pos.j
0.003	
0.003	IN  GEN ^.layer_011.shape.color = ?
0.003	IN  GEN ^.layer_01.shape.color = ?
0.003	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,1) with model Full with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: rectangle with size span(^.layer_01.pos, ^.layer_011.pos) with model Full with color ^.layer_01.shape.color at ^.layer_01.pos
  _011: rectangle with size (area(^.layer_011.shape.mask) - ^.layer_01111111.pos.j - ^.layer_011.pos.j,1) with model Full with color ^.layer_0111111.shape.color at ^.layer_0111111.pos
  _0111: 
0 0 0 0 0 0 
 with color ^.layer_01111111.shape.color at ^.layer_01111111.pos
  _01111: rectangle with size (?,area(^) - ^.layer_011.pos.j - ^.layer_01111111.pos.j) with model Full with color ^.layer_0111.shape.color at ^.layer_0111.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)
  _01: point with color green at (?,?)
  _011: point with color green at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)

DL input  with Mi: L = 164.1 + 4954.7 = 5118.7
DL output with Mo: L = 379.6 + 319.7 = 699.2
DL input+output M: L = 543.6 + 5274.3 = 5818.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,1) with model Full with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: rectangle with size span(^.layer_01.pos, ^.layer_011.pos) with model Full with color ^.layer_01.shape.color at ^.layer_01.pos
  _011: rectangle with size (area(^.layer_011.shape.mask) - ^.layer_01111111.pos.j - ^.layer_011.pos.j,1) with model Full with color ^.layer_0111111.shape.color at ^.layer_0111111.pos
  _0111: 
0 0 0 0 0 0 
 with color ^.layer_01111111.shape.color at ^.layer_01111111.pos
  _01111: rectangle with size (?,area(^) - ^.layer_011.pos.j - ^.layer_01111111.pos.j) with model Full with color ^.layer_0111.shape.color at ^.layer_0111.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)

DL input  with Mi: L = 157.3 + 0.0 = 157.3
DL output with Mo: L = 379.6 + 319.7 = 699.2
DL input+output M: L = 536.9 + 319.7 = 856.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (30,20) and color black and layers
  _0: point with color red at (2,6)
  _01: point with color green at (6,3)
  _011: point with color green at (6,11)
  _0111: point with color cyan at (12,14)
  _01111: point with color red at (13,6)
  _011111: point with color cyan at (17,14)
  _0111111: point with color pink at (18,4)
  _01111111: point with color grey at (20,2)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (30,20) and color black and layers
  _0: rectangle with size (12,1) with model Full with color red at (2,6)
  _01: rectangle with size (1,9) with model Full with color green at (6,3)
  _011: rectangle with size (10,1) with model Full with color pink at (18,4)
  _0111: 
0 0 0 0 0 0 
 with color grey at (20,2)
  _01111: rectangle with size (6,1) with model Full with color cyan at (12,14)
diff: 
   (19.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (30,20) and color black and layers
  _0: point with color red at (2,6)
  _01: point with color green at (6,3)
  _011: point with color green at (6,11)
  _0111: point with color cyan at (12,14)
  _01111: point with color red at (13,6)
  _011111: point with color cyan at (17,14)
  _0111111: point with color pink at (18,4)
  _01111111: point with color grey at (20,2)
  + 2 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (30,20) and color black and layers
  _0: point with color red at (2,6)
  _01: point with color green at (6,3)
  _011: point with color green at (6,11)
  _0111: point with color cyan at (12,14)
  _01111: point with color red at (13,6)
  _011111: point with color cyan at (17,14)
  _0111111: point with color pink at (18,4)
  _01111111: point with color grey at (20,7)
  + 2 delta pixels
diff: 
! 38 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (30,20) and color black and layers
  _0: point with color red at (2,6)
  _01: point with color green at (6,3)
  _011: point with color green at (6,11)
  _0111: point with color cyan at (12,14)
  _01111: point with color red at (13,6)
  _011111: point with color cyan at (17,14)
  _0111111: point with color grey at (20,2)
  _01111111: point with color pink at (18,4)
  + 2 delta pixels
diff: 
! 43 wrong pixels (generated / expected)

TRAIN 40853293.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (20,10) and color black and layers
  _0: point with color yellow at (2,3)
  _01: point with color green at (4,2)
  _011: point with color green at (4,7)
  _0111: point with color orange at (8,2)
  _01111: point with color orange at (8,5)
  _011111: point with color yellow at (10,3)
  _0111111: point with color brown at (12,5)
  _01111111: point with color cyan at (14,1)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,10) and color black and layers
  _0: rectangle with size (9,1) with model Full with color yellow at (2,3)
  _01: rectangle with size (1,6) with model Full with color green at (4,2)
  _011: rectangle with size (7,1) with model Full with color brown at (12,5)
  _0111: 
0 0 0 0 0 0 
 with color cyan at (14,1)
  _01111: rectangle with size (1,4) with model Full with color orange at (8,2)
diff: 
   (13.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,10) and color black and layers
  _0: point with color yellow at (2,3)
  _01: point with color green at (4,2)
  _011: point with color green at (4,7)
  _0111: point with color orange at (8,2)
  _01111: point with color orange at (8,5)
  _011111: point with color yellow at (10,3)
  _0111111: point with color brown at (12,5)
  _01111111: point with color cyan at (14,1)
  + 2 delta pixels
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,10) and color black and layers
  _0: point with color yellow at (2,3)
  _01: point with color green at (4,2)
  _011: point with color green at (4,7)
  _0111: point with color orange at (8,2)
  _01111: point with color orange at (8,5)
  _011111: point with color yellow at (10,3)
  _0111111: point with color brown at (12,5)
  _01111111: point with color cyan at (14,6)
  + 2 delta pixels
diff: 
! 30 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (20,10) and color black and layers
  _0: point with color yellow at (2,3)
  _01: point with color green at (4,2)
  _011: point with color green at (4,7)
  _0111: point with color orange at (8,2)
  _01111: point with color orange at (8,5)
  _011111: point with color yellow at (10,3)
  _0111111: point with color cyan at (14,1)
  _01111111: point with color brown at (12,5)
  + 2 delta pixels
diff: 
! 34 wrong pixels (generated / expected)

TRAIN 40853293.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
Invalid_argument("Model2.mask_rectangle: negative or null mask size")

TEST 40853293.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 42.5 sec (42.5 sec/task)
bits-train-error = 319.7 bits (319.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-308] Checking task 4093f84a.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 239423.3 = 239425.6
DL output with Mo: L = 2.3 + 239423.3 = 239425.6
DL input+output M: L = 4.6 + 478846.6 = 478851.2

# learning a model for train pairs
2.000	
1.311	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.621	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.329	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.073	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.070	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.067	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.064	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.061	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.059	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.056	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.053	IN  ADD ^.layer_01111111 = point with color ? at (?,?)
0.050	OUT SPE ^.size = ^.size
0.049	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.049	IN  SPE ^.layer_0.shape.color = grey
0.048	OUT SPE ^.layer_0.pos.j = min(^.layer_0.pos.j, ^.layer_0111.pos.j)
0.048	OUT SPE ^.layer_0.pos.i = ^.layer_0111111.pos.i - ^.layer_01111111.pos.i - ^.layer_0.pos.i
0.047	IN  SPE ^.layer_0.shape.mask.model = Full
0.047	IN  SPE ^.color = black
0.047	OUT SPE ^.color = black
0.014	
0.014	IN  GEN ^.layer_0.shape.color = ?
0.014	IN  GEN ^.layer_0.shape.mask.model = ?
0.014	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (^.layer_0111111.pos.i - ^.layer_01111111.pos.i - ^.layer_0.pos.i,min(^.layer_0.pos.j, ^.layer_0111.pos.j))
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color grey at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)

DL input  with Mi: L = 171.1 + 7842.3 = 8013.4
DL output with Mo: L = 125.7 + 3025.4 = 3151.1
DL input+output M: L = 296.7 + 10867.8 = 11164.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (^.layer_0111111.pos.i - ^.layer_01111111.pos.i - ^.layer_0.pos.i,min(^.layer_0.pos.j, ^.layer_0111.pos.j))
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)

DL input  with Mi: L = 167.1 + 20.0 = 187.1
DL output with Mo: L = 125.7 + 3025.4 = 3151.1
DL input+output M: L = 292.8 + 3045.4 = 3338.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (14,14) and color black and layers
  _0: rectangle with size (4,14) with model Full with color grey at (5,0)
  _01: point with color red at (0,8)
  _011: point with color red at (2,2)
  _0111: point with color red at (3,10)
  _01111: point with color red at (9,9)
  _011111: point with color red at (10,1)
  _0111111: point with color red at (11,4)
  _01111111: point with color red at (12,11)
diff: 
   (0.0 bits)
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (6,14) with mask 
. . 0 . . . . . 0 . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. 0 . . 0 . . . . 0 . 0 . . 
 with color grey at (4,0)
diff: 
   (91.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (4,14) with model Full with color grey at (5,0)
  _01: point with color red at (0,8)
  _011: point with color red at (2,2)
  _0111: point with color red at (3,10)
  _01111: point with color red at (9,9)
  _011111: point with color red at (10,1)
  _0111111: point with color red at (11,4)
  _01111111: point with color red at (12,11)
diff: 
! 63 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (4,14) with model Full with color grey at (5,0)
  _01: point with color red at (0,8)
  _011: point with color red at (2,2)
  _0111: point with color red at (3,10)
  _01111: point with color red at (9,9)
  _011111: point with color red at (10,1)
  _0111111: point with color red at (12,11)
  _01111111: point with color red at (11,4)
diff: 
! 59 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (4,14) with model Full with color grey at (5,0)
  _01: point with color red at (0,8)
  _011: point with color red at (2,2)
  _0111: point with color red at (3,10)
  _01111: point with color red at (9,9)
  _011111: point with color red at (11,4)
  _0111111: point with color red at (10,1)
  _01111111: point with color red at (12,11)
diff: 
! 67 wrong pixels (generated / expected)

TRAIN 4093f84a.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (14,14) and color black and layers
  _0: rectangle with size (14,5) with model Full with color grey at (0,4)
  _01: point with color green at (0,12)
  _011: point with color green at (1,9)
  _0111: point with color green at (2,3)
  _01111: point with color green at (2,11)
  _011111: point with color green at (4,0)
  _0111111: point with color green at (6,10)
  _01111111: point with color green at (6,12)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (14,8) with mask 
. 0 0 0 0 0 0 . 
. 0 0 0 0 0 0 . 
0 0 0 0 0 0 0 . 
. 0 0 0 0 0 . . 
0 0 0 0 0 0 . . 
. 0 0 0 0 0 . . 
. 0 0 0 0 0 0 0 
0 0 0 0 0 0 . . 
. 0 0 0 0 0 . . 
0 0 0 0 0 0 0 . 
. 0 0 0 0 0 . . 
. 0 0 0 0 0 . . 
. 0 0 0 0 0 0 . 
. 0 0 0 0 0 . . 
 with color grey at (0,3)
diff: 
   (119.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (14,5) with model Full with color grey at (0,4)
  _01: point with color green at (0,12)
  _011: point with color green at (1,9)
  _0111: point with color green at (2,3)
  _01111: point with color green at (2,11)
  _011111: point with color green at (4,0)
  _0111111: point with color green at (6,10)
  _01111111: point with color green at (6,12)
  + 4 delta pixels
diff: 
! 81 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (14,5) with model Full with color grey at (0,4)
  _01: point with color green at (0,12)
  _011: point with color green at (1,9)
  _0111: point with color green at (2,3)
  _01111: point with color green at (2,11)
  _011111: point with color green at (4,0)
  _0111111: point with color green at (6,10)
  _01111111: point with color green at (7,1)
  + 4 delta pixels
diff: 
! 81 wrong pixels (generated / expected)

TRAIN 4093f84a.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (14,14) and color black and layers
  _0: rectangle with size (2,14) with model Full with color grey at (7,0)
  _01: point with color blue at (1,7)
  _011: point with color blue at (3,3)
  _0111: point with color blue at (3,7)
  _01111: point with color blue at (3,12)
  _011111: point with color blue at (5,8)
  _0111111: point with color blue at (9,1)
  _01111111: point with color blue at (11,3)
  + 2 delta pixels
diff: 
   (2.0 bits)
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (5,14) with mask 
. . . . . . . 0 . . . . . . 
. . . 0 . . . 0 0 . . . 0 . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. 0 . 0 . . . . 0 . . 0 . . 
 with color grey at (5,0)
diff: 
   (92.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (2,14) with model Full with color grey at (7,0)
  _01: point with color blue at (1,7)
  _011: point with color blue at (3,3)
  _0111: point with color blue at (3,7)
  _01111: point with color blue at (3,12)
  _011111: point with color blue at (5,8)
  _0111111: point with color blue at (9,1)
  _01111111: point with color blue at (10,11)
  + 2 delta pixels
diff: 
! 37 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (2,14) with model Full with color grey at (7,0)
  _01: point with color blue at (1,7)
  _011: point with color blue at (3,3)
  _0111: point with color blue at (3,7)
  _01111: point with color blue at (3,12)
  _011111: point with color blue at (5,8)
  _0111111: point with color blue at (9,1)
  _01111111: point with color blue at (11,3)
  + 2 delta pixels
diff: 
! 41 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (2,14) with model Full with color grey at (7,0)
  _01: point with color blue at (1,7)
  _011: point with color blue at (3,3)
  _0111: point with color blue at (3,7)
  _01111: point with color blue at (3,12)
  _011111: point with color blue at (5,8)
  _0111111: point with color blue at (10,11)
  _01111111: point with color blue at (9,1)
  + 2 delta pixels
diff: 
! 35 wrong pixels (generated / expected)

TRAIN 4093f84a.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (14,2) with model Full with color grey at (0,5)
  _01: point with color yellow at (1,2)
  _011: point with color yellow at (1,9)
  _0111: point with color yellow at (3,3)
  _01111: point with color yellow at (4,1)
  _011111: point with color yellow at (6,7)
  _0111111: point with color yellow at (6,11)
  _01111111: point with color yellow at (11,1)
  + 3 delta pixels
diff: 
! 38 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (14,2) with model Full with color grey at (0,5)
  _01: point with color yellow at (1,2)
  _011: point with color yellow at (1,9)
  _0111: point with color yellow at (3,3)
  _01111: point with color yellow at (4,1)
  _011111: point with color yellow at (6,7)
  _0111111: point with color yellow at (11,1)
  _01111111: point with color yellow at (6,11)
  + 3 delta pixels
diff: 
! 42 wrong pixels (generated / expected)

TEST 4093f84a.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 11.2 sec (11.2 sec/task)
bits-train-error = 3025.4 bits (3025.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-307] Checking task 41e4d17e.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 184013.0 = 184015.3
DL output with Mo: L = 2.3 + 184013.0 = 184015.3
DL input+output M: L = 4.6 + 368025.9 = 368030.6

# learning a model for train pairs
2.000	
1.111	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.383	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.316	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.245	OUT ADD ^.layer_0 = ^.layer_0
0.185	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.132	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.107	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.084	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.075	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.056	OUT ADD ^.layer_011111 = ^.layer_01
0.053	OUT SPE ^.size = ^.size
0.051	OUT SPE ^.layer_01.shape.mask = 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 

0.027	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: ^.layer_0
  _01: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 4559.9 = 4630.1
DL output with Mo: L = 138.0 + 4701.6 = 4839.5
DL input+output M: L = 208.2 + 9261.4 = 9469.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: ^.layer_0
  _01: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 138.0 + 4701.6 = 4839.5
DL input+output M: L = 208.2 + 4701.6 = 4909.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (1,5) with model Full with color blue at (1,3)
  _01: rectangle with size (1,5) with model Full with color blue at (5,3)
  + 6 delta pixels
diff: 
   (0.0 bits)
data: a background with size (15,15) and color cyan and layers
  _0: 
1 1 1 1 1 
 at (1,3)
  _01: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color pink at (0,5)
  _011: rectangle with size (5,1) with model Full with color blue at (1,3)
  _0111: rectangle with size (5,1) with model Full with color blue at (1,7)
  _01111: rectangle with size (1,15) with model Full with color pink at (3,0)
  _011111: 
1 1 1 1 1 
 at (5,3)
  + 1 delta pixels
diff: 
   (169.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (1,5) with model Full with color blue at (1,3)
  _01: rectangle with size (1,5) with model Full with color blue at (5,3)
  + 6 delta pixels
diff: 
! 215 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (5,1) with model Full with color blue at (1,3)
  _01: rectangle with size (5,1) with model Full with color blue at (1,7)
  + 6 delta pixels
diff: 
! 215 wrong pixels (generated / expected)

TRAIN 41e4d17e.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (5,5) with model Border with color blue at (3,3)
  _01: rectangle with size (5,5) with model Border with color blue at (9,8)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color cyan and layers
  _0: 
1 1 1 1 1 
1 . . . 1 
1 . . . 1 
1 . . . 1 
1 1 1 1 1 
 at (3,3)
  _01: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color pink at (0,5)
  _011: rectangle with size (15,1) with model Full with color pink at (0,10)
  _0111: rectangle with size (1,15) with model Full with color pink at (5,0)
  _01111: rectangle with size (1,15) with model Full with color pink at (11,0)
  _011111: 
1 1 1 1 1 
1 . . . 1 
1 . . . 1 
1 . . . 1 
1 1 1 1 1 
 at (9,8)
  + 4 delta pixels
diff: 
   (300.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (5,5) with model Border with color blue at (3,3)
  _01: rectangle with size (5,5) with model Border with color blue at (9,8)
diff: 
! 193 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (5,5) with model Border with color blue at (3,3)
  _01: rectangle with size (5,5) with model Full with color blue at (9,8)
  + 9 delta pixels
diff: 
! 193 wrong pixels (generated / expected)

TRAIN 41e4d17e.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (5,5) with model Border with color blue at (1,6)
  _01: rectangle with size (5,5) with model Border with color blue at (9,3)
diff: 
! 193 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (5,5) with model Border with color blue at (1,6)
  _01: rectangle with size (5,5) with model Full with color blue at (9,3)
  + 9 delta pixels
diff: 
! 193 wrong pixels (generated / expected)

TEST 41e4d17e.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.7 sec (59.7 sec/task)
bits-train-error = 4701.6 bits (4701.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-306] Checking task 4258a5f9.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 64315.6 = 64317.9
DL output with Mo: L = 2.3 + 64315.6 = 64317.9
DL input+output M: L = 4.6 + 128631.2 = 128635.9

# learning a model for train pairs
2.000	
1.051	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.445	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.241	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.183	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.149	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.134	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.127	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.120	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.113	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.107	OUT SPE ^.size = ^.size
0.104	OUT SPE ^.layer_0.pos = projJ(^.layer_01.pos) - (0, 1)
0.103	IN  SPE ^.layer_0.shape.color = grey
0.101	IN  SPE ^.layer_01.shape.color = grey
0.099	IN  SPE ^.layer_011.shape.color = grey
0.098	OUT SPE ^.layer_0.shape.color = blue
0.096	OUT SPE ^.layer_01.pos.i = 1
0.094	OUT SPE ^.layer_011.pos.i = center(^.layer_011)
0.093	OUT SPE ^.layer_0111.pos.i = ^.layer_011.pos.i + area(^)
0.091	OUT SPE ^.layer_011.pos.j = average(^.layer_01.pos.j, ^.layer_011.pos.j) + 1
0.090	OUT SPE ^.layer_0111.pos.j = span(^.layer_0.pos.j, ^.layer_011.pos.j) - 3
0.089	OUT SPE ^.layer_01.shape.mask.model = Full
0.089	OUT SPE ^.layer_011.shape.mask.model = Full
0.088	OUT SPE ^.layer_0111.shape.mask.model = Full
0.087	IN  SPE ^.color = black
0.086	OUT SPE ^.color = black
0.063	
0.063	IN  GEN ^.layer_011.shape.color = ?
0.063	IN  GEN ^.layer_01.shape.color = ?
0.063	IN  GEN ^.layer_0.shape.color = ?
0.063	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color blue at projJ(^.layer_01.pos) - (0, 1)
  _01: rectangle with size (?,?) with model Full with color ? at (1,?)
  _011: rectangle with size (?,?) with model Full with color ? at (center(^.layer_011),average(^.layer_01.pos.j, ^.layer_011.pos.j) + 1)
  _0111: rectangle with size (?,?) with model Full with color ? at (^.layer_011.pos.i + area(^),span(^.layer_0.pos.j, ^.layer_011.pos.j) - 3)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color grey at (?,?)
  _01: point with color grey at (?,?)
  _011: point with color grey at (?,?)

DL input  with Mi: L = 78.8 + 1509.4 = 1588.1
DL output with Mo: L = 257.6 + 3695.0 = 3952.5
DL input+output M: L = 336.3 + 5204.3 = 5540.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color blue at projJ(^.layer_01.pos) - (0, 1)
  _01: rectangle with size (?,?) with model Full with color ? at (1,?)
  _011: rectangle with size (?,?) with model Full with color ? at (center(^.layer_011),average(^.layer_01.pos.j, ^.layer_011.pos.j) + 1)
  _0111: rectangle with size (?,?) with model Full with color ? at (^.layer_011.pos.i + area(^),span(^.layer_0.pos.j, ^.layer_011.pos.j) - 3)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 68.7 + 51.7 = 120.4
DL output with Mo: L = 257.6 + 3695.0 = 3952.5
DL input+output M: L = 326.2 + 3746.7 = 4072.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,6)
  _01: point with color grey at (7,1)
  _011: point with color grey at (4,3)
diff: 
   (2.0 bits)
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,8) with mask 
. . . . . 0 0 0 
. . . . . 0 . 0 
. . . . . 0 0 0 
. . 0 0 0 . . . 
. . 0 . 0 . . . 
. . 0 0 0 . . . 
0 0 0 . . . . . 
0 . 0 . . . . . 
0 0 0 . . . . . 
 with color blue at (0,0)
  _01: rectangle with size (1,1) with model Full with color grey at (1,6)
  _011: rectangle with size (1,1) with model Full with color grey at (4,3)
  _0111: rectangle with size (1,1) with model Full with color grey at (7,1)
diff: 
   (130.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,6)
  _01: point with color grey at (4,3)
  _011: point with color grey at (7,1)
diff: 
! 37 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,6)
  _01: point with color grey at (7,1)
  _011: point with color grey at (4,3)
diff: 
! 33 wrong pixels (generated / expected)

TRAIN 4258a5f9.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,7)
  _01: point with color grey at (5,7)
  _011: point with color grey at (2,3)
  + 1 delta pixels
diff: 
   (3.2 bits)
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (3,3) with model Full with color blue at (0,6)
  _01: rectangle with size (3,3) with model Full with color blue at (1,2)
  _011: rectangle with size (3,3) with model Full with color blue at (4,6)
  _0111: rectangle with size (3,3) with model Full with color blue at (6,2)
  + 4 delta pixels
diff: 
   (238.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,7)
  _01: point with color grey at (2,3)
  _011: point with color grey at (7,3)
  + 1 delta pixels
diff: 
! 44 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,7)
  _01: point with color grey at (5,7)
  _011: point with color grey at (2,3)
  + 1 delta pixels
diff: 
! 37 wrong pixels (generated / expected)

TRAIN 4258a5f9.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,1)
  _01: point with color grey at (2,7)
  _011: point with color grey at (4,3)
  + 2 delta pixels
diff: 
! 49 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,1)
  _01: point with color grey at (4,3)
  _011: point with color grey at (2,7)
  + 2 delta pixels
diff: 
! 46 wrong pixels (generated / expected)

TEST 4258a5f9.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 18.2 sec (18.2 sec/task)
bits-train-error = 3695.0 bits (3695.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-305] Checking task 4290ef0e.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 358354.1 = 358356.4
DL output with Mo: L = 2.3 + 87016.6 = 87018.9
DL input+output M: L = 4.6 + 445370.7 = 445375.3

# learning a model for train pairs
2.000	
1.141	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.758	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.662	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.589	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.524	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.463	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.420	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.396	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.385	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.375	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.360	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.280	
0.279	IN  GEN ^ = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 28731.9 = 28857.7
DL output with Mo: L = 153.4 + 24149.9 = 24303.3
DL input+output M: L = 279.2 + 52881.8 = 53161.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 153.4 + 24149.9 = 24303.3
DL input+output M: L = 155.7 + 24149.9 = 24305.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 4 3 3 3 4 4 
4 4 4 1 1 4 1 1 4 4 4 4 3 4 3 4 4 
4 4 4 1 4 4 4 1 4 4 4 4 3 3 3 4 4 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 1 4 4 4 1 4 4 4 4 4 4 4 4 4 
4 4 4 1 1 4 1 1 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 6 6 4 4 4 6 6 
4 4 4 4 4 4 4 4 4 4 6 4 4 4 4 4 6 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 6 4 4 4 4 4 6 

diff: 
   (0.0 bits)
data: a background with size (7,7) and color yellow and layers
  _0: rectangle with size (3,3) with model Border with color green at (2,2)
  _01: rectangle with size (2,5) with model Full with color blue at (1,1)
  _011: rectangle with size (2,7) with model Full with color pink at (0,0)
  _0111: rectangle with size (2,5) with model Full with color blue at (4,1)
  _01111: rectangle with size (2,2) with model Full with color pink at (5,0)
  + 8 delta pixels
diff: 
   (502.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 4 3 3 3 4 4 
4 4 4 1 1 4 1 1 4 4 4 4 3 4 3 4 4 
4 4 4 1 4 4 4 1 4 4 4 4 3 3 3 4 4 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 1 4 4 4 1 4 4 4 4 4 4 4 4 4 
4 4 4 1 1 4 1 1 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 6 6 4 4 4 6 6 
4 4 4 4 4 4 4 4 4 4 6 4 4 4 4 4 6 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 4 6 4 4 4 4 4 6 

diff: 
! size mismatch, 10x10 instead of 7x7

TRAIN 4290ef0e.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 8 1 1 1 8 8 8 8 8 8 8 8 8 
8 8 1 8 8 8 8 8 1 8 8 8 8 8 8 8 8 8 
8 8 1 8 8 8 8 8 1 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 8 8 8 8 8 1 8 8 8 8 0 8 8 8 8 
8 8 1 8 8 8 8 8 1 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 8 1 1 1 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 4 4 4 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 4 8 4 8 8 8 2 2 8 2 2 8 8 8 8 8 8 
8 4 4 4 8 8 8 2 8 8 8 2 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 2 8 8 8 2 8 8 8 8 8 8 
8 8 8 8 8 8 8 2 2 8 2 2 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 

diff: 
   (0.0 bits)
data: a background with size (7,7) and color blue and layers
  _0: rectangle with size (3,3) with model Full with color yellow at (2,2)
  _01: rectangle with size (2,5) with model Full with color red at (1,1)
  _011: rectangle with size (2,5) with model Full with color red at (4,1)
  _0111: rectangle with size (1,7) with model Full with color cyan at (3,0)
  _01111: rectangle with size (7,1) with model Full with color cyan at (0,3)
  + 3 delta pixels
diff: 
   (304.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 8 1 1 1 8 8 8 8 8 8 8 8 8 
8 8 1 8 8 8 8 8 1 8 8 8 8 8 8 8 8 8 
8 8 1 8 8 8 8 8 1 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 1 8 8 8 8 8 1 8 8 8 8 0 8 8 8 8 
8 8 1 8 8 8 8 8 1 8 8 8 8 8 8 8 8 8 
8 8 1 1 1 8 1 1 1 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 4 4 4 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 4 8 4 8 8 8 2 2 8 2 2 8 8 8 8 8 8 
8 4 4 4 8 8 8 2 8 8 8 2 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 2 8 8 8 2 8 8 8 8 8 8 
8 8 8 8 8 8 8 2 2 8 2 2 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 

diff: 
! size mismatch, 10x10 instead of 7x7

TRAIN 4290ef0e.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 2 3 3 1 1 1 3 3 3 1 1 1 3 8 8 3 
3 3 2 3 3 1 3 3 3 3 3 3 3 1 3 8 3 3 
3 3 3 3 3 1 3 3 3 3 3 3 3 1 3 3 3 3 
3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 8 3 3 
3 3 2 3 3 3 3 7#7#7#3 3 3 3 3 8 8 3 
2 2 2 3 3 3 3 7#3 7#3 3 3 3 3 3 3 3 
3 3 3 3 3 1 3 7#7#7#3 3 3 1 3 3 3 3 
3 3 3 3 3 1 3 3 3 3 3 3 3 1 3 3 3 3 
3 3 3 3 3 1 1 1 3 3 3 1 1 1 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 4 4 3 3 3 3 3 3 3 4 4 3 3 3 3 
3 3 3 4 3 3 3 3 3 3 3 3 3 4 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 

diff: 
   (0.0 bits)
data: a background with size (11,11) and color green and layers
  _0: rectangle with size (3,3) with model Full with color orange at (4,4)
  _01: rectangle with size (3,7) with model Full with color red at (2,2)
  _011: rectangle with size (3,9) with model Full with color blue at (1,1)
  _0111: rectangle with size (3,7) with model Full with color red at (6,2)
  _01111: rectangle with size (3,9) with model Full with color blue at (7,1)
  + 35 delta pixels
diff: 
   (1609.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 2 3 3 1 1 1 3 3 3 1 1 1 3 8 8 3 
3 3 2 3 3 1 3 3 3 3 3 3 3 1 3 8 3 3 
3 3 3 3 3 1 3 3 3 3 3 3 3 1 3 3 3 3 
3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 8 3 3 
3 3 2 3 3 3 3 7#7#7#3 3 3 3 3 8 8 3 
2 2 2 3 3 3 3 7#3 7#3 3 3 3 3 3 3 3 
3 3 3 3 3 1 3 7#7#7#3 3 3 1 3 3 3 3 
3 3 3 3 3 1 3 3 3 3 3 3 3 1 3 3 3 3 
3 3 3 3 3 1 1 1 3 3 3 1 1 1 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 4 4 3 3 3 3 3 3 3 4 4 3 3 3 3 
3 3 3 4 3 3 3 3 3 3 3 3 3 4 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 

diff: 
! size mismatch, 10x10 instead of 11x11

TRAIN 4290ef0e.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 
1 1 1 1 1 1 1 8 8 8 1 1 1 4 1 1 1 1 1 
1 1 1 1 1 1 1 8 1 8 1 1 1 4 1 1 1 1 1 
1 1 1 1 1 1 1 8 8 8 1 1 1 4 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 3 3 1 3 3 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 3 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 3 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 3 3 1 3 3 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 6 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 
1 1 1 1 2 2 2 1 1 1 2 2 2 1 1 1 1 1 1 
1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 
1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 

diff: 
! size mismatch, 10x10 instead of 11x11

TEST 4290ef0e.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.8 sec (59.8 sec/task)
bits-train-error = 24149.9 bits (24149.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-304] Checking task 42a50994.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 306748.5 = 306750.9
DL output with Mo: L = 2.3 + 306748.5 = 306750.9
DL input+output M: L = 4.6 + 613497.1 = 613501.7

# learning a model for train pairs
2.000	
1.116	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.288	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.266	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.244	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.221	OUT ADD ^.layer_01 = ^.layer_0
0.202	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.184	OUT ADD ^.layer_011 = ^.layer_01
0.172	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.162	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.150	OUT ADD ^.layer_0111 = ^.layer_0111.shape at (?,?)
0.144	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.138	IN  ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.129	OUT ADD ^.layer_0110 = ^.layer_011.shape at (?,?)
0.123	IN  ADD ^.layer_0110 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.120	IN  ADD ^.layer_01110 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.117	OUT SPE ^.size = ^.size
0.116	OUT SPE ^.layer_0111.pos.i = ^.layer_0111.pos.i
0.115	OUT SPE ^.layer_0.pos.i = ^.layer_00.pos.i
0.115	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.114	OUT SPE ^.layer_01111.shape.color = ^.layer_0111.shape.color
0.113	OUT SPE ^.layer_0110.pos.i = ^.layer_01110.pos.j - ^.layer_0.shape.mask.size.i
0.113	OUT SPE ^.layer_01111.shape.mask.size.j = ^.layer_0.shape.mask.size.j - 1
0.112	IN  SPE ^.layer_01110.shape.mask.model = Full
0.109	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.109	IN  SPE ^.color = black
0.109	OUT SPE ^.color = black
0.021	
0.021	IN  DEL ^.layer_01111
0.021	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (^.layer_00.pos.i,?)
  _01: ^.layer_0
  _0110: ^.layer_011.shape at (^.layer_01110.pos.j - ^.layer_0.shape.mask.size.i,?)
  _011: ^.layer_01
  _0111: ^.layer_0111.shape at (^.layer_0111.pos.i,?)
  _01111: rectangle with size (?,^.layer_0.shape.mask.size.j - 1) with model ? with color ^.layer_0111.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01110: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 226.6 + 27019.9 = 27246.5
DL output with Mo: L = 211.6 + 5882.8 = 6094.4
DL input+output M: L = 438.2 + 32902.7 = 33340.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (^.layer_00.pos.i,?)
  _01: ^.layer_0
  _0110: ^.layer_011.shape at (^.layer_01110.pos.j - ^.layer_0.shape.mask.size.i,?)
  _011: ^.layer_01
  _0111: ^.layer_0111.shape at (^.layer_0111.pos.i,?)
  _01111: rectangle with size (?,^.layer_0.shape.mask.size.j - 1) with model ? with color ^.layer_0111.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01110: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 208.8 + 40.0 = 248.8
DL output with Mo: L = 211.6 + 5882.8 = 6094.4
DL input+output M: L = 420.4 + 5922.8 = 6343.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (16,11) and color black and layers
  _00: rectangle with size (5,3) with mask 
. . 0 
. . 0 
0 0 . 
. 0 . 
0 . . 
 with color cyan at (2,2)
  _0: rectangle with size (3,3) with mask 
. 0 . 
. 0 0 
0 . . 
 with color cyan at (8,4)
  _01: rectangle with size (2,2) with model Odd Checkboard with color cyan at (0,0)
  _0110: rectangle with size (3,1) with model Full with color cyan at (10,1)
  _011: rectangle with size (1,1) with model Full with color cyan at (2,7)
  _01110: rectangle with size (1,1) with model Full with color cyan at (2,9)
  _0111: rectangle with size (1,1) with model Full with color cyan at (5,8)
  + 7 delta pixels
diff: 
   (0.0 bits)
data: a background with size (16,11) and color black and layers
  _0: rectangle with size (2,1) with model Full with color cyan at (2,4)
  _01: 
. 8 . 
. 8 8 
8 . . 
 at (8,4)
  _0110: 
8 
 at (6,2)
  _011: 
. 8 
8 . 
 at (0,0)
  _0111: 
8 
 at (5,3)
  _01111: rectangle with size (1,2) with model Full with color cyan at (4,2)
diff: 
   (47.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,11) and color black and layers
  _00: rectangle with size (5,3) with mask 
. . 0 
. . 0 
0 0 . 
. 0 . 
0 . . 
 with color cyan at (2,2)
  _0: rectangle with size (3,3) with mask 
. 0 . 
. 0 0 
0 . . 
 with color cyan at (8,4)
  _01: rectangle with size (2,2) with model Odd Checkboard with color cyan at (0,0)
  _0110: rectangle with size (3,1) with model Full with color cyan at (10,1)
  _011: rectangle with size (1,1) with model Full with color cyan at (2,7)
  _01110: rectangle with size (1,1) with model Full with color cyan at (2,9)
  _0111: rectangle with size (1,1) with model Full with color cyan at (5,8)
  + 7 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (16,11) and color black and layers
  _00: rectangle with size (5,3) with mask 
. . 0 
. . 0 
0 0 . 
. 0 . 
0 . . 
 with color cyan at (2,2)
  _0: rectangle with size (3,3) with mask 
. 0 . 
. 0 0 
0 . . 
 with color cyan at (8,4)
  _01: rectangle with size (2,2) with model Odd Checkboard with color cyan at (0,0)
  _0110: rectangle with size (1,1) with model Full with color cyan at (2,7)
  _011: rectangle with size (3,1) with model Full with color cyan at (10,1)
  _01110: rectangle with size (1,1) with model Full with color cyan at (2,9)
  _0111: rectangle with size (1,1) with model Full with color cyan at (5,8)
  + 7 delta pixels
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (16,11) and color black and layers
  _00: rectangle with size (5,3) with mask 
. . 0 
. . 0 
0 0 . 
. 0 . 
0 . . 
 with color cyan at (2,2)
  _0: rectangle with size (3,3) with mask 
. 0 . 
. 0 0 
0 . . 
 with color cyan at (8,4)
  _01: rectangle with size (2,2) with model Odd Checkboard with color cyan at (0,0)
  _0110: rectangle with size (1,3) with model Full with color cyan at (2,7)
  _011: rectangle with size (1,1) with model Full with color cyan at (5,8)
  _01110: rectangle with size (1,1) with model Full with color cyan at (6,6)
  _0111: rectangle with size (1,1) with model Full with color cyan at (8,10)
  + 7 delta pixels
diff: 
! 13 wrong pixels (generated / expected)

TRAIN 42a50994.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (12,18) and color black and layers
  _00: rectangle with size (3,1) with model Full with color pink at (1,14)
  _0: rectangle with size (3,2) with model Even Checkboard with color pink at (1,1)
  _01: rectangle with size (2,2) with model Odd Checkboard with color pink at (0,10)
  _0110: rectangle with size (2,2) with model Even Checkboard with color pink at (4,7)
  _011: rectangle with size (1,2) with model Full with color pink at (8,7)
  _01110: rectangle with size (2,1) with model Full with color pink at (9,11)
  _0111: rectangle with size (1,2) with model Full with color pink at (11,16)
  + 13 delta pixels
diff: 
   (2.0 bits)
data: a background with size (12,18) and color black and layers
  _0: rectangle with size (3,1) with model Full with color pink at (1,14)
  _01: 
6 . 
. 6 
6 . 
 at (1,1)
  _0110: 
6 6 
 at (8,7)
  _011: 
. 6 
6 . 
 at (0,10)
  _0111: 
6 6 
 at (11,16)
  _01111: rectangle with size (2,1) with model Full with color pink at (9,11)
  + 2 delta pixels
diff: 
   (137.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,18) and color black and layers
  _00: rectangle with size (3,1) with model Full with color pink at (1,14)
  _0: rectangle with size (3,2) with model Even Checkboard with color pink at (1,1)
  _01: rectangle with size (2,2) with model Odd Checkboard with color pink at (0,10)
  _0110: rectangle with size (2,2) with model Even Checkboard with color pink at (4,7)
  _011: rectangle with size (1,2) with model Full with color pink at (8,7)
  _01110: rectangle with size (2,1) with model Full with color pink at (9,11)
  _0111: rectangle with size (1,2) with model Full with color pink at (11,16)
  + 13 delta pixels
diff: 
! 19 wrong pixels (generated / expected)

TRAIN 42a50994.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (11,19) and color black and layers
  _00: rectangle with size (4,5) with mask 
0 . . . . 
. 0 . . . 
0 . 0 0 . 
. . . . 0 
 with color grey at (1,9)
  _0: rectangle with size (4,3) with mask 
. 0 0 
0 . . 
0 0 . 
. . 0 
 with color grey at (7,16)
  _01: rectangle with size (5,3) with mask 
0 . . 
. 0 . 
. 0 . 
. . 0 
. . 0 
 with color grey at (4,1)
  _0110: rectangle with size (3,2) with mask 
. 0 
. 0 
0 0 
 with color grey at (2,15)
  _011: rectangle with size (3,3) with mask 
. . 0 
0 . 0 
. 0 . 
 with color grey at (8,9)
  _01110: rectangle with size (1,4) with model Full with color grey at (6,12)
  _0111: rectangle with size (3,2) with mask 
0 . 
0 . 
. 0 
 with color grey at (8,0)
  + 10 delta pixels
diff: 
   (2.0 bits)
data: a background with size (11,19) and color black and layers
  _0: rectangle with size (4,5) with mask 
0 . . . . 
. 0 . . . 
0 . 0 0 . 
. . . . 0 
 with color grey at (1,9)
  _01: 
. 5#5#
5#. . 
5#5#. 
. . 5#
 at (7,16)
  _0110: 
. . 5#
5#. 5#
. 5#. 
 at (8,9)
  _011: 
5#. . 
. 5#. 
. 5#. 
. . 5#
. . 5#
 at (4,1)
  _0111: 
5#. 
5#. 
. 5#
 at (8,0)
  _01111: rectangle with size (3,2) with mask 
. 0 
. 0 
0 0 
 with color grey at (2,15)
  + 2 delta pixels
diff: 
   (165.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,19) and color black and layers
  _00: rectangle with size (4,5) with mask 
0 . . . . 
. 0 . . . 
0 . 0 0 . 
. . . . 0 
 with color grey at (1,9)
  _0: rectangle with size (4,3) with mask 
. 0 0 
0 . . 
0 0 . 
. . 0 
 with color grey at (7,16)
  _01: rectangle with size (5,3) with mask 
0 . . 
. 0 . 
. 0 . 
. . 0 
. . 0 
 with color grey at (4,1)
  _0110: rectangle with size (3,2) with mask 
. 0 
. 0 
0 0 
 with color grey at (2,15)
  _011: rectangle with size (3,3) with mask 
. . 0 
0 . 0 
. 0 . 
 with color grey at (8,9)
  _01110: rectangle with size (1,2) with model Full with color grey at (6,14)
  _0111: rectangle with size (3,2) with mask 
0 . 
0 . 
. 0 
 with color grey at (8,0)
  + 10 delta pixels
diff: 
! 23 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,19) and color black and layers
  _00: rectangle with size (4,5) with mask 
0 . . . . 
. 0 . . . 
0 . 0 0 . 
. . . . 0 
 with color grey at (1,9)
  _0: rectangle with size (4,3) with mask 
. 0 0 
0 . . 
0 0 . 
. . 0 
 with color grey at (7,16)
  _01: rectangle with size (5,3) with mask 
0 . . 
. 0 . 
. 0 . 
. . 0 
. . 0 
 with color grey at (4,1)
  _0110: rectangle with size (3,2) with mask 
. 0 
. 0 
0 0 
 with color grey at (2,15)
  _011: rectangle with size (3,3) with mask 
. . 0 
0 . 0 
. 0 . 
 with color grey at (8,9)
  _01110: rectangle with size (1,4) with model Full with color grey at (6,12)
  _0111: rectangle with size (3,2) with mask 
0 . 
0 . 
. 0 
 with color grey at (8,0)
  + 10 delta pixels
diff: 
! 24 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (11,19) and color black and layers
  _00: rectangle with size (4,5) with mask 
0 . . . . 
. 0 . . . 
0 . 0 0 . 
. . . . 0 
 with color grey at (1,9)
  _0: rectangle with size (4,3) with mask 
. 0 0 
0 . . 
0 0 . 
. . 0 
 with color grey at (7,16)
  _01: rectangle with size (3,2) with mask 
. 0 
. 0 
0 0 
 with color grey at (2,15)
  _0110: rectangle with size (5,3) with mask 
0 . . 
. 0 . 
. 0 . 
. . 0 
. . 0 
 with color grey at (4,1)
  _011: rectangle with size (3,3) with mask 
. . 0 
0 . 0 
. 0 . 
 with color grey at (8,9)
  _01110: rectangle with size (1,4) with model Full with color grey at (6,12)
  _0111: rectangle with size (3,2) with mask 
0 . 
0 . 
. 0 
 with color grey at (8,0)
  + 10 delta pixels
diff: 
! 25 wrong pixels (generated / expected)

TRAIN 42a50994.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (17,9) and color black and layers
  _00: rectangle with size (5,3) with mask 
. . 0 
. . 0 
. 0 . 
0 . 0 
. 0 . 
 with color yellow at (8,0)
  _0: rectangle with size (4,3) with mask 
. 0 0 
0 . . 
0 . . 
0 . . 
 with color yellow at (3,2)
  _01: rectangle with size (3,3) with mask 
0 . 0 
. 0 . 
. 0 . 
 with color yellow at (10,6)
  _0110: rectangle with size (3,2) with mask 
. 0 
0 0 
0 . 
 with color yellow at (13,4)
  _011: rectangle with size (2,2) with model Odd Checkboard with color yellow at (0,4)
  _01110: rectangle with size (1,5) with model Full with color yellow at (5,4)
  _0111: rectangle with size (2,1) with model Full with color yellow at (15,2)
  + 11 delta pixels
diff: 
   (0.0 bits)
data: a background with size (17,9) and color black and layers
  _0: rectangle with size (5,3) with mask 
. . 0 
. . 0 
. 0 . 
0 . 0 
. 0 . 
 with color yellow at (8,0)
  _01: 
. 4 4 
4 . . 
4 . . 
4 . . 
 at (3,2)
  _0110: 
. 4 
4 . 
 at (0,4)
  _011: 
4 . 4 
. 4 . 
. 4 . 
 at (10,6)
  _0111: 
4 
4 
 at (15,2)
  _01111: rectangle with size (3,2) with mask 
. 0 
0 0 
0 . 
 with color yellow at (13,4)
  + 4 delta pixels
diff: 
   (238.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,9) and color black and layers
  _00: rectangle with size (5,3) with mask 
. . 0 
. . 0 
. 0 . 
0 . 0 
. 0 . 
 with color yellow at (8,0)
  _0: rectangle with size (4,3) with mask 
. 0 0 
0 . . 
0 . . 
0 . . 
 with color yellow at (3,2)
  _01: rectangle with size (3,3) with mask 
0 . 0 
. 0 . 
. 0 . 
 with color yellow at (10,6)
  _0110: rectangle with size (3,2) with mask 
. 0 
0 0 
0 . 
 with color yellow at (13,4)
  _011: rectangle with size (2,2) with model Odd Checkboard with color yellow at (0,4)
  _01110: rectangle with size (1,5) with model Full with color yellow at (5,4)
  _0111: rectangle with size (2,1) with model Full with color yellow at (15,2)
  + 11 delta pixels
diff: 
! 28 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,9) and color black and layers
  _00: rectangle with size (5,3) with mask 
. . 0 
. . 0 
. 0 . 
0 . 0 
. 0 . 
 with color yellow at (8,0)
  _0: rectangle with size (4,3) with mask 
. 0 0 
0 . . 
0 . . 
0 . . 
 with color yellow at (3,2)
  _01: rectangle with size (3,3) with mask 
0 . 0 
. 0 . 
. 0 . 
 with color yellow at (10,6)
  _0110: rectangle with size (3,2) with mask 
. 0 
0 0 
0 . 
 with color yellow at (13,4)
  _011: rectangle with size (1,5) with model Full with color yellow at (5,4)
  _01110: rectangle with size (2,1) with model Full with color yellow at (15,2)
  _0111: rectangle with size (2,2) with model Odd Checkboard with color yellow at (0,4)
  + 11 delta pixels
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (17,9) and color black and layers
  _00: rectangle with size (5,3) with mask 
. . 0 
. . 0 
. 0 . 
0 . 0 
. 0 . 
 with color yellow at (8,0)
  _0: rectangle with size (4,3) with mask 
. 0 0 
0 . . 
0 . . 
0 . . 
 with color yellow at (3,2)
  _01: rectangle with size (3,3) with mask 
0 . 0 
. 0 . 
. 0 . 
 with color yellow at (10,6)
  _0110: rectangle with size (3,2) with mask 
. 0 
0 0 
0 . 
 with color yellow at (13,4)
  _011: rectangle with size (2,2) with model Odd Checkboard with color yellow at (0,4)
  _01110: rectangle with size (1,5) with model Full with color yellow at (5,4)
  _0111: rectangle with size (1,2) with model Full with color yellow at (15,7)
  + 11 delta pixels
diff: 
! 28 wrong pixels (generated / expected)

TRAIN 42a50994.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,14) and color black and layers
  _00: rectangle with size (5,7) with mask 
. . 0 . 0 . . 
. 0 . 0 . . . 
. 0 0 0 . 0 0 
. 0 . . 0 . . 
0 . . . . . . 
 with color green at (10,2)
  _0: rectangle with size (3,5) with mask 
. . . . 0 
. 0 0 0 0 
0 . . . . 
 with color green at (0,6)
  _01: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color green at (3,9)
  _0110: rectangle with size (3,2) with mask 
. 0 
0 . 
0 . 
 with color green at (0,0)
  _011: rectangle with size (3,1) with model Full with color green at (13,0)
  _01110: rectangle with size (2,1) with model Full with color green at (0,13)
  _0111: rectangle with size (2,1) with model Full with color green at (3,2)
  + 24 delta pixels
diff: 
! 45 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,14) and color black and layers
  _00: rectangle with size (5,7) with mask 
. . 0 . 0 . . 
. 0 . 0 . . . 
. 0 0 0 . 0 0 
. 0 . . 0 . . 
0 . . . . . . 
 with color green at (10,2)
  _0: rectangle with size (3,5) with mask 
. . . . 0 
. 0 0 0 0 
0 . . . . 
 with color green at (0,6)
  _01: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color green at (3,9)
  _0110: rectangle with size (3,2) with mask 
. 0 
0 . 
0 . 
 with color green at (0,0)
  _011: rectangle with size (1,5) with model Full with color green at (7,4)
  _01110: rectangle with size (3,1) with model Full with color green at (13,0)
  _0111: rectangle with size (2,1) with model Full with color green at (0,13)
  + 25 delta pixels
diff: 
! 42 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (17,14) and color black and layers
  _00: rectangle with size (5,7) with mask 
. . 0 . 0 . . 
. 0 . 0 . . . 
. 0 0 0 . 0 0 
. 0 . . 0 . . 
0 . . . . . . 
 with color green at (10,2)
  _0: rectangle with size (3,5) with mask 
. . . . 0 
. 0 0 0 0 
0 . . . . 
 with color green at (0,6)
  _01: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color green at (3,9)
  _0110: rectangle with size (3,2) with mask 
. 0 
0 . 
0 . 
 with color green at (0,0)
  _011: rectangle with size (1,5) with model Full with color green at (7,4)
  _01110: rectangle with size (3,1) with model Full with color green at (13,0)
  _0111: rectangle with size (2,1) with model Full with color green at (3,2)
  + 25 delta pixels
diff: 
! 44 wrong pixels (generated / expected)

TEST 42a50994.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 45.2 sec (45.2 sec/task)
bits-train-error = 5882.8 bits (5882.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-303] Checking task 4347f46a.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 193833.1 = 193835.4
DL output with Mo: L = 2.3 + 193833.1 = 193835.4
DL input+output M: L = 4.6 + 387666.2 = 387670.9

# learning a model for train pairs
2.000	
1.234	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.586	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.411	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.305	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.247	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.231	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.206	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.203	OUT SPE ^.size = ^.size
0.201	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.200	OUT SPE ^.layer_0.shape.mask.size.j = ^.layer_0.shape.mask.size.j
0.199	OUT SPE ^.layer_011.shape.mask.size.j = ^.layer_0.shape.mask.size.j
0.197	OUT SPE ^.layer_01.shape.mask.size.i = ^.layer_0.shape.mask.size.i
0.197	OUT SPE ^.layer_0111.pos.i = 1
0.196	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.195	IN  SPE ^.layer_0.shape.mask.model = Full
0.195	IN  SPE ^.color = black
0.195	OUT SPE ^.color = black
0.019	
0.019	IN  GEN ^.layer_0.shape.mask.model = ?
0.019	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,^.layer_0.shape.mask.size.j) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: rectangle with size (^.layer_0.shape.mask.size.i,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,^.layer_0.shape.mask.size.j) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (1,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 42.6 + 33993.2 = 34035.8
DL output with Mo: L = 159.4 + 3510.0 = 3669.4
DL input+output M: L = 202.0 + 37503.2 = 37705.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,^.layer_0.shape.mask.size.j) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: rectangle with size (^.layer_0.shape.mask.size.i,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,^.layer_0.shape.mask.size.j) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (1,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 159.4 + 3510.0 = 3669.4
DL input+output M: L = 201.4 + 3510.0 = 3711.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (18,16) and color black and layers
  _0: rectangle with size (5,7) with model Full with color green at (3,6)
  + 55 delta pixels
diff: 
   (0.0 bits)
data: a background with size (18,16) and color black and layers
  _0: rectangle with size (5,7) with model Border with color green at (3,6)
  _01: rectangle with size (5,3) with model Border with color orange at (10,12)
  _011: rectangle with size (4,7) with model Border with color pink at (10,2)
  _0111: rectangle with size (3,4) with model Border with color cyan at (1,1)
diff: 
   (107.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,16) and color black and layers
  _0: rectangle with size (5,7) with model Full with color green at (3,6)
  + 55 delta pixels
diff: 
! 70 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (18,16) and color black and layers
  _0: rectangle with size (4,7) with model Full with color pink at (10,2)
  + 62 delta pixels
diff: 
! 68 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (18,16) and color black and layers
  _0: rectangle with size (5,3) with model Full with color orange at (10,12)
  + 75 delta pixels
diff: 
! 64 wrong pixels (generated / expected)

TRAIN 4347f46a.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (8,7) and color black and layers
  _0: rectangle with size (4,5) with model Full with color red at (1,1)
diff: 
   (0.0 bits)
data: a background with size (8,7) and color black and layers
  _0: rectangle with size (1,5) with model Full with color red at (1,1)
  _01: rectangle with size (4,1) with model Full with color red at (1,1)
  _011: rectangle with size (1,5) with model Full with color red at (4,1)
  _0111: rectangle with size (4,1) with model Full with color red at (1,5)
diff: 
   (74.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,7) and color black and layers
  _0: rectangle with size (4,5) with model Full with color red at (1,1)
diff: 
! 18 wrong pixels (generated / expected)

TRAIN 4347f46a.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (11,12) and color black and layers
  _0: rectangle with size (4,8) with model Full with color grey at (1,2)
  + 24 delta pixels
diff: 
   (0.0 bits)
data: a background with size (11,12) and color black and layers
  _0: rectangle with size (1,8) with model Full with color grey at (1,2)
  _01: rectangle with size (4,6) with model Border with color yellow at (6,1)
  _011: rectangle with size (1,8) with model Full with color grey at (4,2)
  _0111: rectangle with size (4,1) with model Full with color grey at (1,2)
  + 2 delta pixels
diff: 
   (169.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,12) and color black and layers
  _0: rectangle with size (4,8) with model Full with color grey at (1,2)
  + 24 delta pixels
diff: 
! 46 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,12) and color black and layers
  _0: rectangle with size (4,6) with model Full with color yellow at (6,1)
  + 32 delta pixels
diff: 
! 44 wrong pixels (generated / expected)

TRAIN 4347f46a.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,19) and color black and layers
  _0: rectangle with size (6,8) with model Full with color blue at (6,10)
  + 87 delta pixels
diff: 
! 94 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,19) and color black and layers
  _0: rectangle with size (7,6) with model Full with color yellow at (5,2)
  + 93 delta pixels
diff: 
! 93 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (17,19) and color black and layers
  _0: rectangle with size (3,6) with model Full with color cyan at (1,1)
  + 117 delta pixels
diff: 
! 86 wrong pixels (generated / expected)

TEST 4347f46a.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 33.0 sec (33.0 sec/task)
bits-train-error = 3510.0 bits (3510.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-302] Checking task 444801d8.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.232	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.637	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.510	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.388	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.259	OUT ADD ^.layer_00 = ^.layer_0
0.192	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.130	OUT ADD ^.layer_01 = ^.layer_01
0.076	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.070	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.065	OUT SPE ^.size = ^.size
0.060	OUT SPE ^.layer_011.shape = scaleTo(^.layer_011.shape, min(^.layer_0.shape.mask.size, ^.layer_01.shape.mask.size))
0.057	OUT SPE ^.layer_011.pos = ^.layer_01.pos - (1, 0)
0.056	OUT SPE ^.layer_0.shape.mask.size.j = min(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i) + 2
0.055	IN  SPE ^.layer_0.shape.color = blue
0.053	IN  SPE ^.layer_01.shape.color = blue
0.052	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_0.shape.mask.size.j - ^.layer_011.pos.i - ^.layer_01.pos.i
0.051	OUT SPE ^.layer_0.pos.j = right(^.layer_0) / colorCount(^)
0.050	OUT SPE ^.layer_0.pos.i = center(^.layer_01) - ^.layer_011.pos.i - ^.layer_0.pos.i
0.049	OUT SPE ^.layer_0.shape.mask.model = Full
0.048	IN  SPE ^.color = black
0.048	OUT SPE ^.color = black
0.009	
0.009	IN  GEN ^.layer_01.shape.color = ?
0.008	IN  GEN ^.layer_0.shape.color = ?
0.008	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (^.layer_0.shape.mask.size.j - ^.layer_011.pos.i - ^.layer_01.pos.i,min(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i) + 2) with model Full with color ? at (center(^.layer_01) - ^.layer_011.pos.i - ^.layer_0.pos.i,right(^.layer_0) / colorCount(^))
  _01: ^.layer_01
  _011: scaleTo(^.layer_011.shape, min(^.layer_0.shape.mask.size, ^.layer_01.shape.mask.size)) at ^.layer_01.pos - (1, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color blue at (?,?)
  _01: rectangle with size (?,?) with model ? with color blue at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 95.0 + 4741.2 = 4836.2
DL output with Mo: L = 304.3 + 584.1 = 888.4
DL input+output M: L = 399.3 + 5325.3 = 5724.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (^.layer_0.shape.mask.size.j - ^.layer_011.pos.i - ^.layer_01.pos.i,min(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i) + 2) with model Full with color ? at (center(^.layer_01) - ^.layer_011.pos.i - ^.layer_0.pos.i,right(^.layer_0) / colorCount(^))
  _01: ^.layer_01
  _011: scaleTo(^.layer_011.shape, min(^.layer_0.shape.mask.size, ^.layer_01.shape.mask.size)) at ^.layer_01.pos - (1, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 88.3 + 40.0 = 128.3
DL output with Mo: L = 304.3 + 584.1 = 888.4
DL input+output M: L = 392.6 + 624.1 = 1016.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,5) with model Full with color blue at (1,1)
  _01: rectangle with size (5,5) with model Border with color blue at (1,1)
  _011: point with color red at (3,3)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
1 1 1 1 1 
 at (1,1)
  _0: rectangle with size (3,3) with model Full with color red at (2,2)
  _01: 
1 1 1 1 1 
1 . . . 1 
1 . . . 1 
1 . . . 1 
1 1 1 1 1 
 at (1,1)
  _011: 
2 2 2 2 2 
 at (0,1)
  + 1 delta pixels
diff: 
   (47.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,5) with model Full with color blue at (1,1)
  _01: rectangle with size (5,5) with model Border with color blue at (1,1)
  _011: point with color red at (3,3)
  + 1 delta pixels
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,1) with model Full with color blue at (1,1)
  _01: rectangle with size (5,1) with model Full with color blue at (1,5)
  _011: point with color blue at (1,2)
  + 5 delta pixels
diff: 
! 27 wrong pixels (generated / expected)

TRAIN 444801d8.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (2,1)
  _01: rectangle with size (3,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (7,4)
  _011: point with color green at (8,6)
  + 1 delta pixels
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
1 1 . 1 1 
1 . . . 1 
1 . . . 1 
1 1 1 1 1 
 at (2,1)
  _0: rectangle with size (4,5) with model Full with color red at (1,1)
  _01: 
1 1 . 1 1 
1 . . . 1 
1 1 1 1 1 
 at (7,4)
  _011: 
3 3 3 3 3 
3 3 3 3 3 
3 3 3 3 3 
 at (6,4)
diff: 
   (5.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (2,1)
  _01: rectangle with size (3,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (7,4)
  _011: point with color red at (3,3)
  + 1 delta pixels
diff: 
! 38 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (2,1)
  _01: rectangle with size (3,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (7,4)
  _011: point with color green at (8,6)
  + 1 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (7,4)
  _01: rectangle with size (4,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (2,1)
  _011: point with color red at (3,3)
  + 1 delta pixels
diff: 
! 16 wrong pixels (generated / expected)

TRAIN 444801d8.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (1,1)
  _01: rectangle with size (3,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (7,4)
  _011: point with color cyan at (8,6)
  + 1 delta pixels
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
1 1 . 1 1 
1 . . . 1 
1 . . . 1 
1 1 1 1 1 
 at (1,1)
  _0: rectangle with size (4,5) with model Full with color pink at (0,1)
  _01: 
1 1 . 1 1 
1 . . . 1 
1 1 1 1 1 
 at (7,4)
  _011: 
8 8 8 8 8 
8 8 8 8 8 
8 8 8 8 8 
 at (6,4)
diff: 
   (5.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (1,1)
  _01: rectangle with size (3,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (7,4)
  _011: point with color pink at (2,3)
  + 1 delta pixels
diff: 
! 38 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (1,1)
  _01: rectangle with size (3,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (7,4)
  _011: point with color cyan at (8,6)
  + 1 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (7,4)
  _01: rectangle with size (4,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (1,1)
  _011: point with color pink at (2,3)
  + 1 delta pixels
diff: 
! 14 wrong pixels (generated / expected)

TRAIN 444801d8.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (6,4)
  _01: rectangle with size (4,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 . . . 0 
0 0 0 0 0 
 with color blue at (1,0)
  _011: point with color yellow at (2,2)
  + 1 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TEST 444801d8.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 9.2 sec (9.2 sec/task)
bits-train-error = 584.1 bits (584.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-301] Checking task 445eab21.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 4857.0 = 4859.4
DL input+output M: L = 4.6 + 124632.9 = 124637.5

# learning a model for train pairs
2.000	
1.124	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.416	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.253	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.149	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.085	OUT SPE ^.size = '(2, 2)
0.031	OUT SPE ^.color = majorityColor(^)
0.029	IN  SPE ^.layer_0.shape.mask.model = Border
0.028	IN  SPE ^.layer_01.shape.mask.model = Border
0.027	IN  SPE ^.color = black
0.006	
0.005	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(2, 2) and color majorityColor(^) and layers
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Border with color ? at (?,?)
  _01: rectangle with size (?,?) with model Border with color ? at (?,?)

DL input  with Mi: L = 77.0 + 2527.4 = 2604.4
DL output with Mo: L = 26.5 + 0.0 = 26.5
DL input+output M: L = 103.5 + 2527.4 = 2631.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(2, 2) and color majorityColor(^) and layers
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 26.5 + 0.0 = 26.5
DL input+output M: L = 28.9 + 0.0 = 28.9

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 7#7#7#7#0 0 0 0 0 
0 7#0 0 7#0 0 0 0 0 
0 7#0 0 7#0 0 0 0 0 
0 7#7#7#7#0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 8 8 8 8 8 0 0 
0 0 0 8 0 0 0 8 0 0 
0 0 0 8 0 0 0 8 0 0 
0 0 0 8 8 8 8 8 0 0 
0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (2,2) and color cyan and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 7#7#7#7#0 0 0 0 0 
0 7#0 0 7#0 0 0 0 0 
0 7#0 0 7#0 0 0 0 0 
0 7#7#7#7#0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 8 8 8 8 8 0 0 
0 0 0 8 0 0 0 8 0 0 
0 0 0 8 0 0 0 8 0 0 
0 0 0 8 8 8 8 8 0 0 
0 0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 445eab21.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
6 6 6 6 6 0 0 0 0 0 
6 0 0 0 6 0 0 0 0 0 
6 0 0 0 6 0 0 0 0 0 
6 6 6 6 6 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 7#7#7#7#7#7#0 0 
0 0 7#0 0 0 0 7#0 0 
0 0 7#0 0 0 0 7#0 0 
0 0 7#7#7#7#7#7#0 0 
0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (2,2) and color orange and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
6 6 6 6 6 0 0 0 0 0 
6 0 0 0 6 0 0 0 0 0 
6 0 0 0 6 0 0 0 0 0 
6 6 6 6 6 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 7#7#7#7#7#7#0 0 
0 0 7#0 0 0 0 7#0 0 
0 0 7#0 0 0 0 7#0 0 
0 0 7#7#7#7#7#7#0 0 
0 0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 445eab21.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 4 4 4 4 4 4 0 0 0 
0 4 0 0 0 0 4 0 0 0 
0 4 0 0 0 0 4 0 0 0 
0 4 0 0 0 0 4 0 0 0 
0 4 0 0 0 0 4 0 0 0 
0 4 0 0 0 0 4 0 0 0 
0 4 4 4 4 4 4 0 0 0 
0 0 0 0 0 0 0 2 2 2 
0 0 0 0 0 0 0 2 0 2 
0 0 0 0 0 0 0 2 2 2 

diff: 
   (0.0 bits)
data: a background with size (2,2) and color yellow and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 4 4 4 4 4 4 0 0 0 
0 4 0 0 0 0 4 0 0 0 
0 4 0 0 0 0 4 0 0 0 
0 4 0 0 0 0 4 0 0 0 
0 4 0 0 0 0 4 0 0 0 
0 4 0 0 0 0 4 0 0 0 
0 4 4 4 4 4 4 0 0 0 
0 0 0 0 0 0 0 2 2 2 
0 0 0 0 0 0 0 2 0 2 
0 0 0 0 0 0 0 2 2 2 

diff: 
correct output grid

TRAIN 445eab21.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 3 3 3 3 0 9#9#9#9#
3 0 0 0 3 0 9#0 0 9#
3 0 0 0 3 0 9#0 0 9#
3 0 0 0 3 0 9#0 0 9#
3 0 0 0 3 0 9#0 0 9#
3 0 0 0 3 0 9#0 0 9#
3 0 0 0 3 0 9#0 0 9#
3 0 0 0 3 0 9#0 0 9#
3 3 3 3 3 0 9#0 0 9#
0 0 0 0 0 0 9#9#9#9#

diff: 
correct output grid

TEST 445eab21.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 2.5 sec (2.5 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-300] Checking task 447fd412.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 204262.0 = 204264.3
DL output with Mo: L = 2.3 + 204262.0 = 204264.3
DL input+output M: L = 4.6 + 408524.0 = 408528.6

# learning a model for train pairs
2.000	
1.082	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.268	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.178	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.142	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.110	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.084	OUT ADD ^.layer_00 = ^.layer_0
0.070	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.063	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.056	OUT ADD ^.layer_011 = ^.layer_01
0.053	OUT SPE ^.size = ^.size
0.052	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.051	IN  SPE ^.layer_011.shape.color = red
0.051	IN  SPE ^.layer_0.shape.color = blue
0.050	IN  SPE ^.layer_01.shape.color = red
0.049	OUT SPE ^.layer_01.pos.i = ^.layer_011.pos.i
0.048	OUT SPE ^.layer_0.shape.mask.size.i = area(^.layer_011.shape) + average(^.layer_01.shape.mask.size.j, ^.layer_011.shape.mask.size.j)
0.048	OUT SPE ^.layer_01.shape.mask.size.i = min(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i)
0.047	IN  SPE ^.layer_01.shape.mask.model = Full
0.047	IN  SPE ^.layer_011.shape.mask.model = Full
0.047	IN  SPE ^.color = black
0.046	OUT SPE ^.color = black
0.022	
0.022	IN  GEN ^.layer_011.shape.color = ?
0.022	IN  GEN ^.layer_01.shape.color = ?
0.022	IN  GEN ^.layer_011.shape.mask.model = ?
0.022	IN  GEN ^.layer_01.shape.mask.model = ?
0.022	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (area(^.layer_011.shape) + average(^.layer_01.shape.mask.size.j, ^.layer_011.shape.mask.size.j),?) with model ? with color ^.layer_0.shape.color at (?,?)
  _01: rectangle with size (min(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i),?) with model ? with color ? at (^.layer_011.pos.i,?)
  _011: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color blue at (?,?)
  _01: rectangle with size (?,?) with model Full with color red at (?,?)
  _011: rectangle with size (?,?) with model Full with color red at (?,?)

DL input  with Mi: L = 109.2 + 4961.9 = 5071.1
DL output with Mo: L = 208.0 + 4180.8 = 4388.9
DL input+output M: L = 317.2 + 9142.8 = 9460.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (area(^.layer_011.shape) + average(^.layer_01.shape.mask.size.j, ^.layer_011.shape.mask.size.j),?) with model ? with color ^.layer_0.shape.color at (?,?)
  _01: rectangle with size (min(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i),?) with model ? with color ? at (^.layer_011.pos.i,?)
  _011: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color blue at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 101.4 + 20.0 = 121.4
DL output with Mo: L = 208.0 + 4180.8 = 4388.9
DL input+output M: L = 309.4 + 4200.8 = 4510.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (14,12) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 . 
0 0 0 
 with color blue at (2,2)
  _01: rectangle with size (2,2) with model Full with color red at (8,3)
  _011: rectangle with size (2,2) with model Full with color red at (8,9)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (14,12) and color black and layers
  _00: 
1 1 . 
. 1 . 
1 1 1 
 at (2,2)
  _0: rectangle with size (6,6) with mask 
0 0 0 0 . . 
0 0 0 0 . . 
. . 0 0 . . 
. . 0 0 . . 
0 0 0 0 0 0 
0 0 0 0 0 0 
 with color blue at (8,5)
  _01: rectangle with size (2,2) with model Full with color red at (8,9)
  _011: 
2 2 
2 2 
 at (8,3)
  + 2 delta pixels
diff: 
   (159.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,12) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 . 
0 0 0 
 with color blue at (2,2)
  _01: rectangle with size (2,2) with model Full with color red at (8,3)
  _011: rectangle with size (2,2) with model Full with color red at (8,9)
  + 2 delta pixels
diff: 
! 45 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,12) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 . 
0 0 0 
 with color blue at (2,2)
  _01: rectangle with size (2,2) with model Full with color red at (8,9)
  _011: rectangle with size (2,2) with model Full with color red at (8,3)
  + 2 delta pixels
diff: 
! 45 wrong pixels (generated / expected)

TRAIN 447fd412.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (14,12) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color blue at (4,5)
  _01: rectangle with size (4,1) with model Full with color red at (3,6)
  _011: rectangle with size (1,1) with model Full with color red at (9,9)
  + 3 delta pixels
diff: 
   (2.0 bits)
data: a background with size (14,12) and color black and layers
  _00: 
1 1 1 
. 1 . 
 at (4,5)
  _0: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color blue at (10,8)
  _01: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color blue at (9,1)
  _011: 
2 
2 
2 
2 
 at (3,6)
  + 4 delta pixels
diff: 
   (216.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,12) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color blue at (4,5)
  _01: rectangle with size (4,1) with model Full with color red at (3,6)
  _011: rectangle with size (1,1) with model Full with color red at (8,2)
  + 3 delta pixels
diff: 
! 19 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,12) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color blue at (4,5)
  _01: rectangle with size (4,1) with model Full with color red at (3,6)
  _011: rectangle with size (1,1) with model Full with color red at (9,9)
  + 3 delta pixels
diff: 
! 19 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (14,12) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color blue at (4,5)
  _01: rectangle with size (4,1) with model Full with color red at (3,6)
  _011: rectangle with size (1,1) with model Full with color red at (11,2)
  + 3 delta pixels
diff: 
! 20 wrong pixels (generated / expected)

TRAIN 447fd412.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (14,12) and color black and layers
  _0: rectangle with size (1,3) with model Full with color blue at (2,1)
  _01: rectangle with size (3,3) with model Full with color red at (7,7)
  _011: rectangle with size (1,1) with model Full with color red at (2,4)
diff: 
   (0.0 bits)
data: a background with size (14,12) and color black and layers
  _00: 
1 1 1 
 at (2,1)
  _0: rectangle with size (3,7) with model Full with color blue at (7,0)
  _01: rectangle with size (1,1) with model Full with color red at (2,4)
  _011: 
2 2 2 
2 2 2 
2 2 2 
 at (7,7)
diff: 
   (41.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,12) and color black and layers
  _0: rectangle with size (1,3) with model Full with color blue at (2,1)
  _01: rectangle with size (3,3) with model Full with color red at (7,7)
  _011: rectangle with size (1,1) with model Full with color red at (2,4)
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,12) and color black and layers
  _0: rectangle with size (1,3) with model Full with color blue at (2,1)
  _01: rectangle with size (1,1) with model Full with color red at (2,4)
  _011: rectangle with size (3,3) with model Full with color red at (7,7)
diff: 
! 39 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (14,12) and color black and layers
  _0: rectangle with size (3,3) with model Full with color red at (7,7)
  _01: rectangle with size (1,3) with model Full with color blue at (2,1)
  _011: rectangle with size (1,1) with model Full with color red at (2,4)
diff:   ^.layer_0.shape.color
! 28 wrong pixels (generated / expected)

TRAIN 447fd412.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
undefined expression: Average: not an integer

TEST 447fd412.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 28.1 sec (28.1 sec/task)
bits-train-error = 4180.8 bits (4180.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-299] Checking task 44d8ac46.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 232373.4 = 232375.8
DL output with Mo: L = 2.3 + 232373.4 = 232375.8
DL input+output M: L = 4.6 + 464746.9 = 464751.5

# learning a model for train pairs
2.000	
1.306	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.663	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.493	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.359	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.250	OUT ADD ^.layer_01 = ^.layer_0
0.154	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.114	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.100	IN  ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.057	OUT ADD ^.layer_00 = ^.layer_00
0.048	OUT ADD ^.layer_010 = ^.layer_01
0.045	OUT SPE ^.size = ^.size
0.044	IN  SPE ^.layer_00.shape.color = grey
0.043	IN  SPE ^.layer_0.shape.color = grey
0.042	IN  SPE ^.layer_01.shape.color = grey
0.041	OUT SPE ^.layer_0.pos.j = min(^.layer_0.pos.i, ^.layer_01.pos.i)
0.040	OUT SPE ^.layer_011.pos.j = max(^.layer_01.pos.j, ^.layer_00.pos.j) + 1
0.040	OUT SPE ^.layer_0.shape.mask.model = Full
0.039	OUT SPE ^.layer_011.shape.mask.model = Full
0.039	IN  SPE ^.color = black
0.038	OUT SPE ^.color = black
0.013	
0.013	IN  GEN ^.layer_01.shape.color = ?
0.013	IN  GEN ^.layer_0.shape.color = ?
0.013	IN  GEN ^.layer_00.shape.color = ?
0.013	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_00
  _0: rectangle with size (?,?) with model Full with color ? at (?,min(^.layer_0.pos.i, ^.layer_01.pos.i))
  _010: ^.layer_01
  _01: ^.layer_0
  _011: rectangle with size (?,?) with model Full with color ? at (?,max(^.layer_01.pos.j, ^.layer_00.pos.j) + 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: rectangle with size (?,?) with model ? with color grey at (?,?)
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)
  _01: rectangle with size (?,?) with model ? with color grey at (?,?)

DL input  with Mi: L = 108.2 + 5973.1 = 6081.3
DL output with Mo: L = 162.0 + 2641.8 = 2803.8
DL input+output M: L = 270.1 + 8614.9 = 8885.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_00
  _0: rectangle with size (?,?) with model Full with color ? at (?,min(^.layer_0.pos.i, ^.layer_01.pos.i))
  _010: ^.layer_01
  _01: ^.layer_0
  _011: rectangle with size (?,?) with model Full with color ? at (?,max(^.layer_01.pos.j, ^.layer_00.pos.j) + 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 51.7 = 149.8
DL output with Mo: L = 162.0 + 2641.8 = 2803.8
DL input+output M: L = 260.1 + 2693.5 = 2953.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _00: rectangle with size (4,4) with mask 
0 0 0 0 
0 0 0 0 
0 . 0 0 
0 0 0 0 
 with color grey at (8,2)
  _0: rectangle with size (4,4) with mask 
0 0 0 0 
0 . 0 0 
0 . . 0 
0 0 0 0 
 with color grey at (4,7)
  _01: rectangle with size (4,4) with model Border with color grey at (2,1)
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _00: 
5#5#5#5#
5#5#5#5#
5#. 5#5#
5#5#5#5#
 at (8,2)
  _0: rectangle with size (2,2) with model Full with color red at (3,2)
  _010: 
5#5#5#5#
5#. . 5#
5#. . 5#
5#5#5#5#
 at (2,1)
  _01: 
5#5#5#5#
5#. 5#5#
5#. . 5#
5#5#5#5#
 at (4,7)
  _011: rectangle with size (1,1) with model Full with color red at (10,3)
diff: 
   (40.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (4,4) with mask 
0 0 0 0 
0 0 0 0 
0 . 0 0 
0 0 0 0 
 with color grey at (8,2)
  _0: rectangle with size (4,4) with mask 
0 0 0 0 
0 . 0 0 
0 . . 0 
0 0 0 0 
 with color grey at (4,7)
  _01: rectangle with size (4,4) with model Border with color grey at (2,1)
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (4,4) with mask 
0 0 0 0 
0 0 0 0 
0 . 0 0 
0 0 0 0 
 with color grey at (8,2)
  _0: rectangle with size (4,4) with model Border with color grey at (2,1)
  _01: rectangle with size (4,4) with mask 
0 0 0 0 
0 . 0 0 
0 . . 0 
0 0 0 0 
 with color grey at (4,7)
diff: 
! 13 wrong pixels (generated / expected)

TRAIN 44d8ac46.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _00: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 . . 0 0 
0 . . 0 0 
0 0 0 0 0 
 with color grey at (7,0)
  _0: rectangle with size (4,4) with mask 
0 0 0 0 
0 0 . 0 
0 0 0 0 
0 0 0 0 
 with color grey at (1,1)
  _01: rectangle with size (6,6) with model Border with color grey at (3,6)
diff: 
   (2.0 bits)
data: a background with size (12,12) and color black and layers
  _00: 
5#5#5#5#5#
5#5#5#5#5#
5#. . 5#5#
5#. . 5#5#
5#5#5#5#5#
 at (7,0)
  _0: rectangle with size (2,2) with model Full with color red at (9,1)
  _010: 
5#5#5#5#5#5#
5#. . . . 5#
5#. . . . 5#
5#. . . . 5#
5#. . . . 5#
5#5#5#5#5#5#
 at (3,6)
  _01: 
5#5#5#5#
5#5#. 5#
5#5#5#5#
5#5#5#5#
 at (1,1)
  _011: rectangle with size (4,4) with model Full with color red at (4,7)
  + 1 delta pixels
diff: 
   (90.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 . . 0 0 
0 . . 0 0 
0 0 0 0 0 
 with color grey at (7,0)
  _0: rectangle with size (6,6) with model Border with color grey at (3,6)
  _01: rectangle with size (4,4) with mask 
0 0 0 0 
0 0 . 0 
0 0 0 0 
0 0 0 0 
 with color grey at (1,1)
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 . . 0 0 
0 . . 0 0 
0 0 0 0 0 
 with color grey at (7,0)
  _0: rectangle with size (4,4) with mask 
0 0 0 0 
0 0 . 0 
0 0 0 0 
0 0 0 0 
 with color grey at (1,1)
  _01: rectangle with size (6,6) with model Border with color grey at (3,6)
diff: 
! 29 wrong pixels (generated / expected)

TRAIN 44d8ac46.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _00: rectangle with size (4,6) with model Border with color grey at (8,3)
  _0: rectangle with size (6,5) with model Border with color grey at (1,1)
  _01: rectangle with size (4,4) with model Border with color grey at (3,7)
diff: 
   (3.2 bits)
data: a background with size (12,12) and color black and layers
  _00: 
5#5#5#5#5#5#
5#. . . . 5#
5#. . . . 5#
5#5#5#5#5#5#
 at (8,3)
  _0: rectangle with size (1,10) with model Full with color grey at (6,1)
  _010: 
5#5#5#5#
5#. . 5#
5#. . 5#
5#5#5#5#
 at (3,7)
  _01: 
5#5#5#5#5#
5#. . . 5#
5#. . . 5#
5#. . . 5#
5#. . . 5#
5#5#5#5#5#
 at (1,1)
  _011: rectangle with size (2,2) with model Full with color red at (4,8)
  + 1 delta pixels
diff: 
   (89.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (6,5) with model Border with color grey at (1,1)
  _0: rectangle with size (4,6) with model Border with color grey at (8,3)
  _01: rectangle with size (4,4) with model Border with color grey at (3,7)
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (6,5) with model Border with color grey at (1,1)
  _0: rectangle with size (4,4) with model Border with color grey at (3,7)
  _01: rectangle with size (4,6) with model Border with color grey at (8,3)
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (4,6) with model Border with color grey at (8,3)
  _0: rectangle with size (6,5) with model Border with color grey at (1,1)
  _01: rectangle with size (4,4) with model Border with color grey at (3,7)
diff: 
! 12 wrong pixels (generated / expected)

TRAIN 44d8ac46.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _00: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 . . 0 0 
0 . . 0 0 
0 . . . 0 
0 0 0 0 0 
 with color grey at (6,3)
  _0: rectangle with size (2,4) with model Full with color grey at (3,1)
  _01: rectangle with size (1,4) with model Full with color grey at (1,1)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _00: 
5#5#5#5#5#
5#. . 5#5#
5#. . 5#5#
5#. . . 5#
5#5#5#5#5#
 at (6,3)
  _0: rectangle with size (4,1) with model Full with color grey at (1,1)
  _010: 
5#5#5#5#
 at (1,1)
  _01: 
5#5#5#5#
5#5#5#5#
 at (3,1)
  _011: rectangle with size (4,1) with model Full with color grey at (1,4)
diff: 
   (44.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 . . 0 0 
0 . . 0 0 
0 . . . 0 
0 0 0 0 0 
 with color grey at (6,3)
  _0: rectangle with size (2,4) with model Full with color grey at (3,1)
  _01: rectangle with size (1,4) with model Full with color grey at (1,1)
  + 2 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (2,4) with model Full with color grey at (3,1)
  _0: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 . . 0 0 
0 . . 0 0 
0 . . . 0 
0 0 0 0 0 
 with color grey at (6,3)
  _01: rectangle with size (1,4) with model Full with color grey at (1,1)
  + 2 delta pixels
diff: 
! 7 wrong pixels (generated / expected)

TRAIN 44d8ac46.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (5,5) with model Border with color grey at (1,0)
  _0: rectangle with size (4,6) with model Border with color grey at (8,2)
  _01: rectangle with size (5,4) with mask 
0 0 0 0 
0 0 . 0 
0 . . 0 
0 . . 0 
0 0 0 0 
 with color grey at (1,7)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (5,5) with model Border with color grey at (1,0)
  _0: rectangle with size (5,4) with mask 
0 0 0 0 
0 0 . 0 
0 . . 0 
0 . . 0 
0 0 0 0 
 with color grey at (1,7)
  _01: rectangle with size (4,6) with model Border with color grey at (8,2)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (4,6) with model Border with color grey at (8,2)
  _0: rectangle with size (5,5) with model Border with color grey at (1,0)
  _01: rectangle with size (5,4) with mask 
0 0 0 0 
0 0 . 0 
0 . . 0 
0 . . 0 
0 0 0 0 
 with color grey at (1,7)
diff: 
! 15 wrong pixels (generated / expected)

TEST 44d8ac46.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 20.3 sec (20.3 sec/task)
bits-train-error = 2641.8 bits (2641.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-298] Checking task 44f52bb0.json: 6 train, 2 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 21069.6 = 21071.9
DL output with Mo: L = 2.3 + 2917.4 = 2919.7
DL input+output M: L = 4.6 + 23987.0 = 23991.7

# learning a model for train pairs
2.000	
1.325	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.713	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.476	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.341	OUT SPE ^.size = '(1, 1)
0.193	
0.191	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(1, 1) and color ? and layers
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 3135.9 = 3177.9
DL output with Mo: L = 18.5 + 537.9 = 556.4
DL input+output M: L = 60.4 + 3673.9 = 3734.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(1, 1) and color ? and layers
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 18.5 + 537.9 = 556.4
DL input+output M: L = 20.8 + 537.9 = 558.7

# train input/output grids

## instance 1

> Input and output best reading:

data: 
2 0 2 
0 2 0 
2 0 2 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color blue and layers
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 0 2 
0 2 0 
2 0 2 

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 44f52bb0.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
2 0 0 
2 0 0 
0 2 0 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color orange and layers
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 0 0 
2 0 0 
0 2 0 

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 44f52bb0.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
2 0 2 
2 0 2 
2 0 2 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color blue and layers
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 0 2 
2 0 2 
2 0 2 

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 44f52bb0.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: 
0 0 0 
2 0 2 
0 0 0 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color blue and layers
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 
2 0 2 
0 0 0 

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 44f52bb0.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: 
2 2 0 
0 2 2 
0 0 0 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color orange and layers
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 2 0 
0 2 2 
0 0 0 

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 44f52bb0.json/5: 0 - (FAILURE)

## instance 6

> Input and output best reading:

data: 
2 2 0 
0 2 0 
0 0 0 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color orange and layers
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 2 0 
0 2 0 
0 0 0 

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 44f52bb0.json/6: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 0 2 
2 2 2 
2 0 2 

diff: 
! 1 wrong pixels (generated / expected)

TEST 44f52bb0.json/1: 0 - (FAILURE)

## instance 2

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 
2 0 0 
2 0 0 

diff: 
! 1 wrong pixels (generated / expected)

TEST 44f52bb0.json/2: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 1.0 sec (1.0 sec/task)
bits-train-error = 537.9 bits (537.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-297] Checking task 4522001f.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 7023.2 = 7025.5
DL output with Mo: L = 2.3 + 64315.6 = 64317.9
DL input+output M: L = 4.6 + 71338.8 = 71343.5

# learning a model for train pairs
2.000	
1.400	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.870	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.509	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.274	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.207	IN  ADD ^.layer_00 = point with color ? at (?,?)
0.168	IN  SPE ^.layer_0.shape.mask = 
0 0 
0 0 

0.142	OUT SPE ^.layer_0.shape.mask = 
0 0 0 0 . . . . 
0 0 0 0 . . . . 
0 0 0 0 . . . . 
0 0 0 0 . . . . 
. . . . 0 0 0 0 
. . . . 0 0 0 0 
. . . . 0 0 0 0 
. . . . 0 0 0 0 

0.127	IN  SPE ^.layer_00.shape.color = red
0.111	IN  SPE ^.layer_0.shape.color = green
0.104	IN  SPE ^.color = black
0.098	OUT SPE ^.size = tiling(^.size, 3, 3)
0.095	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.093	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.092	OUT SPE ^.color = black
0.011	
0.008	IN  DEL ^.layer_00
0.007	IN  GEN ^.layer_0.shape.color = ?
0.007	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size tiling(^.size, 3, 3) and color black and layers
  _0: 
0 0 0 0 . . . . 
0 0 0 0 . . . . 
0 0 0 0 . . . . 
0 0 0 0 . . . . 
. . . . 0 0 0 0 
. . . . 0 0 0 0 
. . . . 0 0 0 0 
. . . . 0 0 0 0 
 with color ^.layer_0.shape.color at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: point with color red at (?,?)
  _0: 
0 0 
0 0 
 with color green at (?,?)

DL input  with Mi: L = 64.2 + 572.2 = 636.5
DL output with Mo: L = 121.4 + 0.0 = 121.4
DL input+output M: L = 185.7 + 572.2 = 757.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size tiling(^.size, 3, 3) and color black and layers
  _0: 
0 0 0 0 . . . . 
0 0 0 0 . . . . 
0 0 0 0 . . . . 
0 0 0 0 . . . . 
. . . . 0 0 0 0 
. . . . 0 0 0 0 
. . . . 0 0 0 0 
. . . . 0 0 0 0 
 with color ^.layer_0.shape.color at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 0 
0 0 
 with color ? at (?,?)

DL input  with Mi: L = 39.1 + 0.0 = 39.1
DL output with Mo: L = 121.4 + 0.0 = 121.4
DL input+output M: L = 160.5 + 0.0 = 160.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (0,0)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: 
0 0 0 0 . . . . 
0 0 0 0 . . . . 
0 0 0 0 . . . . 
0 0 0 0 . . . . 
. . . . 0 0 0 0 
. . . . 0 0 0 0 
. . . . 0 0 0 0 
. . . . 0 0 0 0 
 with color green at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (0,0)
  + 1 delta pixels
diff: 
correct output grid

TRAIN 4522001f.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (1,1)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: 
0 0 0 0 . . . . 
0 0 0 0 . . . . 
0 0 0 0 . . . . 
0 0 0 0 . . . . 
. . . . 0 0 0 0 
. . . . 0 0 0 0 
. . . . 0 0 0 0 
. . . . 0 0 0 0 
 with color green at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (1,1)
  + 1 delta pixels
diff: 
correct output grid

TRAIN 4522001f.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (0,1)
  + 1 delta pixels
diff: 
! 64 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color green and layers
  _0: 
0 . . 
0 . . 
0 0 0 
 with color black at (0,0)
  + 1 delta pixels
diff:   ^.layer_0.shape.mask
! 32 wrong pixels (generated / expected)

TEST 4522001f.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 2.2 sec (2.2 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-296] Checking task 4612dd53.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 173101.0 = 173103.3
DL output with Mo: L = 2.3 + 173101.0 = 173103.3
DL input+output M: L = 4.6 + 346201.9 = 346206.6

# learning a model for train pairs
2.000	
1.147	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.370	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.334	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.305	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.279	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.251	OUT ADD ^.layer_00 = ^.layer_0
0.234	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.216	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.198	OUT ADD ^.layer_001 = ^.layer_01
0.183	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.173	OUT ADD ^.layer_000 = ^.layer_011
0.167	IN  ADD ^.layer_010 = point with color ? at (?,?)
0.163	OUT ADD ^.layer_0110 = point with color ? at (?,?)
0.161	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.155	IN  ADD ^.layer_0101 = point with color ? at (?,?)
0.151	OUT SPE ^.size = ^.size
0.150	OUT SPE ^.layer_0.pos.i = ^.layer_0.pos.i
0.149	OUT SPE ^.layer_011.shape.color = ^.layer_011.shape.color
0.148	IN  SPE ^.layer_0.shape.color = blue
0.147	IN  SPE ^.layer_010.shape.color = blue
0.146	IN  SPE ^.layer_0101.shape.color = blue
0.145	IN  SPE ^.layer_01.shape.color = blue
0.144	IN  SPE ^.layer_011.shape.color = blue
0.143	OUT SPE ^.layer_0111.shape.color = red
0.142	OUT SPE ^.layer_0.pos = ^.layer_0.pos + translationOnto(^.layer_0, ^.layer_010)
0.142	OUT SPE ^.layer_0111.shape.mask.size.i = 1
0.141	OUT SPE ^.layer_0110.pos.j = right(^.layer_0) + ^.layer_01.pos.j - ^.layer_0.pos.j
0.140	OUT SPE ^.layer_0110.pos.i = ^.layer_010.pos.i + ^.layer_011.shape.mask.size.i
0.139	OUT SPE ^.layer_011.shape.mask.size.i = ^.layer_01.shape.mask.size.j - min(^.layer_01.shape.mask.size.i, ^.layer_011.shape.mask.size.i)
0.139	OUT SPE ^.layer_0111.pos.i = ^.layer_010.pos.j + ^.layer_01.pos.i - ^.layer_0.pos.i
0.138	OUT SPE ^.layer_0111.pos.j = ^.layer_01.pos.j + ^.layer_0101.pos.j - ^.layer_010.pos.j
0.138	OUT SPE ^.layer_0111.shape.mask.size.j = ^.layer_01.shape.mask.size.i - ^.layer_01.pos.j - ^.layer_010.pos.j
0.137	IN  SPE ^.layer_011.shape.mask.model = Full
0.137	OUT SPE ^.layer_01.shape.mask.model = Full
0.136	OUT SPE ^.layer_011.shape.mask.model = Full
0.136	OUT SPE ^.layer_0111.shape.mask.model = Full
0.135	OUT SPE ^.layer_0.shape.mask.size.j = min(^.layer_01.shape.mask.size.i, ^.layer_011.shape.mask.size.i) - ^.layer_0101.pos.j - ^.layer_0.pos.j
0.057	
0.057	IN  GEN ^.layer_011.shape.color = ?
0.057	IN  GEN ^.layer_01.shape.color = ?
0.057	IN  GEN ^.layer_0101.shape.color = ?
0.057	IN  GEN ^.layer_010.shape.color = ?
0.057	IN  GEN ^.layer_0.shape.color = ?
0.057	IN  GEN ^.layer_011.shape.mask.model = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _000: ^.layer_011
  _00: ^.layer_0
  _001: ^.layer_01
  _0: rectangle with size (?,min(^.layer_01.shape.mask.size.i, ^.layer_011.shape.mask.size.i) - ^.layer_0101.pos.j - ^.layer_0.pos.j) with model ? with color ? at ^.layer_0.pos + translationOnto(^.layer_0, ^.layer_010)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0110: point with color ? at (^.layer_010.pos.i + ^.layer_011.shape.mask.size.i,right(^.layer_0) + ^.layer_01.pos.j - ^.layer_0.pos.j)
  _011: rectangle with size (^.layer_01.shape.mask.size.j - min(^.layer_01.shape.mask.size.i, ^.layer_011.shape.mask.size.i),?) with model Full with color ^.layer_011.shape.color at (?,?)
  _0111: rectangle with size (1,^.layer_01.shape.mask.size.i - ^.layer_01.pos.j - ^.layer_010.pos.j) with model Full with color red at (^.layer_010.pos.j + ^.layer_01.pos.i - ^.layer_0.pos.i,^.layer_01.pos.j + ^.layer_0101.pos.j - ^.layer_010.pos.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color blue at (?,?)
  _010: point with color blue at (?,?)
  _0101: point with color blue at (?,?)
  _01: rectangle with size (?,?) with model ? with color blue at (?,?)
  _011: rectangle with size (?,?) with model Full with color blue at (?,?)

DL input  with Mi: L = 150.8 + 13587.2 = 13738.1
DL output with Mo: L = 637.1 + 9018.5 = 9655.6
DL input+output M: L = 787.9 + 22605.8 = 23393.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _000: ^.layer_011
  _00: ^.layer_0
  _001: ^.layer_01
  _0: rectangle with size (?,min(^.layer_01.shape.mask.size.i, ^.layer_011.shape.mask.size.i) - ^.layer_0101.pos.j - ^.layer_0.pos.j) with model ? with color ? at ^.layer_0.pos + translationOnto(^.layer_0, ^.layer_010)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0110: point with color ? at (^.layer_010.pos.i + ^.layer_011.shape.mask.size.i,right(^.layer_0) + ^.layer_01.pos.j - ^.layer_0.pos.j)
  _011: rectangle with size (^.layer_01.shape.mask.size.j - min(^.layer_01.shape.mask.size.i, ^.layer_011.shape.mask.size.i),?) with model Full with color ^.layer_011.shape.color at (?,?)
  _0111: rectangle with size (1,^.layer_01.shape.mask.size.i - ^.layer_01.pos.j - ^.layer_010.pos.j) with model Full with color red at (^.layer_010.pos.j + ^.layer_01.pos.i - ^.layer_0.pos.i,^.layer_01.pos.j + ^.layer_0101.pos.j - ^.layer_010.pos.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: point with color ? at (?,?)
  _0101: point with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 133.8 + 0.0 = 133.8
DL output with Mo: L = 637.1 + 9018.5 = 9655.6
DL input+output M: L = 770.8 + 9018.5 = 9789.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,13) and color black and layers
  _0: rectangle with size (7,1) with model Full with color blue at (1,10)
  _010: point with color blue at (1,2)
  _0101: point with color blue at (1,4)
  _01: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color blue at (6,2)
  _011: rectangle with size (1,2) with model Full with color blue at (1,7)
  + 6 delta pixels
diff: 
   (0.0 bits)
data: a background with size (9,13) and color black and layers
  _000: 
1 1 
 at (1,7)
  _00: 
1 
1 
1 
1 
1 
1 
1 
 at (1,10)
  _001: 
1 . 
1 1 
 at (6,2)
  _0: rectangle with size (1,7) with model Full with color red at (1,3)
  _01: rectangle with size (3,1) with model Full with color red at (3,2)
  _0110: point with color blue at (2,2)
  _011: rectangle with size (1,5) with model Full with color blue at (7,6)
  _0111: rectangle with size (1,2) with model Full with color red at (7,4)
  + 5 delta pixels
diff: 
   (270.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,13) and color black and layers
  _0: rectangle with size (7,1) with model Full with color blue at (1,10)
  _010: point with color blue at (1,2)
  _0101: point with color blue at (1,4)
  _01: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color blue at (6,2)
  _011: rectangle with size (1,2) with model Full with color blue at (1,7)
  + 6 delta pixels
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,13) and color black and layers
  _0: rectangle with size (7,1) with model Full with color blue at (1,10)
  _010: point with color blue at (1,2)
  _0101: point with color blue at (1,4)
  _01: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color blue at (6,2)
  _011: rectangle with size (1,5) with model Full with color blue at (7,6)
  + 6 delta pixels
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,13) and color black and layers
  _0: rectangle with size (7,1) with model Full with color blue at (1,10)
  _010: point with color blue at (1,2)
  _0101: point with color blue at (1,7)
  _01: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color blue at (6,2)
  _011: rectangle with size (1,5) with model Full with color blue at (7,6)
  + 6 delta pixels
diff: 
! 25 wrong pixels (generated / expected)

TRAIN 4612dd53.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (11,13) and color black and layers
  _0: rectangle with size (6,1) with model Full with color blue at (2,8)
  _010: point with color blue at (2,3)
  _0101: point with color blue at (2,7)
  _01: rectangle with size (2,4) with mask 
. . 0 . 
0 0 0 0 
 with color blue at (7,2)
  _011: rectangle with size (5,1) with model Full with color blue at (2,2)
  + 6 delta pixels
diff: 
   (0.0 bits)
data: a background with size (11,13) and color black and layers
  _000: 
1 
1 
1 
1 
1 
 at (2,2)
  _00: 
1 
1 
1 
1 
1 
1 
 at (2,8)
  _001: 
. . 1 . 
1 1 1 1 
 at (7,2)
  _0: rectangle with size (2,3) with mask 
. 0 0 
0 . . 
 with color red at (2,4)
  _01: rectangle with size (1,7) with model Full with color blue at (2,2)
  _0110: point with color red at (7,2)
  _011: rectangle with size (2,1) with model Full with color blue at (4,4)
  _0111: rectangle with size (1,3) with model Full with color red at (8,6)
  + 4 delta pixels
diff: 
   (236.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,13) and color black and layers
  _0: rectangle with size (6,1) with model Full with color blue at (2,8)
  _010: point with color blue at (2,3)
  _0101: point with color blue at (2,7)
  _01: rectangle with size (2,4) with mask 
. . 0 . 
0 0 0 0 
 with color blue at (7,2)
  _011: rectangle with size (5,1) with model Full with color blue at (2,2)
  + 6 delta pixels
diff: 
! 19 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,13) and color black and layers
  _0: rectangle with size (1,7) with model Full with color blue at (2,2)
  _010: point with color blue at (3,8)
  _0101: point with color blue at (3,2)
  _01: rectangle with size (2,4) with mask 
. . 0 . 
0 0 0 0 
 with color blue at (7,2)
  _011: rectangle with size (4,2) with mask 
. 0 
. 0 
. 0 
0 . 
 with color blue at (5,7)
  + 6 delta pixels
diff: 
! 20 wrong pixels (generated / expected)

TRAIN 4612dd53.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: rectangle with size (1,9) with model Full with color blue at (3,2)
  _010: point with color blue at (4,2)
  _0101: point with color blue at (6,2)
  _01: rectangle with size (1,9) with model Full with color blue at (10,2)
  _011: rectangle with size (1,7) with model Full with color blue at (7,2)
  + 12 delta pixels
diff: 
   (0.0 bits)
data: a background with size (13,13) and color black and layers
  _000: 
1 1 1 1 1 1 1 
 at (7,2)
  _00: 
1 1 1 1 1 1 1 1 1 
 at (3,2)
  _001: 
1 1 1 1 1 1 1 1 1 
 at (10,2)
  _0: rectangle with size (6,1) with model Full with color blue at (3,2)
  _01: rectangle with size (1,2) with model Full with color red at (7,9)
  _0110: point with color red at (5,10)
  _011: rectangle with size (8,1) with model Full with color blue at (3,10)
  _0111: rectangle with size (1,1) with model Full with color red at (9,2)
  + 8 delta pixels
diff: 
   (395.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (1,9) with model Full with color blue at (3,2)
  _010: point with color blue at (4,2)
  _0101: point with color blue at (6,2)
  _01: rectangle with size (1,9) with model Full with color blue at (10,2)
  _011: rectangle with size (1,7) with model Full with color blue at (7,2)
  + 12 delta pixels
diff: 
! 34 wrong pixels (generated / expected)

TRAIN 4612dd53.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
Invalid_argument("Model2.mask_rectangle: negative or null mask size")

TEST 4612dd53.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 59.3 sec (59.3 sec/task)
bits-train-error = 9018.5 bits (9018.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-295] Checking task 46442a0e.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 8642.2 = 8644.5
DL output with Mo: L = 2.3 + 34284.2 = 34286.5
DL input+output M: L = 4.6 + 42926.4 = 42931.1

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = unfoldSym( [ id rotate90 ] [ rotate270 rotate180 ], ^)
0.546	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.261	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.249	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.239	IN  SPE ^.layer_0.shape.mask.model = Full
0.229	IN  SPE ^.layer_01.shape.mask.model = Full
0.009	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
unfoldSym( [ id rotate90 ] [ rotate270 rotate180 ], ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 71.2 + 1906.9 = 1978.2
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 82.5 + 1906.9 = 1989.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
unfoldSym( [ id rotate90 ] [ rotate270 rotate180 ], ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 13.6 + 0.0 = 13.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
8 6 
6 8 

diff: 
   (0.0 bits)
data: 
8 6 6 8 
6 8 8 6 
6 8 8 6 
8 6 6 8 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 6 
6 8 

diff: 
correct output grid

TRAIN 46442a0e.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
7#7#8 
7#7#8 
8 8 8 

diff: 
   (0.0 bits)
data: 
7#7#8 8 7#7#
7#7#8 8 7#7#
8 8 8 8 8 8 
8 8 8 8 8 8 
7#7#8 8 7#7#
7#7#8 8 7#7#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
7#7#8 
7#7#8 
8 8 8 

diff: 
correct output grid

TRAIN 46442a0e.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
6 9#9#
6 4 4 
6 4 4 

diff: 
   (0.0 bits)
data: 
6 9#9#6 6 6 
6 4 4 4 4 9#
6 4 4 4 4 9#
9#4 4 4 4 6 
9#4 4 4 4 6 
6 6 6 9#9#6 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
6 9#9#
6 4 4 
6 4 4 

diff: 
correct output grid

TRAIN 46442a0e.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 4 1 
4 9#4 
9#1 9#

diff: 
correct output grid

TEST 46442a0e.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 0.8 sec (0.8 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-294] Checking task 469497ad.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 29114.4 = 29116.7
DL output with Mo: L = 2.3 + 298502.2 = 298504.5
DL input+output M: L = 4.6 + 327616.6 = 327621.2

# learning a model for train pairs
2.000	
1.530	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.092	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.896	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.701	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.550	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.427	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.358	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.291	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.265	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.242	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.220	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.063	
0.059	IN  GEN ^ = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 4591.7 = 4717.5
DL output with Mo: L = 153.4 + 17299.4 = 17452.8
DL input+output M: L = 279.2 + 21891.1 = 22170.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 153.4 + 17299.4 = 17452.8
DL input+output M: L = 155.7 + 17299.4 = 17455.1

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 3 
0 8 8 0 3 
0 8 8 0 3 
0 0 0 0 3 
3 3 3 3 3 

diff: 
   (0.0 bits)
data: a background with size (10,10) and color green and layers
  _0: rectangle with size (8,8) with mask 
. 0 0 0 0 0 0 . 
0 . 0 0 0 0 . 0 
0 0 . . . . 0 0 
0 0 . . . . 0 0 
0 0 . . . . 0 0 
0 0 . . . . 0 0 
0 . 0 0 0 0 . 0 
. 0 0 0 0 0 0 . 
 with color black at (0,0)
  _01: rectangle with size (4,4) with model Full with color cyan at (2,2)
  _011: rectangle with size (2,8) with model Full with color red at (0,0)
  _0111: rectangle with size (2,2) with model Full with color red at (6,0)
  _01111: rectangle with size (2,2) with model Full with color red at (6,6)
diff: 
   (258.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 3 
0 8 8 0 3 
0 8 8 0 3 
0 0 0 0 3 
3 3 3 3 3 

diff: 
! 62 wrong pixels (generated / expected)

TRAIN 469497ad.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 7#
4 4 0 0 7#
4 4 0 0 6 
0 0 0 0 6 
7#7#6 6 6 

diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (10,9) with mask 
. . . . . . 0 0 0 
. . . . . . 0 0 0 
. . . . . . 0 0 0 
. . . . . . 0 0 0 
. . . . . . 0 0 0 
. . . . . . 0 0 0 
. . . . . . 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color pink at (5,6)
  _01: rectangle with size (6,6) with model Full with color yellow at (3,0)
  _011: rectangle with size (3,6) with model Full with color orange at (12,0)
  _0111: rectangle with size (5,3) with model Full with color orange at (0,12)
  _01111: rectangle with size (3,3) with mask 
. . 0 
. 0 . 
0 . . 
 with color red at (0,6)
  + 3 delta pixels
diff: 
   (432.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 7#
4 4 0 0 7#
4 4 0 0 6 
0 0 0 0 6 
7#7#6 6 6 

diff: 
! size mismatch, 10x10 instead of 15x15

TRAIN 469497ad.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 9#
0 1 1 0 9#
0 1 1 0 3 
0 0 0 0 3 
9#9#3 3 4 

diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (8,8) with model Full with color blue at (4,4)
  _01: rectangle with size (12,12) with mask 
. . . . . . . . 0 0 0 0 
. . . . . . . . 0 0 0 0 
. . . . . . . . 0 0 0 0 
. . . . . . . . 0 0 0 0 
. . . . . . . . 0 0 0 0 
. . . . . . . . 0 0 0 0 
. . . . . . . . 0 0 0 0 
. . . . . . . . 0 0 0 0 
0 0 0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 0 0 . . . . 
 with color green at (8,8)
  _011: rectangle with size (8,4) with model Full with color brown at (0,16)
  _0111: rectangle with size (4,8) with model Full with color brown at (16,0)
  _01111: rectangle with size (4,4) with model Full with color yellow at (16,16)
  + 16 delta pixels
diff: 
   (1039.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 9#
0 1 1 0 9#
0 1 1 0 3 
0 0 0 0 3 
9#9#3 3 4 

diff: 
! size mismatch, 10x10 instead of 20x20

TRAIN 469497ad.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 6 6 0 8 
0 6 6 0 8 
0 0 0 0 1 
0 0 0 0 7#
8 8 1 7#9#

diff: 
! size mismatch, 10x10 instead of 25x25

TEST 469497ad.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.9 sec (59.9 sec/task)
bits-train-error = 17299.4 bits (17299.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-293] Checking task 46f33fce.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 499711.3 = 499713.6
DL input+output M: L = 4.6 + 619487.1 = 619491.8

# learning a model for train pairs
2.000	
1.063	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.292	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.227	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.190	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.152	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.114	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.108	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.103	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.097	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.091	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.086	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.084	OUT SPE ^.size = tiling(^.size, 2, 2)
0.083	OUT SPE ^.layer_01.shape.mask = 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 

0.082	OUT SPE ^.layer_011.shape.mask = 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 

0.081	OUT SPE ^.layer_0111.shape.mask = 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 

0.080	OUT SPE ^.layer_01.pos = '(0, 0) + translationSym(flipHeight, ^.layer_0, ^.layer_01)
0.080	IN  SPE ^.color = black
0.079	OUT SPE ^.layer_0111.pos = ^.layer_0111.pos + translationOnto(^.layer_0, ^.layer_0111)
0.078	OUT SPE ^.layer_011.pos = '(0, 0) + translationSym(flipWidth, ^.layer_0, ^.layer_01)
0.078	OUT SPE ^.layer_0.shape.mask.size.i = area(^.layer_0.shape.mask) + 3
0.078	OUT SPE ^.layer_0111.shape.color = ^.layer_0111.shape.color
0.077	OUT SPE ^.layer_0.shape.color = majorityColor(^)
0.077	OUT SPE ^.layer_0.shape.mask.model = Full
0.077	OUT SPE ^.color = black
0.044	
0.044	IN  DEL ^.layer_01111
0.044	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size tiling(^.size, 2, 2) and color black and layers
  _0: rectangle with size (area(^.layer_0.shape.mask) + 3,?) with model Full with color majorityColor(^) at (?,?)
  _01: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color ? at '(0, 0) + translationSym(flipHeight, ^.layer_0, ^.layer_01)
  _011: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color ? at '(0, 0) + translationSym(flipWidth, ^.layer_0, ^.layer_01)
  _0111: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color ^.layer_0111.shape.color at ^.layer_0111.pos + translationOnto(^.layer_0, ^.layer_0111)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 104.5 + 3986.0 = 4090.5
DL output with Mo: L = 246.6 + 21109.2 = 21355.7
DL input+output M: L = 351.1 + 25095.1 = 25446.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size tiling(^.size, 2, 2) and color black and layers
  _0: rectangle with size (area(^.layer_0.shape.mask) + 3,?) with model Full with color majorityColor(^) at (?,?)
  _01: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color ? at '(0, 0) + translationSym(flipHeight, ^.layer_0, ^.layer_01)
  _011: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color ? at '(0, 0) + translationSym(flipWidth, ^.layer_0, ^.layer_01)
  _0111: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color ^.layer_0111.shape.color at ^.layer_0111.pos + translationOnto(^.layer_0, ^.layer_0111)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 86.6 + 20.0 = 106.6
DL output with Mo: L = 246.6 + 21109.2 = 21355.7
DL input+output M: L = 333.1 + 21129.2 = 21462.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color red at (1,1)
  _01: point with color yellow at (3,1)
  _011: point with color blue at (3,3)
  _0111: point with color green at (5,5)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (4,4) with model Full with color green at (16,16)
  _01: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color yellow at (4,0)
  _011: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color red at (0,0)
  _0111: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color green at (8,8)
  + 32 delta pixels
diff: 
   (1370.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color red at (1,1)
  _01: point with color yellow at (3,1)
  _011: point with color blue at (3,3)
  _0111: point with color green at (5,5)
  + 2 delta pixels
diff: 
! 80 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color red at (1,1)
  _01: point with color yellow at (3,1)
  _011: point with color blue at (3,3)
  _0111: point with color yellow at (7,7)
  + 2 delta pixels
diff: 
! 80 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color red at (1,1)
  _01: point with color yellow at (3,1)
  _011: point with color green at (5,5)
  _0111: point with color blue at (3,3)
  + 2 delta pixels
diff: 
! 80 wrong pixels (generated / expected)

TRAIN 46f33fce.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color blue at (1,1)
  _01: point with color green at (1,3)
  _011: point with color yellow at (3,3)
  _0111: point with color cyan at (7,9)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (4,8) with model Full with color red at (16,12)
  _01: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color blue at (0,0)
  _011: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color green at (0,4)
  _0111: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color cyan at (12,16)
  + 16 delta pixels
diff: 
   (706.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (1,1)
  _01: point with color green at (1,3)
  _011: point with color yellow at (3,3)
  _0111: point with color cyan at (7,9)
  + 2 delta pixels
diff: 
! 80 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (1,1)
  _01: point with color green at (1,3)
  _011: point with color yellow at (3,3)
  _0111: point with color red at (9,7)
  + 2 delta pixels
diff: 
! 80 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (1,1)
  _01: point with color green at (1,3)
  _011: point with color cyan at (7,9)
  _0111: point with color yellow at (3,3)
  + 2 delta pixels
diff: 
! 80 wrong pixels (generated / expected)

TRAIN 46f33fce.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color green at (1,1)
  _01: point with color red at (1,3)
  _011: point with color blue at (9,1)
  _0111: point with color yellow at (9,9)
  + 1 delta pixels
diff: 
   (2.0 bits)
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (4,8) with model Full with color blue at (16,0)
  _01: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color green at (0,0)
  _011: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color red at (0,4)
  _0111: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color yellow at (16,16)
diff: 
   (33.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color green at (1,1)
  _01: point with color red at (1,3)
  _011: point with color blue at (9,1)
  _0111: point with color blue at (9,3)
  + 1 delta pixels
diff: 
! 64 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color green at (1,1)
  _01: point with color red at (1,3)
  _011: point with color blue at (9,1)
  _0111: point with color yellow at (9,9)
  + 1 delta pixels
diff: 
! 64 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color green at (1,1)
  _01: point with color red at (1,3)
  _011: point with color blue at (9,3)
  _0111: point with color blue at (9,1)
  + 1 delta pixels
diff: 
! 64 wrong pixels (generated / expected)

TRAIN 46f33fce.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color pink at (3,3)
  _01: point with color blue at (5,5)
  _011: point with color green at (7,3)
  _0111: point with color yellow at (7,7)
  + 1 delta pixels
diff: 
! 124 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color pink at (3,3)
  _01: point with color blue at (5,5)
  _011: point with color green at (7,3)
  _0111: point with color red at (9,1)
  + 1 delta pixels
diff: 
! 120 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color pink at (3,3)
  _01: point with color blue at (5,5)
  _011: point with color yellow at (7,7)
  _0111: point with color green at (7,3)
  + 1 delta pixels
diff: 
! 124 wrong pixels (generated / expected)

TEST 46f33fce.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 25.7 sec (25.7 sec/task)
bits-train-error = 21109.2 bits (21109.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-292] Checking task 47c1f68c.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 99950.4 = 99952.7
DL output with Mo: L = 2.3 + 79227.3 = 79229.7
DL input+output M: L = 4.6 + 179177.7 = 179182.4

# learning a model for train pairs
2.000	
1.265	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.551	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.362	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.254	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.210	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.176	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.163	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.117	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.110	OUT SPE ^.size = ^.size - (1, 1)
0.108	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.106	OUT SPE ^.layer_01.shape.color = majorityColor(^)
0.104	OUT SPE ^.layer_011.shape.color = majorityColor(^)
0.102	OUT SPE ^.layer_0111.shape.color = majorityColor(^)
0.100	IN  SPE ^.layer_0.shape.mask.model = +-cross
0.098	OUT SPE ^.layer_0111.pos.i = center(^.layer_0)
0.069	
0.068	IN  DEL ^.layer_01
0.068	IN  GEN ^.layer_0.shape.mask.model = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size - (1, 1) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (?,?)
  _01: rectangle with size (?,?) with model ? with color majorityColor(^) at (?,?)
  _011: rectangle with size (?,?) with model ? with color majorityColor(^) at (?,?)
  _0111: rectangle with size (?,?) with model ? with color majorityColor(^) at (center(^.layer_0),?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model +-cross with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 74.5 + 2936.8 = 3011.3
DL output with Mo: L = 174.6 + 5200.7 = 5375.3
DL input+output M: L = 249.1 + 8137.6 = 8386.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size - (1, 1) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (?,?)
  _01: rectangle with size (?,?) with model ? with color majorityColor(^) at (?,?)
  _011: rectangle with size (?,?) with model ? with color majorityColor(^) at (?,?)
  _0111: rectangle with size (?,?) with model ? with color majorityColor(^) at (center(^.layer_0),?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 174.6 + 5200.7 = 5375.3
DL input+output M: L = 216.5 + 5200.7 = 5417.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with model +-cross with color red at (0,0)
  + 5 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 . 
. 0 0 
 with color red at (1,0)
  _01: rectangle with size (3,3) with mask 
. 0 . 
. 0 0 
0 0 . 
 with color red at (1,7)
  _011: rectangle with size (3,3) with mask 
. 0 0 
0 0 . 
. 0 . 
 with color red at (6,0)
  _0111: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
. 0 . 
 with color red at (6,7)
diff: 
   (137.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with model +-cross with color red at (0,0)
  + 5 delta pixels
diff: 
! 20 wrong pixels (generated / expected)

TRAIN 47c1f68c.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,9) with model +-cross with color cyan at (0,0)
  + 5 delta pixels
diff: 
   (0.0 bits)
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 . 
0 . . 
 with color cyan at (0,0)
  _01: rectangle with size (3,3) with mask 
0 . 0 
. 0 0 
. . 0 
 with color cyan at (0,5)
  _011: rectangle with size (3,3) with mask 
0 . . 
0 0 . 
0 . 0 
 with color cyan at (5,0)
  _0111: rectangle with size (3,3) with mask 
. . 0 
. 0 0 
0 . 0 
 with color cyan at (5,5)
diff: 
   (135.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,9) with model +-cross with color cyan at (0,0)
  + 5 delta pixels
diff: 
! 16 wrong pixels (generated / expected)

TRAIN 47c1f68c.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (7,7) and color black and layers
  _0: rectangle with size (7,7) with model +-cross with color yellow at (0,0)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (1,4) with model Full with color yellow at (1,1)
  _01: rectangle with size (4,1) with model Full with color yellow at (1,1)
  _011: rectangle with size (4,1) with model Full with color yellow at (1,4)
  _0111: rectangle with size (1,4) with model Full with color yellow at (4,1)
  + 4 delta pixels
diff: 
   (247.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (7,7) with model +-cross with color yellow at (0,0)
  + 4 delta pixels
diff: 
! 16 wrong pixels (generated / expected)

TRAIN 47c1f68c.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (13,13) with model +-cross with color green at (0,0)
  + 7 delta pixels
diff: 
! 34 wrong pixels (generated / expected)

TEST 47c1f68c.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 58.9 sec (58.9 sec/task)
bits-train-error = 5200.7 bits (5200.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-291] Checking task 484b58aa.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 1076222.2 = 1076224.6
DL output with Mo: L = 2.3 + 1076222.2 = 1076224.6
DL input+output M: L = 4.6 + 2152444.5 = 2152449.1

# learning a model for train pairs
2.000	
1.630	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.298	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.668	OUT SPE ^ = fillResizeAlike(black, ^.size, ^)
0.556	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.000	
0.000	IN  GEN ^ = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
fillResizeAlike(black, ^.size, ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 598415.9 = 598457.9
DL output with Mo: L = 20.8 + 0.0 = 20.8
DL input+output M: L = 62.8 + 598415.9 = 598478.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
fillResizeAlike(black, ^.size, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 20.8 + 0.0 = 20.8
DL input+output M: L = 23.2 + 0.0 = 23.2

# train input/output grids

## instance 1

> Input and output best reading:

data: 
5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 
4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 
5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#
2 1 2 3 4 5#0 0 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 
1 2 5#4 5#6 0 0 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#
2 0 0 0 0 1 0 0 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 
5#0 0 0 0 2 0 0 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 0 0 0 6 1 
4 0 0 0 0 0 0 0 2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 0 0 0 1 2 
5#6 1 2 0 0 0 0 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 0 0 0 2 5#
2 1 2 3 0 0 2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#0 0 0 3 4 
1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 0 0 0 4 5#
2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 0 0 0 5#2 
5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 
4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 
5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#
2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 
1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#
2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 
5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 
4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 
5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#
2 1 2 3 4 5#2 1 2 3 4 5#2 0 0 0 0 5#2 1 2 3 4 5#2 1 2 3 4 
1 2 5#4 5#6 1 2 5#4 5#6 1 0 0 0 0 6 1 2 5#4 5#6 1 2 5#4 5#
2 3 4 5#2 1 2 3 4 5#2 1 2 0 0 0 0 1 2 3 4 5#2 1 2 3 4 5#2 
5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 
4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 
5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#
2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 
1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#

diff: 
   (0.0 bits)
data: 
5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 
4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 
5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#
2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 
1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#
2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 
5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 
4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 
5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#
2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 
1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#
2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 
5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 
4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 
5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#
2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 
1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#
2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 
5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 
4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 
5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#
2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 
1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#
2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 
5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 
4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 
5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#
2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 
1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 
4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 
5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#
2 1 2 3 4 5#0 0 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 
1 2 5#4 5#6 0 0 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#
2 0 0 0 0 1 0 0 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 
5#0 0 0 0 2 0 0 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 0 0 0 6 1 
4 0 0 0 0 0 0 0 2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 0 0 0 1 2 
5#6 1 2 0 0 0 0 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 0 0 0 2 5#
2 1 2 3 0 0 2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#0 0 0 3 4 
1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 0 0 0 4 5#
2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 0 0 0 5#2 
5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 
4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 
5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#
2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 
1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#
2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 
5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 
4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 
5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#
2 1 2 3 4 5#2 1 2 3 4 5#2 0 0 0 0 5#2 1 2 3 4 5#2 1 2 3 4 
1 2 5#4 5#6 1 2 5#4 5#6 1 0 0 0 0 6 1 2 5#4 5#6 1 2 5#4 5#
2 3 4 5#2 1 2 3 4 5#2 1 2 0 0 0 0 1 2 3 4 5#2 1 2 3 4 5#2 
5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 
4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 
5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#
2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 5#2 1 2 3 4 
1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#6 1 2 5#4 5#

diff: 
correct output grid

TRAIN 484b58aa.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 
0 0 0 0 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#
0 0 0 0 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 
0 0 0 0 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 
0 0 0 0 5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 
3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#
5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 
5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 
3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#
2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 
1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 
2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 0 0 0 0 0 5#4 2 1 2 
3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 0 0 0 0 0 3 7#1 2 5#
5#3 2 7#1 2 3 6 2 0 0 0 0 0 2 5#5#7#1 0 0 0 0 0 2 1 2 3 3 
5#4 2 1 2 2 5#3 2 0 0 0 0 0 2 6 2 1 2 0 0 0 0 0 1 2 2 4 3 
3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 0 0 0 0 1 2 5#2 5#5#
2 1 2 3 0 0 0 7#1 2 5#7#5#4 2 1 2 2 5#0 0 0 0 2 3 6 2 6 2 
1 2 2 4 0 0 0 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 
2 5#2 5#0 0 0 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 
3 6 2 6 0 0 0 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#
5#3 2 7#0 0 0 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 
5#4 2 1 0 0 0 3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 
3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#
2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 
1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 
2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 
3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#
5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 
5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 

diff: 
   (0.0 bits)
data: 
5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 
3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#
2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 
1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 
2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 
3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#
5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 
5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 
3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#
2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 
1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 
2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 
3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#
5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 
5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 
3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#
2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 
1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 
2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 
3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#
5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 
5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 
3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#
2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 
1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 
2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 
3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#
5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 
5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 
0 0 0 0 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#
0 0 0 0 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 
0 0 0 0 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 
0 0 0 0 5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 
3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#
5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 
5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 
3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#
2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 
1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 
2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 0 0 0 0 0 5#4 2 1 2 
3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 0 0 0 0 0 3 7#1 2 5#
5#3 2 7#1 2 3 6 2 0 0 0 0 0 2 5#5#7#1 0 0 0 0 0 2 1 2 3 3 
5#4 2 1 2 2 5#3 2 0 0 0 0 0 2 6 2 1 2 0 0 0 0 0 1 2 2 4 3 
3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 0 0 0 0 1 2 5#2 5#5#
2 1 2 3 0 0 0 7#1 2 5#7#5#4 2 1 2 2 5#0 0 0 0 2 3 6 2 6 2 
1 2 2 4 0 0 0 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 
2 5#2 5#0 0 0 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 
3 6 2 6 0 0 0 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#
5#3 2 7#0 0 0 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 
5#4 2 1 0 0 0 3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 
3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#
2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 
1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 2 5#3 2 7#1 
2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#7#5#4 2 1 2 
3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 2 3 7#1 2 5#
5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 7#2 1 2 3 3 
5#4 2 1 2 2 5#3 2 7#1 2 3 6 2 6 2 1 2 5#2 5#5#7#1 2 2 4 3 

diff: 
correct output grid

TRAIN 484b58aa.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 6 1 8 1 2 0 0 0 0 0 0 0 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 
2 1 2 1 2 1 0 0 0 0 0 0 0 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 8 1 2 1 4 0 0 0 0 0 0 0 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 
2 1 2 1 2 1 0 0 0 0 0 0 0 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 2 1 4 1 6 0 0 0 0 0 0 0 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 
2 1 2 1 2 1 0 0 0 0 0 0 0 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 4 1 6 1 8 0 0 0 0 0 0 0 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 0 0 0 0 4 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 0 0 0 0 1 2 
1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 0 0 0 0 6 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 0 0 0 0 0 0 0 2 
1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 0 0 0 0 0 0 0 0 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 0 0 0 0 0 0 0 0 2 
1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 0 0 0 0 0 0 0 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 0 0 0 0 0 0 0 2 
1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 0 0 0 0 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 0 0 0 0 2 
1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 

diff: 
   (0.0 bits)
data: 
1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 6 1 8 1 2 0 0 0 0 0 0 0 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 
2 1 2 1 2 1 0 0 0 0 0 0 0 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 8 1 2 1 4 0 0 0 0 0 0 0 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 
2 1 2 1 2 1 0 0 0 0 0 0 0 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 2 1 4 1 6 0 0 0 0 0 0 0 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 
2 1 2 1 2 1 0 0 0 0 0 0 0 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 4 1 6 1 8 0 0 0 0 0 0 0 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 0 0 0 0 4 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 0 0 0 0 1 2 
1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 0 0 0 0 6 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 0 0 0 0 0 0 0 2 
1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 0 0 0 0 0 0 0 0 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 0 0 0 0 0 0 0 0 2 
1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 0 0 0 0 0 0 0 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 0 0 0 0 0 0 0 2 
1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 0 0 0 0 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 0 0 0 0 2 
1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 
2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 
1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 2 1 4 1 6 1 8 1 

diff: 
correct output grid

TRAIN 484b58aa.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 1 2 6 1 2 0 0 0 0 1 2 5#1 2 9#1 2 8 1 2 6 1 2 2 1 2 3 1 
1 8 2 1 5#9#0 0 0 0 8 9#1 5#0 0 0 9#1 8 2 1 5#9#1 2 2 1 8 
5#3 1 8 2 1 0 0 0 0 8 1 8 9#0 0 0 1 5#3 1 8 2 1 2 6 1 5#8 
5#1 2 9#1 2 0 0 0 0 1 2 2 1 0 0 0 2 5#1 2 9#1 2 8 1 2 6 1 
1 5#2 1 2 9#0 0 0 0 5#9#1 2 0 0 0 9#1 5#2 1 2 9#1 8 2 1 5#
8 9#1 2 5#1 5#3 1 8 2 1 2 6 0 0 0 1 8 9#1 2 5#1 5#3 1 8 2 
2 1 2 3 1 2 5#1 2 9#1 2 8 1 0 0 0 2 2 1 2 3 1 2 5#1 2 9#1 
1 2 2 1 8 9#1 5#2 1 2 9#1 8 0 0 0 9#1 2 2 1 8 9#1 5#2 1 2 
2 6 1 5#8 1 8 9#1 2 5#1 5#3 1 8 2 1 2 6 1 5#8 1 8 9#1 2 5#
8 1 2 6 1 2 2 1 2 3 1 2 5#1 2 9#1 2 8 1 2 6 1 2 2 1 2 3 1 
1 8 2 1 5#9#1 2 2 1 8 9#1 5#2 1 2 9#1 8 2 1 5#9#1 2 2 1 8 
5#3 1 8 2 1 2 6 1 5#8 1 8 9#1 2 5#1 5#3 1 8 2 1 2 6 1 5#8 
5#1 0 0 1 2 8 1 2 6 1 2 2 0 0 0 1 2 5#1 2 9#1 2 8 1 2 6 1 
1 5#0 0 2 9#1 8 2 1 5#9#1 0 0 0 8 9#1 5#2 1 2 9#1 8 2 1 5#
8 9#0 0 5#1 5#3 1 8 2 1 2 6 1 5#8 1 8 9#1 2 5#1 5#3 1 8 2 
2 1 0 0 0 2 5#1 2 9#1 2 8 1 2 6 1 2 2 1 2 3 1 2 5#1 2 9#1 
1 2 0 0 0 9#1 5#2 1 2 9#1 8 2 1 5#9#1 2 2 1 8 9#1 5#2 1 2 
2 6 1 0 0 1 8 9#1 2 5#1 5#3 1 8 2 1 2 6 1 5#8 1 8 9#1 2 5#
8 1 2 0 0 2 2 1 2 3 1 2 5#1 2 9#1 2 8 1 2 6 1 2 2 1 2 3 1 
1 8 2 1 5#9#1 2 2 1 8 9#1 5#2 1 2 9#1 8 2 1 5#9#1 2 2 1 8 
5#3 1 8 2 1 2 6 1 5#8 1 8 9#1 2 5#1 5#3 1 8 2 1 2 6 1 5#8 
5#1 2 9#1 2 8 1 2 6 1 2 2 1 2 3 1 2 5#1 2 9#1 2 8 1 2 6 1 
1 5#2 1 2 9#1 8 2 1 5#9#1 2 2 1 8 9#1 5#2 1 2 9#1 8 2 1 5#
8 9#1 2 5#1 5#3 1 8 2 1 2 6 1 5#8 1 8 9#1 2 5#1 5#3 1 8 2 
2 1 2 3 1 2 5#1 2 9#1 2 8 1 2 6 1 2 2 1 2 3 1 2 5#1 2 9#1 
1 2 2 1 8 9#1 5#2 1 2 9#1 8 2 1 5#9#1 2 2 1 8 9#1 5#2 1 2 
2 6 1 5#8 1 8 9#1 2 5#1 5#3 1 8 2 1 2 6 1 5#8 1 8 9#1 2 5#
8 1 2 6 1 2 2 1 2 3 1 2 5#1 2 9#1 2 8 1 2 6 1 2 2 1 2 3 1 
1 8 2 1 5#9#1 2 2 1 8 9#1 5#2 1 2 9#1 8 2 1 5#9#1 2 2 1 8 

diff: 
correct output grid

TEST 484b58aa.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 59.8 sec (59.8 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-290] Checking task 48d8fb45.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 10534.8 = 10537.1
DL input+output M: L = 4.6 + 130310.7 = 130315.3

# learning a model for train pairs
2.000	
1.140	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.586	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.293	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.247	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.207	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.123	OUT SPE ^.layer_0.shape = ^.layer_0.shape
0.087	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.065	OUT SPE ^.layer_0.pos = '(0, 0)
0.048	IN  ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.041	OUT SPE ^.color = black
0.041	IN  SPE ^.color = black
0.004	
0.004	IN  DEL ^.layer_01
0.004	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: ^.layer_0.shape at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.2 + 4368.3 = 4466.5
DL output with Mo: L = 37.8 + 0.0 = 37.8
DL input+output M: L = 136.1 + 4368.3 = 4504.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: ^.layer_0.shape at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 37.8 + 0.0 = 37.8
DL input+output M: L = 108.0 + 0.0 = 108.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _00: rectangle with size (3,3) with mask 
. 0 0 
0 0 0 
. 0 0 
 with color blue at (7,5)
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
. 0 0 
 with color blue at (3,2)
  + 6 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
. 1 . 
1 1 1 
. 1 1 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (3,3) with mask 
. 0 0 
0 0 0 
. 0 0 
 with color blue at (7,5)
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
. 0 0 
 with color blue at (3,2)
  + 6 delta pixels
diff: 
correct output grid

TRAIN 48d8fb45.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _00: rectangle with size (3,3) with mask 
. 0 . 
0 . 0 
. 0 0 
 with color yellow at (3,1)
  _0: rectangle with size (3,3) with mask 
0 0 . 
. . 0 
. 0 . 
 with color yellow at (2,6)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
4 4 . 
. . 4 
. 4 . 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (3,3) with mask 
. 0 . 
0 . 0 
. 0 0 
 with color yellow at (3,1)
  _0: rectangle with size (3,3) with mask 
0 0 . 
. . 0 
. 0 . 
 with color yellow at (2,6)
  + 1 delta pixels
diff: 
correct output grid

TRAIN 48d8fb45.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _00: rectangle with size (3,3) with mask 
. 0 0 
0 . 0 
. 0 . 
 with color red at (2,1)
  _0: rectangle with size (3,3) with mask 
. 0 0 
0 0 . 
. 0 . 
 with color red at (5,6)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
. 2 2 
2 2 . 
. 2 . 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (3,3) with mask 
. 0 0 
0 . 0 
. 0 . 
 with color red at (2,1)
  _0: rectangle with size (3,3) with mask 
. 0 0 
0 0 . 
. 0 . 
 with color red at (5,6)
  + 1 delta pixels
diff: 
correct output grid

TRAIN 48d8fb45.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
. 0 0 
 with color green at (6,5)
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 . 
. 0 0 
 with color green at (1,5)
  + 5 delta pixels
diff: 
correct output grid

TEST 48d8fb45.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 2.8 sec (2.8 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-289] Checking task 4938f0c2.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 361159.8 = 361162.1
DL output with Mo: L = 2.3 + 361159.8 = 361162.1
DL input+output M: L = 4.6 + 722319.5 = 722324.2

# learning a model for train pairs
2.000	
1.041	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.157	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.137	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.113	OUT ADD ^.layer_0 = ^.layer_0
0.093	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.073	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.053	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.042	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.028	OUT ADD ^.layer_010 = ^.layer_01
0.025	OUT SPE ^.layer_01.shape = applySym(flipWidth, ^.layer_0.shape)
0.022	OUT SPE ^.layer_011.shape = applySym(flipHeight, ^.layer_0.shape)
0.020	OUT SPE ^.layer_0111.shape = applySym(rotate180, ^.layer_0.shape)
0.018	OUT SPE ^.size = ^.size
0.017	IN  SPE ^.layer_01.shape.mask = 
0 0 
0 0 

0.016	OUT SPE ^.layer_0111.pos = ^.layer_01.pos + (2, 2)
0.015	OUT SPE ^.layer_01.pos = corner(^.layer_0.pos, ^.layer_01.pos) + (0, 2)
0.014	OUT SPE ^.layer_011.pos = corner(^.layer_01.pos, ^.layer_0.pos) + (2, 0)
0.013	IN  SPE ^.layer_0.shape.color = red
0.013	IN  SPE ^.layer_01.shape.color = green
0.013	IN  SPE ^.color = black
0.013	OUT SPE ^.color = black
0.005	
0.005	IN  GEN ^.layer_01.shape.color = ?
0.005	IN  GEN ^.layer_0.shape.color = ?
0.005	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _010: ^.layer_01
  _01: applySym(flipWidth, ^.layer_0.shape) at corner(^.layer_0.pos, ^.layer_01.pos) + (0, 2)
  _011: applySym(flipHeight, ^.layer_0.shape) at corner(^.layer_01.pos, ^.layer_0.pos) + (2, 0)
  _0111: applySym(rotate180, ^.layer_0.shape) at ^.layer_01.pos + (2, 2)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at (?,?)
  _01: 
0 0 
0 0 
 with color green at (?,?)

DL input  with Mi: L = 74.0 + 2624.5 = 2698.5
DL output with Mo: L = 179.0 + 1657.2 = 1836.3
DL input+output M: L = 253.1 + 4281.7 = 4534.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _010: ^.layer_01
  _01: applySym(flipWidth, ^.layer_0.shape) at corner(^.layer_0.pos, ^.layer_01.pos) + (0, 2)
  _011: applySym(flipHeight, ^.layer_0.shape) at corner(^.layer_01.pos, ^.layer_0.pos) + (2, 0)
  _0111: applySym(rotate180, ^.layer_0.shape) at ^.layer_01.pos + (2, 2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: 
0 0 
0 0 
 with color ? at (?,?)

DL input  with Mi: L = 67.3 + 0.0 = 67.3
DL output with Mo: L = 179.0 + 1657.2 = 1836.3
DL input+output M: L = 246.3 + 1657.2 = 1903.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (20,30) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . . 0 
0 . . 0 
0 . . 0 
0 0 0 0 
 with color red at (3,5)
  _01: 
0 0 
0 0 
 with color green at (7,9)
diff: 
   (0.0 bits)
data: a background with size (20,30) and color black and layers
  _0: 
2 . . 2 
2 . . 2 
2 . . 2 
2 2 2 2 
 at (3,5)
  _010: 
3 3 
3 3 
 at (7,9)
  _01: 
2 . . 2 
2 . . 2 
2 . . 2 
2 2 2 2 
 at (3,11)
  _011: 
2 2 2 2 
2 . . 2 
2 . . 2 
2 . . 2 
 at (9,5)
  _0111: 
2 2 2 2 
2 . . 2 
2 . . 2 
2 . . 2 
 at (9,11)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,30) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . . 0 
0 . . 0 
0 . . 0 
0 0 0 0 
 with color red at (3,5)
  _01: 
0 0 
0 0 
 with color green at (7,9)
diff: 
correct output grid

TRAIN 4938f0c2.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 0 
 with color red at (0,1)
  _01: 
0 0 
0 0 
 with color green at (3,4)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
2 2 . 
2 . 2 
. 2 2 
 at (0,1)
  _010: 
3 3 
3 3 
 at (3,4)
  _01: 
. 2 2 
2 . 2 
2 2 . 
 at (0,6)
  _011: 
. 2 2 
2 . 2 
2 2 . 
 at (5,1)
  _0111: 
2 2 . 
2 . 2 
. 2 2 
 at (5,6)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 0 
 with color red at (0,1)
  _01: 
0 0 
0 0 
 with color green at (3,4)
diff: 
correct output grid

TRAIN 4938f0c2.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (12,14) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
0 . . 
0 0 0 
 with color red at (1,2)
  _01: 
0 0 
0 0 
 with color green at (4,5)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (12,14) and color black and layers
  _0: 
2 . . 
2 . . 
2 2 2 
 at (1,2)
  _010: 
3 3 
3 3 
 at (4,5)
  _01: 
. . 2 
. . 2 
2 2 2 
 at (1,7)
  _011: 
2 2 2 
2 . . 
2 . . 
 at (6,2)
  _0111: 
2 2 2 
. . 2 
. . 2 
 at (6,7)
  + 4 delta pixels
diff: 
   (165.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,14) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
0 . . 
0 0 0 
 with color red at (1,2)
  _01: 
0 0 
0 0 
 with color green at (4,5)
  + 1 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,14) and color black and layers
  _0: rectangle with size (2,2) with model Full with color green at (4,5)
  _01: 
0 . . 
0 . . 
0 0 0 
 with color red at (1,2)
  + 1 delta pixels
diff:   ^.layer_01.shape.mask
! 23 wrong pixels (generated / expected)

TRAIN 4938f0c2.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,14) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 0 
. 0 . . 
. . 0 . 
. . 0 0 
 with color red at (2,2)
  _01: 
0 0 
0 0 
 with color green at (6,6)
diff: 
correct output grid

TEST 4938f0c2.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 22.4 sec (22.4 sec/task)
bits-train-error = 1657.2 bits (1657.2 bits/task)
acc-train-micro = 0.67 tasks (66.67%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.67
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-288] Checking task 496994bd.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 31294.8 = 31297.1
DL output with Mo: L = 2.3 + 31294.8 = 31297.1
DL input+output M: L = 4.6 + 62589.6 = 62594.2

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = closeSym(flipHeight; flipWidth; , black, ^)
0.250	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.134	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.053	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.050	IN  SPE ^.layer_0.shape.color = red
0.048	IN  SPE ^.layer_0.shape.mask.model = Full
0.046	IN  SPE ^.layer_01.shape.mask.model = Full
0.044	IN  SPE ^.color = black
0.003	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
closeSym(flipHeight; flipWidth; , black, ^)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color red at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 74.7 + 1295.3 = 1370.0
DL output with Mo: L = 18.1 + 0.0 = 18.1
DL input+output M: L = 92.8 + 1295.3 = 1388.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
closeSym(flipHeight; flipWidth; , black, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 18.1 + 0.0 = 18.1
DL input+output M: L = 20.4 + 0.0 = 20.4

# train input/output grids

## instance 1

> Input and output best reading:

data: 
2 2 2 
2 2 2 
3 3 3 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 

diff: 
   (0.0 bits)
data: 
2 2 2 
2 2 2 
3 3 3 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
3 3 3 
2 2 2 
2 2 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 2 2 
2 2 2 
3 3 3 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 

diff: 
correct output grid

TRAIN 496994bd.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
2 2 2 2 2 
8 8 8 8 8 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
2 2 2 2 2 
8 8 8 8 8 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
8 8 8 8 8 
2 2 2 2 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 2 2 2 2 
8 8 8 8 8 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 

diff: 
correct output grid

TRAIN 496994bd.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 3 3 3 3 3 
5#5#5#5#5#5#
5#5#5#5#5#5#
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 

diff: 
correct output grid

TEST 496994bd.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 0.9 sec (0.9 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-287] Checking task 49d1d64f.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 7503.7 = 7506.0
DL output with Mo: L = 2.3 + 23656.2 = 23658.5
DL input+output M: L = 4.6 + 31159.9 = 31164.5

# learning a model for train pairs
2.000	
1.672	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.372	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.258	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
1.154	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
1.049	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.959	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.867	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.773	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.695	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.685	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.663	IN  SPE ^.layer_0.shape.color = blue
0.640	IN  SPE ^.layer_011.shape.color = green
0.622	OUT SPE ^.size = ^.size + (2, 2)
0.608	OUT SPE ^.layer_01.shape.mask.size = '(2, 2)
0.597	OUT SPE ^.layer_0.pos = '(0, 0)
0.586	OUT SPE ^.layer_0111.pos = '(2, 2)
0.575	OUT SPE ^.layer_01.pos = projJ(^.layer_01.pos) + (0, 1)
0.568	OUT SPE ^.layer_0.shape.color = majorityColor(^)
0.562	OUT SPE ^.layer_0111.shape.mask.size.i = ^.size.i
0.555	OUT SPE ^.layer_011.shape.mask.size.i = 2
0.548	OUT SPE ^.layer_01111.shape.mask.size.j = 2
0.542	OUT SPE ^.layer_01111.pos = projI(^.layer_01.pos) + (1, 0)
0.200	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size + (2, 2) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color majorityColor(^) at '(0, 0)
  _01: rectangle with size '(2, 2) with model ? with color ? at projJ(^.layer_01.pos) + (0, 1)
  _011: rectangle with size (2,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (^.size.i,?) with model ? with color ? at '(2, 2)
  _01111: rectangle with size (?,2) with model ? with color ? at projI(^.layer_01.pos) + (1, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color blue at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color green at (?,?)

DL input  with Mi: L = 75.3 + 2596.0 = 2671.3
DL output with Mo: L = 237.3 + 4166.0 = 4403.3
DL input+output M: L = 312.6 + 6762.0 = 7074.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size + (2, 2) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color majorityColor(^) at '(0, 0)
  _01: rectangle with size '(2, 2) with model ? with color ? at projJ(^.layer_01.pos) + (0, 1)
  _011: rectangle with size (2,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (^.size.i,?) with model ? with color ? at '(2, 2)
  _01111: rectangle with size (?,2) with model ? with color ? at projI(^.layer_01.pos) + (1, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color blue at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color green at (?,?)

DL input  with Mi: L = 75.3 + 31.7 = 107.0
DL output with Mo: L = 237.3 + 4166.0 = 4403.3
DL input+output M: L = 312.6 + 4197.7 = 4510.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (2,2) and color red and layers
  _0: point with color blue at (0,0)
  _01: point with color cyan at (1,1)
  _011: point with color green at (1,0)
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color blue at (0,0)
  _01: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color red at (0,2)
  _011: rectangle with size (2,1) with model Full with color green at (2,1)
  _0111: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color cyan at (2,2)
  _01111: rectangle with size (1,2) with model Full with color green at (2,0)
diff: 
   (75.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (2,2) and color red and layers
  _0: point with color blue at (0,0)
  _01: point with color cyan at (1,1)
  _011: point with color green at (1,0)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (2,2) and color red and layers
  _0: point with color blue at (0,0)
  _01: point with color green at (1,0)
  _011: point with color cyan at (1,1)
diff:   ^.layer_011.shape.color
! 12 wrong pixels (generated / expected)

TRAIN 49d1d64f.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (2,3) and color cyan and layers
  _0: point with color blue at (0,0)
  _01: point with color yellow at (0,2)
  _011: point with color green at (1,1)
diff: 
   (0.0 bits)
data: a background with size (4,5) and color black and layers
  _0: rectangle with size (4,5) with mask 
. . 0 . . 
. . 0 . . 
0 0 . 0 0 
. 0 . 0 . 
 with color cyan at (0,0)
  _01: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color yellow at (0,3)
  _011: rectangle with size (2,1) with model Full with color blue at (0,1)
  _0111: rectangle with size (2,1) with model Full with color green at (2,2)
  _01111: rectangle with size (1,2) with model Full with color blue at (1,0)
diff: 
   (94.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (2,3) and color cyan and layers
  _0: point with color blue at (0,0)
  _01: point with color yellow at (0,2)
  _011: point with color green at (1,1)
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (2,3) and color cyan and layers
  _0: point with color blue at (0,0)
  _01: point with color green at (1,1)
  _011: point with color yellow at (0,2)
diff:   ^.layer_011.shape.color
! 18 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (2,3) and color cyan and layers
  _0: point with color yellow at (0,2)
  _01: point with color blue at (0,0)
  _011: point with color green at (1,1)
diff:   ^.layer_0.shape.color
! 17 wrong pixels (generated / expected)

TRAIN 49d1d64f.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,3) and color red and layers
  _0: point with color blue at (0,1)
  _01: point with color cyan at (2,2)
  _011: point with color green at (2,0)
  + 3 delta pixels
diff: 
   (3.2 bits)
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color red at (0,0)
  _01: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color yellow at (0,3)
  _011: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color cyan at (3,3)
  _0111: rectangle with size (3,3) with mask 
. 0 0 
0 . . 
0 . . 
 with color red at (2,2)
  _01111: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color green at (3,0)
  + 4 delta pixels
diff: 
   (246.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color red and layers
  _0: point with color blue at (0,1)
  _01: point with color yellow at (0,2)
  _011: point with color green at (2,0)
  + 3 delta pixels
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color red and layers
  _0: point with color blue at (0,1)
  _01: point with color cyan at (1,0)
  _011: point with color green at (2,0)
  + 3 delta pixels
diff: 
! 19 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,3) and color red and layers
  _0: point with color blue at (0,1)
  _01: point with color cyan at (2,2)
  _011: point with color green at (2,0)
  + 3 delta pixels
diff: 
! 21 wrong pixels (generated / expected)

TRAIN 49d1d64f.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,2) and color yellow and layers
  _0: point with color blue at (1,0)
  _01: point with color red at (0,0)
  _011: point with color green at (2,0)
  + 1 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,2) and color yellow and layers
  _0: point with color blue at (1,0)
  _01: point with color cyan at (0,1)
  _011: point with color green at (2,0)
  + 1 delta pixels
diff: 
! 19 wrong pixels (generated / expected)

TEST 49d1d64f.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.5 sec (59.5 sec/task)
bits-train-error = 4166.0 bits (4166.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-286] Checking task 4be741c5.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 155955.8 = 155958.2
DL output with Mo: L = 2.3 + 4105.1 = 4107.4
DL input+output M: L = 4.6 + 160060.9 = 160065.6

# learning a model for train pairs
2.000	
1.596	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.275	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
1.033	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.839	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.671	OUT ADD ^.layer_0 = point with color ? at (?,?)
0.497	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.412	OUT SPE ^.layer_0 = fillResizeAlike(transparent, '(1, 1), ^.layer_0)
0.373	IN  ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.333	OUT SPE ^.layer_01.pos = average(^.layer_0.pos, ^.layer_01.pos) / '3
0.304	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.285	OUT SPE ^.layer_011.pos.i = ^.layer_01.pos.i / '3
0.276	OUT SPE ^.layer_011.pos.j = average(^.layer_0.pos.j, ^.layer_00.pos.j) / '2
0.235	

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: fillResizeAlike(transparent, '(1, 1), ^.layer_0)
  _01: point with color ? at average(^.layer_0.pos, ^.layer_01.pos) / '3
  _011: point with color ? at (^.layer_01.pos.i / '3,average(^.layer_0.pos.j, ^.layer_00.pos.j) / '2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 6394.1 = 6492.2
DL output with Mo: L = 183.7 + 779.3 = 963.0
DL input+output M: L = 281.8 + 7173.4 = 7455.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: fillResizeAlike(transparent, '(1, 1), ^.layer_0)
  _01: point with color ? at average(^.layer_0.pos, ^.layer_01.pos) / '3
  _011: point with color ? at (^.layer_01.pos.i / '3,average(^.layer_0.pos.j, ^.layer_00.pos.j) / '2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 0.0 = 98.1
DL output with Mo: L = 183.7 + 779.3 = 963.0
DL input+output M: L = 281.8 + 779.3 = 1061.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (14,16) and color black and layers
  _00: rectangle with size (14,10) with mask 
. . . 0 0 0 0 0 0 0 
. . . . 0 0 0 0 . . 
. . . . 0 0 0 0 . . 
. . . 0 0 0 0 0 . . 
. . 0 0 0 0 0 0 0 . 
. . 0 0 0 0 0 0 . . 
. . . 0 0 0 0 0 . . 
. . . 0 0 0 0 0 0 . 
. 0 0 0 0 0 0 0 0 0 
. 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 . 
0 0 0 0 0 0 0 0 . . 
. 0 0 0 0 0 0 0 . . 
. . 0 0 0 0 0 0 0 . 
 with color red at (0,4)
  _0: rectangle with size (14,8) with model Full with color yellow at (0,0)
  _01: rectangle with size (14,4) with model Full with color cyan at (0,12)
diff: 
   (0.0 bits)
data: a background with size (1,3) and color black and layers
  _0: 
4 
 at (0,0)
  _01: point with color cyan at (0,2)
  _011: point with color red at (0,1)
diff: 
   (23.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,16) and color black and layers
  _00: rectangle with size (14,10) with mask 
. . . 0 0 0 0 0 0 0 
. . . . 0 0 0 0 . . 
. . . . 0 0 0 0 . . 
. . . 0 0 0 0 0 . . 
. . 0 0 0 0 0 0 0 . 
. . 0 0 0 0 0 0 . . 
. . . 0 0 0 0 0 . . 
. . . 0 0 0 0 0 0 . 
. 0 0 0 0 0 0 0 0 0 
. 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 . 
0 0 0 0 0 0 0 0 . . 
. 0 0 0 0 0 0 0 . . 
. . 0 0 0 0 0 0 0 . 
 with color red at (0,4)
  _0: rectangle with size (14,8) with model Full with color yellow at (0,0)
  _01: rectangle with size (14,4) with model Full with color cyan at (0,12)
diff: 
! size mismatch, 10x10 instead of 1x3

TRAIN 4be741c5.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,7) and color black and layers
  _00: rectangle with size (5,7) with mask 
. 0 0 0 . . 0 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 0 0 . . 0 0 
. 0 . . . . . 
 with color cyan at (3,0)
  _0: rectangle with size (4,7) with model Full with color red at (0,0)
  _01: rectangle with size (3,7) with model Full with color grey at (6,0)
diff: 
   (0.0 bits)
data: a background with size (3,1) and color black and layers
  _0: 
2 
 at (0,0)
  _01: point with color cyan at (1,0)
  _011: point with color grey at (2,0)
diff: 
   (23.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,7) and color black and layers
  _00: rectangle with size (5,7) with mask 
. 0 0 0 . . 0 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 0 0 . . 0 0 
. 0 . . . . . 
 with color cyan at (3,0)
  _0: rectangle with size (4,7) with model Full with color red at (0,0)
  _01: rectangle with size (3,7) with model Full with color grey at (6,0)
diff: 
! size mismatch, 10x10 instead of 3x1

TRAIN 4be741c5.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (11,9) and color yellow and layers
  _00: rectangle with size (3,9) with mask 
. 0 . . . . . 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color green at (8,0)
  _0: rectangle with size (3,9) with mask 
0 0 0 0 0 0 0 0 0 
0 0 . . 0 0 0 0 0 
0 . . . 0 . 0 . . 
 with color pink at (0,0)
  _01: rectangle with size (3,9) with mask 
. 0 0 . . . 0 0 . 
0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 0 . . 
 with color red at (6,0)
diff: 
   (0.0 bits)
data: a background with size (4,1) and color green and layers
  _0: 
6 
 at (0,0)
  _01: point with color yellow at (1,0)
  _011: point with color red at (2,0)
diff: 
   (30.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,9) and color yellow and layers
  _00: rectangle with size (3,9) with mask 
. 0 . . . . . 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color green at (8,0)
  _0: rectangle with size (3,9) with mask 
0 0 0 0 0 0 0 0 0 
0 0 . . 0 0 0 0 0 
0 . . . 0 . 0 . . 
 with color pink at (0,0)
  _01: rectangle with size (3,9) with mask 
. 0 0 . . . 0 0 . 
0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 0 . . 
 with color red at (6,0)
diff: 
! size mismatch, 10x10 instead of 4x1
>> Trial 2
data: a background with size (11,9) and color yellow and layers
  _00: rectangle with size (3,9) with mask 
. 0 . . . . . 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color green at (8,0)
  _0: rectangle with size (3,9) with mask 
. 0 0 . . . 0 0 . 
0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 0 . . 
 with color red at (6,0)
  _01: rectangle with size (3,9) with mask 
0 0 0 0 0 0 0 0 0 
0 0 . . 0 0 0 0 0 
0 . . . 0 . 0 . . 
 with color pink at (0,0)
diff: 
! size mismatch, 10x10 instead of 4x1

TRAIN 4be741c5.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
undefined expression: Average: not an integer

TEST 4be741c5.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 8.3 sec (8.3 sec/task)
bits-train-error = 779.3 bits (779.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-285] Checking task 4c4377d9.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 18634.8 = 18637.2
DL output with Mo: L = 2.3 + 37252.5 = 37254.8
DL input+output M: L = 4.6 + 55887.4 = 55892.0

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = unfoldSym( [ id ] [ flipHeight ], applySym(flipHeight, ^))
0.433	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.134	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.003	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
unfoldSym( [ id ] [ flipHeight ], applySym(flipHeight, ^))
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 2451.0 = 2492.9
DL output with Mo: L = 19.9 + 0.0 = 19.9
DL input+output M: L = 61.9 + 2451.0 = 2512.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
unfoldSym( [ id ] [ flipHeight ], applySym(flipHeight, ^))
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 19.9 + 0.0 = 19.9
DL input+output M: L = 22.2 + 0.0 = 22.2

# train input/output grids

## instance 1

> Input and output best reading:

data: 
9#9#5#9#
5#5#9#9#
9#5#9#9#

diff: 
   (0.0 bits)
data: 
9#5#9#9#
5#5#9#9#
9#9#5#9#
9#9#5#9#
5#5#9#9#
9#5#9#9#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
9#9#5#9#
5#5#9#9#
9#5#9#9#

diff: 
correct output grid

TRAIN 4c4377d9.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
4 1 1 4 
1 1 1 1 
4 4 4 1 

diff: 
   (0.0 bits)
data: 
4 4 4 1 
1 1 1 1 
4 1 1 4 
4 1 1 4 
1 1 1 1 
4 4 4 1 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 1 1 4 
1 1 1 1 
4 4 4 1 

diff: 
correct output grid

TRAIN 4c4377d9.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
9#4 9#4 
9#9#4 4 
4 4 4 4 

diff: 
   (0.0 bits)
data: 
4 4 4 4 
9#9#4 4 
9#4 9#4 
9#4 9#4 
9#9#4 4 
4 4 4 4 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
9#4 9#4 
9#9#4 4 
4 4 4 4 

diff: 
correct output grid

TRAIN 4c4377d9.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: 
3 3 5#5#
3 5#5#3 
5#5#3 3 

diff: 
   (0.0 bits)
data: 
5#5#3 3 
3 5#5#3 
3 3 5#5#
3 3 5#5#
3 5#5#3 
5#5#3 3 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 3 5#5#
3 5#5#3 
5#5#3 3 

diff: 
correct output grid

TRAIN 4c4377d9.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 4 9#9#
4 4 4 4 
4 4 9#9#

diff: 
correct output grid

TEST 4c4377d9.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 0.4 sec (0.4 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-284] Checking task 4c5c2cf0.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 217708.9 = 217711.2
DL output with Mo: L = 2.3 + 217708.9 = 217711.2
DL input+output M: L = 4.6 + 435417.8 = 435422.4

# learning a model for train pairs
2.000	
1.073	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.269	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.234	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.193	OUT ADD ^.layer_0 = ^.layer_0
0.159	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.125	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.099	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.076	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.039	OUT ADD ^.layer_01111 = ^.layer_01
0.034	OUT SPE ^.layer_011.shape = applySym(rotate180, ^.layer_0.shape)
0.029	OUT SPE ^.layer_01.shape = applySym(flipWidth, ^.layer_0.shape)
0.024	OUT SPE ^.layer_0111.shape = applySym(flipHeight, ^.layer_0.shape)
0.021	OUT SPE ^.size = ^.size
0.019	IN  SPE ^.layer_01.shape.mask = 
0 . 0 
. 0 . 
0 . 0 

0.017	OUT SPE ^.layer_01.pos = ^.layer_0.pos - translationSym(flipWidth, ^.layer_01, ^.layer_0)
0.015	OUT SPE ^.layer_011.pos = ^.layer_0.pos - translationSym(rotate180, ^.layer_01, ^.layer_0)
0.014	OUT SPE ^.layer_0111.pos = ^.layer_0.pos - translationSym(flipHeight, ^.layer_01, ^.layer_0)
0.014	IN  SPE ^.color = black
0.013	OUT SPE ^.color = black
0.001	
0.001	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: applySym(flipWidth, ^.layer_0.shape) at ^.layer_0.pos - translationSym(flipWidth, ^.layer_01, ^.layer_0)
  _011: applySym(rotate180, ^.layer_0.shape) at ^.layer_0.pos - translationSym(rotate180, ^.layer_01, ^.layer_0)
  _0111: applySym(flipHeight, ^.layer_0.shape) at ^.layer_0.pos - translationSym(flipHeight, ^.layer_01, ^.layer_0)
  _01111: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: 
0 . 0 
. 0 . 
0 . 0 
 with color ? at (?,?)

DL input  with Mi: L = 78.8 + 2605.4 = 2684.1
DL output with Mo: L = 206.1 + 0.0 = 206.1
DL input+output M: L = 284.9 + 2605.4 = 2890.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: applySym(flipWidth, ^.layer_0.shape) at ^.layer_0.pos - translationSym(flipWidth, ^.layer_01, ^.layer_0)
  _011: applySym(rotate180, ^.layer_0.shape) at ^.layer_0.pos - translationSym(rotate180, ^.layer_01, ^.layer_0)
  _0111: applySym(flipHeight, ^.layer_0.shape) at ^.layer_0.pos - translationSym(flipHeight, ^.layer_01, ^.layer_0)
  _01111: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: 
0 . 0 
. 0 . 
0 . 0 
 with color ? at (?,?)

DL input  with Mi: L = 78.6 + 0.0 = 78.6
DL output with Mo: L = 206.1 + 0.0 = 206.1
DL input+output M: L = 284.7 + 0.0 = 284.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (14,14) and color black and layers
  _0: rectangle with size (5,4) with mask 
0 . . 0 
0 0 . 0 
. . 0 0 
. 0 0 . 
0 . . . 
 with color red at (3,3)
  _01: 
0 . 0 
. 0 . 
0 . 0 
 with color yellow at (7,6)
diff: 
   (0.0 bits)
data: a background with size (14,14) and color black and layers
  _0: 
2 . . 2 
2 2 . 2 
. . 2 2 
. 2 2 . 
2 . . . 
 at (3,3)
  _01: 
2 . . 2 
2 . 2 2 
2 2 . . 
. 2 2 . 
. . . 2 
 at (3,8)
  _011: 
. . . 2 
. 2 2 . 
2 2 . . 
2 . 2 2 
2 . . 2 
 at (9,8)
  _0111: 
2 . . . 
. 2 2 . 
. . 2 2 
2 2 . 2 
2 . . 2 
 at (9,3)
  _01111: 
4 . 4 
. 4 . 
4 . 4 
 at (7,6)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (5,4) with mask 
0 . . 0 
0 0 . 0 
. . 0 0 
. 0 0 . 
0 . . . 
 with color red at (3,3)
  _01: 
0 . 0 
. 0 . 
0 . 0 
 with color yellow at (7,6)
diff: 
correct output grid

TRAIN 4c5c2cf0.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (14,14) and color black and layers
  _0: rectangle with size (3,4) with mask 
. . 0 . 
. 0 0 0 
0 0 0 . 
 with color cyan at (3,6)
  _01: 
0 . 0 
. 0 . 
0 . 0 
 with color green at (6,4)
diff: 
   (0.0 bits)
data: a background with size (14,14) and color black and layers
  _0: 
. . 8 . 
. 8 8 8 
8 8 8 . 
 at (3,6)
  _01: 
. 8 . . 
8 8 8 . 
. 8 8 8 
 at (3,1)
  _011: 
. 8 8 8 
8 8 8 . 
. 8 . . 
 at (9,1)
  _0111: 
8 8 8 . 
. 8 8 8 
. . 8 . 
 at (9,6)
  _01111: 
3 . 3 
. 3 . 
3 . 3 
 at (6,4)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (3,4) with mask 
. . 0 . 
. 0 0 0 
0 0 0 . 
 with color cyan at (3,6)
  _01: 
0 . 0 
. 0 . 
0 . 0 
 with color green at (6,4)
diff: 
correct output grid

TRAIN 4c5c2cf0.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
0 . 0 
. 0 . 
 with color blue at (9,1)
  _01: 
0 . 0 
. 0 . 
0 . 0 
 with color cyan at (6,4)
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _0: 
. 1 1 
1 . 1 
. 1 . 
 at (9,1)
  _01: 
1 1 . 
1 . 1 
. 1 . 
 at (9,7)
  _011: 
. 1 . 
1 . 1 
1 1 . 
 at (3,7)
  _0111: 
. 1 . 
1 . 1 
. 1 1 
 at (3,1)
  _01111: 
8 . 8 
. 8 . 
8 . 8 
 at (6,4)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
0 . 0 
. 0 . 
 with color blue at (9,1)
  _01: 
0 . 0 
. 0 . 
0 . 0 
 with color cyan at (6,4)
diff: 
correct output grid

TRAIN 4c5c2cf0.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (6,4) with mask 
. . 0 . 
0 0 . 0 
. 0 . . 
. 0 0 . 
0 . . . 
0 . . . 
 with color yellow at (8,7)
  _01: 
0 . 0 
. 0 . 
0 . 0 
 with color orange at (6,5)
diff: 
correct output grid

TEST 4c5c2cf0.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 22.1 sec (22.1 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-283] Checking task 50846271.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 545182.8 = 545185.1
DL output with Mo: L = 2.3 + 545182.8 = 545185.1
DL input+output M: L = 4.6 + 1090365.6 = 1090370.3

# learning a model for train pairs
2.000	
1.457	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.931	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.574	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.285	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.249	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.228	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.210	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.194	OUT ADD ^.layer_010 = ^.layer_01
0.180	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.169	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.161	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.154	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.092	
0.092	IN  DEL ^.layer_0111
0.092	IN  DEL ^.layer_011
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 33743.7 = 33869.5
DL output with Mo: L = 160.7 + 49947.0 = 50107.8
DL input+output M: L = 286.5 + 83690.7 = 83977.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 31.7 = 101.9
DL output with Mo: L = 160.7 + 49947.0 = 50107.8
DL input+output M: L = 230.9 + 49978.7 = 50209.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (20,22) and color black and layers
  _0: rectangle with size (20,22) with mask 
. . . . . . . 0 . . . . . . . . . . . . . . 
. 0 . . 0 0 0 0 . . . . . . . . . . . . 0 0 
0 . 0 0 . 0 0 0 . . . . . . . . . . . . 0 . 
0 . . 0 0 . . . 0 . . . . . . . . 0 0 0 . . 
. . . . . 0 . . . 0 . . . . . . . 0 . 0 0 . 
. . . . 0 . . . 0 . 0 . . . . . 0 . 0 . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . 0 0 0 
. . . . . 0 . . . 0 0 . . . . 0 0 . 0 . . . 
0 . . . . . 0 . 0 . . . . . . . . . . 0 . . 
0 . . 0 . . . . . 0 0 . . . . . . . . 0 . . 
. 0 . 0 . 0 0 0 0 0 . . . . . . 0 0 0 . 0 0 
. 0 0 . . 0 . . 0 . 0 0 . . . . 0 0 . . 0 0 
. . 0 0 . . 0 0 0 . . 0 . . . . . 0 0 . . . 
. . 0 . . 0 0 0 . . . . . 0 . . 0 0 . . . . 
. . . 0 0 . . . . . . . 0 0 . 0 . . 0 . . . 
. 0 0 . . 0 0 . 0 . . 0 . . 0 0 0 . . . . . 
0 . . . 0 . . 0 0 . 0 . . 0 . . 0 0 0 . . . 
. . 0 0 . . 0 . . . 0 . . . 0 0 . . . 0 0 0 
. 0 0 0 . . . 0 0 0 0 . . 0 0 . 0 . . . 0 0 
. . . . . . . . . . . . . 0 . 0 . 0 . . . 0 
 with color grey at (0,0)
  _01: rectangle with size (3,6) with mask 
0 0 0 0 0 0 
0 . 0 . 0 . 
0 0 . . . . 
 with color grey at (0,10)
  + 41 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,22) and color black and layers
  _0: rectangle with size (19,16) with mask 
. . . . . . . . . . . . . . 0 0 
. . . . . . . . . . . . . . 0 . 
. . . . . . . . . . . 0 0 0 . . 
. . . . . . . . . . . 0 . 0 0 . 
. . . . . . . . . . 0 . 0 . . . 
. . . . . . . . . . 0 . . 0 0 0 
. . . . . . . . . 0 0 . 0 . . . 
. . . . . . . . . . . . . 0 . . 
. . . . . . . . . . . . . 0 . . 
. . . . . . . . . . 0 0 0 . 0 0 
. . . . . . . . . . 0 0 . . 0 0 
. . . . . . . . . . . 0 0 . . . 
. . . . . . . 0 . . 0 0 . . . . 
. . . . . . 0 0 . 0 . . 0 . . . 
0 . 0 . . 0 . . 0 0 0 . . . . . 
. 0 0 . 0 . . 0 . . 0 0 0 . . . 
0 . . . 0 . . . 0 0 . . . 0 0 0 
. 0 0 0 0 . . 0 0 . 0 . . . 0 0 
. . . . . . . 0 . 0 . 0 . . . 0 
 with color grey at (1,6)
  _010: 
5#5#5#5#5#5#
5#. 5#. 5#. 
5#5#. . . . 
 at (0,10)
  _01: rectangle with size (9,10) with mask 
. . . . . . . 0 . . 
. 0 . . 0 0 0 0 . . 
0 . 0 0 . 0 0 0 . . 
0 . . 0 0 . . . 0 . 
. . . . . 0 . . . 0 
. . . . 0 . . . 0 . 
. . . . 0 . . . . . 
. . . . . 0 . . . . 
. . . . . . 0 . . . 
 with color grey at (0,0)
  _011: rectangle with size (8,7) with mask 
. . . . . 0 . 
. . . . 0 0 . 
. . . 0 . . . 
. . . . 0 0 . 
0 0 0 0 0 . . 
. . . 0 . 0 0 
. 0 0 0 . . 0 
. 0 0 . . . . 
 with color grey at (6,5)
  _0111: rectangle with size (6,4) with mask 
0 . . . 
0 . . 0 
. 0 . 0 
. 0 0 . 
. . 0 0 
. . 0 . 
 with color grey at (8,0)
  _01111: rectangle with size (7,2) with mask 
. 0 
. 0 
. 0 
0 . 
. 0 
. 0 
. 0 
 with color red at (2,11)
  + 49 delta pixels
diff: 
   (2684.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,22) and color black and layers
  _0: rectangle with size (20,22) with mask 
. . . . . . . 0 . . . . . . . . . . . . . . 
. 0 . . 0 0 0 0 . . . . . . . . . . . . 0 0 
0 . 0 0 . 0 0 0 . . . . . . . . . . . . 0 . 
0 . . 0 0 . . . 0 . . . . . . . . 0 0 0 . . 
. . . . . 0 . . . 0 . . . . . . . 0 . 0 0 . 
. . . . 0 . . . 0 . 0 . . . . . 0 . 0 . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . 0 0 0 
. . . . . 0 . . . 0 0 . . . . 0 0 . 0 . . . 
0 . . . . . 0 . 0 . . . . . . . . . . 0 . . 
0 . . 0 . . . . . 0 0 . . . . . . . . 0 . . 
. 0 . 0 . 0 0 0 0 0 . . . . . . 0 0 0 . 0 0 
. 0 0 . . 0 . . 0 . 0 0 . . . . 0 0 . . 0 0 
. . 0 0 . . 0 0 0 . . 0 . . . . . 0 0 . . . 
. . 0 . . 0 0 0 . . . . . 0 . . 0 0 . . . . 
. . . 0 0 . . . . . . . 0 0 . 0 . . 0 . . . 
. 0 0 . . 0 0 . 0 . . 0 . . 0 0 0 . . . . . 
0 . . . 0 . . 0 0 . 0 . . 0 . . 0 0 0 . . . 
. . 0 0 . . 0 . . . 0 . . . 0 0 . . . 0 0 0 
. 0 0 0 . . . 0 0 0 0 . . 0 0 . 0 . . . 0 0 
. . . . . . . . . . . . . 0 . 0 . 0 . . . 0 
 with color grey at (0,0)
  _01: rectangle with size (3,6) with mask 
0 0 0 0 0 0 
0 . 0 . 0 . 
0 0 . . . . 
 with color grey at (0,10)
  + 41 delta pixels
diff: 
! size mismatch, 10x10 instead of 20x22
>> Trial 2
data: a background with size (20,22) and color black and layers
  _0: rectangle with size (3,6) with mask 
0 0 0 0 0 0 
0 . 0 . 0 . 
0 0 . . . . 
 with color grey at (0,10)
  _01: rectangle with size (20,22) with mask 
. . . . . . . 0 . . . . . . . . . . . . . . 
. 0 . . 0 0 0 0 . . . . . . . . . . . . 0 0 
0 . 0 0 . 0 0 0 . . . . . . . . . . . . 0 . 
0 . . 0 0 . . . 0 . . . . . . . . 0 0 0 . . 
. . . . . 0 . . . 0 . . . . . . . 0 . 0 0 . 
. . . . 0 . . . 0 . 0 . . . . . 0 . 0 . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . 0 0 0 
. . . . . 0 . . . 0 0 . . . . 0 0 . 0 . . . 
0 . . . . . 0 . 0 . . . . . . . . . . 0 . . 
0 . . 0 . . . . . 0 0 . . . . . . . . 0 . . 
. 0 . 0 . 0 0 0 0 0 . . . . . . 0 0 0 . 0 0 
. 0 0 . . 0 . . 0 . 0 0 . . . . 0 0 . . 0 0 
. . 0 0 . . 0 0 0 . . 0 . . . . . 0 0 . . . 
. . 0 . . 0 0 0 . . . . . 0 . . 0 0 . . . . 
. . . 0 0 . . . . . . . 0 0 . 0 . . 0 . . . 
. 0 0 . . 0 0 . 0 . . 0 . . 0 0 0 . . . . . 
0 . . . 0 . . 0 0 . 0 . . 0 . . 0 0 0 . . . 
. . 0 0 . . 0 . . . 0 . . . 0 0 . . . 0 0 0 
. 0 0 0 . . . 0 0 0 0 . . 0 0 . 0 . . . 0 0 
. . . . . . . . . . . . . 0 . 0 . 0 . . . 0 
 with color grey at (0,0)
  + 41 delta pixels
diff: 
! size mismatch, 10x10 instead of 20x22

TRAIN 50846271.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (20,20) with mask 
. 0 . 0 . . . 0 0 . 0 0 . . . 0 0 . 0 0 
0 0 . 0 0 0 . 0 0 . 0 . . 0 . . . 0 0 . 
. 0 . 0 0 . 0 0 . 0 . . 0 . . 0 . . 0 0 
0 . . 0 0 . . 0 . 0 . 0 . . . 0 0 0 0 0 
. 0 . 0 . 0 . . . . 0 0 . 0 . 0 0 . . . 
0 0 . . 0 0 . 0 0 0 . 0 . . 0 0 . . . . 
. . 0 0 . . 0 0 . . 0 0 . . 0 . . 0 . 0 
. . . 0 . 0 . 0 0 0 . 0 0 0 . . 0 0 . 0 
. . . . 0 . . 0 0 0 0 . 0 0 0 . . 0 . 0 
. . . 0 . 0 0 0 . 0 0 . 0 . 0 0 0 0 0 0 
. . 0 0 . 0 0 0 0 0 . 0 . 0 . . . . . 0 
. . 0 . . . . . . 0 0 0 . . 0 . . 0 . 0 
. . 0 . . 0 . 0 0 . 0 0 0 0 0 0 0 0 0 . 
0 0 . . 0 0 . 0 . . 0 0 0 . . . . . . . 
0 0 . . . 0 0 0 . 0 0 . 0 0 0 0 . . 0 0 
. . 0 . 0 0 0 . . 0 0 . . 0 . . 0 0 . . 
. 0 0 . . 0 0 . 0 . 0 0 . . 0 . 0 0 . . 
. . 0 . 0 . 0 0 . 0 0 0 . . 0 . . . 0 . 
. . 0 . 0 0 . 0 0 0 . 0 0 0 . 0 . . 0 0 
0 0 0 . 0 . 0 . 0 0 . . 0 0 . . . . . 0 
 with color grey at (0,0)
  _01: rectangle with size (3,3) with mask 
0 . . 
0 0 0 
0 . . 
 with color red at (3,6)
  + 11 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (20,20) with mask 
. 0 . 0 . . . 0 0 . 0 0 . . . 0 0 . 0 0 
0 0 . 0 0 0 . 0 0 . 0 . . 0 . . . 0 0 . 
. 0 . 0 0 . . 0 . 0 . . 0 . . 0 . . 0 0 
0 . . 0 0 . . 0 . 0 . 0 . . . 0 0 0 0 0 
. 0 . 0 . . . . . . 0 0 . 0 . 0 0 . . . 
0 0 . . 0 0 . 0 0 0 . 0 . . 0 0 . . . . 
. . 0 0 . . . 0 . . 0 0 . . 0 . . . . . 
. . . 0 . 0 . 0 0 0 . 0 0 0 . . . . . . 
. . . . 0 . . 0 0 0 0 . 0 0 . . . . . . 
. . . 0 . 0 0 0 . 0 0 . 0 . . . . . . . 
. . 0 0 . 0 0 0 0 0 . 0 . . . . . . . . 
. . 0 . . . . . . 0 0 0 . . . . . . . . 
. . 0 . . 0 . 0 0 . 0 0 0 0 . . . . . . 
0 0 . . 0 0 . . . . 0 0 0 . . . . . . . 
0 0 . . . 0 0 . . 0 0 . 0 0 0 0 . . 0 0 
. . 0 . 0 . . . . . 0 . . 0 . . 0 0 . . 
. 0 0 . . 0 0 . 0 . 0 0 . . 0 . 0 0 . . 
. . 0 . 0 . 0 . . 0 0 0 . . 0 . . . 0 . 
. . 0 . 0 0 . 0 0 0 . 0 0 0 . 0 . . 0 0 
0 0 0 . 0 . 0 . 0 0 . . 0 0 . . . . . 0 
 with color grey at (0,0)
  _010: 
2 . . 
2 2 2 
2 . . 
 at (3,6)
  _01: rectangle with size (7,5) with mask 
. . 0 . 0 
. 0 0 . 0 
. . 0 . 0 
0 0 0 0 0 
. . . . 0 
. . 0 . 0 
0 0 0 0 . 
 with color grey at (6,15)
  _011: rectangle with size (5,2) with mask 
. 0 
. 0 
0 . 
. 0 
. 0 
 with color cyan at (8,13)
  _0111: rectangle with size (1,5) with model Full with color red at (10,12)
  _01111: rectangle with size (3,3) with mask 
. . 0 
. . 0 
0 0 . 
 with color cyan at (13,5)
  + 12 delta pixels
diff: 
   (1167.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (20,20) with mask 
. 0 . 0 . . . 0 0 . 0 0 . . . 0 0 . 0 0 
0 0 . 0 0 0 . 0 0 . 0 . . 0 . . . 0 0 . 
. 0 . 0 0 . 0 0 . 0 . . 0 . . 0 . . 0 0 
0 . . 0 0 . . 0 . 0 . 0 . . . 0 0 0 0 0 
. 0 . 0 . 0 . . . . 0 0 . 0 . 0 0 . . . 
0 0 . . 0 0 . 0 0 0 . 0 . . 0 0 . . . . 
. . 0 0 . . 0 0 . . 0 0 . . 0 . . 0 . 0 
. . . 0 . 0 . 0 0 0 . 0 0 0 . . 0 0 . 0 
. . . . 0 . . 0 0 0 0 . 0 0 0 . . 0 . 0 
. . . 0 . 0 0 0 . 0 0 . 0 . 0 0 0 0 0 0 
. . 0 0 . 0 0 0 0 0 . 0 . 0 . . . . . 0 
. . 0 . . . . . . 0 0 0 . . 0 . . 0 . 0 
. . 0 . . 0 . 0 0 . 0 0 0 0 0 0 0 0 0 . 
0 0 . . 0 0 . 0 . . 0 0 0 . . . . . . . 
0 0 . . . 0 0 0 . 0 0 . 0 0 0 0 . . 0 0 
. . 0 . 0 0 0 . . 0 0 . . 0 . . 0 0 . . 
. 0 0 . . 0 0 . 0 . 0 0 . . 0 . 0 0 . . 
. . 0 . 0 . 0 0 . 0 0 0 . . 0 . . . 0 . 
. . 0 . 0 0 . 0 0 0 . 0 0 0 . 0 . . 0 0 
0 0 0 . 0 . 0 . 0 0 . . 0 0 . . . . . 0 
 with color grey at (0,0)
  _01: rectangle with size (3,3) with mask 
0 . . 
0 0 0 
0 . . 
 with color red at (3,6)
  + 11 delta pixels
diff: 
! size mismatch, 10x10 instead of 20x20
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (20,20) with mask 
. 0 . 0 . . . 0 0 . 0 0 . . . 0 0 . 0 0 
0 0 . 0 0 0 . 0 0 . 0 . . 0 . . . 0 0 . 
. 0 . 0 0 . 0 0 . 0 . . 0 . . 0 . . 0 0 
0 . . 0 0 . . 0 . 0 . 0 . . . 0 0 0 0 0 
. 0 . 0 . 0 . . . . 0 0 . 0 . 0 0 . . . 
0 0 . . 0 0 . 0 0 0 . 0 . . 0 0 . . . . 
. . 0 0 . . 0 0 . . 0 0 . . 0 . . 0 . 0 
. . . 0 . 0 . 0 0 0 . 0 0 0 . . 0 0 . 0 
. . . . 0 . . 0 0 0 0 . 0 0 0 . . 0 . 0 
. . . 0 . 0 0 0 . 0 0 . 0 . 0 0 0 0 0 0 
. . 0 0 . 0 0 0 0 0 . 0 . 0 . . . . . 0 
. . 0 . . . . . . 0 0 0 . . 0 . . 0 . 0 
. . 0 . . 0 . 0 0 . 0 0 0 0 0 0 0 0 0 . 
0 0 . . 0 0 . 0 . . 0 0 0 . . . . . . . 
0 0 . . . 0 0 0 . 0 0 . 0 0 0 0 . . 0 0 
. . 0 . 0 0 0 . . 0 0 . . 0 . . 0 0 . . 
. 0 0 . . 0 0 . 0 . 0 0 . . 0 . 0 0 . . 
. . 0 . 0 . 0 0 . 0 0 0 . . 0 . . . 0 . 
. . 0 . 0 0 . 0 0 0 . 0 0 0 . 0 . . 0 0 
0 0 0 . 0 . 0 . 0 0 . . 0 0 . . . . . 0 
 with color grey at (0,0)
  _01: rectangle with size (1,5) with model Full with color red at (4,4)
  + 12 delta pixels
diff: 
! size mismatch, 10x10 instead of 20x20
>> Trial 3
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (20,20) with mask 
. 0 . 0 . . . 0 0 . 0 0 . . . 0 0 . 0 0 
0 0 . 0 0 0 . 0 0 . 0 . . 0 . . . 0 0 . 
. 0 . 0 0 . 0 0 . 0 . . 0 . . 0 . . 0 0 
0 . . 0 0 . . 0 . 0 . 0 . . . 0 0 0 0 0 
. 0 . 0 . 0 . . . . 0 0 . 0 . 0 0 . . . 
0 0 . . 0 0 . 0 0 0 . 0 . . 0 0 . . . . 
. . 0 0 . . 0 0 . . 0 0 . . 0 . . 0 . 0 
. . . 0 . 0 . 0 0 0 . 0 0 0 . . 0 0 . 0 
. . . . 0 . . 0 0 0 0 . 0 0 0 . . 0 . 0 
. . . 0 . 0 0 0 . 0 0 . 0 . 0 0 0 0 0 0 
. . 0 0 . 0 0 0 0 0 . 0 . 0 . . . . . 0 
. . 0 . . . . . . 0 0 0 . . 0 . . 0 . 0 
. . 0 . . 0 . 0 0 . 0 0 0 0 0 0 0 0 0 . 
0 0 . . 0 0 . 0 . . 0 0 0 . . . . . . . 
0 0 . . . 0 0 0 . 0 0 . 0 0 0 0 . . 0 0 
. . 0 . 0 0 0 . . 0 0 . . 0 . . 0 0 . . 
. 0 0 . . 0 0 . 0 . 0 0 . . 0 . 0 0 . . 
. . 0 . 0 . 0 0 . 0 0 0 . . 0 . . . 0 . 
. . 0 . 0 0 . 0 0 0 . 0 0 0 . 0 . . 0 0 
0 0 0 . 0 . 0 . 0 0 . . 0 0 . . . . . 0 
 with color grey at (0,0)
  _01: rectangle with size (1,5) with model Full with color red at (10,12)
  + 12 delta pixels
diff: 
! size mismatch, 10x10 instead of 20x20

TRAIN 50846271.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (18,19) and color black and layers
  _0: rectangle with size (18,19) with mask 
. . 0 . 0 . 0 0 0 0 . 0 0 . . . 0 0 . 
. . 0 0 0 . 0 0 0 0 . . 0 0 0 0 0 . 0 
. 0 0 0 . 0 . 0 0 . . . 0 0 0 . 0 . . 
0 0 0 0 0 . . . 0 0 0 0 0 0 . . 0 . . 
0 0 . . . 0 0 0 . 0 0 0 0 . . . 0 . . 
0 . . . . . 0 . 0 . 0 . 0 . . 0 . 0 0 
0 . 0 . . 0 0 . 0 . . 0 . . 0 0 . 0 . 
. 0 . 0 0 0 0 0 . 0 . 0 0 0 0 . 0 0 0 
0 0 0 . 0 0 0 0 . . 0 . 0 0 0 . . . . 
0 . . 0 . . 0 . . 0 0 0 0 0 0 0 0 . . 
0 . 0 0 0 . . 0 0 0 0 . . 0 0 0 0 . 0 
. . 0 . 0 0 . . 0 0 0 0 0 . 0 0 0 0 . 
. 0 . . 0 0 . . 0 0 . . 0 . . 0 . . . 
0 . . 0 0 0 0 0 . . 0 0 0 . 0 0 0 . . 
. 0 0 0 . . 0 . . . 0 . 0 0 0 0 . . . 
0 0 . . 0 0 0 0 . 0 0 . 0 . 0 . . . . 
0 . 0 . 0 . . . . . . 0 . . 0 . 0 . 0 
. 0 0 . 0 . . . . . 0 . . 0 . 0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (2,5) with mask 
. . 0 . . 
0 0 . 0 0 
 with color red at (5,9)
  + 6 delta pixels
diff: 
   (0.0 bits)
data: a background with size (18,19) and color black and layers
  _0: rectangle with size (18,19) with mask 
. . 0 . 0 . 0 0 0 0 . 0 0 . . . 0 0 . 
. . 0 0 0 . 0 0 0 0 . . 0 0 0 0 0 . 0 
. 0 0 0 . 0 . 0 0 . . . 0 0 0 . 0 . . 
0 0 0 0 0 . . . 0 0 0 0 0 0 . . 0 . . 
0 0 . . . 0 0 0 . 0 0 . 0 . . . 0 . . 
0 . . . . . 0 . 0 . 0 . 0 . . 0 . 0 0 
0 . 0 . . 0 0 . 0 . . . . . 0 0 . 0 . 
. . . 0 0 0 0 0 . 0 . . 0 0 0 . 0 0 0 
. . 0 . 0 0 0 0 . . 0 . 0 0 0 . . . . 
. . . . . . 0 . . 0 0 0 0 0 0 0 0 . . 
. . 0 0 0 . . 0 0 0 0 . . 0 0 0 0 . 0 
. . 0 . 0 0 . . 0 0 0 0 0 . 0 0 0 0 . 
. 0 . . 0 0 . . 0 0 . . 0 . . 0 . . . 
0 . . 0 0 0 0 0 . . 0 0 0 . 0 0 0 . . 
. 0 0 0 . . 0 . . . 0 . 0 0 0 0 . . . 
0 0 . . 0 0 0 0 . 0 0 . 0 . 0 . . . . 
0 . 0 . 0 . . . . . . 0 . . 0 . 0 . 0 
. 0 0 . 0 . . . . . 0 . . 0 . 0 0 0 0 
 with color grey at (0,0)
  _010: 
. . 2 . . 
2 2 . 2 2 
 at (5,9)
  _01: rectangle with size (3,2) with model Full with color red at (9,1)
  _011: rectangle with size (4,1) with model Full with color cyan at (4,11)
  _0111: rectangle with size (3,2) with mask 
. 0 
. 0 
0 . 
 with color cyan at (7,0)
  _01111: rectangle with size (3,1) with model Full with color grey at (8,0)
  + 3 delta pixels
diff: 
   (677.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,19) and color black and layers
  _0: rectangle with size (18,19) with mask 
. . 0 . 0 . 0 0 0 0 . 0 0 . . . 0 0 . 
. . 0 0 0 . 0 0 0 0 . . 0 0 0 0 0 . 0 
. 0 0 0 . 0 . 0 0 . . . 0 0 0 . 0 . . 
0 0 0 0 0 . . . 0 0 0 0 0 0 . . 0 . . 
0 0 . . . 0 0 0 . 0 0 0 0 . . . 0 . . 
0 . . . . . 0 . 0 . 0 . 0 . . 0 . 0 0 
0 . 0 . . 0 0 . 0 . . 0 . . 0 0 . 0 . 
. 0 . 0 0 0 0 0 . 0 . 0 0 0 0 . 0 0 0 
0 0 0 . 0 0 0 0 . . 0 . 0 0 0 . . . . 
0 . . 0 . . 0 . . 0 0 0 0 0 0 0 0 . . 
0 . 0 0 0 . . 0 0 0 0 . . 0 0 0 0 . 0 
. . 0 . 0 0 . . 0 0 0 0 0 . 0 0 0 0 . 
. 0 . . 0 0 . . 0 0 . . 0 . . 0 . . . 
0 . . 0 0 0 0 0 . . 0 0 0 . 0 0 0 . . 
. 0 0 0 . . 0 . . . 0 . 0 0 0 0 . . . 
0 0 . . 0 0 0 0 . 0 0 . 0 . 0 . . . . 
0 . 0 . 0 . . . . . . 0 . . 0 . 0 . 0 
. 0 0 . 0 . . . . . 0 . . 0 . 0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (2,5) with mask 
. . 0 . . 
0 0 . 0 0 
 with color red at (5,9)
  + 6 delta pixels
diff: 
! size mismatch, 10x10 instead of 18x19
>> Trial 2
data: a background with size (18,19) and color black and layers
  _0: rectangle with size (18,19) with mask 
. . 0 . 0 . 0 0 0 0 . 0 0 . . . 0 0 . 
. . 0 0 0 . 0 0 0 0 . . 0 0 0 0 0 . 0 
. 0 0 0 . 0 . 0 0 . . . 0 0 0 . 0 . . 
0 0 0 0 0 . . . 0 0 0 0 0 0 . . 0 . . 
0 0 . . . 0 0 0 . 0 0 0 0 . . . 0 . . 
0 . . . . . 0 . 0 . 0 . 0 . . 0 . 0 0 
0 . 0 . . 0 0 . 0 . . 0 . . 0 0 . 0 . 
. 0 . 0 0 0 0 0 . 0 . 0 0 0 0 . 0 0 0 
0 0 0 . 0 0 0 0 . . 0 . 0 0 0 . . . . 
0 . . 0 . . 0 . . 0 0 0 0 0 0 0 0 . . 
0 . 0 0 0 . . 0 0 0 0 . . 0 0 0 0 . 0 
. . 0 . 0 0 . . 0 0 0 0 0 . 0 0 0 0 . 
. 0 . . 0 0 . . 0 0 . . 0 . . 0 . . . 
0 . . 0 0 0 0 0 . . 0 0 0 . 0 0 0 . . 
. 0 0 0 . . 0 . . . 0 . 0 0 0 0 . . . 
0 0 . . 0 0 0 0 . 0 0 . 0 . 0 . . . . 
0 . 0 . 0 . . . . . . 0 . . 0 . 0 . 0 
. 0 0 . 0 . . . . . 0 . . 0 . 0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (3,2) with model Full with color red at (9,1)
  + 7 delta pixels
diff: 
! size mismatch, 10x10 instead of 18x19

TRAIN 50846271.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (11,12) and color black and layers
  _0: rectangle with size (11,12) with mask 
. 0 . . . . . . . . . . 
0 . 0 . . . . . . . . . 
0 . 0 . . 0 0 . . . . . 
0 0 . . 0 . 0 . . . . . 
0 . . 0 0 0 . 0 . . . . 
0 0 0 . 0 0 . 0 . . . . 
0 0 0 . 0 . . 0 0 . . . 
0 . . . . 0 . . . . . . 
. 0 0 . 0 . . . . 0 . . 
0 . . . 0 0 0 0 0 . . . 
0 . . . . 0 . . 0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (4,3) with mask 
. . 0 
. . 0 
. 0 . 
0 . 0 
 with color grey at (0,9)
  + 10 delta pixels
diff: 
   (3.2 bits)
data: a background with size (11,12) and color black and layers
  _0: rectangle with size (11,12) with mask 
. 0 . . . . . . . . . . 
0 . 0 . . . . . . . . . 
0 . 0 . . 0 0 . . . . . 
0 0 . . 0 . 0 . . . . . 
0 . . 0 0 0 . . . . . . 
0 0 0 . 0 0 . . . . . . 
0 0 0 . 0 . . . . . . . 
0 . . . . 0 . . . . . . 
. 0 0 . 0 . . . . 0 . . 
0 . . . 0 0 0 0 0 . . . 
0 . . . . 0 . . 0 0 0 0 
 with color grey at (0,0)
  _010: 
. . 5#
. . 5#
. 5#. 
5#. 5#
 at (0,9)
  _01: rectangle with size (4,1) with model Full with color red at (2,8)
  _011: rectangle with size (1,5) with model Full with color red at (4,6)
  _0111: rectangle with size (2,1) with model Full with color grey at (5,7)
  _01111: rectangle with size (1,1) with model Full with color grey at (0,6)
  + 4 delta pixels
diff: 
   (466.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,12) and color black and layers
  _0: rectangle with size (11,12) with mask 
. 0 . . . . . . . . . . 
0 . 0 . . . . . . . . . 
0 . 0 . . 0 0 . . . . . 
0 0 . . 0 . 0 . . . . . 
0 . . 0 0 0 . 0 . . . . 
0 0 0 . 0 0 . 0 . . . . 
0 0 0 . 0 . . 0 0 . . . 
0 . . . . 0 . . . . . . 
. 0 0 . 0 . . . . 0 . . 
0 . . . 0 0 0 0 0 . . . 
0 . . . . 0 . . 0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (4,3) with mask 
0 . . 
0 . . 
0 0 0 
0 . . 
 with color red at (2,8)
  + 9 delta pixels
diff: 
! size mismatch, 10x10 instead of 11x12
>> Trial 2
data: a background with size (11,12) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 . . 
0 . . 
0 0 0 
0 . . 
 with color red at (2,8)
  _01: rectangle with size (11,12) with mask 
. 0 . . . . . . . . . . 
0 . 0 . . . . . . . . . 
0 . 0 . . 0 0 . . . . . 
0 0 . . 0 . 0 . . . . . 
0 . . 0 0 0 . 0 . . . . 
0 0 0 . 0 0 . 0 . . . . 
0 0 0 . 0 . . 0 0 . . . 
0 . . . . 0 . . . . . . 
. 0 0 . 0 . . . . 0 . . 
0 . . . 0 0 0 0 0 . . . 
0 . . . . 0 . . 0 0 0 0 
 with color grey at (0,0)
  + 9 delta pixels
diff: 
! size mismatch, 10x10 instead of 11x12
>> Trial 3
data: a background with size (11,12) and color black and layers
  _0: rectangle with size (11,12) with mask 
. 0 . . . . . . . . . . 
0 . 0 . . . . . . . . . 
0 . 0 . . 0 0 . . . . . 
0 0 . . 0 . 0 . . . . . 
0 . . 0 0 0 . 0 . . . . 
0 0 0 . 0 0 . 0 . . . . 
0 0 0 . 0 . . 0 0 . . . 
0 . . . . 0 . . . . . . 
. 0 0 . 0 . . . . 0 . . 
0 . . . 0 0 0 0 0 . . . 
0 . . . . 0 . . 0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (4,3) with mask 
. . 0 
. . 0 
. 0 . 
0 . 0 
 with color grey at (0,9)
  + 10 delta pixels
diff: 
! size mismatch, 10x10 instead of 11x12

TRAIN 50846271.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,22) and color black and layers
  _0: rectangle with size (19,22) with mask 
. . . . . . . . . . . . . 0 . . . . . 0 0 . 
. . . . . . . . . . . . 0 0 . . . . . 0 0 0 
. . . . . . . . . . . 0 0 . . 0 0 . . 0 0 0 
. . . . . . . . . . . 0 . 0 . 0 0 . 0 0 0 . 
. . . . . . . . . . . . 0 . 0 0 0 . . 0 0 . 
. . . . . . . . . . . 0 . . . . 0 0 0 0 . . 
0 0 . . . . . . . . . . . 0 . . . 0 0 0 0 0 
0 . . . . . . . . . . 0 0 0 . 0 . . 0 . 0 . 
0 0 0 0 0 . . 0 0 . 0 . 0 . 0 0 . . 0 0 0 . 
. . . 0 0 0 . . 0 . . . 0 0 . 0 0 0 . . . . 
. . . 0 0 0 . 0 . 0 . 0 0 . 0 . 0 . . 0 0 . 
. 0 0 0 . . . 0 0 0 0 . . 0 . 0 0 . . . 0 0 
0 0 . . 0 0 0 . . 0 0 . 0 . 0 0 . . 0 0 . 0 
. . 0 0 0 0 0 0 0 0 . . 0 0 0 0 0 . . 0 . 0 
0 0 . 0 0 . . . 0 0 0 . 0 0 0 . 0 . . 0 0 . 
0 . . . 0 . 0 . 0 . 0 . 0 0 0 0 . . . . 0 0 
0 0 0 . . . . 0 0 . . . . . . . 0 . 0 . 0 0 
0 . 0 . . 0 . 0 . . . . . . . 0 0 0 . 0 0 . 
0 0 0 0 0 . 0 . 0 0 0 0 . . . . 0 0 . 0 . 0 
 with color grey at (0,0)
  _01: rectangle with size (7,9) with mask 
. . 0 . . . . . . 
. . 0 0 . . . . . 
. . . 0 0 0 . . . 
. 0 0 . 0 0 0 . 0 
0 . 0 . . 0 . . 0 
. . 0 . 0 . 0 0 0 
. . . 0 0 . . 0 0 
 with color grey at (0,1)
  + 29 delta pixels
diff: 
! size mismatch, 10x10 instead of 19x22
>> Trial 2
data: a background with size (19,22) and color black and layers
  _0: rectangle with size (7,9) with mask 
. . 0 . . . . . . 
. . 0 0 . . . . . 
. . . 0 0 0 . . . 
. 0 0 . 0 0 0 . 0 
0 . 0 . . 0 . . 0 
. . 0 . 0 . 0 0 0 
. . . 0 0 . . 0 0 
 with color grey at (0,1)
  _01: rectangle with size (19,22) with mask 
. . . . . . . . . . . . . 0 . . . . . 0 0 . 
. . . . . . . . . . . . 0 0 . . . . . 0 0 0 
. . . . . . . . . . . 0 0 . . 0 0 . . 0 0 0 
. . . . . . . . . . . 0 . 0 . 0 0 . 0 0 0 . 
. . . . . . . . . . . . 0 . 0 0 0 . . 0 0 . 
. . . . . . . . . . . 0 . . . . 0 0 0 0 . . 
0 0 . . . . . . . . . . . 0 . . . 0 0 0 0 0 
0 . . . . . . . . . . 0 0 0 . 0 . . 0 . 0 . 
0 0 0 0 0 . . 0 0 . 0 . 0 . 0 0 . . 0 0 0 . 
. . . 0 0 0 . . 0 . . . 0 0 . 0 0 0 . . . . 
. . . 0 0 0 . 0 . 0 . 0 0 . 0 . 0 . . 0 0 . 
. 0 0 0 . . . 0 0 0 0 . . 0 . 0 0 . . . 0 0 
0 0 . . 0 0 0 . . 0 0 . 0 . 0 0 . . 0 0 . 0 
. . 0 0 0 0 0 0 0 0 . . 0 0 0 0 0 . . 0 . 0 
0 0 . 0 0 . . . 0 0 0 . 0 0 0 . 0 . . 0 0 . 
0 . . . 0 . 0 . 0 . 0 . 0 0 0 0 . . . . 0 0 
0 0 0 . . . . 0 0 . . . . . . . 0 . 0 . 0 0 
0 . 0 . . 0 . 0 . . . . . . . 0 0 0 . 0 0 . 
0 0 0 0 0 . 0 . 0 0 0 0 . . . . 0 0 . 0 . 0 
 with color grey at (0,0)
  + 29 delta pixels
diff: 
! size mismatch, 10x10 instead of 19x22
>> Trial 3
data: a background with size (19,22) and color grey and layers
  _0: rectangle with size (19,22) with mask 
0 . 0 . 0 0 . . 0 . 0 0 0 . 0 . 0 0 0 . . . 
0 . 0 . . 0 0 0 . . 0 0 . . 0 0 0 0 0 . . . 
0 0 0 0 . . . 0 0 0 0 . . 0 0 . . 0 0 . . . 
0 0 . . 0 . . . 0 . 0 . 0 . 0 . . 0 . . . . 
0 . 0 . . . . . . . 0 0 . 0 . . . 0 0 . . . 
0 0 0 . 0 . . . . . 0 . 0 0 0 0 . . . . . . 
. . 0 0 . . . 0 . . 0 0 0 . 0 0 0 . . . . . 
. 0 0 0 0 0 0 0 0 0 0 . . . 0 . 0 0 . . . 0 
. . . . . 0 0 . . 0 . . . . . . 0 0 . . . 0 
. . . . . . 0 0 . 0 0 0 . . 0 . . . 0 0 0 0 
. . . . . . 0 . 0 . 0 . . . . 0 . 0 0 . . 0 
. . . . 0 0 0 . . . . 0 0 . 0 . . 0 0 0 . . 
. . 0 0 . . . 0 0 . . 0 . 0 . . 0 0 . . 0 . 
0 0 . . . . . . . . 0 0 . . . . . 0 0 . 0 . 
. . 0 . . . . . . . . 0 . . . 0 . 0 0 . . 0 
. 0 0 0 . . . 0 . 0 . 0 . . . . 0 0 0 0 . . 
. . . 0 0 . 0 . . 0 0 . . . . . . 0 . 0 . . 
. . . 0 0 . 0 . 0 0 0 0 0 . . . . . 0 . . . 
. . . . . 0 . 0 . . . . 0 . . . . . 0 . . . 
 with color black at (0,0)
  _01: rectangle with size (3,3) with mask 
0 0 0 
0 0 0 
0 . . 
 with color black at (9,0)
  + 31 delta pixels
diff: 
! size mismatch, 10x10 instead of 19x22

TEST 50846271.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.8 sec (59.8 sec/task)
bits-train-error = 49947.0 bits (49947.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-282] Checking task 508bd3b6.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 174280.1 = 174282.4
DL output with Mo: L = 2.3 + 174280.1 = 174282.4
DL input+output M: L = 4.6 + 348560.2 = 348564.8

# learning a model for train pairs
2.000	
1.217	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.499	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.311	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.118	OUT ADD ^.layer_0 = ^.layer_0
0.066	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.054	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.041	IN  ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.035	OUT SPE ^.layer_01 = ^.layer_00
0.031	OUT SPE ^.size = ^.size
0.030	OUT SPE ^.layer_011.shape.mask.size.j = ^.layer_0.shape.mask.size.j * '3
0.029	OUT SPE ^.layer_011.shape.color = green
0.028	OUT SPE ^.layer_011.pos.j = right(^.layer_0) + 1
0.028	IN  SPE ^.color = black
0.027	OUT SPE ^.color = black
0.011	
0.011	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_00
  _011: rectangle with size (?,^.layer_0.shape.mask.size.j * '3) with model ? with color green at (?,right(^.layer_0) + 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.3 + 2904.2 = 2974.6
DL output with Mo: L = 112.5 + 1647.6 = 1760.1
DL input+output M: L = 182.9 + 4551.8 = 4734.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_00
  _011: rectangle with size (?,^.layer_0.shape.mask.size.j * '3) with model ? with color green at (?,right(^.layer_0) + 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 20.0 = 90.2
DL output with Mo: L = 112.5 + 1647.6 = 1760.1
DL input+output M: L = 182.7 + 1667.6 = 1850.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _00: rectangle with size (12,2) with model Full with color red at (0,10)
  _0: rectangle with size (2,2) with model Odd Checkboard with color cyan at (10,2)
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _0: 
. 8 
8 . 
 at (10,2)
  _01: 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
 at (0,10)
  _011: rectangle with size (10,6) with mask 
. 0 . . . . 
. . 0 . . . 
. . . 0 . . 
. . . . 0 . 
. . . . . 0 
. . . . 0 . 
. . . 0 . . 
. . 0 . . . 
. 0 . . . . 
0 . . . . . 
 with color green at (0,4)
diff: 
   (58.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (12,2) with model Full with color red at (0,10)
  _0: rectangle with size (2,2) with model Odd Checkboard with color cyan at (10,2)
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (2,2) with model Odd Checkboard with color cyan at (10,2)
  _0: rectangle with size (12,2) with model Full with color red at (0,10)
diff: 
! 10 wrong pixels (generated / expected)

TRAIN 508bd3b6.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _00: rectangle with size (3,12) with model Full with color red at (9,0)
  _0: rectangle with size (3,3) with mask 
0 . . 
. 0 . 
. . 0 
 with color cyan at (2,0)
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _0: 
8 . . 
. 8 . 
. . 8 
 at (2,0)
  _01: 
2 2 2 2 2 2 2 2 2 2 2 2 
2 2 2 2 2 2 2 2 2 2 2 2 
2 2 2 2 2 2 2 2 2 2 2 2 
 at (9,0)
  _011: rectangle with size (6,9) with mask 
. . . . . . . . 0 
. . . . . . . 0 . 
0 . . . . . 0 . . 
. 0 . . . 0 . . . 
. . 0 . 0 . . . . 
. . . 0 . . . . . 
 with color green at (3,3)
diff: 
   (52.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (3,12) with model Full with color red at (9,0)
  _0: rectangle with size (3,3) with mask 
0 . . 
. 0 . 
. . 0 
 with color cyan at (2,0)
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (3,3) with mask 
0 . . 
. 0 . 
. . 0 
 with color cyan at (2,0)
  _0: rectangle with size (3,12) with model Full with color red at (9,0)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color red and layers
  _00: rectangle with size (9,12) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
. 0 0 0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 0 0 0 0 0 0 
0 0 . 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color black at (0,0)
  _0: rectangle with size (3,3) with model Full with color cyan at (2,0)
diff: 
! 51 wrong pixels (generated / expected)

TRAIN 508bd3b6.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _00: rectangle with size (3,3) with mask 
0 . . 
. 0 . 
. . 0 
 with color cyan at (9,6)
  _0: rectangle with size (12,2) with model Full with color red at (0,0)
diff: 
   (2.0 bits)
data: a background with size (12,12) and color black and layers
  _0: 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
2 2 
 at (0,0)
  _01: 
8 . . 
. 8 . 
. . 8 
 at (9,6)
  _011: rectangle with size (9,6) with mask 
. . . . . 0 
. . . . 0 . 
. . . 0 . . 
. . 0 . . . 
. 0 . . . . 
0 . . . . . 
. 0 . . . . 
. . 0 . . . 
. . . 0 . . 
 with color green at (0,2)
diff: 
   (53.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (12,2) with model Full with color red at (0,0)
  _0: rectangle with size (3,3) with mask 
0 . . 
. 0 . 
. . 0 
 with color cyan at (9,6)
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (3,3) with mask 
0 . . 
. 0 . 
. . 0 
 with color cyan at (9,6)
  _0: rectangle with size (12,2) with model Full with color red at (0,0)
diff: 
! 17 wrong pixels (generated / expected)

TRAIN 508bd3b6.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (12,4) with model Full with color red at (0,8)
  _0: rectangle with size (2,2) with model Even Checkboard with color cyan at (0,3)
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _00: rectangle with size (2,2) with model Even Checkboard with color cyan at (0,3)
  _0: rectangle with size (12,4) with model Full with color red at (0,8)
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color red and layers
  _00: rectangle with size (2,2) with model Even Checkboard with color cyan at (0,3)
  _0: rectangle with size (12,8) with model Full with color black at (0,0)
diff: 
! 60 wrong pixels (generated / expected)

TEST 508bd3b6.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 5.7 sec (5.7 sec/task)
bits-train-error = 1647.6 bits (1647.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-281] Checking task 50cb2852.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 195588.9 = 195591.2
DL output with Mo: L = 2.3 + 195588.9 = 195591.2
DL input+output M: L = 4.6 + 391177.8 = 391182.5

# learning a model for train pairs
2.000	
1.376	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.752	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.582	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.443	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.332	OUT ADD ^.layer_0 = ^.layer_0
0.237	OUT ADD ^.layer_01 = ^.layer_01
0.178	OUT ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.126	OUT ADD ^.layer_010 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.100	OUT ADD ^.layer_0101 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.092	OUT ADD ^.layer_001 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.089	OUT SPE ^.layer_001.shape = scaleTo(coloring(^.layer_01.shape, cyan), ^.layer_0.shape.mask.size - (2, 2))
0.085	OUT SPE ^.size = ^.size
0.082	OUT SPE ^.layer_010.shape = scaleTo(coloring(^.layer_01.shape, cyan), ^.layer_01.shape.mask.size - (2, 2))
0.081	OUT SPE ^.layer_010.pos = ^.layer_01.pos + (1, 1)
0.079	OUT SPE ^.layer_001.pos = ^.layer_0.pos + (1, 1)
0.078	IN  SPE ^.layer_0.shape.color = red
0.077	OUT SPE ^.layer_00.shape.mask.size.i = ^.layer_01.shape.mask.size.j / '2
0.077	IN  SPE ^.layer_0.shape.mask.model = Full
0.076	IN  SPE ^.layer_01.shape.mask.model = Full
0.076	OUT SPE ^.layer_0101.shape.mask.model = Full
0.075	OUT SPE ^.layer_0101.shape.mask.size.j = ^.layer_0.shape.mask.size.i - ^.layer_01.shape.mask.size.i
0.075	IN  SPE ^.color = black
0.075	OUT SPE ^.color = black
0.010	
0.010	IN  GEN ^.layer_01.shape.mask.model = ?
0.010	IN  GEN ^.layer_0.shape.mask.model = ?
0.010	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: rectangle with size (^.layer_01.shape.mask.size.j / '2,?) with model ? with color ? at (?,?)
  _001: scaleTo(coloring(^.layer_01.shape, cyan), ^.layer_0.shape.mask.size - (2, 2)) at ^.layer_0.pos + (1, 1)
  _0: ^.layer_0
  _010: scaleTo(coloring(^.layer_01.shape, cyan), ^.layer_01.shape.mask.size - (2, 2)) at ^.layer_01.pos + (1, 1)
  _0101: rectangle with size (?,^.layer_0.shape.mask.size.i - ^.layer_01.shape.mask.size.i) with model Full with color ? at (?,?)
  _01: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color red at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 74.7 + 12696.8 = 12771.4
DL output with Mo: L = 323.5 + 1519.1 = 1842.6
DL input+output M: L = 398.2 + 14215.9 = 14614.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: rectangle with size (^.layer_01.shape.mask.size.j / '2,?) with model ? with color ? at (?,?)
  _001: scaleTo(coloring(^.layer_01.shape, cyan), ^.layer_0.shape.mask.size - (2, 2)) at ^.layer_0.pos + (1, 1)
  _0: ^.layer_0
  _010: scaleTo(coloring(^.layer_01.shape, cyan), ^.layer_01.shape.mask.size - (2, 2)) at ^.layer_01.pos + (1, 1)
  _0101: rectangle with size (?,^.layer_0.shape.mask.size.i - ^.layer_01.shape.mask.size.i) with model Full with color ? at (?,?)
  _01: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color red at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 73.5 + 0.0 = 73.5
DL output with Mo: L = 323.5 + 1519.1 = 1842.6
DL input+output M: L = 397.0 + 1519.1 = 1916.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (13,15) and color black and layers
  _0: rectangle with size (6,5) with model Full with color red at (1,2)
  _01: rectangle with size (5,7) with model Full with color green at (8,8)
  + 9 delta pixels
diff: 
   (0.0 bits)
data: a background with size (13,15) and color black and layers
  _00: rectangle with size (3,3) with model Border with color blue at (1,10)
  _001: 
8 8 8 
8 8 8 
8 8 8 
8 8 8 
 at (2,3)
  _0: 
2 2 2 2 2 
2 2 2 2 2 
2 2 2 2 2 
2 2 2 2 2 
2 2 2 2 2 
2 2 2 2 2 
 at (1,2)
  _010: 
8 8 8 8 8 
8 8 8 8 8 
8 8 8 8 8 
 at (9,9)
  _0101: rectangle with size (1,1) with model Full with color cyan at (2,11)
  _01: 
3 3 3 3 3 3 3 
3 3 3 3 3 3 3 
3 3 3 3 3 3 3 
3 3 3 3 3 3 3 
3 3 3 3 3 3 3 
 at (8,8)
diff: 
   (51.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,15) and color black and layers
  _0: rectangle with size (6,5) with model Full with color red at (1,2)
  _01: rectangle with size (5,7) with model Full with color green at (8,8)
  + 9 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,15) and color black and layers
  _0: rectangle with size (5,7) with model Full with color green at (8,8)
  _01: rectangle with size (3,3) with model Full with color blue at (1,10)
  + 30 delta pixels
diff:   ^.layer_0.shape.color
! 34 wrong pixels (generated / expected)

TRAIN 50cb2852.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (12,11) and color black and layers
  _0: rectangle with size (4,4) with model Full with color red at (1,1)
  _01: rectangle with size (3,6) with model Full with color blue at (7,2)
diff: 
   (0.0 bits)
data: a background with size (12,11) and color black and layers
  _00: rectangle with size (3,1) with model Full with color blue at (7,2)
  _001: 
8 8 
8 8 
 at (2,2)
  _0: 
2 2 2 2 
2 2 2 2 
2 2 2 2 
2 2 2 2 
 at (1,1)
  _010: 
8 8 8 8 
 at (8,3)
  _0101: rectangle with size (3,1) with model Full with color blue at (7,7)
  _01: 
1 1 1 1 1 1 
1 1 1 1 1 1 
1 1 1 1 1 1 
 at (7,2)
diff: 
   (47.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,11) and color black and layers
  _0: rectangle with size (4,4) with model Full with color red at (1,1)
  _01: rectangle with size (3,6) with model Full with color blue at (7,2)
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 50cb2852.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (12,13) and color black and layers
  _0: rectangle with size (6,4) with model Full with color red at (1,6)
  _01: rectangle with size (4,8) with model Full with color blue at (8,2)
  + 16 delta pixels
diff: 
   (0.0 bits)
data: a background with size (12,13) and color black and layers
  _00: rectangle with size (4,4) with model Border with color green at (2,0)
  _001: 
8 8 
8 8 
8 8 
8 8 
 at (2,7)
  _0: 
2 2 2 2 
2 2 2 2 
2 2 2 2 
2 2 2 2 
2 2 2 2 
2 2 2 2 
 at (1,6)
  _010: 
8 8 8 8 8 8 
8 8 8 8 8 8 
 at (9,3)
  _0101: rectangle with size (2,2) with model Full with color cyan at (3,1)
  _01: 
1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 
 at (8,2)
diff: 
   (53.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,13) and color black and layers
  _0: rectangle with size (6,4) with model Full with color red at (1,6)
  _01: rectangle with size (4,8) with model Full with color blue at (8,2)
  + 16 delta pixels
diff: 
! 20 wrong pixels (generated / expected)

TRAIN 50cb2852.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,13) and color black and layers
  _0: rectangle with size (7,4) with model Full with color green at (7,9)
  _01: rectangle with size (6,6) with model Full with color red at (5,2)
  + 29 delta pixels
diff:   ^.layer_0.shape.color
! 32 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,13) and color black and layers
  _0: rectangle with size (6,6) with model Full with color red at (5,2)
  _01: rectangle with size (4,5) with model Full with color blue at (0,1)
  + 37 delta pixels
diff: 
! 41 wrong pixels (generated / expected)

TEST 50cb2852.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 31.3 sec (31.3 sec/task)
bits-train-error = 1519.1 bits (1519.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-280] Checking task 5117e062.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 205514.5 = 205516.9
DL output with Mo: L = 2.3 + 10534.8 = 10537.1
DL input+output M: L = 4.6 + 216049.3 = 216054.0

# learning a model for train pairs
2.000	
1.122	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.540	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.271	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.235	OUT SPE ^.size = '(3, 3)
0.199	OUT SPE ^.layer_0.shape.mask.size = '(3, 3)
0.164	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.136	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.114	OUT SPE ^.layer_0.pos = '(0, 0)
0.094	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.084	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.070	OUT SPE ^.layer_0.shape.color = ^.layer_011.shape.color
0.063	OUT SPE ^.color = black
0.063	IN  SPE ^.color = black
0.034	
0.034	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: rectangle with size '(3, 3) with model ? with color ^.layer_011.shape.color at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.9 + 5944.9 = 6070.9
DL output with Mo: L = 78.4 + 270.8 = 349.2
DL input+output M: L = 204.3 + 6215.7 = 6420.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: rectangle with size '(3, 3) with model ? with color ^.layer_011.shape.color at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 20.0 = 145.8
DL output with Mo: L = 78.4 + 270.8 = 349.2
DL input+output M: L = 204.2 + 290.8 = 495.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
0 . 0 
0 0 0 
 with color pink at (9,8)
  _01: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
0 0 . 
 with color green at (0,1)
  _011: rectangle with size (3,3) with model Odd Checkboard with color yellow at (0,9)
  _0111: rectangle with size (3,3) with mask 
0 . . 
0 0 0 
. 0 . 
 with color red at (4,4)
  + 1 delta pixels
diff: 
   (2.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with model +-cross with color yellow at (0,0)
diff: 
   (6.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
0 . 0 
0 0 0 
 with color pink at (9,8)
  _01: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
0 0 . 
 with color green at (0,1)
  _011: rectangle with size (3,3) with mask 
0 . . 
0 0 0 
. 0 . 
 with color red at (4,4)
  _0111: rectangle with size (3,3) with model Odd Checkboard with color yellow at (0,9)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
0 . 0 
0 0 0 
 with color pink at (9,8)
  _01: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
0 0 . 
 with color green at (0,1)
  _011: rectangle with size (3,3) with model Odd Checkboard with color yellow at (0,9)
  _0111: rectangle with size (3,3) with mask 
0 . . 
0 0 0 
. 0 . 
 with color red at (4,4)
  + 1 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
0 . 0 
0 0 0 
 with color pink at (9,8)
  _01: rectangle with size (3,3) with mask 
0 . . 
0 0 0 
. 0 . 
 with color red at (4,4)
  _011: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
0 0 . 
 with color green at (0,1)
  _0111: rectangle with size (3,3) with model Odd Checkboard with color yellow at (0,9)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 5117e062.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 0 
0 0 0 
 with color blue at (8,7)
  _01: rectangle with size (3,3) with model +-cross with color red at (0,7)
  _011: rectangle with size (3,3) with mask 
. 0 0 
0 . . 
. 0 0 
 with color green at (4,2)
  _0111: rectangle with size (1,1) with model Full with color cyan at (5,3)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
0 0 . 
. 0 0 
 with color green at (0,0)
diff: 
   (10.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 0 
0 0 0 
 with color blue at (8,7)
  _01: rectangle with size (3,3) with model +-cross with color red at (0,7)
  _011: rectangle with size (3,3) with mask 
. 0 0 
0 . . 
. 0 0 
 with color green at (4,2)
  _0111: rectangle with size (1,1) with model Full with color cyan at (5,3)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 0 
0 0 0 
 with color blue at (8,7)
  _01: rectangle with size (3,3) with mask 
. 0 0 
0 . . 
. 0 0 
 with color green at (4,2)
  _011: rectangle with size (3,3) with model +-cross with color red at (0,7)
  _0111: rectangle with size (1,1) with model Full with color cyan at (5,3)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 5117e062.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 0 
. . 0 
 with color green at (3,8)
  _01: rectangle with size (3,3) with mask 
0 . 0 
0 0 0 
. 0 . 
 with color blue at (8,3)
  _011: rectangle with size (1,3) with model Full with color red at (2,1)
  _0111: rectangle with size (1,2) with model Full with color red at (4,1)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. 0 . 
0 0 . 
 with color red at (0,0)
diff: 
   (10.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 0 
. . 0 
 with color green at (3,8)
  _01: rectangle with size (3,3) with mask 
0 . 0 
0 0 0 
. 0 . 
 with color blue at (8,3)
  _011: rectangle with size (1,3) with model Full with color red at (2,1)
  _0111: rectangle with size (1,2) with model Full with color red at (4,1)
  + 1 delta pixels
diff: 
! 3 wrong pixels (generated / expected)

TRAIN 5117e062.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. 0 . 
0 0 0 
 with color green at (9,7)
  _01: rectangle with size (3,3) with mask 
0 0 0 
. 0 0 
. . 0 
 with color blue at (1,5)
  _011: rectangle with size (3,3) with mask 
. 0 0 
0 . 0 
. 0 . 
 with color orange at (4,9)
  _0111: rectangle with size (3,3) with mask 
0 . . 
0 0 . 
. 0 0 
 with color red at (6,1)
  + 1 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. 0 . 
0 0 0 
 with color green at (9,7)
  _01: rectangle with size (3,3) with mask 
0 0 0 
. 0 0 
. . 0 
 with color blue at (1,5)
  _011: rectangle with size (3,3) with mask 
0 . . 
0 0 . 
. 0 0 
 with color red at (6,1)
  _0111: rectangle with size (3,3) with mask 
. 0 0 
0 . 0 
. 0 . 
 with color orange at (4,9)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. 0 . 
0 0 0 
 with color green at (9,7)
  _01: rectangle with size (3,3) with mask 
. 0 0 
0 . 0 
. 0 . 
 with color orange at (4,9)
  _011: rectangle with size (3,3) with mask 
0 0 0 
. 0 0 
. . 0 
 with color blue at (1,5)
  _0111: rectangle with size (3,3) with mask 
0 . . 
0 0 . 
. 0 0 
 with color red at (6,1)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TEST 5117e062.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 5.1 sec (5.1 sec/task)
bits-train-error = 270.8 bits (270.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-279] Checking task 5168d44c.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 91702.2 = 91704.5
DL output with Mo: L = 2.3 + 91702.2 = 91704.5
DL input+output M: L = 4.6 + 183404.4 = 183409.1

# learning a model for train pairs
2.000	
1.185	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.369	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.277	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.178	OUT ADD ^.layer_0 = ^.layer_0.shape at (?,?)
0.151	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.127	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.116	OUT SPE ^.layer_01 = ^.layer_01
0.110	OUT SPE ^.size = ^.size
0.104	IN  SPE ^.layer_0.shape.mask = 
0 0 0 
0 . 0 
0 0 0 

0.102	IN  SPE ^.layer_0.shape.color = red
0.100	IN  SPE ^.layer_01.shape.color = green
0.098	OUT SPE ^.layer_0.pos.j = ^.layer_0.pos.i
0.097	OUT SPE ^.layer_0.pos.i = right(^.layer_0)
0.096	IN  SPE ^.layer_01.shape.mask.model = Full
0.095	IN  SPE ^.color = black
0.094	OUT SPE ^.color = black
0.037	
0.037	IN  GEN ^.layer_0.shape.mask = rectangle with size (?,?) with model ?
0.037	IN  GEN ^.layer_01.shape.color = ?
0.037	IN  GEN ^.layer_0.shape.color = ?
0.037	IN  GEN ^.layer_01.shape.mask.model = ?
0.037	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0.shape at (right(^.layer_0),^.layer_0.pos.i)
  _01: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
0 0 0 
0 . 0 
0 0 0 
 with color red at (?,?)
  _01: rectangle with size (?,?) with model Full with color green at (?,?)

DL input  with Mi: L = 81.5 + 5270.5 = 5352.0
DL output with Mo: L = 47.2 + 3248.4 = 3295.5
DL input+output M: L = 128.7 + 8518.8 = 8647.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0.shape at (right(^.layer_0),^.layer_0.pos.i)
  _01: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 47.2 + 3248.4 = 3295.5
DL input+output M: L = 117.4 + 3248.4 = 3365.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (7,13) and color black and layers
  _0: rectangle with size (3,3) with model Border with color red at (2,0)
  _01: rectangle with size (1,11) with model Full with color green at (3,1)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (7,13) and color black and layers
  _0: 
2 2 2 
2 . 2 
2 2 2 
 at (2,2)
  _01: 
3 3 3 3 3 3 3 3 3 3 3 
 at (3,1)
  + 3 delta pixels
diff: 
   (122.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,13) and color black and layers
  _0: rectangle with size (3,3) with model Border with color red at (2,0)
  _01: rectangle with size (1,11) with model Full with color green at (3,1)
  + 4 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,13) and color black and layers
  _0: rectangle with size (3,3) with model Full with color red at (2,0)
  _01: rectangle with size (1,1) with model Full with color green at (3,3)
  + 5 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (7,13) and color black and layers
  _0: rectangle with size (3,3) with model Full with color red at (2,0)
  _01: rectangle with size (1,1) with model Full with color green at (3,5)
  + 5 delta pixels
diff: 
! 5 wrong pixels (generated / expected)

TRAIN 5168d44c.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (13,7) and color black and layers
  _0: rectangle with size (3,3) with model Border with color red at (3,3)
  _01: rectangle with size (13,1) with model Full with color green at (0,4)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (13,7) and color black and layers
  _0: 
2 2 2 
2 . 2 
2 2 2 
 at (5,3)
  _01: 
3 
3 
3 
3 
3 
3 
3 
3 
3 
3 
3 
3 
3 
 at (0,4)
  + 4 delta pixels
diff: 
   (162.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,7) and color black and layers
  _0: rectangle with size (3,3) with model Border with color red at (3,3)
  _01: rectangle with size (13,1) with model Full with color green at (0,4)
  + 4 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,7) and color black and layers
  _0: rectangle with size (3,3) with model Full with color red at (3,3)
  _01: rectangle with size (13,1) with model Full with color green at (0,4)
  + 5 delta pixels
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (13,7) and color black and layers
  _0: rectangle with size (3,3) with model Full with color red at (3,3)
  _01: rectangle with size (1,1) with model Full with color green at (0,4)
  + 6 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 5168d44c.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (7,7) and color black and layers
  _0: rectangle with size (3,3) with model Border with color red at (1,1)
  _01: rectangle with size (7,1) with model Full with color green at (0,2)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (7,7) and color black and layers
  _0: 
2 2 2 
2 . 2 
2 2 2 
 at (3,1)
  _01: 
3 
3 
3 
3 
3 
3 
3 
 at (0,2)
  + 1 delta pixels
diff: 
   (40.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (3,3) with model Border with color red at (1,1)
  _01: rectangle with size (7,1) with model Full with color green at (0,2)
  + 1 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (3,3) with model Full with color red at (1,1)
  _01: rectangle with size (7,1) with model Full with color green at (0,2)
  + 2 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (3,3) with model Full with color red at (1,1)
  _01: rectangle with size (1,1) with model Full with color green at (0,2)
  + 3 delta pixels
diff: 
! 3 wrong pixels (generated / expected)

TRAIN 5168d44c.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,17) and color black and layers
  _0: rectangle with size (3,3) with model Border with color red at (3,7)
  _01: rectangle with size (1,17) with model Full with color green at (4,0)
  + 6 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,17) and color black and layers
  _0: rectangle with size (3,3) with model Full with color red at (3,7)
  _01: rectangle with size (1,1) with model Full with color green at (4,0)
  + 8 delta pixels
diff: 
! 16 wrong pixels (generated / expected)

TEST 5168d44c.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 6.3 sec (6.3 sec/task)
bits-train-error = 3248.4 bits (3248.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-278] Checking task 539a4f51.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 29114.4 = 29116.7
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 148890.2 = 148894.9

# learning a model for train pairs
2.000	
1.452	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.101	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.649	OUT SPE ^ = fillResizeAlike_total(black, ^.size * '2, ^)
0.395	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.195	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.137	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.131	IN  SPE ^.layer_01.shape.mask.model = Full
0.128	IN  SPE ^.layer_011.shape.mask.model = Full
0.004	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
fillResizeAlike_total(black, ^.size * '2, ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 99.1 + 3628.1 = 3727.2
DL output with Mo: L = 36.9 + 0.0 = 36.9
DL input+output M: L = 136.0 + 3628.1 = 3764.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
fillResizeAlike_total(black, ^.size * '2, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 36.9 + 0.0 = 36.9
DL input+output M: L = 39.2 + 0.0 = 39.2

# train input/output grids

## instance 1

> Input and output best reading:

data: 
2 2 2 3 0 
2 2 2 3 0 
2 2 2 3 0 
3 3 3 3 0 
0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
2 2 2 3 2 2 2 3 2 2 
2 2 2 3 2 2 2 3 2 2 
2 2 2 3 2 2 2 3 2 2 
3 3 3 3 2 2 2 3 2 2 
2 2 2 2 2 2 2 3 2 2 
2 2 2 2 2 2 2 3 2 2 
2 2 2 2 2 2 2 3 2 2 
3 3 3 3 3 3 3 3 2 2 
2 2 2 2 2 2 2 2 2 2 
2 2 2 2 2 2 2 2 2 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 2 2 3 0 
2 2 2 3 0 
2 2 2 3 0 
3 3 3 3 0 
0 0 0 0 0 

diff: 
correct output grid

TRAIN 539a4f51.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
1 1 4 6 0 
1 1 4 6 0 
4 4 4 6 0 
6 6 6 6 0 
0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
1 1 4 6 1 1 4 6 1 1 
1 1 4 6 1 1 4 6 1 1 
4 4 4 6 1 1 4 6 1 1 
6 6 6 6 1 1 4 6 1 1 
1 1 1 1 1 1 4 6 1 1 
1 1 1 1 1 1 4 6 1 1 
4 4 4 4 4 4 4 6 1 1 
6 6 6 6 6 6 6 6 1 1 
1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 4 6 0 
1 1 4 6 0 
4 4 4 6 0 
6 6 6 6 0 
0 0 0 0 0 

diff: 
correct output grid

TRAIN 539a4f51.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
2 3 4 1 6 
3 3 4 1 6 
4 4 4 1 6 
1 1 1 1 6 
6 6 6 6 6 

diff: 
   (0.0 bits)
data: 
2 3 4 1 6 2 3 4 1 6 
3 3 4 1 6 2 3 4 1 6 
4 4 4 1 6 2 3 4 1 6 
1 1 1 1 6 2 3 4 1 6 
6 6 6 6 6 2 3 4 1 6 
2 2 2 2 2 2 3 4 1 6 
3 3 3 3 3 3 3 4 1 6 
4 4 4 4 4 4 4 4 1 6 
1 1 1 1 1 1 1 1 1 6 
6 6 6 6 6 6 6 6 6 6 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 3 4 1 6 
3 3 4 1 6 
4 4 4 1 6 
1 1 1 1 6 
6 6 6 6 6 

diff: 
correct output grid

TRAIN 539a4f51.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
7#7#3 2 2 
7#7#3 2 2 
3 3 3 2 2 
2 2 2 2 2 
2 2 2 2 2 

diff: 
correct output grid

TEST 539a4f51.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.5 sec (1.5 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-277] Checking task 53b68214.json: 3 train, 2 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 75020.4 = 75022.7
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 194796.2 = 194800.8

# learning a model for train pairs
2.000	
1.143	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.294	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.173	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.053	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.051	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.048	OUT SPE ^.size.j = ^.size.j
0.046	OUT SPE ^.size.i = ^.size.j
0.044	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.043	IN  SPE ^.color = black
0.043	OUT SPE ^.color = black
0.014	
0.014	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (^.size.j,^.size.j) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.1 + 2171.7 = 2213.8
DL output with Mo: L = 49.1 + 1531.7 = 1580.8
DL input+output M: L = 91.3 + 3703.4 = 3794.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (^.size.j,^.size.j) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 49.1 + 1531.7 = 1580.8
DL input+output M: L = 91.1 + 1531.7 = 1622.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (6,10) and color black and layers
  _0: rectangle with size (6,7) with mask 
0 0 0 . . . . 
. . 0 . . . . 
. . 0 0 0 . . 
. . . . 0 . . 
. . . . 0 0 0 
. . . . . . 0 
 with color blue at (0,0)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (9,10) with mask 
0 0 0 . . . . . . . 
. . 0 . . . . . . . 
. . 0 0 0 . . . . . 
. . . . 0 . . . . . 
. . . . 0 0 0 . . . 
. . . . . . 0 . . . 
. . . . . . 0 0 0 . 
. . . . . . . . 0 . 
. . . . . . . . 0 0 
 with color blue at (0,0)
diff: 
   (88.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,10) and color black and layers
  _0: rectangle with size (6,7) with mask 
0 0 0 . . . . 
. . 0 . . . . 
. . 0 0 0 . . 
. . . . 0 . . 
. . . . 0 0 0 
. . . . . . 0 
 with color blue at (0,0)
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,10) and color black and layers
  _0: rectangle with size (3,1) with model Full with color blue at (0,2)
  + 9 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TRAIN 53b68214.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (5,10) and color black and layers
  _0: rectangle with size (5,1) with model Full with color green at (0,2)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color green at (0,2)
diff: 
   (16.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,10) and color black and layers
  _0: rectangle with size (5,1) with model Full with color green at (0,2)
diff: 
! 10 wrong pixels (generated / expected)

TRAIN 53b68214.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (8,10) and color black and layers
  _0: rectangle with size (8,3) with mask 
. 0 . 
. 0 . 
0 . 0 
. 0 . 
. 0 . 
0 . 0 
. 0 . 
. 0 . 
 with color red at (0,0)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,3) with mask 
. 0 . 
. 0 . 
0 . 0 
. 0 . 
. 0 . 
0 . 0 
. 0 . 
. 0 . 
0 . 0 
. 0 . 
 with color red at (0,0)
diff: 
   (48.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,10) and color black and layers
  _0: rectangle with size (8,3) with mask 
. 0 . 
. 0 . 
0 . 0 
. 0 . 
. 0 . 
0 . 0 
. 0 . 
. 0 . 
 with color red at (0,0)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,10) and color black and layers
  _0: rectangle with size (8,1) with model Full with color red at (0,1)
  + 6 delta pixels
diff: 
! 13 wrong pixels (generated / expected)

TRAIN 53b68214.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,10) and color black and layers
  _0: rectangle with size (8,2) with model Odd Checkboard with color pink at (0,3)
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color pink at (0,4)
  + 7 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (8,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color pink at (1,3)
  + 7 delta pixels
diff: 
! 10 wrong pixels (generated / expected)

TEST 53b68214.json/1: 0 - (FAILURE)

## instance 2

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,10) and color black and layers
  _0: rectangle with size (5,3) with mask 
0 0 0 
0 . 0 
0 0 0 
0 . 0 
0 0 0 
 with color cyan at (0,1)
diff: 
! 23 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,10) and color cyan and layers
  _0: rectangle with size (5,6) with model Full with color black at (0,4)
  + 7 delta pixels
diff: 
! 25 wrong pixels (generated / expected)

TEST 53b68214.json/2: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 2.6 sec (2.6 sec/task)
bits-train-error = 1531.7 bits (1531.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-276] Checking task 543a7ed5.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 184013.0 = 184015.3
DL output with Mo: L = 2.3 + 184013.0 = 184015.3
DL input+output M: L = 4.6 + 368025.9 = 368030.6

# learning a model for train pairs
2.000	
1.175	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.664	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.489	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.404	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.329	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.258	OUT ADD ^.layer_00 = ^.layer_0
0.200	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.142	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.095	OUT ADD ^.layer_010 = ^.layer_01
0.070	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.055	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.045	OUT ADD ^.layer_0110 = ^.layer_011
0.042	OUT SPE ^.size = ^.size
0.040	OUT SPE ^.layer_011.shape.mask = 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 

0.038	OUT SPE ^.layer_01.shape.mask.size = ^.layer_01.shape.mask.size + (1, 2)
0.038	IN  SPE ^.color = cyan
0.037	IN  SPE ^.layer_01.shape.mask.model = Border
0.036	OUT SPE ^.layer_01.pos = ^.layer_0.pos - (1, 1)
0.034	OUT SPE ^.layer_0111.shape.mask = scaleTo(^.layer_0.shape.mask, ^.layer_0.shape.mask.size - (1, 2))
0.034	OUT SPE ^.layer_0.shape.mask.size.j = ^.layer_01.shape.mask.size.i + 1
0.033	IN  SPE ^.layer_0.shape.color = pink
0.033	IN  SPE ^.layer_01.shape.color = pink
0.032	IN  SPE ^.layer_011.shape.color = pink
0.031	OUT SPE ^.layer_0111.shape.color = yellow
0.031	OUT SPE ^.layer_011.pos.i = ^.layer_01.pos.i + 1
0.030	OUT SPE ^.layer_0111.pos.i = right(^.layer_011) - 1
0.030	OUT SPE ^.layer_0.pos.i = ^.layer_011.pos.i - 3
0.029	OUT SPE ^.layer_0.pos.j = max(^.layer_0.pos.i, ^.layer_011.pos.i) - 3
0.029	IN  SPE ^.layer_0.shape.mask.model = Full
0.028	OUT SPE ^.layer_011.pos.j = bottom(^.layer_01) - max(^.layer_0.shape.mask.size.j, ^.layer_011.shape.mask.size.j)
0.017	
0.017	IN  GEN ^.color = ?
0.017	IN  GEN ^.layer_01.shape.mask.model = ?
0.016	IN  GEN ^.layer_011.shape.color = ?
0.016	IN  GEN ^.layer_01.shape.color = ?
0.016	IN  GEN ^.layer_0.shape.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,^.layer_01.shape.mask.size.i + 1) with model ? with color ? at (^.layer_011.pos.i - 3,max(^.layer_0.pos.i, ^.layer_011.pos.i) - 3)
  _010: ^.layer_01
  _01: rectangle with size ^.layer_01.shape.mask.size + (1, 2) with model ? with color ? at ^.layer_0.pos - (1, 1)
  _0110: ^.layer_011
  _011: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color ? at (^.layer_01.pos.i + 1,bottom(^.layer_01) - max(^.layer_0.shape.mask.size.j, ^.layer_011.shape.mask.size.j))
  _0111: scaleTo(^.layer_0.shape.mask, ^.layer_0.shape.mask.size - (1, 2)) with color yellow at (right(^.layer_011) - 1,?)
WHERE (Mi)
a background with size (?,?) and color cyan and layers
  _0: rectangle with size (?,?) with model Full with color pink at (?,?)
  _01: rectangle with size (?,?) with model Border with color pink at (?,?)
  _011: rectangle with size (?,?) with model ? with color pink at (?,?)

DL input  with Mi: L = 118.5 + 2183.8 = 2302.3
DL output with Mo: L = 403.1 + 2525.7 = 2928.7
DL input+output M: L = 521.6 + 4709.4 = 5231.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,^.layer_01.shape.mask.size.i + 1) with model ? with color ? at (^.layer_011.pos.i - 3,max(^.layer_0.pos.i, ^.layer_011.pos.i) - 3)
  _010: ^.layer_01
  _01: rectangle with size ^.layer_01.shape.mask.size + (1, 2) with model ? with color ? at ^.layer_0.pos - (1, 1)
  _0110: ^.layer_011
  _011: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color ? at (^.layer_01.pos.i + 1,bottom(^.layer_01) - max(^.layer_0.shape.mask.size.j, ^.layer_011.shape.mask.size.j))
  _0111: scaleTo(^.layer_0.shape.mask, ^.layer_0.shape.mask.size - (1, 2)) with color yellow at (right(^.layer_011) - 1,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.6 + 0.0 = 98.6
DL output with Mo: L = 403.1 + 2525.7 = 2928.7
DL input+output M: L = 501.7 + 2525.7 = 3027.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (4,4) with model Full with color pink at (10,5)
  _01: rectangle with size (5,4) with model Border with color pink at (2,8)
  _011: rectangle with size (2,2) with model Full with color pink at (4,3)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color cyan and layers
  _00: 
6 6 6 6 
6 6 6 6 
6 6 6 6 
6 6 6 6 
 at (10,5)
  _0: rectangle with size (7,6) with model Border with color green at (1,7)
  _010: 
6 6 6 6 
6 . . 6 
6 . . 6 
6 . . 6 
6 6 6 6 
 at (2,8)
  _01: rectangle with size (6,6) with model Full with color green at (9,4)
  _0110: 
6 6 
6 6 
 at (4,3)
  _011: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color green at (3,2)
  _0111: 
0 0 
0 0 
0 0 
 with color yellow at (3,9)
diff: 
   (49.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (4,4) with model Full with color pink at (10,5)
  _01: rectangle with size (5,4) with model Border with color pink at (2,8)
  _011: rectangle with size (2,2) with model Full with color pink at (4,3)
diff: 
! 195 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (4,4) with model Full with color pink at (10,5)
  _01: rectangle with size (5,4) with model Full with color pink at (2,8)
  _011: rectangle with size (2,2) with model Full with color pink at (4,3)
  + 6 delta pixels
diff: 
! 195 wrong pixels (generated / expected)

TRAIN 543a7ed5.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (3,3) with model Full with color pink at (1,8)
  _01: rectangle with size (6,6) with model Border with color pink at (8,8)
  _011: rectangle with size (4,4) with mask 
0 0 0 0 
0 . 0 0 
0 . 0 0 
0 0 0 0 
 with color pink at (3,2)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color green and layers
  _00: 
6 6 6 
6 6 6 
6 6 6 
 at (1,8)
  _0: rectangle with size (15,7) with mask 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 . . . . . . 
0 . . . . . . 
0 . . . . . . 
0 . . . . . . 
0 . . . . . . 
0 . . . . . . 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
 with color cyan at (0,0)
  _010: 
6 6 6 6 6 6 
6 . . . . 6 
6 . . . . 6 
6 . . . . 6 
6 . . . . 6 
6 6 6 6 6 6 
 at (8,8)
  _01: rectangle with size (7,8) with mask 
. . . . . 0 0 0 
. . . . . 0 0 0 
. . . . . 0 0 0 
. . . . . 0 0 0 
. . . . . 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
 with color cyan at (0,7)
  _0110: 
6 6 6 6 
6 . 6 6 
6 . 6 6 
6 6 6 6 
 at (3,2)
  _011: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color yellow at (9,9)
  _0111: 
0 
0 
 with color yellow at (4,3)
diff: 
   (203.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (3,3) with model Full with color pink at (1,8)
  _01: rectangle with size (6,6) with model Border with color pink at (8,8)
  _011: rectangle with size (4,4) with mask 
0 0 0 0 
0 . 0 0 
0 . 0 0 
0 0 0 0 
 with color pink at (3,2)
diff: 
! 182 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (3,3) with model Full with color pink at (1,8)
  _01: rectangle with size (4,4) with mask 
0 0 0 0 
0 . 0 0 
0 . 0 0 
0 0 0 0 
 with color pink at (3,2)
  _011: rectangle with size (6,6) with model Border with color pink at (8,8)
diff: 
! 184 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (4,4) with model Full with color pink at (3,2)
  _01: rectangle with size (6,6) with model Border with color pink at (8,8)
  _011: rectangle with size (3,3) with model Full with color pink at (1,8)
  + 2 delta pixels
diff: 
! 184 wrong pixels (generated / expected)

TRAIN 543a7ed5.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (3,7) with model Full with color pink at (11,4)
  _01: rectangle with size (6,3) with mask 
0 0 0 
0 0 0 
0 . 0 
0 . 0 
0 . 0 
0 0 0 
 with color pink at (2,9)
  _011: rectangle with size (4,4) with model Border with color pink at (3,2)
  + 2 delta pixels
diff: 
! 177 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (3,7) with model Full with color pink at (11,4)
  _01: rectangle with size (4,4) with model Border with color pink at (3,2)
  _011: rectangle with size (6,3) with mask 
0 0 0 
0 0 0 
0 . 0 
0 . 0 
0 . 0 
0 0 0 
 with color pink at (2,9)
  + 2 delta pixels
diff: 
! 179 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (6,3) with model Full with color pink at (2,9)
  _01: rectangle with size (3,7) with mask 
0 0 0 0 0 0 0 
0 0 . . 0 0 0 
0 0 0 0 0 0 0 
 with color pink at (11,4)
  _011: rectangle with size (4,4) with model Border with color pink at (3,2)
  + 3 delta pixels
diff: 
! 179 wrong pixels (generated / expected)

TEST 543a7ed5.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 47.9 sec (47.9 sec/task)
bits-train-error = 2525.7 bits (2525.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-275] Checking task 54d82841.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 48610.5 = 48612.9
DL output with Mo: L = 2.3 + 48610.5 = 48612.9
DL input+output M: L = 4.6 + 97221.1 = 97225.7

# learning a model for train pairs
2.000	
1.213	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.466	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.367	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.248	OUT ADD ^.layer_0 = ^.layer_0
0.179	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.141	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.113	OUT ADD ^.layer_011 = ^.layer_01
0.099	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.088	OUT SPE ^.size = ^.size
0.082	OUT SPE ^.layer_01.shape.mask = 
0 

0.078	OUT SPE ^.layer_01.shape.color = yellow
0.075	OUT SPE ^.layer_01.pos.j = 2
0.073	OUT SPE ^.layer_0111.pos.j = right(^.layer_01) - 1
0.071	IN  SPE ^.color = black
0.070	OUT SPE ^.color = black
0.013	
0.013	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: 
0 
 with color yellow at (?,2)
  _011: ^.layer_01
  _0111: point with color ? at (?,right(^.layer_01) - 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.3 + 2768.3 = 2838.7
DL output with Mo: L = 88.3 + 461.1 = 549.3
DL input+output M: L = 158.6 + 3229.4 = 3388.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: 
0 
 with color yellow at (?,2)
  _011: ^.layer_01
  _0111: point with color ? at (?,right(^.layer_01) - 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 88.3 + 461.1 = 549.3
DL input+output M: L = 158.5 + 461.1 = 619.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (8,8) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color pink at (0,1)
  _01: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color pink at (2,5)
diff: 
   (0.0 bits)
data: a background with size (8,8) and color black and layers
  _0: 
6 6 6 
6 . 6 
 at (0,1)
  _01: 
0 
 with color yellow at (7,2)
  _011: 
6 6 6 
6 . 6 
 at (2,5)
  _0111: point with color yellow at (7,6)
diff: 
   (16.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color pink at (0,1)
  _01: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color pink at (2,5)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color pink at (2,5)
  _01: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color pink at (0,1)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color pink at (0,1)
  _01: rectangle with size (2,3) with model Full with color pink at (2,5)
  + 1 delta pixels
diff: 
! 4 wrong pixels (generated / expected)

TRAIN 54d82841.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,1) with model Full with color green at (0,1)
  _01: rectangle with size (2,1) with model Full with color green at (0,3)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: 
3 
3 
 at (0,1)
  _01: 
0 
 with color yellow at (4,2)
  _011: 
3 
3 
 at (0,3)
  _0111: point with color green at (0,2)
diff: 
   (14.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,1) with model Full with color green at (0,1)
  _01: rectangle with size (2,1) with model Full with color green at (0,3)
  + 1 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,1) with model Full with color green at (0,3)
  _01: rectangle with size (2,1) with model Full with color green at (0,1)
  + 1 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,1) with model Full with color green at (0,1)
  _01: rectangle with size (1,3) with model Full with color green at (0,1)
  + 1 delta pixels
diff: 
! 3 wrong pixels (generated / expected)

TRAIN 54d82841.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (5,7) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color cyan at (1,1)
  _01: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color pink at (2,4)
diff: 
   (0.0 bits)
data: a background with size (5,7) and color black and layers
  _0: 
8 8 8 
8 . 8 
 at (1,1)
  _01: 
0 
 with color yellow at (4,2)
  _011: 
6 6 6 
6 . 6 
 at (2,4)
  _0111: point with color yellow at (4,5)
diff: 
   (14.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,7) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color cyan at (1,1)
  _01: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color pink at (2,4)
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,7) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color pink at (2,4)
  _01: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color cyan at (1,1)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (5,7) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color cyan at (1,1)
  _01: rectangle with size (2,3) with model Full with color pink at (2,4)
  + 1 delta pixels
diff: 
! 5 wrong pixels (generated / expected)

TRAIN 54d82841.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,11) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color grey at (0,1)
  _01: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color cyan at (1,5)
  + 5 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,11) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color grey at (0,1)
  _01: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color green at (2,8)
  + 5 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (7,11) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color cyan at (1,5)
  _01: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color grey at (0,1)
  + 5 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TEST 54d82841.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 8.2 sec (8.2 sec/task)
bits-train-error = 461.1 bits (461.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-274] Checking task 54d9e175.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 69093.3 = 69095.6
DL output with Mo: L = 2.3 + 69093.3 = 69095.6
DL input+output M: L = 4.6 + 138186.6 = 138191.3

# learning a model for train pairs
2.000	
1.328	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.001	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.820	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.654	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.502	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.401	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.361	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.327	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.291	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.278	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.264	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.251	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.240	OUT SPE ^.size = ^.size
0.231	OUT SPE ^.layer_0.shape.mask = 
0 0 0 
0 0 0 
0 0 0 

0.222	OUT SPE ^.layer_01.shape.mask = 
0 0 0 
0 0 0 
0 0 0 

0.213	OUT SPE ^.layer_011.shape.mask = 
0 0 0 
0 0 0 
0 0 0 

0.207	OUT SPE ^.layer_0.pos = '(0, 0)
0.202	OUT SPE ^.layer_011.pos = projJ(^.layer_011.pos) + (0, 3)
0.197	OUT SPE ^.layer_01.pos = projJ(^.layer_01111.pos) - (0, 1)
0.191	OUT SPE ^.layer_01111.pos = corner(^.layer_01111.pos, ^.layer_0.pos) - (1, 0)
0.187	OUT SPE ^.layer_0111.shape.mask.size.i = 3
0.184	OUT SPE ^.layer_01111.shape.mask.size.i = 3
0.180	IN  SPE ^.layer_0.shape.color = grey
0.178	OUT SPE ^.layer_0111.pos.j = ^.layer_0111.pos.j - ^.layer_011.pos.j - ^.layer_0.pos.j
0.175	OUT SPE ^.layer_0111.pos.i = ^.layer_011.pos.j - 1
0.173	OUT SPE ^.layer_0111.shape.mask.size.j = ^.size.i / '2
0.171	OUT SPE ^.layer_01111.shape.mask.size.j = ^.size.i / '2
0.170	IN  SPE ^.layer_01.shape.mask.model = Full
0.168	OUT SPE ^.layer_0111.shape.mask.model = Full
0.167	OUT SPE ^.layer_01111.shape.mask.model = Full
0.165	IN  SPE ^.color = black
0.078	
0.078	IN  GEN ^.layer_0.shape.color = ?
0.078	IN  GEN ^.layer_01.shape.mask.model = ?
0.078	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color ? at '(0, 0)
  _01: 
0 0 0 
0 0 0 
0 0 0 
 with color ? at projJ(^.layer_01111.pos) - (0, 1)
  _011: 
0 0 0 
0 0 0 
0 0 0 
 with color ? at projJ(^.layer_011.pos) + (0, 3)
  _0111: rectangle with size (3,^.size.i / '2) with model Full with color ? at (^.layer_011.pos.j - 1,^.layer_0111.pos.j - ^.layer_011.pos.j - ^.layer_0.pos.j)
  _01111: rectangle with size (3,^.size.i / '2) with model Full with color ? at corner(^.layer_01111.pos, ^.layer_0.pos) - (1, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 127.9 + 6072.0 = 6199.9
DL output with Mo: L = 332.4 + 4878.8 = 5211.1
DL input+output M: L = 460.3 + 10950.7 = 11411.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color ? at '(0, 0)
  _01: 
0 0 0 
0 0 0 
0 0 0 
 with color ? at projJ(^.layer_01111.pos) - (0, 1)
  _011: 
0 0 0 
0 0 0 
0 0 0 
 with color ? at projJ(^.layer_011.pos) + (0, 3)
  _0111: rectangle with size (3,^.size.i / '2) with model Full with color ? at (^.layer_011.pos.j - 1,^.layer_0111.pos.j - ^.layer_011.pos.j - ^.layer_0.pos.j)
  _01111: rectangle with size (3,^.size.i / '2) with model Full with color ? at corner(^.layer_01111.pos, ^.layer_0.pos) - (1, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 124.0 + 20.0 = 144.0
DL output with Mo: L = 332.4 + 4878.8 = 5211.1
DL input+output M: L = 456.4 + 4898.8 = 5355.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,1) with model Full with color grey at (0,3)
  _01: rectangle with size (3,1) with model Full with color grey at (0,7)
  _011: point with color blue at (1,1)
  _0111: point with color red at (1,5)
  _01111: point with color blue at (1,9)
diff: 
   (0.0 bits)
data: a background with size (3,11) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color pink at (0,0)
  _01: 
0 0 0 
0 0 0 
0 0 0 
 with color pink at (0,8)
  _011: 
0 0 0 
0 0 0 
0 0 0 
 with color orange at (0,4)
  _0111: rectangle with size (3,1) with model Full with color grey at (0,7)
  _01111: rectangle with size (3,1) with model Full with color grey at (0,3)
diff: 
   (30.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,1) with model Full with color grey at (0,3)
  _01: rectangle with size (3,1) with model Full with color grey at (0,7)
  _011: point with color blue at (1,1)
  _0111: point with color red at (1,5)
  _01111: point with color blue at (1,9)
diff: 
! 33 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,1) with model Full with color grey at (0,3)
  _01: rectangle with size (3,1) with model Full with color grey at (0,7)
  _011: point with color blue at (1,1)
  _0111: point with color blue at (1,9)
  _01111: point with color red at (1,5)
diff: 
! 33 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,1) with model Full with color grey at (0,3)
  _01: rectangle with size (3,1) with model Full with color grey at (0,7)
  _011: point with color red at (1,5)
  _0111: point with color blue at (1,1)
  _01111: point with color blue at (1,9)
diff: 
! 33 wrong pixels (generated / expected)

TRAIN 54d9e175.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,1) with model Full with color grey at (0,3)
  _01: rectangle with size (3,1) with model Full with color grey at (0,7)
  _011: point with color red at (1,1)
  _0111: point with color green at (1,5)
  _01111: point with color blue at (1,9)
diff: 
   (0.0 bits)
data: a background with size (3,11) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color orange at (0,0)
  _01: 
0 0 0 
0 0 0 
0 0 0 
 with color pink at (0,8)
  _011: 
0 0 0 
0 0 0 
0 0 0 
 with color cyan at (0,4)
  _0111: rectangle with size (3,1) with model Full with color grey at (0,7)
  _01111: rectangle with size (3,1) with model Full with color grey at (0,3)
diff: 
   (30.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,1) with model Full with color grey at (0,3)
  _01: rectangle with size (3,1) with model Full with color grey at (0,7)
  _011: point with color red at (1,1)
  _0111: point with color green at (1,5)
  _01111: point with color blue at (1,9)
diff: 
! 33 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,1) with model Full with color grey at (0,3)
  _01: rectangle with size (3,1) with model Full with color grey at (0,7)
  _011: point with color red at (1,1)
  _0111: point with color blue at (1,9)
  _01111: point with color green at (1,5)
diff: 
! 33 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,1) with model Full with color grey at (0,3)
  _01: rectangle with size (3,1) with model Full with color grey at (0,7)
  _011: point with color green at (1,5)
  _0111: point with color red at (1,1)
  _01111: point with color blue at (1,9)
diff: 
! 33 wrong pixels (generated / expected)

TRAIN 54d9e175.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,1) with model Full with color grey at (0,3)
  _01: rectangle with size (3,1) with model Full with color grey at (0,7)
  _011: point with color green at (1,1)
  _0111: point with color blue at (1,5)
  _01111: point with color yellow at (1,9)
diff: 
   (0.0 bits)
data: a background with size (3,11) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color cyan at (0,0)
  _01: 
0 0 0 
0 0 0 
0 0 0 
 with color brown at (0,8)
  _011: 
0 0 0 
0 0 0 
0 0 0 
 with color pink at (0,4)
  _0111: rectangle with size (3,1) with model Full with color grey at (0,7)
  _01111: rectangle with size (3,1) with model Full with color grey at (0,3)
diff: 
   (30.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,1) with model Full with color grey at (0,3)
  _01: rectangle with size (3,1) with model Full with color grey at (0,7)
  _011: point with color green at (1,1)
  _0111: point with color blue at (1,5)
  _01111: point with color yellow at (1,9)
diff: 
! 33 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,1) with model Full with color grey at (0,3)
  _01: rectangle with size (3,1) with model Full with color grey at (0,7)
  _011: point with color green at (1,1)
  _0111: point with color yellow at (1,9)
  _01111: point with color blue at (1,5)
diff: 
! 33 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,1) with model Full with color grey at (0,3)
  _01: rectangle with size (3,1) with model Full with color grey at (0,7)
  _011: point with color blue at (1,5)
  _0111: point with color green at (1,1)
  _01111: point with color yellow at (1,9)
diff: 
! 33 wrong pixels (generated / expected)

TRAIN 54d9e175.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (7,11) and color black and layers
  _0: rectangle with size (7,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,1) with model Full with color yellow at (1,1)
  _011: point with color blue at (1,5)
  _0111: point with color red at (1,9)
  _01111: point with color green at (5,5)
  + 2 delta pixels
diff: 
   (2.0 bits)
data: a background with size (7,11) and color grey and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color brown at (0,0)
  _01: 
0 0 0 
0 0 0 
0 0 0 
 with color pink at (0,4)
  _011: 
0 0 0 
0 0 0 
0 0 0 
 with color orange at (0,8)
  _0111: rectangle with size (3,3) with model Full with color cyan at (4,4)
  _01111: rectangle with size (3,3) with model Full with color orange at (4,0)
  + 9 delta pixels
diff: 
   (396.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,11) and color black and layers
  _0: rectangle with size (7,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,1) with model Full with color yellow at (1,1)
  _011: point with color blue at (1,5)
  _0111: point with color red at (1,9)
  _01111: point with color red at (5,1)
  + 2 delta pixels
diff: 
! 77 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,11) and color black and layers
  _0: rectangle with size (7,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,1) with model Full with color yellow at (1,1)
  _011: point with color blue at (1,5)
  _0111: point with color red at (1,9)
  _01111: point with color green at (5,5)
  + 2 delta pixels
diff: 
! 77 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (7,11) and color black and layers
  _0: rectangle with size (7,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,1) with model Full with color yellow at (1,1)
  _011: point with color blue at (1,5)
  _0111: point with color red at (5,1)
  _01111: point with color red at (1,9)
  + 2 delta pixels
diff: 
! 77 wrong pixels (generated / expected)

TRAIN 54d9e175.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,11) and color black and layers
  _0: rectangle with size (7,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,1) with model Full with color red at (1,1)
  _011: point with color green at (1,5)
  _0111: point with color yellow at (1,9)
  _01111: point with color blue at (5,1)
  + 2 delta pixels
diff: 
! 77 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,11) and color black and layers
  _0: rectangle with size (7,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,1) with model Full with color red at (1,1)
  _011: point with color green at (1,5)
  _0111: point with color yellow at (1,9)
  _01111: point with color blue at (5,5)
  + 2 delta pixels
diff: 
! 77 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (7,11) and color black and layers
  _0: rectangle with size (7,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (1,1) with model Full with color red at (1,1)
  _011: point with color green at (1,5)
  _0111: point with color blue at (5,1)
  _01111: point with color yellow at (1,9)
  + 2 delta pixels
diff: 
! 77 wrong pixels (generated / expected)

TEST 54d9e175.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 41.1 sec (41.1 sec/task)
bits-train-error = 4878.8 bits (4878.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-273] Checking task 5521c0d9.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 276019.4 = 276021.8
DL output with Mo: L = 2.3 + 276019.4 = 276021.8
DL input+output M: L = 4.6 + 552038.9 = 552043.5

# learning a model for train pairs
2.000	
1.128	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.255	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.191	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.124	OUT ADD ^.layer_0 = ^.layer_0.shape at (?,?)
0.095	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.064	OUT ADD ^.layer_01 = ^.layer_01.shape at (?,?)
0.044	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.021	OUT ADD ^.layer_011 = ^.layer_011.shape at (?,?)
0.018	OUT SPE ^.size = ^.size
0.017	OUT SPE ^.layer_011.pos = ^.layer_011.pos - projI(^.layer_011.shape.mask.size)
0.016	OUT SPE ^.layer_01.pos = ^.layer_01.pos - projI(^.layer_01.shape.mask.size)
0.015	OUT SPE ^.layer_0.pos = ^.layer_0.pos - projI(^.layer_0.shape.mask.size)
0.014	IN  SPE ^.layer_0.shape.color = yellow
0.013	IN  SPE ^.layer_01.shape.color = blue
0.013	IN  SPE ^.layer_011.shape.color = red
0.013	IN  SPE ^.layer_0.shape.mask.model = Full
0.012	IN  SPE ^.layer_01.shape.mask.model = Full
0.012	IN  SPE ^.layer_011.shape.mask.model = Full
0.012	IN  SPE ^.color = black
0.011	OUT SPE ^.color = black
0.001	
0.001	IN  GEN ^.layer_011.shape.color = ?
0.001	IN  GEN ^.layer_01.shape.color = ?
0.001	IN  GEN ^.layer_0.shape.color = ?
0.001	IN  GEN ^.layer_011.shape.mask.model = ?
0.001	IN  GEN ^.layer_01.shape.mask.model = ?
0.001	IN  GEN ^.layer_0.shape.mask.model = ?
0.001	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0.shape at ^.layer_0.pos - projI(^.layer_0.shape.mask.size)
  _01: ^.layer_01.shape at ^.layer_01.pos - projI(^.layer_01.shape.mask.size)
  _011: ^.layer_011.shape at ^.layer_011.pos - projI(^.layer_011.shape.mask.size)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color yellow at (?,?)
  _01: rectangle with size (?,?) with model Full with color blue at (?,?)
  _011: rectangle with size (?,?) with model Full with color red at (?,?)

DL input  with Mi: L = 109.7 + 2917.1 = 3026.8
DL output with Mo: L = 123.3 + 0.0 = 123.3
DL input+output M: L = 233.0 + 2917.1 = 3150.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0.shape at ^.layer_0.pos - projI(^.layer_0.shape.mask.size)
  _01: ^.layer_01.shape at ^.layer_01.pos - projI(^.layer_01.shape.mask.size)
  _011: ^.layer_011.shape at ^.layer_011.pos - projI(^.layer_011.shape.mask.size)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 0.0 = 98.1
DL output with Mo: L = 123.3 + 0.0 = 123.3
DL input+output M: L = 221.4 + 0.0 = 221.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (4,4) with model Full with color yellow at (11,9)
  _01: rectangle with size (4,2) with model Full with color blue at (11,1)
  _011: rectangle with size (2,4) with model Full with color red at (13,4)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: 
4 4 4 4 
4 4 4 4 
4 4 4 4 
4 4 4 4 
 at (7,9)
  _01: 
1 1 
1 1 
1 1 
1 1 
 at (7,1)
  _011: 
2 2 2 2 
2 2 2 2 
 at (11,4)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (4,4) with model Full with color yellow at (11,9)
  _01: rectangle with size (4,2) with model Full with color blue at (11,1)
  _011: rectangle with size (2,4) with model Full with color red at (13,4)
diff: 
correct output grid

TRAIN 5521c0d9.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (6,4) with model Full with color yellow at (9,1)
  _01: rectangle with size (5,2) with model Full with color red at (10,11)
  _011: rectangle with size (2,2) with model Full with color blue at (13,7)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: 
4 4 4 4 
4 4 4 4 
4 4 4 4 
4 4 4 4 
4 4 4 4 
4 4 4 4 
 at (3,1)
  _01: 
2 2 
2 2 
2 2 
2 2 
2 2 
 at (5,11)
  _011: 
1 1 
1 1 
 at (11,7)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (6,4) with model Full with color yellow at (9,1)
  _01: rectangle with size (5,2) with model Full with color red at (10,11)
  _011: rectangle with size (2,2) with model Full with color blue at (13,7)
diff: 
correct output grid

TRAIN 5521c0d9.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (3,2) with model Full with color yellow at (12,11)
  _01: rectangle with size (4,1) with model Full with color blue at (11,7)
  _011: rectangle with size (1,4) with model Full with color red at (14,1)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: 
4 4 
4 4 
4 4 
 at (9,11)
  _01: 
1 
1 
1 
1 
 at (7,7)
  _011: 
2 2 2 2 
 at (13,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (3,2) with model Full with color yellow at (12,11)
  _01: rectangle with size (4,1) with model Full with color blue at (11,7)
  _011: rectangle with size (1,4) with model Full with color red at (14,1)
diff: 
correct output grid

TRAIN 5521c0d9.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (7,4) with model Full with color red at (8,0)
  _01: rectangle with size (6,3) with model Full with color yellow at (9,5)
  _011: rectangle with size (3,5) with model Full with color blue at (12,10)
diff: 
correct output grid

TEST 5521c0d9.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 4.5 sec (4.5 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-272] Checking task 5582e5ca.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 10534.8 = 10537.1
DL output with Mo: L = 2.3 + 10534.8 = 10537.1
DL input+output M: L = 4.6 + 21069.6 = 21074.2

# learning a model for train pairs
2.000	
1.064	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.759	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.625	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.498	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.433	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.365	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.328	OUT SPE ^.size = ^.size
0.303	OUT SPE ^.color = majorityColor(^)
0.293	IN  SPE ^.layer_0.shape.mask.model = Full
0.012	
0.002	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color majorityColor(^) and layers
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 106.7 + 2966.7 = 3073.4
DL output with Mo: L = 15.4 + 0.0 = 15.4
DL input+output M: L = 122.1 + 2966.7 = 3088.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color majorityColor(^) and layers
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 15.4 + 0.0 = 15.4
DL input+output M: L = 17.8 + 0.0 = 17.8

# train input/output grids

## instance 1

> Input and output best reading:

data: 
4 4 8 
6 4 3 
6 3 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color yellow and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 4 8 
6 4 3 
6 3 0 

diff: 
correct output grid

TRAIN 5582e5ca.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
6 8 9#
1 8 1 
9#4 9#

diff: 
   (0.0 bits)
data: a background with size (3,3) and color brown and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
6 8 9#
1 8 1 
9#4 9#

diff: 
correct output grid

TRAIN 5582e5ca.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
4 6 9#
6 4 1 
8 8 6 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color pink and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 6 9#
6 4 1 
8 8 6 

diff: 
correct output grid

TRAIN 5582e5ca.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 8 6 
4 6 9#
8 3 0 

diff: 
correct output grid

TEST 5582e5ca.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 2.3 sec (2.3 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-271] Checking task 5614dbcf.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 64315.6 = 64317.9
DL output with Mo: L = 2.3 + 7023.2 = 7025.5
DL input+output M: L = 4.6 + 71338.8 = 71343.5

# learning a model for train pairs
2.000	
1.417	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.854	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.754	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.667	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.603	OUT ADD ^.layer_0 = point with color ? at (?,?)
0.537	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.492	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.446	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.401	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.365	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.349	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.333	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.322	OUT SPE ^.layer_0.pos.i = ^.layer_0.pos.i
0.302	OUT SPE ^.layer_01.pos = ^.layer_01.pos / '3
0.295	OUT SPE ^.color = black
0.285	OUT SPE ^.layer_0.pos = ^.layer_0.pos / '3
0.279	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.272	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.265	IN  ADD ^.layer_01111111 = point with color ? at (?,?)
0.261	IN  SPE ^.layer_0.shape.mask = 
0 0 0 
0 0 0 
0 0 0 

0.259	IN  SPE ^.layer_011111.shape.color = grey
0.257	IN  SPE ^.layer_0111111.shape.color = grey
0.255	IN  SPE ^.layer_01111111.shape.color = grey
0.254	IN  SPE ^.layer_0111.shape.mask.model = Full
0.253	IN  SPE ^.layer_011.shape.mask.model = Full
0.252	IN  SPE ^.layer_01111.shape.mask.model = Full
0.251	IN  SPE ^.color = black
0.175	
0.175	IN  DEL ^.layer_01111
0.175	IN  DEL ^.layer_0111
0.174	IN  DEL ^.layer_011
0.174	IN  DEL ^.layer_01111111
0.173	IN  DEL ^.layer_0111111
0.173	IN  DEL ^.layer_011111
0.173	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: point with color ^.layer_0.shape.color at ^.layer_0.pos / '3
  _01: point with color ^.layer_01.shape.color at ^.layer_01.pos / '3
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011111: point with color grey at (?,?)
  _0111111: point with color grey at (?,?)
  _01111111: point with color grey at (?,?)

DL input  with Mi: L = 217.9 + 4893.5 = 5111.4
DL output with Mo: L = 87.1 + 1121.4 = 1208.6
DL input+output M: L = 305.0 + 6014.9 = 6319.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: point with color ^.layer_0.shape.color at ^.layer_0.pos / '3
  _01: point with color ^.layer_01.shape.color at ^.layer_01.pos / '3
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 87.1 + 1121.4 = 1208.6
DL input+output M: L = 157.3 + 1121.4 = 1278.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color green at (0,0)
  _01: rectangle with size (3,3) with model Full with color cyan at (0,6)
  + 30 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: point with color green at (0,0)
  _01: point with color cyan at (0,2)
  + 3 delta pixels
diff: 
   (112.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color green at (0,0)
  _01: rectangle with size (3,3) with model Full with color cyan at (0,6)
  + 30 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color orange at (3,3)
  _01: rectangle with size (3,3) with model Full with color green at (0,0)
  + 30 delta pixels
diff: 
! 3 wrong pixels (generated / expected)

TRAIN 5614dbcf.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color red at (0,3)
  _01: rectangle with size (3,3) with model Full with color orange at (6,3)
  + 6 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: point with color red at (0,1)
  _01: point with color orange at (2,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color red at (0,3)
  _01: rectangle with size (3,3) with model Full with color orange at (6,3)
  + 6 delta pixels
diff: 
correct output grid

TRAIN 5614dbcf.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color green at (3,3)
  _01: rectangle with size (3,3) with model Full with color yellow at (0,0)
  + 14 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color brown at (6,3)
  _01: rectangle with size (3,3) with model Full with color green at (3,3)
  + 14 delta pixels
diff: 
! 1 wrong pixels (generated / expected)

TEST 5614dbcf.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 14.8 sec (14.8 sec/task)
bits-train-error = 1121.4 bits (1121.4 bits/task)
acc-train-micro = 0.50 tasks (50.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.50
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-270] Checking task 56dc2b01.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 92836.6 = 92838.9
DL output with Mo: L = 2.3 + 92836.6 = 92838.9
DL input+output M: L = 4.6 + 185673.1 = 185677.8

# learning a model for train pairs
2.000	
1.187	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.433	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.330	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.215	OUT ADD ^.layer_0 = ^.layer_0.shape at (?,?)
0.164	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.105	OUT ADD ^.layer_01 = ^.layer_01
0.054	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.048	OUT SPE ^.layer_011.shape = coloring(^.layer_01.shape, cyan)
0.042	OUT SPE ^.size = ^.size
0.039	OUT SPE ^.layer_0.pos = ^.layer_0.pos + translationOnto(^.layer_0, ^.layer_01)
0.037	IN  SPE ^.layer_0.shape.color = green
0.035	IN  SPE ^.layer_01.shape.color = red
0.034	OUT SPE ^.layer_011.pos.j = ^.layer_01.pos.j / '2
0.033	IN  SPE ^.layer_01.shape.mask.model = Full
0.032	IN  SPE ^.color = black
0.031	OUT SPE ^.color = black
0.004	
0.004	IN  GEN ^.layer_01.shape.color = ?
0.004	IN  GEN ^.layer_0.shape.color = ?
0.004	IN  GEN ^.layer_01.shape.mask.model = ?
0.004	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0.shape at ^.layer_0.pos + translationOnto(^.layer_0, ^.layer_01)
  _01: ^.layer_01
  _011: coloring(^.layer_01.shape, cyan) at (?,^.layer_01.pos.j / '2)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color green at (?,?)
  _01: rectangle with size (?,?) with model Full with color red at (?,?)

DL input  with Mi: L = 77.5 + 2526.0 = 2603.4
DL output with Mo: L = 110.3 + 171.4 = 281.8
DL input+output M: L = 187.8 + 2697.4 = 2885.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0.shape at ^.layer_0.pos + translationOnto(^.layer_0, ^.layer_01)
  _01: ^.layer_01
  _011: coloring(^.layer_01.shape, cyan) at (?,^.layer_01.pos.j / '2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 110.3 + 171.4 = 281.8
DL input+output M: L = 180.6 + 171.4 = 352.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (4,16) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 . . 
. 0 0 0 
0 0 . . 
. 0 0 0 
 with color green at (0,0)
  _01: rectangle with size (4,1) with model Full with color red at (0,10)
diff: 
   (0.0 bits)
data: a background with size (4,16) and color black and layers
  _0: 
. 3 . . 
. 3 3 3 
3 3 . . 
. 3 3 3 
 at (0,6)
  _01: 
2 
2 
2 
2 
 at (0,10)
  _011: 
8 
8 
8 
8 
 at (0,5)
diff: 
   (4.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,16) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 . . 
. 0 0 0 
0 0 . . 
. 0 0 0 
 with color green at (0,0)
  _01: rectangle with size (4,1) with model Full with color red at (0,10)
diff: 
correct output grid

TRAIN 56dc2b01.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (17,5) and color black and layers
  _0: rectangle with size (4,5) with mask 
0 0 . . . 
0 . . . . 
0 0 . 0 0 
. 0 0 0 . 
 with color green at (1,0)
  _01: rectangle with size (1,5) with model Full with color red at (15,0)
diff: 
   (0.0 bits)
data: a background with size (17,5) and color black and layers
  _0: 
3 3 . . . 
3 . . . . 
3 3 . 3 3 
. 3 3 3 . 
 at (11,0)
  _01: 
2 2 2 2 2 
 at (15,0)
  _011: 
8 8 8 8 8 
 at (10,0)
diff: 
   (6.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,5) and color black and layers
  _0: rectangle with size (4,5) with mask 
0 0 . . . 
0 . . . . 
0 0 . 0 0 
. 0 0 0 . 
 with color green at (1,0)
  _01: rectangle with size (1,5) with model Full with color red at (15,0)
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,5) and color black and layers
  _0: rectangle with size (1,5) with model Full with color red at (15,0)
  _01: rectangle with size (4,5) with mask 
0 0 . . . 
0 . . . . 
0 0 . 0 0 
. 0 0 0 . 
 with color green at (1,0)
diff: 
! 41 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (17,5) and color black and layers
  _0: rectangle with size (1,5) with model Full with color green at (3,0)
  _01: rectangle with size (4,5) with mask 
0 0 . . . 
0 . . . . 
0 0 . 0 0 
. 0 0 0 . 
 with color green at (1,0)
  + 6 delta pixels
diff: 
! 36 wrong pixels (generated / expected)

TRAIN 56dc2b01.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (17,5) and color black and layers
  _0: rectangle with size (3,4) with mask 
0 0 0 0 
0 . . 0 
0 0 . 0 
 with color green at (11,0)
  _01: rectangle with size (1,5) with model Full with color red at (3,0)
diff: 
   (0.0 bits)
data: a background with size (17,5) and color black and layers
  _0: 
3 3 3 3 
3 . . 3 
3 3 . 3 
 at (4,0)
  _01: 
2 2 2 2 2 
 at (3,0)
  _011: 
8 8 8 8 8 
 at (7,0)
diff: 
   (6.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,5) and color black and layers
  _0: rectangle with size (3,4) with mask 
0 0 0 0 
0 . . 0 
0 0 . 0 
 with color green at (11,0)
  _01: rectangle with size (1,5) with model Full with color red at (3,0)
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,5) and color black and layers
  _0: rectangle with size (1,5) with model Full with color red at (3,0)
  _01: rectangle with size (3,4) with mask 
0 0 0 0 
0 . . 0 
0 0 . 0 
 with color green at (11,0)
diff: 
! 42 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (17,5) and color black and layers
  _0: rectangle with size (3,4) with model Full with color green at (11,0)
  _01: rectangle with size (1,5) with model Full with color red at (3,0)
  + 3 delta pixels
diff: 
! 13 wrong pixels (generated / expected)

TRAIN 56dc2b01.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,18) and color black and layers
  _0: rectangle with size (4,3) with mask 
. 0 0 
0 . 0 
0 0 0 
0 . . 
 with color green at (0,11)
  _01: rectangle with size (4,1) with model Full with color red at (0,4)
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,18) and color black and layers
  _0: rectangle with size (4,1) with model Full with color red at (0,4)
  _01: rectangle with size (4,3) with mask 
. 0 0 
0 . 0 
0 0 0 
0 . . 
 with color green at (0,11)
diff: 
! 28 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (4,18) and color black and layers
  _0: rectangle with size (4,3) with model Full with color green at (0,11)
  _01: rectangle with size (4,1) with model Full with color red at (0,4)
  + 4 delta pixels
diff: 
! 12 wrong pixels (generated / expected)

TEST 56dc2b01.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.5 sec (3.5 sec/task)
bits-train-error = 171.4 bits (171.4 bits/task)
acc-train-micro = 0.33 tasks (33.33%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.33
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-269] Checking task 56ff96f3.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 127953.0 = 127955.3
DL output with Mo: L = 2.3 + 127953.0 = 127955.3
DL input+output M: L = 4.6 + 255906.0 = 255910.6

# learning a model for train pairs
2.000	
1.045	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.346	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.134	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.127	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.120	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.113	OUT SPE ^.layer_0.shape = scaleTo(^.layer_0.shape, span(^.layer_0.pos, ^.layer_01.pos))
0.107	OUT SPE ^.size = ^.size
0.103	OUT SPE ^.layer_0.pos = projI(^.layer_0.pos) + (0, 1)
0.103	IN  SPE ^.color = black
0.102	OUT SPE ^.color = black
0.073	
0.073	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: scaleTo(^.layer_0.shape, span(^.layer_0.pos, ^.layer_01.pos)) at projI(^.layer_0.pos) + (0, 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.7 + 3740.7 = 3791.5
DL output with Mo: L = 73.8 + 9166.5 = 9240.3
DL input+output M: L = 124.5 + 12907.2 = 13031.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: scaleTo(^.layer_0.shape, span(^.layer_0.pos, ^.layer_01.pos)) at projI(^.layer_0.pos) + (0, 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.6 + 20.0 = 70.6
DL output with Mo: L = 73.8 + 9166.5 = 9240.3
DL input+output M: L = 124.4 + 9186.5 = 9310.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color blue at (1,6)
  _01: point with color blue at (3,1)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
1 1 1 1 1 1 
1 1 1 1 1 1 
1 1 1 1 1 1 
 at (1,1)
  + 15 delta pixels
diff: 
   (600.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (1,6)
  _01: point with color blue at (3,1)
  + 2 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (1,6)
  _01: point with color red at (5,3)
  + 2 delta pixels
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (3,1)
  _01: point with color blue at (1,6)
  + 2 delta pixels
diff: 
! 35 wrong pixels (generated / expected)

TRAIN 56ff96f3.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (7,8) and color black and layers
  _0: point with color green at (1,1)
  _01: point with color green at (4,2)
  + 2 delta pixels
diff: 
   (2.0 bits)
data: a background with size (7,8) and color black and layers
  _0: 
3 3 
3 3 
3 3 
3 3 
 at (1,1)
  + 8 delta pixels
diff: 
   (315.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,8) and color black and layers
  _0: point with color green at (1,1)
  _01: point with color orange at (3,7)
  + 2 delta pixels
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,8) and color black and layers
  _0: point with color green at (1,1)
  _01: point with color green at (4,2)
  + 2 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (7,8) and color black and layers
  _0: point with color orange at (3,7)
  _01: point with color green at (1,1)
  + 2 delta pixels
diff: 
! 17 wrong pixels (generated / expected)

TRAIN 56ff96f3.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (2,1)
  _01: point with color yellow at (6,5)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
4 4 4 4 4 
4 4 4 4 4 
4 4 4 4 4 
4 4 4 4 4 
4 4 4 4 4 
 at (2,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (2,1)
  _01: point with color yellow at (6,5)
diff: 
correct output grid

TRAIN 56ff96f3.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: a background with size (6,11) and color black and layers
  _0: point with color orange at (1,1)
  _01: point with color orange at (3,7)
diff: 
   (0.0 bits)
data: a background with size (6,11) and color black and layers
  _0: 
7#7#7#7#7#7#7#
7#7#7#7#7#7#7#
7#7#7#7#7#7#7#
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,11) and color black and layers
  _0: point with color orange at (1,1)
  _01: point with color orange at (3,7)
diff: 
correct output grid

TRAIN 56ff96f3.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,8) and color black and layers
  _0: point with color cyan at (0,0)
  _01: point with color cyan at (1,2)
  + 2 delta pixels
diff: 
! 24 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,8) and color black and layers
  _0: point with color cyan at (0,0)
  _01: point with color pink at (4,5)
  + 2 delta pixels
diff: 
! 43 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,8) and color black and layers
  _0: point with color cyan at (1,2)
  _01: point with color cyan at (0,0)
  + 2 delta pixels
diff: 
! 28 wrong pixels (generated / expected)

TEST 56ff96f3.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 1.6 sec (1.6 sec/task)
bits-train-error = 9166.5 bits (9166.5 bits/task)
acc-train-micro = 0.50 tasks (50.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.50
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-268] Checking task 57aa92db.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 434192.3 = 434194.6
DL output with Mo: L = 2.3 + 434192.3 = 434194.6
DL input+output M: L = 4.6 + 868384.6 = 868389.2

# learning a model for train pairs
2.000	
1.063	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.211	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.123	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.105	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.088	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.069	OUT ADD ^.layer_00 = ^.layer_0
0.055	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.043	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.036	OUT ADD ^.layer_011 = ^.layer_011
0.034	IN  ADD ^.layer_010 = point with color ? at (?,?)
0.032	OUT SPE ^.size = ^.size
0.031	OUT SPE ^.layer_01.shape.mask.size.i = ^.layer_01.shape.mask.size.i * '3
0.030	OUT SPE ^.layer_01.pos.i = ^.layer_011.pos.i - ^.layer_01.shape.mask.size.i
0.030	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.030	IN  SPE ^.layer_01.shape.mask.model = Full
0.029	IN  SPE ^.layer_011.shape.mask.model = Full
0.029	IN  SPE ^.color = black
0.029	OUT SPE ^.color = black
0.012	
0.012	IN  GEN ^.layer_011.shape.mask.model = ?
0.012	IN  GEN ^.layer_01.shape.mask.model = ?
0.012	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (^.layer_01.shape.mask.size.i * '3,?) with model ? with color ^.layer_01.shape.color at (^.layer_011.pos.i - ^.layer_01.shape.mask.size.i,?)
  _011: ^.layer_011
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: point with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 117.2 + 7273.7 = 7390.8
DL output with Mo: L = 135.0 + 5070.9 = 5206.0
DL input+output M: L = 252.2 + 12344.6 = 12596.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (^.layer_01.shape.mask.size.i * '3,?) with model ? with color ^.layer_01.shape.color at (^.layer_011.pos.i - ^.layer_01.shape.mask.size.i,?)
  _011: ^.layer_011
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: point with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 116.0 + 31.7 = 147.7
DL output with Mo: L = 135.0 + 5070.9 = 5206.0
DL input+output M: L = 251.0 + 5102.6 = 5353.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (16,12) and color black and layers
  _0: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color green at (1,2)
  _010: point with color blue at (2,4)
  _01: rectangle with size (2,2) with model Full with color yellow at (9,5)
  _011: rectangle with size (2,2) with model Full with color blue at (9,7)
diff: 
   (0.0 bits)
data: a background with size (16,12) and color black and layers
  _00: 
. 3 
3 3 
. 3 
 at (1,2)
  _0: rectangle with size (1,1) with model Full with color blue at (2,4)
  _01: rectangle with size (6,4) with mask 
. . 0 0 
. . 0 0 
0 0 0 0 
0 0 0 0 
. . 0 0 
. . 0 0 
 with color yellow at (7,3)
  _011: 
1 1 
1 1 
 at (9,7)
diff: 
   (65.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,12) and color black and layers
  _0: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color green at (1,2)
  _010: point with color blue at (2,4)
  _01: rectangle with size (2,2) with model Full with color yellow at (9,5)
  _011: rectangle with size (2,2) with model Full with color blue at (9,7)
diff: 
! 33 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (16,12) and color black and layers
  _0: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color green at (1,2)
  _010: point with color blue at (2,4)
  _01: rectangle with size (2,2) with model Full with color blue at (9,7)
  _011: rectangle with size (2,2) with model Full with color yellow at (9,5)
diff: 
! 33 wrong pixels (generated / expected)

TRAIN 57aa92db.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (16,18) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. . 0 
 with color cyan at (1,3)
  _010: point with color red at (2,2)
  _01: rectangle with size (1,1) with model Full with color pink at (7,11)
  _011: rectangle with size (1,1) with model Full with color red at (7,10)
  + 2 delta pixels
diff: 
   (3.2 bits)
data: a background with size (16,18) and color black and layers
  _00: 
. . 8 
8 8 8 
. . 8 
 at (1,3)
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. . 0 
 with color green at (11,6)
  _01: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. . 0 
 with color pink at (6,11)
  _011: 
2 
 at (7,10)
  + 2 delta pixels
diff: 
   (151.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,18) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. . 0 
 with color cyan at (1,3)
  _010: point with color red at (2,2)
  _01: rectangle with size (1,1) with model Full with color red at (7,10)
  _011: rectangle with size (1,1) with model Full with color pink at (7,11)
  + 2 delta pixels
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (16,18) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. . 0 
 with color cyan at (1,3)
  _010: point with color red at (2,2)
  _01: rectangle with size (1,1) with model Full with color red at (7,10)
  _011: rectangle with size (1,1) with model Full with color red at (12,5)
  + 2 delta pixels
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (16,18) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. . 0 
 with color cyan at (1,3)
  _010: point with color red at (2,2)
  _01: rectangle with size (1,1) with model Full with color pink at (7,11)
  _011: rectangle with size (1,1) with model Full with color red at (7,10)
  + 2 delta pixels
diff: 
! 22 wrong pixels (generated / expected)

TRAIN 57aa92db.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (17,18) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
0 . 0 
0 . 0 
 with color blue at (2,2)
  _010: point with color yellow at (3,3)
  _01: rectangle with size (3,3) with model Full with color cyan at (7,9)
  _011: rectangle with size (3,3) with model Full with color yellow at (10,9)
diff: 
   (0.0 bits)
data: a background with size (17,18) and color black and layers
  _00: 
1 1 1 
1 . 1 
1 . 1 
 at (2,2)
  _0: rectangle with size (1,1) with model Full with color yellow at (3,3)
  _01: rectangle with size (9,9) with mask 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 . . . 0 0 0 
0 0 0 . . . 0 0 0 
0 0 0 . . . 0 0 0 
0 0 0 . . . 0 0 0 
0 0 0 . . . 0 0 0 
0 0 0 . . . 0 0 0 
 with color cyan at (7,6)
  _011: 
4 4 4 
4 4 4 
4 4 4 
 at (10,9)
diff: 
   (109.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,18) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
0 . 0 
0 . 0 
 with color blue at (2,2)
  _010: point with color yellow at (3,3)
  _01: rectangle with size (3,3) with model Full with color cyan at (7,9)
  _011: rectangle with size (3,3) with model Full with color yellow at (10,9)
diff: 
! 86 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,18) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
0 . 0 
0 . 0 
 with color blue at (2,2)
  _010: point with color yellow at (3,3)
  _01: rectangle with size (3,3) with model Full with color yellow at (10,9)
  _011: rectangle with size (3,3) with model Full with color cyan at (7,9)
diff: 
! 86 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (17,18) and color black and layers
  _0: rectangle with size (3,3) with model Full with color cyan at (7,9)
  _010: point with color yellow at (3,3)
  _01: rectangle with size (3,3) with model Full with color yellow at (10,9)
  _011: rectangle with size (3,3) with mask 
0 0 0 
0 . 0 
0 . 0 
 with color blue at (2,2)
diff: 
! 80 wrong pixels (generated / expected)

TRAIN 57aa92db.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (15,18) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
. . 0 
 with color cyan at (3,12)
  _010: point with color green at (2,4)
  _01: rectangle with size (2,2) with model Full with color yellow at (7,6)
  _011: rectangle with size (2,2) with model Full with color red at (9,6)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (15,18) and color black and layers
  _00: 
. . 8 
8 8 . 
. . 8 
 at (3,12)
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
. . 0 
 with color green at (1,3)
  _01: rectangle with size (6,6) with mask 
. . . . 0 0 
. . . . 0 0 
0 0 0 0 . . 
0 0 0 0 . . 
. . . . 0 0 
. . . . 0 0 
 with color yellow at (7,2)
  _011: 
2 2 
2 2 
 at (9,6)
  + 2 delta pixels
diff: 
   (180.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,18) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
. . 0 
 with color cyan at (3,12)
  _010: point with color green at (2,4)
  _01: rectangle with size (2,2) with model Full with color yellow at (7,6)
  _011: rectangle with size (2,2) with model Full with color red at (9,6)
  + 2 delta pixels
diff: 
! 38 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,18) and color black and layers
  _0: rectangle with size (2,2) with model Full with color yellow at (7,6)
  _010: point with color green at (2,4)
  _01: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
. . 0 
 with color cyan at (3,12)
  _011: rectangle with size (2,2) with model Full with color red at (9,6)
  + 2 delta pixels
diff: 
! 44 wrong pixels (generated / expected)

TRAIN 57aa92db.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,30) and color black and layers
  _0: rectangle with size (4,4) with model Full with color blue at (7,21)
  _010: point with color cyan at (2,4)
  _01: rectangle with size (4,4) with model Full with color red at (7,25)
  _011: rectangle with size (3,3) with model Full with color yellow at (3,10)
  + 23 delta pixels
diff: 
! 207 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (19,30) and color black and layers
  _0: rectangle with size (4,4) with model Full with color blue at (7,21)
  _010: point with color cyan at (2,4)
  _01: rectangle with size (4,4) with model Full with color red at (7,25)
  _011: rectangle with size (3,3) with model Full with color blue at (3,13)
  + 23 delta pixels
diff: 
! 207 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (19,30) and color black and layers
  _0: rectangle with size (4,4) with model Full with color blue at (7,21)
  _010: point with color cyan at (2,4)
  _01: rectangle with size (3,3) with model Full with color yellow at (3,10)
  _011: rectangle with size (4,4) with model Full with color red at (7,25)
  + 23 delta pixels
diff: 
! 200 wrong pixels (generated / expected)

TEST 57aa92db.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 17.4 sec (17.4 sec/task)
bits-train-error = 5070.9 bits (5070.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-267] Checking task 5ad4f10b.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 645641.1 = 645643.4
DL output with Mo: L = 2.3 + 10534.8 = 10537.1
DL input+output M: L = 4.6 + 656175.9 = 656180.5

# learning a model for train pairs
2.000	
1.228	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.674	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.381	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.223	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.157	OUT SPE ^.layer_0.shape.mask = scaleTo(^.layer_0.shape.mask, '(3, 3))
0.121	OUT SPE ^.size = '(3, 3)
0.099	OUT SPE ^.layer_0.pos = '(0, 0)
0.092	OUT SPE ^.color = black
0.087	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.072	OUT SPE ^.layer_0.shape.color = ^.layer_01.shape.color
0.071	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.070	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.069	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.066	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.063	IN  ADD ^.layer_011110 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.061	IN  ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.061	IN  SPE ^.layer_011111.shape.mask.model = Full
0.061	IN  SPE ^.color = black
0.008	
0.008	IN  DEL ^.layer_011111
0.008	IN  DEL ^.layer_0111111
0.008	IN  DEL ^.layer_011110
0.008	IN  DEL ^.layer_01111
0.008	IN  DEL ^.layer_0111
0.008	IN  DEL ^.layer_011
0.008	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: scaleTo(^.layer_0.shape.mask, '(3, 3)) with color ^.layer_01.shape.color at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _011110: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 207.0 + 34491.0 = 34698.0
DL output with Mo: L = 78.4 + 0.0 = 78.4
DL input+output M: L = 285.4 + 34491.0 = 34776.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: scaleTo(^.layer_0.shape.mask, '(3, 3)) with color ^.layer_01.shape.color at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 78.4 + 0.0 = 78.4
DL input+output M: L = 148.6 + 0.0 = 148.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (20,24) and color black and layers
  _0: rectangle with size (12,12) with mask 
0 0 0 0 . . . . 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 
. . . . 0 0 0 0 . . . . 
. . . . 0 0 0 0 . . . . 
. . . . 0 0 0 0 . . . . 
. . . . 0 0 0 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color yellow at (3,3)
  _01: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color cyan at (0,9)
  + 33 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
0 . 0 
. 0 . 
0 0 0 
 with color cyan at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,24) and color black and layers
  _0: rectangle with size (12,12) with mask 
0 0 0 0 . . . . 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 
. . . . 0 0 0 0 . . . . 
. . . . 0 0 0 0 . . . . 
. . . . 0 0 0 0 . . . . 
. . . . 0 0 0 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color yellow at (3,3)
  _01: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color cyan at (0,9)
  + 33 delta pixels
diff: 
correct output grid

TRAIN 5ad4f10b.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (22,23) and color black and layers
  _0: rectangle with size (9,9) with mask 
0 0 0 . . . 0 0 0 
0 0 0 . . . 0 0 0 
0 0 0 . . . 0 0 0 
. . . 0 0 0 . . . 
. . . 0 0 0 . . . 
. . . 0 0 0 . . . 
0 0 0 . . . . . . 
0 0 0 . . . . . . 
0 0 0 . . . . . . 
 with color blue at (1,10)
  _01: rectangle with size (2,5) with model Even Checkboard with color red at (5,8)
  + 33 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
0 . 0 
. 0 . 
0 . . 
 with color red at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (22,23) and color black and layers
  _0: rectangle with size (9,9) with mask 
0 0 0 . . . 0 0 0 
0 0 0 . . . 0 0 0 
0 0 0 . . . 0 0 0 
. . . 0 0 0 . . . 
. . . 0 0 0 . . . 
. . . 0 0 0 . . . 
0 0 0 . . . . . . 
0 0 0 . . . . . . 
0 0 0 . . . . . . 
 with color blue at (1,10)
  _01: rectangle with size (2,5) with model Even Checkboard with color red at (5,8)
  + 33 delta pixels
diff: 
correct output grid

TRAIN 5ad4f10b.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (24,23) and color black and layers
  _0: rectangle with size (15,15) with mask 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
 with color pink at (5,2)
  _01: rectangle with size (2,1) with model Full with color green at (10,3)
  + 15 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
. 0 . 
. 0 0 
0 . 0 
 with color green at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (24,23) and color black and layers
  _0: rectangle with size (15,15) with mask 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
 with color pink at (5,2)
  _01: rectangle with size (2,1) with model Full with color green at (10,3)
  + 15 delta pixels
diff: 
correct output grid

TRAIN 5ad4f10b.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (22,26) and color black and layers
  _0: rectangle with size (12,12) with mask 
0 0 0 0 . . . . 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 
. . . . 0 0 0 0 0 0 0 0 
. . . . 0 0 0 0 0 0 0 0 
. . . . 0 0 0 0 0 0 0 0 
. . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 
. . . . . . . . 0 0 0 0 
. . . . . . . . 0 0 0 0 
. . . . . . . . 0 0 0 0 
 with color cyan at (4,2)
  _01: rectangle with size (2,5) with mask 
. 0 . . 0 
0 . 0 0 . 
 with color yellow at (15,1)
  + 48 delta pixels
diff: 
correct output grid

TEST 5ad4f10b.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 9.6 sec (9.6 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-266] Checking task 5bd6f4ac.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 128631.2 = 128633.5
DL output with Mo: L = 2.3 + 14046.4 = 14048.7
DL input+output M: L = 4.6 + 142677.6 = 142682.3

# learning a model for train pairs
2.000	
1.354	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.901	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.815	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.749	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.683	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.647	OUT SPE ^.size = '(3, 3)
0.621	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.605	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.594	OUT SPE ^.layer_011.pos.i = 1
0.584	OUT SPE ^.layer_011.pos.j = ^.layer_01.pos.i
0.575	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.545	OUT SPE ^.layer_0.shape.mask = ^.layer_011.shape.mask
0.535	OUT SPE ^.layer_01.pos.i = ^.layer_011.pos.i
0.526	IN  ADD ^.layer_0110 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.519	OUT SPE ^.layer_0.pos.j = span(^.layer_0.pos.i, ^.layer_011.pos.i) - ^.layer_0.shape.mask.size.i
0.512	OUT SPE ^.color = black
0.505	IN  ADD ^.layer_00 = point with color ? at (?,?)
0.499	OUT SPE ^.layer_0.pos.i = middle(^.layer_00) - ^.layer_011.pos.i - ^.layer_0110.pos.i
0.493	OUT SPE ^.layer_01.pos.j = middle(^.layer_00) - ^.layer_011.pos.i - ^.layer_0110.pos.i
0.491	IN  SPE ^.layer_011.shape.mask.model = Full
0.491	IN  SPE ^.color = black
0.206	
0.206	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: ^.layer_011.shape.mask with color ? at (middle(^.layer_00) - ^.layer_011.pos.i - ^.layer_0110.pos.i,span(^.layer_0.pos.i, ^.layer_011.pos.i) - ^.layer_0.shape.mask.size.i)
  _01: point with color ? at (^.layer_011.pos.i,middle(^.layer_00) - ^.layer_011.pos.i - ^.layer_0110.pos.i)
  _011: point with color ? at (1,^.layer_01.pos.i)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 144.2 + 36657.5 = 36801.7
DL output with Mo: L = 312.8 + 2561.3 = 2874.2
DL input+output M: L = 457.1 + 39218.8 = 39675.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: ^.layer_011.shape.mask with color ? at (middle(^.layer_00) - ^.layer_011.pos.i - ^.layer_0110.pos.i,span(^.layer_0.pos.i, ^.layer_011.pos.i) - ^.layer_0.shape.mask.size.i)
  _01: point with color ? at (^.layer_011.pos.i,middle(^.layer_00) - ^.layer_011.pos.i - ^.layer_0110.pos.i)
  _011: point with color ? at (1,^.layer_01.pos.i)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 144.1 + 0.0 = 144.1
DL output with Mo: L = 312.8 + 2561.3 = 2874.2
DL input+output M: L = 456.9 + 2561.3 = 3018.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _00: point with color green at (0,0)
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
0 . . 
 with color orange at (3,4)
  _01: rectangle with size (2,2) with model Full with color blue at (2,0)
  _0110: rectangle with size (1,2) with model Full with color pink at (1,3)
  _011: rectangle with size (2,1) with model Full with color yellow at (1,6)
  + 23 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
0 
0 
 with color yellow at (1,0)
  _01: point with color cyan at (1,1)
  _011: point with color yellow at (1,2)
  + 2 delta pixels
diff: 
   (92.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _00: point with color green at (0,0)
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
0 . . 
 with color orange at (3,4)
  _01: rectangle with size (2,2) with model Full with color blue at (2,0)
  _0110: rectangle with size (1,2) with model Full with color pink at (1,3)
  _011: rectangle with size (2,1) with model Full with color yellow at (1,6)
  + 23 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _00: point with color green at (0,0)
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
0 . . 
 with color orange at (3,4)
  _01: rectangle with size (2,2) with model Full with color blue at (2,0)
  _0110: rectangle with size (1,2) with model Full with color pink at (1,3)
  _011: rectangle with size (1,2) with model Full with color brown at (6,3)
  + 23 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 5bd6f4ac.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _00: point with color brown at (0,0)
  _0: rectangle with size (3,1) with model Full with color orange at (4,8)
  _01: rectangle with size (2,2) with model Even Checkboard with color orange at (1,3)
  _0110: rectangle with size (2,2) with model Odd Checkboard with color yellow at (3,3)
  _011: rectangle with size (1,2) with model Full with color yellow at (2,6)
  + 28 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
0 0 
 with color yellow at (2,0)
  _01: point with color grey at (2,2)
  _011: point with color cyan at (1,1)
  + 2 delta pixels
diff: 
   (92.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _00: point with color brown at (0,0)
  _0: rectangle with size (3,1) with model Full with color orange at (4,8)
  _01: rectangle with size (2,2) with model Even Checkboard with color orange at (1,3)
  _0110: rectangle with size (2,2) with model Odd Checkboard with color yellow at (3,3)
  _011: rectangle with size (1,2) with model Full with color yellow at (2,6)
  + 28 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _00: point with color brown at (0,0)
  _0: rectangle with size (3,1) with model Full with color orange at (4,8)
  _01: rectangle with size (2,2) with model Even Checkboard with color orange at (1,3)
  _0110: rectangle with size (2,2) with model Even Checkboard with color red at (4,4)
  _011: rectangle with size (1,2) with model Full with color yellow at (2,6)
  + 28 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,9) and color black and layers
  _00: point with color brown at (0,0)
  _0: rectangle with size (2,2) with model Even Checkboard with color orange at (1,3)
  _01: rectangle with size (3,1) with model Full with color orange at (4,8)
  _0110: rectangle with size (2,2) with model Odd Checkboard with color yellow at (3,3)
  _011: rectangle with size (1,2) with model Full with color yellow at (2,6)
  + 28 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 5bd6f4ac.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _00: point with color pink at (0,4)
  _0: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color grey at (0,1)
  _01: rectangle with size (2,1) with model Full with color red at (0,0)
  _0110: rectangle with size (3,1) with model Full with color blue at (2,5)
  _011: rectangle with size (1,1) with model Full with color orange at (1,3)
  + 14 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
0 
 with color brown at (2,0)
  _01: point with color blue at (1,2)
  _011: point with color pink at (1,0)
  + 1 delta pixels
diff: 
   (54.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _00: point with color pink at (0,4)
  _0: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color grey at (0,1)
  _01: rectangle with size (2,1) with model Full with color red at (0,0)
  _0110: rectangle with size (3,1) with model Full with color blue at (2,5)
  _011: rectangle with size (1,1) with model Full with color orange at (1,3)
  + 14 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _00: point with color pink at (0,4)
  _0: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color grey at (0,1)
  _01: rectangle with size (2,1) with model Full with color red at (0,0)
  _0110: rectangle with size (1,1) with model Full with color orange at (1,3)
  _011: rectangle with size (3,1) with model Full with color blue at (2,5)
  + 14 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 5bd6f4ac.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _00: point with color green at (1,6)
  _0: rectangle with size (2,2) with model Odd Checkboard with color blue at (3,0)
  _01: rectangle with size (1,1) with model Full with color grey at (0,1)
  _0110: rectangle with size (1,1) with model Full with color cyan at (0,4)
  _011: rectangle with size (1,1) with model Full with color yellow at (0,8)
  + 12 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
0 
 with color green at (2,2)
  _01: point with color yellow at (0,2)
  _011: point with color green at (1,0)
diff: 
   (16.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _00: point with color green at (1,6)
  _0: rectangle with size (2,2) with model Odd Checkboard with color blue at (3,0)
  _01: rectangle with size (1,1) with model Full with color grey at (0,1)
  _0110: rectangle with size (1,1) with model Full with color cyan at (0,4)
  _011: rectangle with size (1,1) with model Full with color yellow at (0,8)
  + 12 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _00: point with color grey at (0,1)
  _0: rectangle with size (3,1) with model Full with color green at (1,6)
  _01: rectangle with size (2,2) with model Odd Checkboard with color blue at (3,0)
  _0110: rectangle with size (1,1) with model Full with color cyan at (0,4)
  _011: rectangle with size (1,1) with model Full with color yellow at (0,8)
  + 12 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,9) and color black and layers
  _00: point with color grey at (0,1)
  _0: rectangle with size (3,1) with model Full with color green at (1,6)
  _01: rectangle with size (2,2) with model Odd Checkboard with color blue at (3,0)
  _0110: rectangle with size (1,1) with model Full with color cyan at (0,4)
  _011: rectangle with size (1,1) with model Full with color red at (2,4)
  + 12 delta pixels
diff: 
! 3 wrong pixels (generated / expected)

TRAIN 5bd6f4ac.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _00: point with color brown at (0,1)
  _0: rectangle with size (3,4) with mask 
. . . 0 
. . 0 . 
0 0 . . 
 with color brown at (0,5)
  _01: rectangle with size (2,3) with mask 
0 0 . 
. . 0 
 with color orange at (4,0)
  _0110: rectangle with size (2,2) with model Full with color brown at (7,0)
  _011: rectangle with size (3,1) with model Full with color cyan at (1,5)
  + 30 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TEST 5bd6f4ac.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 13.9 sec (13.9 sec/task)
bits-train-error = 2561.3 bits (2561.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-265] Checking task 5c0a986e.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.086	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.246	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.185	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.124	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.091	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.059	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.053	OUT SPE ^.size = ^.size
0.050	IN  SPE ^.layer_0.shape.mask = 
0 0 
0 0 

0.047	IN  SPE ^.layer_01.shape.mask = 
0 0 
0 0 

0.044	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.042	IN  SPE ^.layer_0.shape.color = red
0.041	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.040	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.038	IN  SPE ^.layer_01.shape.color = blue
0.037	OUT SPE ^.layer_01.pos.j = '0
0.036	IN  SPE ^.color = black
0.036	OUT SPE ^.color = black
0.025	
0.025	IN  GEN ^.layer_01.shape.color = ?
0.025	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at (?,'0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (?,?)
  _01: 
0 0 
0 0 
 with color blue at (?,?)

DL input  with Mi: L = 71.1 + 1275.2 = 1346.3
DL output with Mo: L = 71.8 + 2854.1 = 2926.0
DL input+output M: L = 142.9 + 4129.4 = 4272.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at (?,'0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 0 
0 0 
 with color red at (?,?)
  _01: 
0 0 
0 0 
 with color ? at (?,?)

DL input  with Mi: L = 67.7 + 0.0 = 67.7
DL output with Mo: L = 71.8 + 2854.1 = 2926.0
DL input+output M: L = 139.5 + 2854.1 = 2993.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (6,4)
  _01: 
0 0 
0 0 
 with color blue at (2,2)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 . . 
0 0 . . 
. . 0 . 
. . . 0 
 with color red at (6,4)
  _01: rectangle with size (4,4) with mask 
0 . . . 
. 0 . . 
. . 0 0 
. . 0 0 
 with color blue at (0,0)
diff: 
   (70.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (6,4)
  _01: 
0 0 
0 0 
 with color blue at (2,2)
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color blue at (2,2)
  _01: 
0 0 
0 0 
 with color red at (6,4)
diff:   ^.layer_0.shape.color
! 10 wrong pixels (generated / expected)

TRAIN 5c0a986e.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (0,2)
  _01: 
0 0 
0 0 
 with color blue at (7,6)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (8,8) with mask 
0 0 . . . . . . 
0 0 . . . . . . 
. . 0 . . . . . 
. . . 0 . . . . 
. . . . 0 . . . 
. . . . . 0 . . 
. . . . . . 0 . 
. . . . . . . 0 
 with color red at (0,2)
  _01: rectangle with size (8,8) with mask 
0 . . . . . . . 
. 0 . . . . . . 
. . 0 . . . . . 
. . . 0 . . . . 
. . . . 0 . . . 
. . . . . 0 . . 
. . . . . . 0 0 
. . . . . . 0 0 
 with color blue at (1,0)
diff: 
   (129.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (0,2)
  _01: 
0 0 
0 0 
 with color blue at (7,6)
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color blue at (7,6)
  _01: 
0 0 
0 0 
 with color red at (0,2)
diff:   ^.layer_0.shape.color
! 19 wrong pixels (generated / expected)

TRAIN 5c0a986e.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (2,5)
  _01: 
0 0 
0 0 
 with color blue at (5,3)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 . . . 
0 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color red at (2,5)
  _01: rectangle with size (5,5) with mask 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 0 
. . . 0 0 
 with color blue at (2,0)
diff: 
   (85.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (2,5)
  _01: 
0 0 
0 0 
 with color blue at (5,3)
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color blue at (5,3)
  _01: 
0 0 
0 0 
 with color red at (2,5)
diff:   ^.layer_0.shape.color
! 14 wrong pixels (generated / expected)

TRAIN 5c0a986e.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (5,2)
  _01: 
0 0 
0 0 
 with color blue at (3,6)
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color blue at (3,6)
  _01: 
0 0 
0 0 
 with color red at (5,2)
diff:   ^.layer_0.shape.color
! 14 wrong pixels (generated / expected)

TEST 5c0a986e.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 20.6 sec (20.6 sec/task)
bits-train-error = 2854.1 bits (2854.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-264] Checking task 5c2c9af4.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 666848.8 = 666851.1
DL output with Mo: L = 2.3 + 666848.8 = 666851.1
DL input+output M: L = 4.6 + 1333697.5 = 1333702.2

# learning a model for train pairs
2.000	
1.007	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.345	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.245	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.171	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.104	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.068	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.040	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.033	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.031	OUT ADD ^.layer_01110 = point with color ? at (?,?)
0.030	OUT SPE ^.size = ^.size
0.029	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.028	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.027	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.027	OUT SPE ^.layer_01110 = ^.layer_01
0.026	OUT SPE ^.layer_01111.shape.mask.model = Full
0.022	
0.022	IN  DEL ^.layer_011
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01110: ^.layer_01
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 68.7 + 2554.7 = 2623.4
DL output with Mo: L = 186.9 + 14518.3 = 14705.3
DL input+output M: L = 255.6 + 17073.1 = 17328.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01110: ^.layer_01
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.6 + 0.0 = 50.6
DL output with Mo: L = 186.9 + 14518.3 = 14705.3
DL input+output M: L = 237.5 + 14518.3 = 14755.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (23,23) and color black and layers
  _0: point with color cyan at (2,11)
  _01: point with color cyan at (5,14)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (12,13) with mask 
0 . . . . . . . . . . . 0 
0 . . . . . . . . . . . 0 
0 . . . . . . . . . . . 0 
0 . . . . . . . . . . . 0 
0 . . . . . . . . . . . 0 
0 . . . . . . . . . . . 0 
0 . . . . . . . . . . . 0 
0 . . . . . . . . . . . 0 
0 . . . . . . . . . . . 0 
0 . . . . . . . . . . . 0 
0 . . . . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color cyan at (0,8)
  _01: rectangle with size (15,18) with mask 
0 . . . . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color cyan at (0,5)
  _011: rectangle with size (7,7) with model Border with color cyan at (2,11)
  _01110: 
8 
 at (5,14)
  _0111: rectangle with size (1,23) with model Full with color cyan at (20,0)
  _01111: rectangle with size (1,21) with model Full with color cyan at (17,2)
  _011111: rectangle with size (18,1) with model Full with color cyan at (0,2)
diff: 
   (507.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (23,23) and color black and layers
  _0: point with color cyan at (2,11)
  _01: point with color cyan at (5,14)
  + 1 delta pixels
diff: 
! 156 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (23,23) and color black and layers
  _0: point with color cyan at (2,11)
  _01: point with color cyan at (8,17)
  + 1 delta pixels
diff: 
! 156 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (23,23) and color black and layers
  _0: point with color cyan at (5,14)
  _01: point with color cyan at (2,11)
  + 1 delta pixels
diff: 
! 156 wrong pixels (generated / expected)

TRAIN 5c2c9af4.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (23,23) and color black and layers
  _0: point with color red at (11,13)
  _01: point with color red at (13,11)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (17,17) with model Border with color red at (5,3)
  _01: rectangle with size (20,21) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . 0 
 with color red at (3,1)
  _011: rectangle with size (13,13) with model Border with color red at (7,5)
  _01110: 
2 
 at (13,11)
  _0111: rectangle with size (9,9) with model Border with color red at (9,7)
  _01111: rectangle with size (1,23) with model Full with color red at (1,0)
  _011111: rectangle with size (5,5) with model Border with color red at (11,9)
diff: 
   (511.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (23,23) and color black and layers
  _0: point with color red at (11,13)
  _01: point with color red at (13,11)
  + 1 delta pixels
diff: 
! 244 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (23,23) and color black and layers
  _0: point with color red at (11,13)
  _01: point with color red at (15,9)
  + 1 delta pixels
diff: 
! 244 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (23,23) and color black and layers
  _0: point with color red at (13,11)
  _01: point with color red at (11,13)
  + 1 delta pixels
diff: 
! 244 wrong pixels (generated / expected)

TRAIN 5c2c9af4.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (23,23) and color black and layers
  _0: point with color green at (4,12)
  _01: point with color green at (8,8)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (17,17) with model Border with color green at (0,0)
  _01: rectangle with size (21,21) with mask 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color green at (0,0)
  _011: rectangle with size (1,9) with model Full with color green at (4,4)
  _01110: 
3 
 at (8,8)
  _0111: rectangle with size (1,9) with model Full with color green at (12,4)
  _01111: rectangle with size (9,1) with model Full with color green at (4,4)
  _011111: rectangle with size (9,1) with model Full with color green at (4,12)
diff: 
   (433.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (23,23) and color black and layers
  _0: point with color green at (4,12)
  _01: point with color green at (8,8)
  + 1 delta pixels
diff: 
! 138 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (23,23) and color black and layers
  _0: point with color green at (4,12)
  _01: point with color green at (12,4)
  + 1 delta pixels
diff: 
! 138 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (23,23) and color black and layers
  _0: point with color green at (8,8)
  _01: point with color green at (4,12)
  + 1 delta pixels
diff: 
! 138 wrong pixels (generated / expected)

TRAIN 5c2c9af4.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (28,28) and color black and layers
  _0: point with color yellow at (12,7)
  _01: point with color yellow at (18,13)
  + 1 delta pixels
diff: 
! 145 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (28,28) and color black and layers
  _0: point with color yellow at (12,7)
  _01: point with color yellow at (24,19)
  + 1 delta pixels
diff: 
! 145 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (28,28) and color black and layers
  _0: point with color yellow at (18,13)
  _01: point with color yellow at (12,7)
  + 1 delta pixels
diff: 
! 145 wrong pixels (generated / expected)

TEST 5c2c9af4.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 61.4 sec (61.4 sec/task)
bits-train-error = 14518.3 bits (14518.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-263] Checking task 5daaa586.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 346573.8 = 346576.2
DL output with Mo: L = 2.3 + 119592.6 = 119594.9
DL input+output M: L = 4.6 + 466166.4 = 466171.1

# learning a model for train pairs
2.000	
1.278	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.796	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.581	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.490	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.402	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.332	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.274	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.222	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.173	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.125	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.119	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.116	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.113	OUT SPE ^.layer_011.pos = '(0, 0)
0.111	OUT SPE ^.layer_01.pos = '(0, 1)
0.109	IN  ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.107	IN  ADD ^.layer_01111110 = point with color ? at (?,?)
0.106	OUT SPE ^.layer_0111.pos.j = center(^.layer_01111)
0.104	OUT SPE ^.size.i = area(^.layer_011111.shape) + 3
0.102	OUT SPE ^.layer_0111.pos.i = middle(^.layer_0111) / colorCount(^)
0.102	OUT SPE ^.layer_011.shape.mask.size.j = 1
0.101	OUT SPE ^.layer_0.pos.j = middle(^.layer_0111) + ^.layer_01111.pos.j - ^.layer_0.pos.j
0.100	OUT SPE ^.layer_01.shape.mask.size.i = ^.layer_01.shape.mask.size.j - ^.layer_01111110.pos.i - ^.layer_0.pos.i
0.099	OUT SPE ^.layer_0.shape.mask.model = Full
0.099	OUT SPE ^.layer_011.shape.mask.model = Full
0.098	IN  SPE ^.layer_01111.shape.mask.model = Full
0.098	OUT SPE ^.layer_0.pos.i = center(^.layer_01111110) - max(^.layer_0.shape.mask.size.j, ^.layer_011111.shape.mask.size.j)
0.097	IN  SPE ^.layer_01.shape.mask.model = Full
0.097	IN  SPE ^.layer_011.shape.mask.model = Full
0.097	IN  SPE ^.layer_0111.shape.mask.model = Full
0.097	IN  SPE ^.color = black
0.041	
0.041	IN  GEN ^.layer_0111.shape.mask.model = ?
0.041	IN  GEN ^.layer_011.shape.mask.model = ?
0.041	IN  GEN ^.layer_01.shape.mask.model = ?
0.041	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (area(^.layer_011111.shape) + 3,?) and color ? and layers
  _0: rectangle with size (?,?) with model Full with color ? at (center(^.layer_01111110) - max(^.layer_0.shape.mask.size.j, ^.layer_011111.shape.mask.size.j),middle(^.layer_0111) + ^.layer_01111.pos.j - ^.layer_0.pos.j)
  _01: rectangle with size (^.layer_01.shape.mask.size.j - ^.layer_01111110.pos.i - ^.layer_0.pos.i,?) with model ? with color ? at '(0, 1)
  _011: rectangle with size (?,1) with model Full with color ? at '(0, 0)
  _0111: rectangle with size (?,?) with model ? with color ? at (middle(^.layer_0111) / colorCount(^),center(^.layer_01111))
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111110: point with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 228.1 + 19365.8 = 19593.9
DL output with Mo: L = 424.2 + 4373.2 = 4797.5
DL input+output M: L = 652.4 + 23739.1 = 24391.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (area(^.layer_011111.shape) + 3,?) and color ? and layers
  _0: rectangle with size (?,?) with model Full with color ? at (center(^.layer_01111110) - max(^.layer_0.shape.mask.size.j, ^.layer_011111.shape.mask.size.j),middle(^.layer_0111) + ^.layer_01111.pos.j - ^.layer_0.pos.j)
  _01: rectangle with size (^.layer_01.shape.mask.size.j - ^.layer_01111110.pos.i - ^.layer_0.pos.i,?) with model ? with color ? at '(0, 1)
  _011: rectangle with size (?,1) with model Full with color ? at '(0, 0)
  _0111: rectangle with size (?,?) with model ? with color ? at (middle(^.layer_0111) / colorCount(^),center(^.layer_01111))
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111110: point with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 226.4 + 51.7 = 278.1
DL output with Mo: L = 424.2 + 4373.2 = 4797.5
DL input+output M: L = 650.7 + 4424.9 = 5075.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (22,22) and color black and layers
  _0: rectangle with size (22,1) with model Full with color green at (0,5)
  _01: rectangle with size (22,1) with model Full with color cyan at (0,16)
  _011: rectangle with size (1,22) with model Full with color blue at (1,0)
  _0111: rectangle with size (1,22) with model Full with color red at (15,0)
  _01111: rectangle with size (2,1) with model Full with color red at (4,0)
  _011111: rectangle with size (3,10) with mask 
0 . . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 
. . 0 . . . . . . . 
 with color red at (14,6)
  _01111110: point with color red at (0,9)
  _0111111: rectangle with size (2,2) with model Even Checkboard with color red at (6,18)
  + 10 delta pixels
diff: 
   (3.2 bits)
data: a background with size (15,12) and color black and layers
  _0: rectangle with size (15,1) with model Full with color cyan at (0,11)
  _01: rectangle with size (1,10) with model Full with color blue at (0,1)
  _011: rectangle with size (15,1) with model Full with color green at (0,0)
  _0111: rectangle with size (11,10) with mask 
. . . . . . . . . 0 
. . . . . . . . . 0 
. . . 0 . . . . . 0 
. . . 0 . . . . 0 0 
. . . 0 . . . . 0 0 
. . . 0 . . . . 0 0 
. . . 0 . . . . 0 0 
. 0 . 0 . . . . 0 0 
. 0 . 0 . . . . 0 0 
0 0 . 0 . . . . 0 0 
0 0 0 0 0 0 0 0 0 0 
 with color red at (4,1)
diff: 
   (201.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (22,22) and color black and layers
  _0: rectangle with size (22,1) with model Full with color green at (0,5)
  _01: rectangle with size (22,1) with model Full with color cyan at (0,16)
  _011: rectangle with size (1,22) with model Full with color blue at (1,0)
  _0111: rectangle with size (1,22) with model Full with color red at (15,0)
  _01111: rectangle with size (2,1) with model Full with color red at (4,0)
  _011111: rectangle with size (2,2) with model Even Checkboard with color red at (6,18)
  _01111110: point with color red at (0,9)
  _0111111: rectangle with size (3,10) with mask 
0 . . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 
. . 0 . . . . . . . 
 with color red at (14,6)
  + 10 delta pixels
diff: 
! size mismatch, 5x10 instead of 15x12
>> Trial 2
data: a background with size (22,22) and color black and layers
  _0: rectangle with size (22,1) with model Full with color green at (0,5)
  _01: rectangle with size (22,1) with model Full with color cyan at (0,16)
  _011: rectangle with size (1,22) with model Full with color blue at (1,0)
  _0111: rectangle with size (1,22) with model Full with color red at (15,0)
  _01111: rectangle with size (2,1) with model Full with color red at (4,0)
  _011111: rectangle with size (3,10) with mask 
0 . . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 
. . 0 . . . . . . . 
 with color red at (14,6)
  _01111110: point with color red at (0,9)
  _0111111: rectangle with size (2,2) with model Even Checkboard with color red at (6,18)
  + 10 delta pixels
diff: 
! size mismatch, 15x10 instead of 15x12

TRAIN 5daaa586.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (12,1) with model Full with color blue at (0,9)
  _01: rectangle with size (1,12) with model Full with color pink at (9,0)
  _011: rectangle with size (12,1) with model Full with color yellow at (0,2)
  _0111: rectangle with size (1,12) with model Full with color cyan at (2,0)
  _01111: rectangle with size (2,1) with model Full with color cyan at (5,6)
  _011111: rectangle with size (1,5) with model Full with color cyan at (8,7)
  _01111110: point with color cyan at (5,11)
  _0111111: rectangle with size (2,2) with model Even Checkboard with color cyan at (10,6)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (1,7) with model Full with color pink at (7,0)
  _01: rectangle with size (7,6) with mask 
0 0 0 0 0 0 
0 . . 0 0 . 
0 . . 0 0 . 
0 . . 0 0 . 
0 . . 0 0 . 
. . . . 0 . 
. . . . 0 . 
 with color cyan at (0,1)
  _011: rectangle with size (7,1) with model Full with color yellow at (0,0)
  _0111: rectangle with size (8,1) with model Full with color blue at (0,7)
diff: 
   (124.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (12,1) with model Full with color blue at (0,9)
  _01: rectangle with size (1,12) with model Full with color pink at (9,0)
  _011: rectangle with size (12,1) with model Full with color yellow at (0,2)
  _0111: rectangle with size (1,12) with model Full with color cyan at (2,0)
  _01111: rectangle with size (2,1) with model Full with color cyan at (5,6)
  _011111: rectangle with size (1,5) with model Full with color cyan at (8,7)
  _01111110: point with color cyan at (5,11)
  _0111111: rectangle with size (2,2) with model Even Checkboard with color cyan at (10,6)
  + 4 delta pixels
diff: 
! size mismatch, 8x10 instead of 8x8

TRAIN 5daaa586.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (14,15) and color black and layers
  _0: rectangle with size (14,3) with mask 
. 0 . 
. 0 . 
. 0 . 
. 0 . 
0 0 0 
. 0 . 
. 0 . 
. 0 . 
0 0 . 
0 0 . 
. 0 . 
0 0 . 
. 0 . 
. 0 . 
 with color yellow at (0,10)
  _01: rectangle with size (14,1) with model Full with color green at (0,3)
  _011: rectangle with size (1,15) with model Full with color red at (5,0)
  _0111: rectangle with size (1,15) with model Full with color cyan at (10,0)
  _01111: rectangle with size (4,1) with model Full with color yellow at (6,0)
  _011111: rectangle with size (3,2) with model Even Checkboard with color yellow at (1,5)
  _01111110: point with color yellow at (0,7)
  _0111111: rectangle with size (1,2) with model Full with color yellow at (6,4)
  + 11 delta pixels
diff: 
   (2.0 bits)
data: a background with size (6,9) and color yellow and layers
  _0: rectangle with size (1,7) with model Full with color cyan at (5,1)
  _01: rectangle with size (1,7) with model Full with color red at (0,1)
  _011: rectangle with size (6,1) with model Full with color green at (0,0)
  _0111: rectangle with size (3,7) with mask 
0 0 0 0 0 0 0 
0 0 0 0 . . . 
0 0 . . . . . 
 with color black at (2,1)
diff: 
   (111.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,15) and color black and layers
  _0: rectangle with size (14,3) with mask 
. 0 . 
. 0 . 
. 0 . 
. 0 . 
0 0 0 
. 0 . 
. 0 . 
. 0 . 
0 0 . 
0 0 . 
. 0 . 
0 0 . 
. 0 . 
. 0 . 
 with color yellow at (0,10)
  _01: rectangle with size (14,1) with model Full with color green at (0,3)
  _011: rectangle with size (1,15) with model Full with color red at (5,0)
  _0111: rectangle with size (1,15) with model Full with color cyan at (10,0)
  _01111: rectangle with size (4,1) with model Full with color yellow at (6,0)
  _011111: rectangle with size (3,2) with model Even Checkboard with color yellow at (1,5)
  _01111110: point with color yellow at (0,2)
  _0111111: rectangle with size (1,2) with model Full with color yellow at (6,4)
  + 11 delta pixels
diff: 
! size mismatch, 6x10 instead of 6x9
>> Trial 2
data: a background with size (14,15) and color black and layers
  _0: rectangle with size (14,3) with mask 
. 0 . 
. 0 . 
. 0 . 
. 0 . 
0 0 0 
. 0 . 
. 0 . 
. 0 . 
0 0 . 
0 0 . 
. 0 . 
0 0 . 
. 0 . 
. 0 . 
 with color yellow at (0,10)
  _01: rectangle with size (14,1) with model Full with color green at (0,3)
  _011: rectangle with size (1,15) with model Full with color red at (5,0)
  _0111: rectangle with size (1,15) with model Full with color cyan at (10,0)
  _01111: rectangle with size (4,1) with model Full with color yellow at (6,0)
  _011111: rectangle with size (3,2) with model Even Checkboard with color yellow at (1,5)
  _01111110: point with color yellow at (0,7)
  _0111111: rectangle with size (1,2) with model Full with color yellow at (6,4)
  + 11 delta pixels
diff: 
! size mismatch, 6x10 instead of 6x9

TRAIN 5daaa586.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,15) and color black and layers
  _0: rectangle with size (13,3) with mask 
0 . . 
0 . . 
0 . . 
0 . . 
0 . . 
0 . . 
0 . . 
0 . . 
0 . . 
0 0 . 
0 . 0 
0 . . 
0 . . 
 with color blue at (0,3)
  _01: rectangle with size (16,1) with model Full with color red at (0,12)
  _011: rectangle with size (1,15) with model Full with color cyan at (13,0)
  _0111: rectangle with size (1,15) with model Full with color green at (2,0)
  _01111: rectangle with size (3,1) with model Full with color blue at (3,0)
  _011111: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color blue at (14,3)
  _01111110: point with color blue at (0,5)
  _0111111: rectangle with size (2,2) with model Odd Checkboard with color blue at (7,9)
  + 12 delta pixels
diff: 
! size mismatch, 6x10 instead of 12x10
>> Trial 2
data: a background with size (16,15) and color black and layers
  _0: rectangle with size (13,3) with mask 
0 . . 
0 . . 
0 . . 
0 . . 
0 . . 
0 . . 
0 . . 
0 . . 
0 . . 
0 0 . 
0 . 0 
0 . . 
0 . . 
 with color blue at (0,3)
  _01: rectangle with size (1,15) with model Full with color cyan at (13,0)
  _011: rectangle with size (16,1) with model Full with color red at (0,12)
  _0111: rectangle with size (1,15) with model Full with color green at (2,0)
  _01111: rectangle with size (5,1) with model Full with color blue at (0,5)
  _011111: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color blue at (14,3)
  _01111110: point with color blue at (0,9)
  _0111111: rectangle with size (3,1) with model Full with color blue at (3,0)
  + 13 delta pixels
diff: 
! size mismatch, 6x10 instead of 12x10

TEST 5daaa586.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 41.6 sec (41.6 sec/task)
bits-train-error = 4373.2 bits (4373.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-262] Checking task 60b61512.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 64315.6 = 64317.9
DL output with Mo: L = 2.3 + 64315.6 = 64317.9
DL input+output M: L = 4.6 + 128631.2 = 128635.9

# learning a model for train pairs
2.000	
1.162	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.391	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.316	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.242	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.174	OUT ADD ^.layer_01 = ^.layer_0
0.119	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.075	OUT ADD ^.layer_00 = ^.layer_01
0.065	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.059	OUT SPE ^.size = ^.size
0.056	OUT SPE ^.layer_011.pos = '(2, 0)
0.052	OUT SPE ^.layer_0.pos = ^.layer_01.pos + (1, 0)
0.051	IN  SPE ^.layer_0.shape.color = yellow
0.049	IN  SPE ^.layer_01.shape.color = yellow
0.047	OUT SPE ^.layer_0.shape.color = orange
0.046	OUT SPE ^.layer_011.shape.color = orange
0.044	OUT SPE ^.layer_0.shape.mask.size.i = 2
0.043	OUT SPE ^.layer_0.shape.mask.model = Full
0.042	OUT SPE ^.layer_011.shape.mask.model = Full
0.041	OUT SPE ^.layer_011.shape.mask.size.i = area(^.layer_01.shape) / '3
0.041	OUT SPE ^.layer_011.shape.mask.size.j = area(^.layer_01.shape) / '3
0.040	IN  SPE ^.color = black
0.039	OUT SPE ^.color = black
0.012	
0.012	IN  GEN ^.layer_01.shape.color = ?
0.012	IN  GEN ^.layer_0.shape.color = ?
0.012	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_01
  _0: rectangle with size (2,?) with model Full with color orange at ^.layer_01.pos + (1, 0)
  _01: ^.layer_0
  _011: rectangle with size (area(^.layer_01.shape) / '3,area(^.layer_01.shape) / '3) with model Full with color orange at '(2, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color yellow at (?,?)
  _01: rectangle with size (?,?) with model ? with color yellow at (?,?)

DL input  with Mi: L = 77.0 + 1723.4 = 1800.4
DL output with Mo: L = 182.5 + 530.3 = 712.8
DL input+output M: L = 259.5 + 2253.7 = 2513.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_01
  _0: rectangle with size (2,?) with model Full with color orange at ^.layer_01.pos + (1, 0)
  _01: ^.layer_0
  _011: rectangle with size (area(^.layer_01.shape) / '3,area(^.layer_01.shape) / '3) with model Full with color orange at '(2, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 182.5 + 530.3 = 712.8
DL input+output M: L = 252.7 + 530.3 = 783.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
0 . 0 
. . 0 
 with color yellow at (1,0)
  _01: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
0 . 0 
 with color yellow at (4,5)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _00: 
4 4 . 
. 4 4 
4 . 4 
 at (4,5)
  _0: rectangle with size (2,2) with model Full with color orange at (5,5)
  _01: 
4 4 4 
4 . 4 
. . 4 
 at (1,0)
  _011: rectangle with size (2,2) with model Full with color orange at (2,0)
  + 1 delta pixels
diff: 
   (46.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
0 . 0 
. . 0 
 with color yellow at (1,0)
  _01: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
0 . 0 
 with color yellow at (4,5)
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
0 . 0 
 with color yellow at (4,5)
  _01: rectangle with size (3,3) with mask 
0 0 0 
0 . 0 
. . 0 
 with color yellow at (1,0)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
0 . 0 
 with color yellow at (4,5)
  _01: rectangle with size (1,3) with model Full with color yellow at (1,0)
  + 3 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 60b61512.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. 0 0 
0 0 0 
 with color yellow at (1,0)
  _01: rectangle with size (3,3) with mask 
0 0 0 
. 0 . 
. 0 . 
 with color yellow at (4,5)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _00: 
4 4 4 
. 4 . 
. 4 . 
 at (4,5)
  _0: rectangle with size (2,3) with model Full with color orange at (5,5)
  _01: 
4 4 4 
. 4 4 
4 4 4 
 at (1,0)
  _011: rectangle with size (1,1) with model Full with color orange at (2,0)
diff: 
   (6.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. 0 0 
0 0 0 
 with color yellow at (1,0)
  _01: rectangle with size (3,3) with mask 
0 0 0 
. 0 . 
. 0 . 
 with color yellow at (4,5)
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. 0 . 
. 0 . 
 with color yellow at (4,5)
  _01: rectangle with size (3,3) with mask 
0 0 0 
. 0 0 
0 0 0 
 with color yellow at (1,0)
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (3,3) with model Full with color yellow at (1,0)
  _01: rectangle with size (3,3) with mask 
0 0 0 
. 0 . 
. 0 . 
 with color yellow at (4,5)
  + 1 delta pixels
diff: 
! 3 wrong pixels (generated / expected)

TRAIN 60b61512.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
0 . . 
 with color yellow at (1,2)
  _01: rectangle with size (3,3) with mask 
0 . . 
0 0 0 
. 0 . 
 with color yellow at (6,5)
diff: 
! 9 wrong pixels (generated / expected)

TEST 60b61512.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 11.1 sec (11.1 sec/task)
bits-train-error = 530.3 bits (530.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-261] Checking task 6150a2bd.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 7023.2 = 7025.5
DL output with Mo: L = 2.3 + 7023.2 = 7025.5
DL input+output M: L = 4.6 + 14046.4 = 14051.0

# learning a model for train pairs
2.000	
1.002	OUT SPE ^ = applySym(rotate180, ^)
0.575	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.392	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.328	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.261	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.253	IN  SPE ^.layer_0.shape.mask.model = Full
0.246	IN  SPE ^.color = black
0.013	
0.002	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
applySym(rotate180, ^)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 79.1 + 1639.6 = 1718.8
DL output with Mo: L = 12.3 + 0.0 = 12.3
DL input+output M: L = 91.5 + 1639.6 = 1731.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
applySym(rotate180, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 12.3 + 0.0 = 12.3
DL input+output M: L = 14.6 + 0.0 = 14.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
3 3 8 
3 7#0 
5#0 0 

diff: 
   (0.0 bits)
data: 
0 0 5#
0 7#3 
8 3 3 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 3 8 
3 7#0 
5#0 0 

diff: 
correct output grid

TRAIN 6150a2bd.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
5#5#2 
1 0 0 
0 0 0 

diff: 
   (0.0 bits)
data: 
0 0 0 
0 0 1 
2 5#5#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#5#2 
1 0 0 
0 0 0 

diff: 
correct output grid

TRAIN 6150a2bd.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
6 3 5#
6 8 0 
4 0 0 

diff: 
correct output grid

TEST 6150a2bd.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.2 sec (1.2 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-260] Checking task 623ea044.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 203237.0 = 203239.3
DL output with Mo: L = 2.3 + 203237.0 = 203239.3
DL input+output M: L = 4.6 + 406474.0 = 406478.6

# learning a model for train pairs
2.000	
1.010	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.119	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.031	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.027	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.024	OUT SPE ^.size = ^.size
0.023	OUT SPE ^.layer_0.shape.mask.size.i = ^.size.i
0.022	OUT SPE ^.layer_0.pos.i = '0
0.021	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.020	OUT SPE ^.layer_0.pos.j = ^.layer_0.pos.i - 3
0.020	IN  SPE ^.color = black
0.020	OUT SPE ^.color = black
0.014	
0.014	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (^.size.i,?) with model ? with color ^.layer_0.shape.color at ('0,^.layer_0.pos.i - 3)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.3 + 1144.8 = 1177.1
DL output with Mo: L = 72.7 + 2734.0 = 2806.7
DL input+output M: L = 105.0 + 3878.8 = 3983.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (^.size.i,?) with model ? with color ^.layer_0.shape.color at ('0,^.layer_0.pos.i - 3)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 0.0 = 32.2
DL output with Mo: L = 72.7 + 2734.0 = 2806.7
DL input+output M: L = 104.9 + 2734.0 = 2838.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: point with color red at (3,3)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (15,15) with mask 
0 . . . . . 0 . . . . . . . . 
. 0 . . . 0 . . . . . . . . . 
. . 0 . 0 . . . . . . . . . . 
. . . 0 . . . . . . . . . . . 
. . 0 . 0 . . . . . . . . . . 
. 0 . . . 0 . . . . . . . . . 
0 . . . . . 0 . . . . . . . . 
. . . . . . . 0 . . . . . . . 
. . . . . . . . 0 . . . . . . 
. . . . . . . . . 0 . . . . . 
. . . . . . . . . . 0 . . . . 
. . . . . . . . . . . 0 . . . 
. . . . . . . . . . . . 0 . . 
. . . . . . . . . . . . . 0 . 
. . . . . . . . . . . . . . 0 
 with color red at (0,0)
diff: 
   (116.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: point with color red at (3,3)
diff: 
! 43 wrong pixels (generated / expected)

TRAIN 623ea044.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: point with color orange at (5,11)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (15,13) with mask 
. . . . 0 . . . . . . . . 
. . . . . 0 . . . . . . . 
. . . . . . 0 . . . . . 0 
. . . . . . . 0 . . . 0 . 
. . . . . . . . 0 . 0 . . 
. . . . . . . . . 0 . . . 
. . . . . . . . 0 . 0 . . 
. . . . . . . 0 . . . 0 . 
. . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . . . 
. . . . 0 . . . . . . . . 
. . . 0 . . . . . . . . . 
. . 0 . . . . . . . . . . 
. 0 . . . . . . . . . . . 
0 . . . . . . . . . . . . 
 with color orange at (0,2)
diff: 
   (111.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: point with color orange at (5,11)
diff: 
! 47 wrong pixels (generated / expected)

TRAIN 623ea044.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (7,7) and color black and layers
  _0: point with color cyan at (3,2)
diff: 
   (0.0 bits)
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (7,6) with mask 
. . . . . 0 
0 . . . 0 . 
. 0 . 0 . . 
. . 0 . . . 
. 0 . 0 . . 
0 . . . 0 . 
. . . . . 0 
 with color cyan at (0,0)
diff: 
   (46.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: point with color cyan at (3,2)
diff: 
! 17 wrong pixels (generated / expected)

TRAIN 623ea044.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,17) and color black and layers
  _0: point with color pink at (7,12)
diff: 
! 53 wrong pixels (generated / expected)

TEST 623ea044.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.2 sec (3.2 sec/task)
bits-train-error = 2734.0 bits (2734.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-259] Checking task 62c24649.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 10534.8 = 10537.1
DL output with Mo: L = 2.3 + 42126.8 = 42129.1
DL input+output M: L = 4.6 + 52661.6 = 52666.3

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = unfoldSym( [ id flipWidth ] [ flipHeight rotate180 ], ^)
0.655	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.517	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.386	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.313	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.297	IN  SPE ^.layer_011.shape.color = blue
0.281	IN  SPE ^.layer_0.shape.color = green
0.266	IN  SPE ^.layer_01.shape.color = red
0.258	IN  SPE ^.layer_011.shape.mask.model = Full
0.251	IN  SPE ^.color = black
0.011	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
unfoldSym( [ id flipWidth ] [ flipHeight rotate180 ], ^)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color green at (?,?)
  _01: rectangle with size (?,?) with model ? with color red at (?,?)
  _011: rectangle with size (?,?) with model Full with color blue at (?,?)

DL input  with Mi: L = 108.7 + 2529.2 = 2637.9
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 120.0 + 2529.2 = 2649.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
unfoldSym( [ id flipWidth ] [ flipHeight rotate180 ], ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 13.6 + 0.0 = 13.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
3 3 3 
0 2 2 
1 1 0 

diff: 
   (0.0 bits)
data: 
3 3 3 3 3 3 
0 2 2 2 2 0 
1 1 0 0 1 1 
1 1 0 0 1 1 
0 2 2 2 2 0 
3 3 3 3 3 3 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 3 3 
0 2 2 
1 1 0 

diff: 
correct output grid

TRAIN 62c24649.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
3 3 1 
1 3 0 
0 2 2 

diff: 
   (0.0 bits)
data: 
3 3 1 1 3 3 
1 3 0 0 3 1 
0 2 2 2 2 0 
0 2 2 2 2 0 
1 3 0 0 3 1 
3 3 1 1 3 3 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 3 1 
1 3 0 
0 2 2 

diff: 
correct output grid

TRAIN 62c24649.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
2 1 0 
0 2 3 
0 3 0 

diff: 
   (0.0 bits)
data: 
2 1 0 0 1 2 
0 2 3 3 2 0 
0 3 0 0 3 0 
0 3 0 0 3 0 
0 2 3 3 2 0 
2 1 0 0 1 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 1 0 
0 2 3 
0 3 0 

diff: 
correct output grid

TRAIN 62c24649.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 0 
0 3 2 
3 3 0 

diff: 
correct output grid

TEST 62c24649.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.4 sec (1.4 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-258] Checking task 63613498.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.262	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.524	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.467	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.398	OUT ADD ^.layer_0 = ^.layer_0
0.364	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.321	OUT ADD ^.layer_01 = ^.layer_01
0.290	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.250	OUT ADD ^.layer_011 = ^.layer_011
0.219	IN  ADD ^.layer_0110 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.189	IN  ADD ^.layer_01101 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.158	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.127	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.111	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.094	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.086	OUT SPE ^.layer_01111 = coloring(^.layer_0111, majorityColor(^))
0.081	OUT SPE ^.size = ^.size
0.076	OUT SPE ^.layer_0111.shape.mask = ^.layer_01101.shape.mask
0.072	OUT SPE ^.layer_011111.shape.mask = ^.layer_0110.shape.mask
0.069	OUT SPE ^.layer_011111.pos = ^.layer_0110.pos
0.066	OUT SPE ^.layer_0111.pos = ^.layer_01101.pos
0.065	IN  SPE ^.layer_0.shape.color = grey
0.064	OUT SPE ^.layer_0111 = ^.layer_01101
0.063	IN  SPE ^.color = black
0.062	OUT SPE ^.color = black
0.004	
0.004	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_01
  _011: ^.layer_011
  _0111: ^.layer_01101
  _01111: coloring(^.layer_0111, majorityColor(^))
  _011111: ^.layer_0110.shape.mask with color ? at ^.layer_0110.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01101: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 184.3 + 6997.9 = 7182.2
DL output with Mo: L = 108.4 + 168.9 = 277.3
DL input+output M: L = 292.8 + 7166.8 = 7459.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_01
  _011: ^.layer_011
  _0111: ^.layer_01101
  _01111: coloring(^.layer_0111, majorityColor(^))
  _011111: ^.layer_0110.shape.mask with color ? at ^.layer_0110.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01101: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 184.2 + 31.7 = 215.9
DL output with Mo: L = 108.4 + 168.9 = 277.3
DL input+output M: L = 292.6 + 200.6 = 493.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . . 0 
. . . 0 
0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
. . 0 
 with color blue at (0,0)
  _0110: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
. . 0 
 with color pink at (5,5)
  _01101: rectangle with size (3,3) with model +-cross with color orange at (0,6)
  _011: rectangle with size (2,4) with mask 
. 0 . . 
0 0 0 0 
 with color cyan at (8,3)
  _0111: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color orange at (6,0)
diff: 
   (3.2 bits)
data: a background with size (10,10) and color black and layers
  _0: 
. . . 5#
. . . 5#
. . . 5#
5#5#5#5#
 at (0,0)
  _01: 
1 1 . 
. 1 1 
. . 1 
 at (0,0)
  _011: 
. 8 . . 
8 8 8 8 
 at (8,3)
  _0111: 
. 7#. 
7#7#7#
. 7#. 
 at (0,6)
  _01111: 
7#7#7#
. . 7#
 at (6,0)
  _011111: 
0 0 . 
. 0 0 
. . 0 
 with color grey at (5,5)
diff: 
   (5.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . . 0 
. . . 0 
0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
. . 0 
 with color blue at (0,0)
  _0110: rectangle with size (3,3) with model +-cross with color orange at (0,6)
  _01101: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
. . 0 
 with color pink at (5,5)
  _011: rectangle with size (2,4) with mask 
. 0 . . 
0 0 0 0 
 with color cyan at (8,3)
  _0111: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color orange at (6,0)
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . . 0 
. . . 0 
0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
. . 0 
 with color blue at (0,0)
  _0110: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
. . 0 
 with color pink at (5,5)
  _01101: rectangle with size (3,3) with model +-cross with color orange at (0,6)
  _011: rectangle with size (2,4) with mask 
. 0 . . 
0 0 0 0 
 with color cyan at (8,3)
  _0111: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color orange at (6,0)
diff: 
! 5 wrong pixels (generated / expected)

TRAIN 63613498.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . . 0 
. . . 0 
0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (2,2) with model Full with color cyan at (8,0)
  _0110: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color green at (0,0)
  _01101: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color yellow at (2,6)
  _011: rectangle with size (1,3) with model Full with color orange at (6,2)
  _0111: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color brown at (7,7)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
. . . 5#
. . . 5#
. . . 5#
5#5#5#5#
 at (0,0)
  _01: 
8 8 
8 8 
 at (8,0)
  _011: 
7#7#7#
 at (6,2)
  _0111: 
4 4 
4 . 
 at (2,6)
  _01111: 
. 5#
5#5#
 at (7,7)
  _011111: 
. 0 
0 0 
 with color green at (0,0)
diff: 
   (5.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . . 0 
. . . 0 
0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (2,2) with model Full with color cyan at (8,0)
  _0110: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color green at (0,0)
  _01101: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color yellow at (2,6)
  _011: rectangle with size (1,3) with model Full with color orange at (6,2)
  _0111: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color brown at (7,7)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . . 0 
. . . 0 
0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (2,2) with model Full with color cyan at (8,0)
  _0110: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color green at (0,0)
  _01101: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color yellow at (2,6)
  _011: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color brown at (7,7)
  _0111: rectangle with size (1,3) with model Full with color orange at (6,2)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . . 0 
. . . 0 
0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color green at (0,0)
  _0110: rectangle with size (2,2) with model Full with color cyan at (8,0)
  _01101: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color yellow at (2,6)
  _011: rectangle with size (1,3) with model Full with color orange at (6,2)
  _0111: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color brown at (7,7)
diff: 
! 4 wrong pixels (generated / expected)

TRAIN 63613498.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,1) with model Full with color grey at (0,3)
  _01: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color yellow at (0,0)
  _0110: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color blue at (0,6)
  _01101: rectangle with size (3,2) with mask 
0 . 
0 0 
0 . 
 with color green at (4,6)
  _011: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color pink at (7,1)
  _0111: rectangle with size (1,4) with model Full with color grey at (3,0)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
5#
5#
5#
5#
 at (0,3)
  _01: 
. 4 . 
4 4 4 
 at (0,0)
  _011: 
6 6 6 
. 6 . 
 at (7,1)
  _0111: 
3 . 
3 3 
3 . 
 at (4,6)
  _01111: 
5#5#5#5#
 at (3,0)
  _011111: 
. 0 . 
0 0 0 
 with color grey at (0,6)
diff: 
   (5.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,1) with model Full with color grey at (0,3)
  _01: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color yellow at (0,0)
  _0110: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color blue at (0,6)
  _01101: rectangle with size (3,2) with mask 
0 . 
0 0 
0 . 
 with color green at (4,6)
  _011: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color pink at (7,1)
  _0111: rectangle with size (1,4) with model Full with color grey at (3,0)
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,1) with model Full with color grey at (0,3)
  _01: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color yellow at (0,0)
  _0110: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color blue at (0,6)
  _01101: rectangle with size (3,2) with mask 
0 . 
0 0 
0 . 
 with color green at (4,6)
  _011: rectangle with size (1,4) with model Full with color grey at (3,0)
  _0111: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color pink at (7,1)
diff: 
! 8 wrong pixels (generated / expected)

TRAIN 63613498.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . . 0 
. . . 0 
0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (3,2) with mask 
0 . 
0 0 
0 . 
 with color pink at (0,7)
  _0110: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color red at (1,0)
  _01101: rectangle with size (3,2) with mask 
0 . 
0 . 
0 0 
 with color green at (3,5)
  _011: rectangle with size (2,3) with mask 
0 0 0 
0 . . 
 with color cyan at (6,0)
  _0111: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color orange at (8,4)
  + 3 delta pixels
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . . 0 
. . . 0 
0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (3,2) with mask 
0 . 
0 0 
0 . 
 with color pink at (0,7)
  _0110: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color red at (1,0)
  _01101: rectangle with size (3,2) with mask 
0 . 
0 . 
0 0 
 with color green at (3,5)
  _011: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color orange at (8,4)
  _0111: rectangle with size (2,3) with mask 
0 0 0 
0 . . 
 with color cyan at (6,0)
  + 3 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . . 0 
. . . 0 
0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (3,2) with mask 
0 . 
0 0 
0 . 
 with color pink at (0,7)
  _0110: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color red at (1,0)
  _01101: rectangle with size (3,2) with mask 
0 . 
0 . 
0 0 
 with color green at (3,5)
  _011: rectangle with size (2,3) with mask 
0 0 0 
0 . . 
 with color cyan at (6,0)
  _0111: rectangle with size (3,1) with model Full with color yellow at (6,8)
  + 4 delta pixels
diff: 
! 11 wrong pixels (generated / expected)

TEST 63613498.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 14.7 sec (14.7 sec/task)
bits-train-error = 168.9 bits (168.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-257] Checking task 6430c8c4.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 56169.1 = 56171.4
DL output with Mo: L = 2.3 + 24798.7 = 24801.0
DL input+output M: L = 4.6 + 80967.8 = 80972.4

# learning a model for train pairs
2.000	
1.303	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.859	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.661	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.521	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.392	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.315	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.289	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.266	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.256	IN  SPE ^.layer_011.shape.mask = 
0 0 0 0 

0.247	OUT SPE ^.layer_0.shape.color = green
0.238	OUT SPE ^.layer_01.shape.color = green
0.231	OUT SPE ^.layer_0.pos.i = '0
0.226	OUT SPE ^.layer_0.pos.j = ^.layer_01.pos.i / '3
0.221	OUT SPE ^.layer_01.pos.i = bottom(^.layer_0) / '3
0.217	OUT SPE ^.layer_01.shape.mask.model = Full
0.213	OUT SPE ^.color = black
0.209	IN  SPE ^.layer_011.shape.color = yellow
0.207	IN  SPE ^.color = black
0.083	
0.083	IN  GEN ^.layer_011.shape.color = ?
0.083	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color green at ('0,^.layer_01.pos.i / '3)
  _01: rectangle with size (?,?) with model Full with color green at (bottom(^.layer_0) / '3,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: 
0 0 0 0 
 with color yellow at (?,?)

DL input  with Mi: L = 98.6 + 7002.5 = 7101.1
DL output with Mo: L = 149.3 + 1845.6 = 1994.9
DL input+output M: L = 247.9 + 8848.1 = 9096.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color green at ('0,^.layer_01.pos.i / '3)
  _01: rectangle with size (?,?) with model Full with color green at (bottom(^.layer_0) / '3,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: 
0 0 0 0 
 with color ? at (?,?)

DL input  with Mi: L = 95.2 + 40.0 = 135.2
DL output with Mo: L = 149.3 + 1845.6 = 1994.9
DL input+output M: L = 244.4 + 1885.6 = 2130.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 . 0 
. 0 0 . 
. 0 0 0 
. 0 0 . 
 with color orange at (0,0)
  _01: rectangle with size (3,4) with mask 
. 0 . 0 
0 0 0 . 
0 . . 0 
 with color red at (6,0)
  _011: 
0 0 0 0 
 with color yellow at (4,0)
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (1,1) with model Full with color green at (0,2)
  _01: rectangle with size (1,1) with model Full with color green at (1,0)
diff: 
   (20.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 . 0 
. 0 0 . 
. 0 0 0 
. 0 0 . 
 with color orange at (0,0)
  _01: rectangle with size (3,4) with mask 
. 0 . 0 
0 0 0 . 
0 . . 0 
 with color red at (6,0)
  _011: 
0 0 0 0 
 with color yellow at (4,0)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (3,4) with mask 
. 0 . 0 
0 0 0 . 
0 . . 0 
 with color red at (6,0)
  _01: rectangle with size (4,4) with mask 
0 0 . 0 
. 0 0 . 
. 0 0 0 
. 0 0 . 
 with color orange at (0,0)
  _011: 
0 0 0 0 
 with color yellow at (4,0)
diff: 
! size mismatch, 3x4 instead of 4x4

TRAIN 6430c8c4.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . 0 . 
. 0 . 0 
. 0 0 . 
. . 0 . 
 with color red at (5,0)
  _01: rectangle with size (4,4) with mask 
. . 0 0 
. . 0 0 
. 0 0 . 
0 0 . . 
 with color orange at (0,0)
  _011: 
0 0 0 0 
 with color yellow at (4,0)
diff: 
   (2.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (3,2) with mask 
. 0 
0 . 
0 . 
 with color green at (0,0)
  _01: rectangle with size (2,1) with model Full with color green at (2,3)
diff: 
   (32.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . 0 0 
. . 0 0 
. 0 0 . 
0 0 . . 
 with color orange at (0,0)
  _01: rectangle with size (4,4) with mask 
0 . 0 . 
. 0 . 0 
. 0 0 . 
. . 0 . 
 with color red at (5,0)
  _011: 
0 0 0 0 
 with color yellow at (4,0)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . 0 . 
. 0 . 0 
. 0 0 . 
. . 0 . 
 with color red at (5,0)
  _01: rectangle with size (4,4) with mask 
. . 0 0 
. . 0 0 
. 0 0 . 
0 0 . . 
 with color orange at (0,0)
  _011: 
0 0 0 0 
 with color yellow at (4,0)
diff: 
! 7 wrong pixels (generated / expected)

TRAIN 6430c8c4.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . 0 . 
. 0 0 0 
0 0 . . 
. 0 . . 
 with color red at (5,0)
  _01: rectangle with size (4,3) with mask 
. . 0 
0 0 0 
0 . . 
0 0 0 
 with color orange at (0,1)
  _011: 
0 0 0 0 
 with color yellow at (4,0)
  + 1 delta pixels
diff: 
   (2.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color green at (0,0)
  _01: rectangle with size (1,2) with model Full with color green at (2,2)
  + 1 delta pixels
diff: 
   (67.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,3) with mask 
. . 0 
0 0 0 
0 . . 
0 0 0 
 with color orange at (0,1)
  _01: rectangle with size (4,4) with mask 
. . 0 . 
. 0 0 0 
0 0 . . 
. 0 . . 
 with color red at (5,0)
  _011: 
0 0 0 0 
 with color yellow at (4,0)
  + 1 delta pixels
diff: 
! size mismatch, 4x3 instead of 4x4
>> Trial 2
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . 0 . 
. 0 0 0 
0 0 . . 
. 0 . . 
 with color red at (5,0)
  _01: rectangle with size (4,3) with mask 
. . 0 
0 0 0 
0 . . 
0 0 0 
 with color orange at (0,1)
  _011: 
0 0 0 0 
 with color yellow at (4,0)
  + 1 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,3) with mask 
. . 0 
0 0 0 
0 . . 
0 0 0 
 with color orange at (0,1)
  _01: rectangle with size (1,3) with model Full with color red at (6,1)
  _011: 
0 0 0 0 
 with color yellow at (4,0)
  + 5 delta pixels
diff: 
! size mismatch, 4x3 instead of 4x4

TRAIN 6430c8c4.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . 0 . 
. . 0 0 
0 . 0 0 
0 0 . . 
 with color orange at (0,0)
  _01: rectangle with size (1,2) with model Full with color red at (5,2)
  _011: 
0 0 0 0 
 with color yellow at (4,0)
  + 5 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (3,1) with model Full with color green at (0,1)
  _01: rectangle with size (1,2) with model Full with color green at (1,0)
  + 1 delta pixels
diff: 
   (64.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . 0 . 
. . 0 0 
0 . 0 0 
0 0 . . 
 with color orange at (0,0)
  _01: rectangle with size (1,2) with model Full with color red at (5,2)
  _011: 
0 0 0 0 
 with color yellow at (4,0)
  + 5 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (5,2)
  _01: rectangle with size (4,4) with mask 
. . 0 . 
. . 0 0 
0 . 0 0 
0 0 . . 
 with color orange at (0,0)
  _011: 
0 0 0 0 
 with color yellow at (4,0)
  + 5 delta pixels
diff: 
! size mismatch, 1x2 instead of 4x4

TRAIN 6430c8c4.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 0 
. 0 0 0 
0 . . . 
0 . . . 
 with color orange at (0,0)
  _01: rectangle with size (1,3) with model Full with color red at (5,1)
  _011: 
0 0 0 0 
 with color yellow at (4,0)
  + 5 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TEST 6430c8c4.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 8.0 sec (8.0 sec/task)
bits-train-error = 1845.6 bits (1845.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-256] Checking task 6455b5f5.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 323248.7 = 323251.0
DL output with Mo: L = 2.3 + 323248.7 = 323251.0
DL input+output M: L = 4.6 + 646497.4 = 646502.0

# learning a model for train pairs
2.000	
1.216	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.810	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.481	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.291	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.078	OUT ADD ^.layer_01 = ^.layer_0
0.048	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.045	OUT SPE ^.size = ^.size
0.044	OUT SPE ^.layer_0.pos.i = ^.layer_0.pos.i
0.044	IN  SPE ^.layer_0.shape.color = red
0.043	OUT SPE ^.layer_0.shape.mask.model = Full
0.043	OUT SPE ^.layer_011.shape.mask.model = Full
0.043	IN  SPE ^.color = black
0.042	OUT SPE ^.color = black
0.017	
0.017	IN  GEN ^.layer_0.shape.color = ?
0.017	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (^.layer_0.pos.i,?)
  _01: ^.layer_0
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at (?,?)

DL input  with Mi: L = 45.4 + 8292.1 = 8337.6
DL output with Mo: L = 77.3 + 5308.0 = 5385.3
DL input+output M: L = 122.7 + 13600.2 = 13722.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (^.layer_0.pos.i,?)
  _01: ^.layer_0
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 77.3 + 5308.0 = 5385.3
DL input+output M: L = 119.3 + 5308.0 = 5427.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (18,13) and color black and layers
  _0: rectangle with size (18,13) with mask 
. 0 . . . . 0 . . . . . . 
0 0 . . . . 0 . . . . . . 
. 0 . . . . 0 . . . . . . 
. 0 . . . . 0 0 0 0 0 0 0 
. 0 . . . . 0 . . 0 . . . 
. 0 0 0 0 0 0 . . 0 . . . 
. 0 . . . . 0 . . 0 . . . 
. 0 . . . . 0 0 0 0 0 0 0 
. 0 . . . . 0 . . . . 0 . 
0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . . . . . . . . . 
. . 0 . . . . . . . . . . 
. . 0 . . . . . . . . . . 
. . 0 . . . . . . . . . . 
. . 0 . . . . . . . . . . 
. . 0 . . . . . . . . . . 
. . 0 . . . . . . . . . . 
. . 0 . . . . . . . . . . 
 with color red at (0,0)
diff: 
   (0.0 bits)
data: a background with size (18,13) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (0,0)
  _01: 
. 2 . . . . 2 . . . . . . 
2 2 . . . . 2 . . . . . . 
. 2 . . . . 2 . . . . . . 
. 2 . . . . 2 2 2 2 2 2 2 
. 2 . . . . 2 . . 2 . . . 
. 2 2 2 2 2 2 . . 2 . . . 
. 2 . . . . 2 . . 2 . . . 
. 2 . . . . 2 2 2 2 2 2 2 
. 2 . . . . 2 . . . . 2 . 
2 2 2 2 2 2 2 2 2 2 2 2 2 
. . 2 . . . . . . . . . . 
. . 2 . . . . . . . . . . 
. . 2 . . . . . . . . . . 
. . 2 . . . . . . . . . . 
. . 2 . . . . . . . . . . 
. . 2 . . . . . . . . . . 
. . 2 . . . . . . . . . . 
. . 2 . . . . . . . . . . 
 at (0,0)
  _011: rectangle with size (8,10) with model Full with color blue at (10,3)
  + 1 delta pixels
diff: 
   (98.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,13) and color black and layers
  _0: rectangle with size (18,13) with mask 
. 0 . . . . 0 . . . . . . 
0 0 . . . . 0 . . . . . . 
. 0 . . . . 0 . . . . . . 
. 0 . . . . 0 0 0 0 0 0 0 
. 0 . . . . 0 . . 0 . . . 
. 0 0 0 0 0 0 . . 0 . . . 
. 0 . . . . 0 . . 0 . . . 
. 0 . . . . 0 0 0 0 0 0 0 
. 0 . . . . 0 . . . . 0 . 
0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . . . . . . . . . 
. . 0 . . . . . . . . . . 
. . 0 . . . . . . . . . . 
. . 0 . . . . . . . . . . 
. . 0 . . . . . . . . . . 
. . 0 . . . . . . . . . . 
. . 0 . . . . . . . . . . 
. . 0 . . . . . . . . . . 
 with color red at (0,0)
diff: 
! 85 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (18,13) and color black and layers
  _0: rectangle with size (1,13) with model Full with color red at (9,0)
  + 47 delta pixels
diff: 
! 133 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (18,13) and color black and layers
  _0: rectangle with size (10,1) with model Full with color red at (0,1)
  + 50 delta pixels
diff: 
! 134 wrong pixels (generated / expected)

TRAIN 6455b5f5.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (11,13) and color black and layers
  _0: rectangle with size (11,13) with mask 
. . . . 0 . . . . . . . . 
. . . . 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . . . . . 
. . . . 0 . . . . . . . . 
. . . . 0 . . . . . . . . 
0 0 0 0 0 . . . . . . . . 
. . . . 0 . . . . . . . . 
. . . . 0 . . . . . . . . 
. . . . 0 . . . . . . . . 
. . . . 0 . . . . . . . . 
. . . . 0 . . . . . . . . 
 with color red at (0,0)
diff: 
   (0.0 bits)
data: a background with size (11,13) and color black and layers
  _0: rectangle with size (1,8) with model Full with color cyan at (0,5)
  _01: 
. . . . 2 . . . . . . . . 
. . . . 2 2 2 2 2 2 2 2 2 
. . . . 2 . . . . . . . . 
. . . . 2 . . . . . . . . 
. . . . 2 . . . . . . . . 
2 2 2 2 2 . . . . . . . . 
. . . . 2 . . . . . . . . 
. . . . 2 . . . . . . . . 
. . . . 2 . . . . . . . . 
. . . . 2 . . . . . . . . 
. . . . 2 . . . . . . . . 
 at (0,0)
  _011: rectangle with size (9,8) with model Full with color blue at (2,5)
diff: 
   (60.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,13) and color black and layers
  _0: rectangle with size (11,13) with mask 
. . . . 0 . . . . . . . . 
. . . . 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . . . . . 
. . . . 0 . . . . . . . . 
. . . . 0 . . . . . . . . 
0 0 0 0 0 . . . . . . . . 
. . . . 0 . . . . . . . . 
. . . . 0 . . . . . . . . 
. . . . 0 . . . . . . . . 
. . . . 0 . . . . . . . . 
. . . . 0 . . . . . . . . 
 with color red at (0,0)
diff: 
! 84 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,13) and color black and layers
  _0: rectangle with size (11,1) with model Full with color red at (0,4)
  + 12 delta pixels
diff: 
! 96 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (11,13) and color black and layers
  _0: rectangle with size (1,9) with model Full with color red at (1,4)
  + 14 delta pixels
diff: 
! 100 wrong pixels (generated / expected)

TRAIN 6455b5f5.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (11,16) and color black and layers
  _0: rectangle with size (11,16) with mask 
. . . 0 . . . 0 . . . . . . . . 
. . . 0 . . . 0 . . . . . . . . 
. . . 0 0 0 0 0 . . . . . . . . 
. . . 0 . . . 0 . . . . . . . . 
. . . 0 . . . 0 . . . . . . . . 
0 0 0 0 0 0 0 0 . . . . . . . . 
. . . . . . . 0 . . . . . . . . 
. . . . . . . 0 0 0 0 0 0 0 0 0 
. . . . . . . 0 . . 0 . . . . . 
. . . . . . . 0 . . 0 . . . . . 
. . . . . . . 0 . . 0 . . . . . 
 with color red at (0,0)
diff: 
   (0.0 bits)
data: a background with size (11,16) and color black and layers
  _0: rectangle with size (7,8) with model Full with color blue at (0,8)
  _01: 
. . . 2 . . . 2 . . . . . . . . 
. . . 2 . . . 2 . . . . . . . . 
. . . 2 2 2 2 2 . . . . . . . . 
. . . 2 . . . 2 . . . . . . . . 
. . . 2 . . . 2 . . . . . . . . 
2 2 2 2 2 2 2 2 . . . . . . . . 
. . . . . . . 2 . . . . . . . . 
. . . . . . . 2 2 2 2 2 2 2 2 2 
. . . . . . . 2 . . 2 . . . . . 
. . . . . . . 2 . . 2 . . . . . 
. . . . . . . 2 . . 2 . . . . . 
 at (0,0)
  _011: rectangle with size (5,3) with model Full with color cyan at (0,4)
  + 6 delta pixels
diff: 
   (310.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,16) and color black and layers
  _0: rectangle with size (11,16) with mask 
. . . 0 . . . 0 . . . . . . . . 
. . . 0 . . . 0 . . . . . . . . 
. . . 0 0 0 0 0 . . . . . . . . 
. . . 0 . . . 0 . . . . . . . . 
. . . 0 . . . 0 . . . . . . . . 
0 0 0 0 0 0 0 0 . . . . . . . . 
. . . . . . . 0 . . . . . . . . 
. . . . . . . 0 0 0 0 0 0 0 0 0 
. . . . . . . 0 . . 0 . . . . . 
. . . . . . . 0 . . 0 . . . . . 
. . . . . . . 0 . . 0 . . . . . 
 with color red at (0,0)
diff: 
! 78 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,16) and color black and layers
  _0: rectangle with size (11,1) with model Full with color red at (0,7)
  + 26 delta pixels
diff: 
! 104 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (11,16) and color black and layers
  _0: rectangle with size (1,9) with model Full with color red at (7,7)
  + 28 delta pixels
diff: 
! 110 wrong pixels (generated / expected)

TRAIN 6455b5f5.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (15,16) and color black and layers
  _0: rectangle with size (15,16) with mask 
. . . 0 . . . . . . . . 0 . . . 
. . . 0 . . . . . . . . 0 . . . 
. . . 0 . . . . . . . . 0 0 0 0 
. . . 0 . . . . . . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 . . . 
. . 0 . . . . . . . . . 0 . . . 
. . 0 . . . . . . . . . 0 . . . 
. . 0 . . . . . . . . . 0 . . . 
. . 0 . . . . . . . . . 0 . . . 
0 0 0 . . . . . . . . . 0 . . . 
. . 0 . . . . . . . . . 0 0 0 0 
. . 0 . . . . . . . . . 0 . . . 
. . 0 . . . . . . . . . 0 . . . 
. . 0 . . . . . . . . . 0 . . . 
. . 0 . . . . . . . . . 0 . . . 
 with color red at (0,0)
diff: 
   (0.0 bits)
data: a background with size (15,16) and color black and layers
  _0: rectangle with size (2,3) with model Full with color cyan at (0,13)
  _01: 
. . . 2 . . . . . . . . 2 . . . 
. . . 2 . . . . . . . . 2 . . . 
. . . 2 . . . . . . . . 2 2 2 2 
. . . 2 . . . . . . . . 2 . . . 
2 2 2 2 2 2 2 2 2 2 2 2 2 . . . 
. . 2 . . . . . . . . . 2 . . . 
. . 2 . . . . . . . . . 2 . . . 
. . 2 . . . . . . . . . 2 . . . 
. . 2 . . . . . . . . . 2 . . . 
2 2 2 . . . . . . . . . 2 . . . 
. . 2 . . . . . . . . . 2 2 2 2 
. . 2 . . . . . . . . . 2 . . . 
. . 2 . . . . . . . . . 2 . . . 
. . 2 . . . . . . . . . 2 . . . 
. . 2 . . . . . . . . . 2 . . . 
 at (0,0)
  _011: rectangle with size (10,9) with model Full with color blue at (5,3)
diff: 
   (61.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,16) and color black and layers
  _0: rectangle with size (15,16) with mask 
. . . 0 . . . . . . . . 0 . . . 
. . . 0 . . . . . . . . 0 . . . 
. . . 0 . . . . . . . . 0 0 0 0 
. . . 0 . . . . . . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 . . . 
. . 0 . . . . . . . . . 0 . . . 
. . 0 . . . . . . . . . 0 . . . 
. . 0 . . . . . . . . . 0 . . . 
. . 0 . . . . . . . . . 0 . . . 
0 0 0 . . . . . . . . . 0 . . . 
. . 0 . . . . . . . . . 0 0 0 0 
. . 0 . . . . . . . . . 0 . . . 
. . 0 . . . . . . . . . 0 . . . 
. . 0 . . . . . . . . . 0 . . . 
. . 0 . . . . . . . . . 0 . . . 
 with color red at (0,0)
diff: 
! 100 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,16) and color black and layers
  _0: rectangle with size (15,1) with model Full with color red at (0,12)
  + 34 delta pixels
diff: 
! 134 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,16) and color black and layers
  _0: rectangle with size (1,13) with model Full with color red at (4,0)
  + 36 delta pixels
diff: 
! 140 wrong pixels (generated / expected)

TRAIN 6455b5f5.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,16) and color black and layers
  _0: rectangle with size (13,16) with mask 
. . . . . . . . . . 0 . . . . . 
. . . . . . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 . . . . . 
. . . . . . . . . . 0 . . . . . 
. . . . . . . . . . 0 0 0 0 0 0 
. . . . . . . . . . 0 . . . . . 
. . . . . . . . . . 0 . . . . . 
. . . . . . . . . . 0 . . . . . 
. . . . . . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . . . . 0 . 0 . . . 
0 0 0 0 . . . . . . 0 . 0 . . . 
. . . 0 . . . . . . 0 . 0 . . . 
 with color red at (0,0)
diff: 
! 73 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,16) and color black and layers
  _0: rectangle with size (1,16) with model Full with color red at (9,0)
  + 36 delta pixels
diff: 
! 111 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (13,16) and color black and layers
  _0: rectangle with size (13,1) with model Full with color red at (0,10)
  + 39 delta pixels
diff: 
! 112 wrong pixels (generated / expected)

TEST 6455b5f5.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 11.7 sec (11.7 sec/task)
bits-train-error = 5308.0 bits (5308.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-255] Checking task 662c240a.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 41958.2 = 41960.6
DL output with Mo: L = 2.3 + 14046.4 = 14048.7
DL input+output M: L = 4.6 + 56004.7 = 56009.3

# learning a model for train pairs
2.000	
1.435	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.157	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.925	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.766	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.624	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.522	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.437	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.381	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.345	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.313	OUT SPE ^.layer_0.shape.mask.size = ^.layer_01.shape.mask.size
0.297	OUT SPE ^.layer_0.pos = '(0, 0)
0.290	IN  ADD ^.layer_011110 = point with color ? at (?,?)
0.286	IN  SPE ^.layer_011.shape.mask.model = Full
0.283	IN  SPE ^.layer_01111.shape.mask.model = Full
0.074	
0.074	IN  GEN ^.layer_01111.shape.mask.model = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color ? and layers
  _0: rectangle with size ^.layer_01.shape.mask.size with model ? with color ? at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011110: point with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 172.1 + 8789.8 = 8961.9
DL output with Mo: L = 65.5 + 916.2 = 981.6
DL input+output M: L = 237.6 + 9706.0 = 9943.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color ? and layers
  _0: rectangle with size ^.layer_01.shape.mask.size with model ? with color ? at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011110: point with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 171.6 + 0.0 = 171.6
DL output with Mo: L = 65.5 + 916.2 = 981.6
DL input+output M: L = 237.1 + 916.2 = 1153.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,3) and color cyan and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
0 0 . 
. . 0 
 with color red at (3,0)
  _01: rectangle with size (2,3) with mask 
0 0 0 
0 0 . 
 with color yellow at (6,0)
  _011: rectangle with size (3,3) with model Full with color blue at (3,0)
  _0111: rectangle with size (2,3) with model Full with color green at (7,0)
  _011110: point with color brown at (0,1)
  _01111: rectangle with size (1,1) with model Full with color brown at (1,0)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color green and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 0 . 
 with color yellow at (0,0)
diff: 
   (20.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,3) and color cyan and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
0 0 . 
. . 0 
 with color red at (3,0)
  _01: rectangle with size (2,3) with mask 
0 0 0 
0 0 . 
 with color yellow at (6,0)
  _011: rectangle with size (3,3) with model Full with color blue at (3,0)
  _0111: rectangle with size (2,3) with model Full with color green at (7,0)
  _011110: point with color brown at (0,1)
  _01111: rectangle with size (1,1) with model Full with color brown at (1,0)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 662c240a.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,3) and color green and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
. 0 0 
. 0 0 
 with color blue at (0,0)
  _01: rectangle with size (3,3) with model Full with color grey at (0,0)
  _011: rectangle with size (2,2) with model Full with color red at (7,1)
  _0111: rectangle with size (3,3) with model Full with color orange at (6,0)
  _011110: point with color pink at (4,1)
  _01111: rectangle with size (1,2) with model Full with color pink at (5,1)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color pink and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
0 . 0 
0 . . 
 with color green at (0,0)
diff: 
   (24.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,3) and color green and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
. 0 0 
. 0 0 
 with color blue at (0,0)
  _01: rectangle with size (3,3) with model Full with color grey at (0,0)
  _011: rectangle with size (2,2) with model Full with color red at (7,1)
  _0111: rectangle with size (3,3) with model Full with color orange at (6,0)
  _011110: point with color pink at (4,1)
  _01111: rectangle with size (1,2) with model Full with color pink at (5,1)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,3) and color green and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
. 0 0 
. 0 0 
 with color blue at (0,0)
  _01: rectangle with size (2,2) with model Full with color red at (7,1)
  _011: rectangle with size (3,3) with model Full with color orange at (6,0)
  _0111: rectangle with size (3,3) with model Full with color grey at (0,0)
  _011110: point with color pink at (4,1)
  _01111: rectangle with size (1,2) with model Full with color pink at (5,1)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 662c240a.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (9,3) and color red and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
. 0 0 
. 0 0 
 with color grey at (3,0)
  _01: rectangle with size (3,2) with mask 
0 0 
. 0 
. 0 
 with color cyan at (6,0)
  _011: rectangle with size (3,3) with model Full with color orange at (3,0)
  _0111: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color green at (1,1)
  _011110: point with color blue at (7,0)
  _01111: rectangle with size (3,1) with model Full with color blue at (6,2)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color blue and layers
  _0: rectangle with size (3,2) with mask 
0 0 
. 0 
. 0 
 with color cyan at (0,0)
diff: 
   (21.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,3) and color red and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
. 0 0 
. 0 0 
 with color grey at (3,0)
  _01: rectangle with size (3,2) with mask 
0 0 
. 0 
. 0 
 with color cyan at (6,0)
  _011: rectangle with size (3,3) with model Full with color orange at (3,0)
  _0111: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color green at (1,1)
  _011110: point with color blue at (7,0)
  _01111: rectangle with size (3,1) with model Full with color blue at (6,2)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,3) and color red and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
. 0 0 
. 0 0 
 with color grey at (3,0)
  _01: rectangle with size (3,3) with model Full with color orange at (3,0)
  _011: rectangle with size (3,2) with model Full with color cyan at (6,0)
  _0111: rectangle with size (3,1) with model Full with color blue at (6,2)
  _011110: point with color green at (1,2)
  _01111: rectangle with size (1,2) with model Full with color green at (2,1)
  + 2 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 662c240a.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (9,3) and color yellow and layers
  _0: rectangle with size (3,3) with model Full with color red at (6,0)
  _01: rectangle with size (3,3) with mask 
. . 0 
. 0 0 
0 0 . 
 with color green at (3,0)
  _011: rectangle with size (2,2) with model Full with color blue at (3,0)
  _0111: rectangle with size (1,2) with model Full with color cyan at (0,0)
  _011110: point with color cyan at (2,2)
  _01111: rectangle with size (1,1) with model Full with color blue at (5,2)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color cyan and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
0 0 . 
 with color yellow at (0,0)
diff: 
   (24.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,3) and color yellow and layers
  _0: rectangle with size (3,3) with model Full with color red at (6,0)
  _01: rectangle with size (3,3) with mask 
. . 0 
. 0 0 
0 0 . 
 with color green at (3,0)
  _011: rectangle with size (2,2) with model Full with color blue at (3,0)
  _0111: rectangle with size (1,2) with model Full with color cyan at (0,0)
  _011110: point with color cyan at (2,2)
  _01111: rectangle with size (1,1) with model Full with color blue at (5,2)
  + 2 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 662c240a.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,3) and color yellow and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
0 0 . 
. . 0 
 with color green at (3,0)
  _01: rectangle with size (3,3) with model Full with color red at (3,0)
  _011: rectangle with size (2,2) with model Full with color cyan at (7,1)
  _0111: rectangle with size (3,3) with model Full with color blue at (6,0)
  _011110: point with color grey at (0,0)
  _01111: rectangle with size (2,1) with model Full with color grey at (1,1)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,3) and color yellow and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
0 0 . 
. . 0 
 with color green at (3,0)
  _01: rectangle with size (2,2) with model Full with color cyan at (7,1)
  _011: rectangle with size (3,3) with model Full with color blue at (6,0)
  _0111: rectangle with size (3,3) with model Full with color red at (3,0)
  _011110: point with color grey at (0,0)
  _01111: rectangle with size (2,1) with model Full with color grey at (1,1)
diff: 
! 9 wrong pixels (generated / expected)

TEST 662c240a.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 8.9 sec (8.9 sec/task)
bits-train-error = 916.2 bits (916.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-254] Checking task 67385a82.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 30694.5 = 30696.8
DL output with Mo: L = 2.3 + 30694.5 = 30696.8
DL input+output M: L = 4.6 + 61389.1 = 61393.7

# learning a model for train pairs
2.000	
1.375	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.771	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.531	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.356	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.309	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.289	OUT SPE ^.size = ^.size
0.272	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.261	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.252	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.245	OUT SPE ^.layer_0.shape.color = cyan
0.238	OUT SPE ^.layer_011.shape.color = green
0.232	OUT SPE ^.layer_0.shape.mask.size.i = ^.size.i / '2
0.227	OUT SPE ^.layer_0111.pos.i = right(^.layer_0) - 1
0.223	OUT SPE ^.layer_01.shape.mask.size.i = ^.layer_0.shape.mask.size.i / '2
0.218	OUT SPE ^.layer_01.shape.mask.size.j = ^.layer_0.shape.mask.size.i / '2
0.215	OUT SPE ^.color = black
0.082	

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (^.size.i / '2,?) with model ? with color cyan at ^.layer_0.pos
  _01: rectangle with size (^.layer_0.shape.mask.size.i / '2,^.layer_0.shape.mask.size.i / '2) with model ? with color ? at (?,?)
  _011: point with color green at (?,?)
  _0111: point with color ? at (right(^.layer_0) - 1,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 4070.8 = 4112.8
DL output with Mo: L = 214.0 + 2265.3 = 2479.2
DL input+output M: L = 256.0 + 6336.1 = 6592.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (^.size.i / '2,?) with model ? with color cyan at ^.layer_0.pos
  _01: rectangle with size (^.layer_0.shape.mask.size.i / '2,^.layer_0.shape.mask.size.i / '2) with model ? with color ? at (?,?)
  _011: point with color green at (?,?)
  _0111: point with color ? at (right(^.layer_0) - 1,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 214.0 + 2265.3 = 2479.2
DL input+output M: L = 256.0 + 2265.3 = 2521.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 . 
0 . 0 
 with color green at (0,0)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,2) with model Full with color cyan at (0,0)
  _01: rectangle with size (1,1) with model Full with color green at (2,0)
  _011: point with color green at (2,2)
  _0111: point with color cyan at (1,1)
diff: 
   (41.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 . 
0 . 0 
 with color green at (0,0)
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color green and layers
  _0: rectangle with size (2,1) with model Full with color black at (0,2)
  + 2 delta pixels
diff: 
! 7 wrong pixels (generated / expected)

TRAIN 67385a82.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (4,6) and color black and layers
  _0: rectangle with size (3,4) with mask 
0 . . . 
0 0 0 . 
. . . 0 
 with color green at (0,1)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,6) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 . . 
0 0 0 
 with color cyan at (0,1)
  _01: rectangle with size (1,1) with model Full with color green at (0,5)
  _011: point with color green at (2,4)
  _0111: point with color green at (3,1)
diff: 
   (51.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,6) and color black and layers
  _0: rectangle with size (3,4) with mask 
0 . . . 
0 0 0 . 
. . . 0 
 with color green at (0,1)
  + 2 delta pixels
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,6) and color black and layers
  _0: rectangle with size (2,1) with model Full with color green at (0,1)
  + 5 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 67385a82.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (4,4) and color green and layers
  _0: rectangle with size (4,4) with mask 
. . 0 . 
. . 0 0 
. 0 0 . 
0 0 . . 
 with color black at (0,0)
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (2,2) with model Full with color cyan at (0,0)
  _01: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color cyan at (2,2)
  _011: point with color green at (0,3)
  _0111: point with color cyan at (2,0)
diff: 
   (45.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,4) and color green and layers
  _0: rectangle with size (4,4) with mask 
. . 0 . 
. . 0 0 
. 0 0 . 
0 0 . . 
 with color black at (0,0)
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 0 
0 0 
0 . 
 with color green at (0,0)
  + 4 delta pixels
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (4,4) and color green and layers
  _0: rectangle with size (3,1) with model Full with color black at (0,2)
  + 4 delta pixels
diff: 
! 12 wrong pixels (generated / expected)

TRAIN 67385a82.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (5,6) and color black and layers
  _0: rectangle with size (5,3) with mask 
0 0 . 
. 0 . 
0 . . 
. 0 0 
. 0 0 
 with color green at (0,0)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,6) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color cyan at (0,0)
  _01: rectangle with size (2,2) with model Full with color cyan at (3,1)
  _011: point with color green at (2,0)
  _0111: point with color green at (1,4)
  + 1 delta pixels
diff: 
   (87.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,6) and color black and layers
  _0: rectangle with size (5,3) with mask 
0 0 . 
. 0 . 
0 . . 
. 0 0 
. 0 0 
 with color green at (0,0)
  + 2 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,6) and color black and layers
  _0: rectangle with size (2,2) with model Full with color green at (3,1)
  + 6 delta pixels
diff: 
! 7 wrong pixels (generated / expected)

TRAIN 67385a82.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color green and layers
  _0: rectangle with size (5,5) with mask 
. . . 0 . 
. . . 0 0 
0 0 0 0 . 
0 . . 0 0 
0 . . 0 0 
 with color black at (0,0)
  + 1 delta pixels
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 . 0 
0 0 0 
 with color green at (0,0)
  + 6 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,2) with model Full with color green at (3,1)
  + 7 delta pixels
diff: 
! 7 wrong pixels (generated / expected)

TEST 67385a82.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 13.3 sec (13.3 sec/task)
bits-train-error = 2265.3 bits (2265.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-253] Checking task 673ef223.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 224392.7 = 224395.0
DL output with Mo: L = 2.3 + 224392.7 = 224395.0
DL input+output M: L = 4.6 + 448785.4 = 448790.1

# learning a model for train pairs
2.000	
1.069	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.278	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.221	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.185	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.158	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.135	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.110	OUT ADD ^.layer_00 = ^.layer_0
0.087	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.065	OUT ADD ^.layer_010 = ^.layer_01
0.061	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.059	OUT SPE ^.size = ^.size
0.057	OUT SPE ^.layer_0.shape.mask.size.j = ^.size.j - 1
0.056	OUT SPE ^.layer_011.pos.i = ^.layer_011.pos.i
0.056	OUT SPE ^.layer_011.shape.color = ^.layer_011.shape.color
0.055	IN  SPE ^.layer_0.shape.color = red
0.054	IN  SPE ^.layer_01.shape.color = red
0.054	IN  SPE ^.layer_011.shape.color = cyan
0.053	OUT SPE ^.layer_0.shape.color = cyan
0.052	OUT SPE ^.layer_01.pos.i = bottom(^.layer_01) - 1
0.051	OUT SPE ^.layer_011.pos.j = min(^.layer_0.pos.i, ^.layer_01.pos.i)
0.051	OUT SPE ^.layer_01.shape.mask.size.i = 1
0.050	OUT SPE ^.layer_0.pos.j = min(^.layer_0.pos.i, ^.layer_01.pos.i) / '2
0.050	IN  SPE ^.layer_0.shape.mask.model = Full
0.050	IN  SPE ^.layer_01.shape.mask.model = Full
0.049	OUT SPE ^.layer_0.shape.mask.model = Full
0.049	OUT SPE ^.layer_01.shape.mask.model = Full
0.049	IN  SPE ^.color = black
0.048	OUT SPE ^.color = black
0.032	
0.032	IN  GEN ^.layer_011.shape.color = ?
0.032	IN  GEN ^.layer_01.shape.color = ?
0.032	IN  GEN ^.layer_0.shape.color = ?
0.032	IN  GEN ^.layer_01.shape.mask.model = ?
0.032	IN  GEN ^.layer_0.shape.mask.model = ?
0.032	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,^.size.j - 1) with model Full with color cyan at (?,min(^.layer_0.pos.i, ^.layer_01.pos.i) / '2)
  _010: ^.layer_01
  _01: rectangle with size (1,?) with model Full with color ? at (bottom(^.layer_01) - 1,?)
  _011: rectangle with size (?,?) with model ? with color ^.layer_011.shape.color at (^.layer_011.pos.i,min(^.layer_0.pos.i, ^.layer_01.pos.i))
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color red at (?,?)
  _01: rectangle with size (?,?) with model Full with color red at (?,?)
  _011: point with color cyan at (?,?)

DL input  with Mi: L = 99.4 + 3706.3 = 3805.7
DL output with Mo: L = 231.8 + 6806.5 = 7038.3
DL input+output M: L = 331.2 + 10512.8 = 10844.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,^.size.j - 1) with model Full with color cyan at (?,min(^.layer_0.pos.i, ^.layer_01.pos.i) / '2)
  _010: ^.layer_01
  _01: rectangle with size (1,?) with model Full with color ? at (bottom(^.layer_01) - 1,?)
  _011: rectangle with size (?,?) with model ? with color ^.layer_011.shape.color at (^.layer_011.pos.i,min(^.layer_0.pos.i, ^.layer_01.pos.i))
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 88.3 + 20.0 = 108.3
DL output with Mo: L = 231.8 + 6806.5 = 7038.3
DL input+output M: L = 320.1 + 6826.5 = 7146.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (19,8) and color black and layers
  _0: rectangle with size (4,1) with model Full with color red at (11,7)
  _01: rectangle with size (4,1) with model Full with color red at (1,0)
  _011: point with color cyan at (3,4)
diff: 
   (2.0 bits)
data: a background with size (19,8) and color black and layers
  _00: 
2 
2 
2 
2 
 at (11,7)
  _0: rectangle with size (1,7) with model Full with color cyan at (13,0)
  _010: 
2 
2 
2 
2 
 at (1,0)
  _01: rectangle with size (1,1) with model Full with color yellow at (3,4)
  _011: rectangle with size (1,3) with model Full with color cyan at (3,1)
diff: 
   (36.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,8) and color black and layers
  _0: rectangle with size (4,1) with model Full with color red at (1,0)
  _01: rectangle with size (4,1) with model Full with color red at (11,7)
  _011: point with color cyan at (3,4)
diff: 
! 24 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (19,8) and color black and layers
  _0: rectangle with size (4,1) with model Full with color red at (11,7)
  _01: rectangle with size (4,1) with model Full with color red at (1,0)
  _011: point with color cyan at (3,4)
diff: 
! 26 wrong pixels (generated / expected)

TRAIN 673ef223.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (20,10) and color black and layers
  _0: rectangle with size (5,1) with model Full with color red at (1,0)
  _01: rectangle with size (5,1) with model Full with color red at (11,9)
  _011: point with color cyan at (2,7)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,10) and color black and layers
  _00: 
2 
2 
2 
2 
2 
 at (1,0)
  _0: rectangle with size (1,9) with model Full with color cyan at (12,0)
  _010: 
2 
2 
2 
2 
2 
 at (11,9)
  _01: rectangle with size (1,9) with model Full with color cyan at (14,0)
  _011: rectangle with size (1,6) with model Full with color cyan at (2,1)
  + 6 delta pixels
diff: 
   (294.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,10) and color black and layers
  _0: rectangle with size (5,1) with model Full with color red at (1,0)
  _01: rectangle with size (5,1) with model Full with color red at (11,9)
  _011: point with color cyan at (2,7)
  + 1 delta pixels
diff: 
! 47 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,10) and color black and layers
  _0: rectangle with size (5,1) with model Full with color red at (1,0)
  _01: rectangle with size (5,1) with model Full with color red at (11,9)
  _011: point with color cyan at (4,5)
  + 1 delta pixels
diff: 
! 47 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (20,10) and color black and layers
  _0: rectangle with size (5,1) with model Full with color red at (11,9)
  _01: rectangle with size (5,1) with model Full with color red at (1,0)
  _011: point with color cyan at (2,7)
  + 1 delta pixels
diff: 
! 48 wrong pixels (generated / expected)

TRAIN 673ef223.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (20,10) and color black and layers
  _0: rectangle with size (6,1) with model Full with color red at (3,9)
  _01: rectangle with size (6,1) with model Full with color red at (13,0)
  _011: point with color cyan at (4,6)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,10) and color black and layers
  _00: 
2 
2 
2 
2 
2 
2 
 at (3,9)
  _0: rectangle with size (2,9) with model Full with color cyan at (14,1)
  _010: 
2 
2 
2 
2 
2 
2 
 at (13,0)
  _01: rectangle with size (1,9) with model Full with color cyan at (17,1)
  _011: rectangle with size (2,6) with mask 
. . . . 0 0 
0 0 0 0 0 0 
 with color cyan at (4,3)
  + 7 delta pixels
diff: 
   (349.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,10) and color black and layers
  _0: rectangle with size (6,1) with model Full with color red at (3,9)
  _01: rectangle with size (6,1) with model Full with color red at (13,0)
  _011: point with color cyan at (4,6)
  + 2 delta pixels
diff: 
! 60 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,10) and color black and layers
  _0: rectangle with size (6,1) with model Full with color red at (3,9)
  _01: rectangle with size (6,1) with model Full with color red at (13,0)
  _011: point with color cyan at (5,2)
  + 2 delta pixels
diff: 
! 60 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (20,10) and color black and layers
  _0: rectangle with size (6,1) with model Full with color red at (13,0)
  _01: rectangle with size (6,1) with model Full with color red at (3,9)
  _011: point with color cyan at (4,6)
  + 2 delta pixels
diff: 
! 62 wrong pixels (generated / expected)

TRAIN 673ef223.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (21,12) and color black and layers
  _0: rectangle with size (6,1) with model Full with color red at (1,0)
  _01: rectangle with size (6,1) with model Full with color red at (14,11)
  _011: point with color cyan at (2,8)
  + 2 delta pixels
diff: 
! 69 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (21,12) and color black and layers
  _0: rectangle with size (6,1) with model Full with color red at (1,0)
  _01: rectangle with size (6,1) with model Full with color red at (14,11)
  _011: point with color cyan at (3,7)
  + 2 delta pixels
diff: 
! 73 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (21,12) and color black and layers
  _0: rectangle with size (6,1) with model Full with color red at (14,11)
  _01: rectangle with size (6,1) with model Full with color red at (1,0)
  _011: point with color cyan at (2,8)
  + 2 delta pixels
diff: 
! 70 wrong pixels (generated / expected)

TEST 673ef223.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 10.6 sec (10.6 sec/task)
bits-train-error = 6806.5 bits (6806.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-252] Checking task 6773b310.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 194274.3 = 194276.6
DL output with Mo: L = 2.3 + 14046.4 = 14048.7
DL input+output M: L = 4.6 + 208320.7 = 208325.3

# learning a model for train pairs
2.000	
1.312	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.741	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.444	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.334	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.287	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.250	OUT SPE ^.size = '(3, 3)
0.223	IN  SPE ^.layer_0.shape.mask = 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 

0.207	OUT SPE ^.layer_0.shape.color = blue
0.192	OUT SPE ^.layer_01.shape.color = blue
0.181	OUT SPE ^.layer_01.pos.j = 2
0.171	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.163	OUT SPE ^.layer_0.shape.mask.model = Full
0.156	OUT SPE ^.layer_0.pos.i = bottom(^.layer_01) / '3
0.149	OUT SPE ^.color = black
0.143	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.136	OUT SPE ^.layer_0.pos.j = min(^.layer_01.pos.j, ^.layer_011.pos.j) / '3
0.132	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.124	OUT SPE ^.layer_01.pos.i = middle(^.layer_0111) - ^.layer_01.shape.mask.size.i
0.117	OUT SPE ^.layer_0.shape.mask.size.j = area(^.layer_0.shape.mask) - ^.layer_0.pos.i - ^.layer_0111.pos.i
0.116	IN  SPE ^.layer_0.shape.color = cyan
0.115	IN  SPE ^.layer_01.shape.color = pink
0.114	IN  SPE ^.layer_011.shape.color = pink
0.113	IN  SPE ^.layer_0111.shape.color = pink
0.112	IN  SPE ^.color = black
0.032	
0.032	IN  GEN ^.layer_0111.shape.color = ?
0.032	IN  GEN ^.layer_011.shape.color = ?
0.032	IN  GEN ^.layer_01.shape.color = ?
0.032	IN  GEN ^.layer_0.shape.color = ?
0.032	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: rectangle with size (?,area(^.layer_0.shape.mask) - ^.layer_0.pos.i - ^.layer_0111.pos.i) with model Full with color blue at (bottom(^.layer_01) / '3,min(^.layer_01.pos.j, ^.layer_011.pos.j) / '3)
  _01: point with color blue at (middle(^.layer_0111) - ^.layer_01.shape.mask.size.i,2)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color cyan at (?,?)
  _01: rectangle with size (?,?) with model ? with color pink at (?,?)
  _011: rectangle with size (?,?) with model ? with color pink at (?,?)
  _0111: point with color pink at (?,?)

DL input  with Mi: L = 249.0 + 15595.7 = 15844.7
DL output with Mo: L = 274.9 + 152.9 = 427.8
DL input+output M: L = 523.9 + 15748.6 = 16272.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: rectangle with size (?,area(^.layer_0.shape.mask) - ^.layer_0.pos.i - ^.layer_0111.pos.i) with model Full with color blue at (bottom(^.layer_01) / '3,min(^.layer_01.pos.j, ^.layer_011.pos.j) / '3)
  _01: point with color blue at (middle(^.layer_0111) - ^.layer_01.shape.mask.size.i,2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 235.6 + 40.0 = 275.6
DL output with Mo: L = 274.9 + 152.9 = 427.8
DL input+output M: L = 510.5 + 192.9 = 703.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color cyan at (0,0)
  _01: rectangle with size (2,2) with model Odd Checkboard with color pink at (1,9)
  _011: rectangle with size (1,1) with model Full with color pink at (1,0)
  _0111: point with color pink at (1,5)
  + 8 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,1) with model Full with color blue at (0,0)
  _01: point with color blue at (0,2)
diff: 
   (5.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color cyan at (0,0)
  _01: rectangle with size (2,2) with model Odd Checkboard with color pink at (1,9)
  _011: rectangle with size (1,1) with model Full with color pink at (1,0)
  _0111: point with color pink at (1,5)
  + 8 delta pixels
diff: 
correct output grid

TRAIN 6773b310.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color cyan at (0,0)
  _01: rectangle with size (1,3) with model Full with color pink at (6,6)
  _011: rectangle with size (2,2) with model Even Checkboard with color pink at (9,0)
  _0111: point with color pink at (1,6)
  + 6 delta pixels
diff: 
   (2.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color blue at (2,0)
  _01: point with color blue at (1,2)
diff: 
   (3.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color cyan at (0,0)
  _01: rectangle with size (1,3) with model Full with color pink at (6,6)
  _011: rectangle with size (2,2) with model Even Checkboard with color pink at (9,0)
  _0111: point with color pink at (1,6)
  + 6 delta pixels
diff: 
correct output grid

TRAIN 6773b310.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color cyan at (0,0)
  _01: rectangle with size (1,1) with model Full with color pink at (0,5)
  _011: rectangle with size (2,2) with model Odd Checkboard with color pink at (0,9)
  _0111: point with color pink at (2,1)
  + 8 delta pixels
diff: 
   (2.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,2) with model Full with color blue at (0,1)
  _01: point with color blue at (2,2)
diff: 
   (3.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color cyan at (0,0)
  _01: rectangle with size (1,1) with model Full with color pink at (0,5)
  _011: rectangle with size (2,2) with model Odd Checkboard with color pink at (0,9)
  _0111: point with color pink at (2,1)
  + 8 delta pixels
diff: 
! 2 wrong pixels (generated / expected)

TRAIN 6773b310.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color cyan at (0,0)
  _01: rectangle with size (2,2) with model Even Checkboard with color pink at (4,5)
  _011: rectangle with size (1,1) with model Full with color pink at (0,10)
  _0111: point with color pink at (1,2)
  + 7 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color blue at (1,1)
  _01: point with color blue at (0,2)
diff: 
   (3.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color cyan at (0,0)
  _01: rectangle with size (2,2) with model Even Checkboard with color pink at (4,5)
  _011: rectangle with size (1,1) with model Full with color pink at (0,10)
  _0111: point with color pink at (1,2)
  + 7 delta pixels
diff: 
! 1 wrong pixels (generated / expected)

TRAIN 6773b310.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
undefined expression: ScaleDown: not an integer

TEST 6773b310.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 9.9 sec (9.9 sec/task)
bits-train-error = 152.9 bits (152.9 bits/task)
acc-train-micro = 0.50 tasks (50.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.50
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-251] Checking task 67a3c6ac.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 39466.0 = 39468.3
DL output with Mo: L = 2.3 + 39466.0 = 39468.3
DL input+output M: L = 4.6 + 78931.9 = 78936.6

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = applySym(flipWidth, ^)
0.683	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.498	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.393	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.337	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.291	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.275	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.254	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.248	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.238	IN  ADD ^.layer_01111111 = point with color ? at (?,?)
0.236	IN  SPE ^.layer_01111.shape.mask.model = Full
0.233	IN  SPE ^.layer_011111.shape.mask.model = Full
0.006	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
applySym(flipWidth, ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)

DL input  with Mi: L = 217.1 + 8984.3 = 9201.4
DL output with Mo: L = 12.3 + 0.0 = 12.3
DL input+output M: L = 229.4 + 8984.3 = 9213.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
applySym(flipWidth, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 12.3 + 0.0 = 12.3
DL input+output M: L = 14.6 + 0.0 = 14.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
6 6 6 2 
6 1 6 2 
7#2 7#2 
1 7#2 2 

diff: 
   (0.0 bits)
data: 
2 6 6 6 
2 6 1 6 
2 7#2 7#
2 2 7#1 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
6 6 6 2 
6 1 6 2 
7#2 7#2 
1 7#2 2 

diff: 
correct output grid

TRAIN 67a3c6ac.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
7#7#7#6 6 6 2 
6 7#1 1 7#7#1 
7#7#2 1 2 6 6 
2 2 7#7#7#2 2 
7#2 7#1 2 7#2 
6 6 6 2 2 1 1 
6 2 6 6 6 6 6 

diff: 
   (0.0 bits)
data: 
2 6 6 6 7#7#7#
1 7#7#1 1 7#6 
6 6 2 1 2 7#7#
2 2 7#7#7#2 2 
2 7#2 1 7#2 7#
1 1 2 2 6 6 6 
6 6 6 6 6 2 6 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
7#7#7#6 6 6 2 
6 7#1 1 7#7#1 
7#7#2 1 2 6 6 
2 2 7#7#7#2 2 
7#2 7#1 2 7#2 
6 6 6 2 2 1 1 
6 2 6 6 6 6 6 

diff: 
correct output grid

TRAIN 67a3c6ac.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
1 2 7#1 1 1 
2 1 7#7#2 6 
2 1 2 6 2 1 
1 2 1 7#6 2 
2 7#1 2 7#1 
2 1 6 2 7#7#

diff: 
   (0.0 bits)
data: 
1 1 1 7#2 1 
6 2 7#7#1 2 
1 2 6 2 1 2 
2 6 7#1 2 1 
1 7#2 1 7#2 
7#7#2 6 1 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 2 7#1 1 1 
2 1 7#7#2 6 
2 1 2 6 2 1 
1 2 1 7#6 2 
2 7#1 2 7#1 
2 1 6 2 7#7#

diff: 
correct output grid

TRAIN 67a3c6ac.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
7#6 1 
6 7#6 
6 2 2 

diff: 
correct output grid

TEST 67a3c6ac.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 3.9 sec (3.9 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-250] Checking task 67a423a3.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 45501.7 = 45504.0
DL output with Mo: L = 2.3 + 45501.7 = 45504.0
DL input+output M: L = 4.6 + 91003.4 = 91008.1

# learning a model for train pairs
2.000	
1.294	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.666	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.509	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.377	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.268	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.188	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.129	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.117	OUT SPE ^.layer_01.shape = scaleTo(^.layer_0.shape, ^.layer_0.shape.mask.size - translationSym(flipWidth, ^.layer_01, ^))
0.105	OUT SPE ^.layer_0.shape.mask = 
0 0 0 
0 . 0 
0 0 0 

0.093	OUT SPE ^.layer_011.shape = scaleTo(^.layer_01.shape, projJ(^.layer_01.shape.mask.size) + (1, 0))
0.082	OUT SPE ^.size = ^.size
0.076	OUT SPE ^.layer_01.pos = ^.layer_0.pos + translationSym(flipWidth, ^.layer_01, ^)
0.070	OUT SPE ^.layer_0.pos = max(^.layer_0.pos, ^.layer_01.pos) - (1, 1)
0.067	OUT SPE ^.layer_0.shape.color = yellow
0.064	OUT SPE ^.layer_011.pos.j = ^.layer_01.pos.j
0.061	OUT SPE ^.layer_011.pos.i = bottom(^.layer_01)
0.059	IN  SPE ^.layer_0.shape.mask.model = Full
0.057	IN  SPE ^.layer_01.shape.mask.model = Full
0.055	IN  SPE ^.color = black
0.054	OUT SPE ^.color = black
0.007	
0.007	IN  GEN ^.layer_01.shape.mask.model = ?
0.007	IN  GEN ^.layer_0.shape.mask.model = ?
0.007	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 0 0 
0 . 0 
0 0 0 
 with color yellow at max(^.layer_0.pos, ^.layer_01.pos) - (1, 1)
  _01: scaleTo(^.layer_0.shape, ^.layer_0.shape.mask.size - translationSym(flipWidth, ^.layer_01, ^)) at ^.layer_0.pos + translationSym(flipWidth, ^.layer_01, ^)
  _011: scaleTo(^.layer_01.shape, projJ(^.layer_01.shape.mask.size) + (1, 0)) at (bottom(^.layer_01),^.layer_01.pos.j)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 71.4 + 2124.5 = 2195.9
DL output with Mo: L = 246.9 + 0.0 = 246.9
DL input+output M: L = 318.3 + 2124.5 = 2442.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 0 0 
0 . 0 
0 0 0 
 with color yellow at max(^.layer_0.pos, ^.layer_01.pos) - (1, 1)
  _01: scaleTo(^.layer_0.shape, ^.layer_0.shape.mask.size - translationSym(flipWidth, ^.layer_01, ^)) at ^.layer_0.pos + translationSym(flipWidth, ^.layer_01, ^)
  _011: scaleTo(^.layer_01.shape, projJ(^.layer_01.shape.mask.size) + (1, 0)) at (bottom(^.layer_01),^.layer_01.pos.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 246.9 + 0.0 = 246.9
DL input+output M: L = 317.1 + 0.0 = 317.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (4,4) and color black and layers
  _0: rectangle with size (1,4) with model Full with color red at (1,0)
  _01: rectangle with size (4,1) with model Full with color green at (0,1)
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: 
0 0 0 
0 . 0 
0 0 0 
 with color yellow at (0,0)
  _01: 
2 2 2 
 at (1,1)
  _011: 
3 
 at (3,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (1,4) with model Full with color red at (1,0)
  _01: rectangle with size (4,1) with model Full with color green at (0,1)
diff: 
correct output grid

TRAIN 67a423a3.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (8,8) and color black and layers
  _0: rectangle with size (8,1) with model Full with color pink at (0,4)
  _01: rectangle with size (1,8) with model Full with color cyan at (4,0)
diff: 
   (0.0 bits)
data: a background with size (8,8) and color black and layers
  _0: 
0 0 0 
0 . 0 
0 0 0 
 with color yellow at (3,3)
  _01: 
6 
6 
6 
6 
6 
6 
6 
6 
 at (0,4)
  _011: 
8 8 8 8 8 8 8 8 
 at (4,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (8,1) with model Full with color pink at (0,4)
  _01: rectangle with size (1,8) with model Full with color cyan at (4,0)
diff: 
correct output grid

TRAIN 67a423a3.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _0: rectangle with size (6,1) with model Full with color blue at (0,2)
  _01: rectangle with size (1,6) with model Full with color brown at (2,0)
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _0: 
0 0 0 
0 . 0 
0 0 0 
 with color yellow at (1,1)
  _01: 
1 
1 
1 
1 
1 
1 
 at (0,2)
  _011: 
9#9#9#9#9#9#
 at (2,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (6,1) with model Full with color blue at (0,2)
  _01: rectangle with size (1,6) with model Full with color brown at (2,0)
diff: 
correct output grid

TRAIN 67a423a3.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (12,1) with model Full with color grey at (0,8)
  _01: rectangle with size (1,12) with model Full with color green at (6,0)
diff: 
correct output grid

TEST 67a423a3.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 7.5 sec (7.5 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-249] Checking task 67e8384a.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 14046.4 = 14048.7
DL output with Mo: L = 2.3 + 56169.1 = 56171.4
DL input+output M: L = 4.6 + 70215.5 = 70220.1

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = unfoldSym( [ id flipWidth ] [ flipHeight rotate180 ], ^)
0.565	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.414	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.348	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.281	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.006	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
unfoldSym( [ id flipWidth ] [ flipHeight rotate180 ], ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 78.5 + 3863.1 = 3941.6
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 89.8 + 3863.1 = 3952.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
unfoldSym( [ id flipWidth ] [ flipHeight rotate180 ], ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 13.6 + 0.0 = 13.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
5#3 4 
3 4 5#
3 4 4 

diff: 
   (0.0 bits)
data: 
5#3 4 4 3 5#
3 4 5#5#4 3 
3 4 4 4 4 3 
3 4 4 4 4 3 
3 4 5#5#4 3 
5#3 4 4 3 5#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#3 4 
3 4 5#
3 4 4 

diff: 
correct output grid

TRAIN 67e8384a.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
7#1 5#
7#7#1 
5#3 1 

diff: 
   (0.0 bits)
data: 
7#1 5#5#1 7#
7#7#1 1 7#7#
5#3 1 1 3 5#
5#3 1 1 3 5#
7#7#1 1 7#7#
7#1 5#5#1 7#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
7#1 5#
7#7#1 
5#3 1 

diff: 
correct output grid

TRAIN 67e8384a.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
2 5#2 
2 6 4 
2 2 2 

diff: 
   (0.0 bits)
data: 
2 5#2 2 5#2 
2 6 4 4 6 2 
2 2 2 2 2 2 
2 2 2 2 2 2 
2 6 4 4 6 2 
2 5#2 2 5#2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 5#2 
2 6 4 
2 2 2 

diff: 
correct output grid

TRAIN 67e8384a.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: 
1 2 1 
2 8 1 
8 1 6 

diff: 
   (0.0 bits)
data: 
1 2 1 1 2 1 
2 8 1 1 8 2 
8 1 6 6 1 8 
8 1 6 6 1 8 
2 8 1 1 8 2 
1 2 1 1 2 1 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 2 1 
2 8 1 
8 1 6 

diff: 
correct output grid

TRAIN 67e8384a.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 6 6 
5#2 2 
2 2 2 

diff: 
correct output grid

TEST 67e8384a.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 0.8 sec (0.8 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-248] Checking task 681b3aeb.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 10534.8 = 10537.1
DL input+output M: L = 4.6 + 130310.7 = 130315.3

# learning a model for train pairs
2.000	
1.096	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.549	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.249	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.205	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.140	OUT SPE ^.layer_0.shape = ^.layer_0.shape
0.104	OUT SPE ^.size = '(3, 3)
0.075	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.051	OUT SPE ^.color = majorityColor(^)
0.040	OUT SPE ^.layer_0.pos.j = '0
0.040	IN  SPE ^.color = black
0.017	
0.017	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color majorityColor(^) and layers
  _0: ^.layer_0.shape at (?,'0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.3 + 2786.8 = 2857.1
DL output with Mo: L = 48.3 + 117.2 = 165.5
DL input+output M: L = 118.7 + 2904.0 = 3022.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color majorityColor(^) and layers
  _0: ^.layer_0.shape at (?,'0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 60.0 = 130.2
DL output with Mo: L = 48.3 + 117.2 = 165.5
DL input+output M: L = 118.5 + 177.2 = 295.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 0 
0 . 
0 . 
 with color green at (2,1)
  _01: rectangle with size (3,2) with mask 
. 0 
0 0 
0 0 
 with color orange at (7,8)
diff: 
   (2.0 bits)
data: a background with size (3,3) and color orange and layers
  _0: 
3 3 
3 . 
3 . 
 at (0,0)
diff: 
   (3.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,2) with mask 
. 0 
0 0 
0 0 
 with color orange at (7,8)
  _01: rectangle with size (3,2) with mask 
0 0 
0 . 
0 . 
 with color green at (2,1)
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 0 
0 . 
0 . 
 with color green at (2,1)
  _01: rectangle with size (3,2) with mask 
. 0 
0 0 
0 0 
 with color orange at (7,8)
diff: 
correct output grid

TRAIN 681b3aeb.json/1: 1 2nd (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color yellow at (0,8)
  _01: rectangle with size (3,3) with mask 
0 0 0 
. 0 0 
. . 0 
 with color pink at (2,3)
diff: 
   (2.0 bits)
data: a background with size (3,3) and color pink and layers
  _0: 
4 . 
4 4 
 at (1,0)
diff: 
   (3.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. 0 0 
. . 0 
 with color pink at (2,3)
  _01: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color yellow at (0,8)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color yellow at (0,8)
  _01: rectangle with size (3,3) with mask 
0 0 0 
. 0 0 
. . 0 
 with color pink at (2,3)
diff: 
! 4 wrong pixels (generated / expected)

TRAIN 681b3aeb.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color green at (4,3)
  _01: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color blue at (8,1)
diff: 
   (2.0 bits)
data: a background with size (3,3) and color blue and layers
  _0: 
. 3 . 
3 3 3 
 at (1,0)
diff: 
   (3.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color blue at (8,1)
  _01: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color green at (4,3)
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color green at (4,3)
  _01: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color blue at (8,1)
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 681b3aeb.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
0 . . 
0 0 0 
 with color cyan at (6,7)
  _01: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color red at (2,3)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color red at (2,3)
  _01: rectangle with size (3,3) with mask 
0 0 . 
0 . . 
0 0 0 
 with color cyan at (6,7)
diff: 
! 4 wrong pixels (generated / expected)

TEST 681b3aeb.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 2.8 sec (2.8 sec/task)
bits-train-error = 117.2 bits (117.2 bits/task)
acc-train-micro = 0.33 tasks (33.33%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.17
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-247] Checking task 6855a6e4.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 276019.4 = 276021.8
DL output with Mo: L = 2.3 + 276019.4 = 276021.8
DL input+output M: L = 4.6 + 552038.9 = 552043.5

# learning a model for train pairs
2.000	
1.102	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.205	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.176	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.148	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.120	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.092	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.068	OUT ADD ^.layer_00 = ^.layer_0
0.052	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.041	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.033	OUT ADD ^.layer_011 = ^.layer_01
0.031	OUT SPE ^.size = ^.size
0.029	OUT SPE ^.layer_0.pos = ^.layer_0.pos + (2, 2)
0.029	IN  SPE ^.layer_0.shape.color = red
0.028	IN  SPE ^.layer_01.shape.color = red
0.027	IN  SPE ^.layer_011.shape.color = grey
0.027	IN  SPE ^.layer_0111.shape.color = grey
0.026	OUT SPE ^.layer_0.shape.color = grey
0.026	OUT SPE ^.layer_01.shape.color = grey
0.025	OUT SPE ^.layer_01.shape.mask.size.i = ^.layer_011.shape.mask.size.i
0.025	OUT SPE ^.layer_01.pos.i = bottom(^.layer_01) - max(^.layer_011.shape.mask.size.i, ^.layer_0111.shape.mask.size.i)
0.024	OUT SPE ^.layer_01.pos.j = bottom(^.layer_0) - min(^.layer_011.shape.mask.size.i, ^.layer_0111.shape.mask.size.i)
0.024	OUT SPE ^.layer_0.shape.mask.size.i = area(^.layer_011.shape) - ^.layer_011.shape.mask.size.i
0.024	OUT SPE ^.layer_0.shape.mask.model = Full
0.023	IN  SPE ^.color = black
0.023	OUT SPE ^.color = black
0.006	
0.006	IN  GEN ^.layer_0111.shape.color = ?
0.006	IN  GEN ^.layer_011.shape.color = ?
0.006	IN  GEN ^.layer_01.shape.color = ?
0.006	IN  GEN ^.layer_0.shape.color = ?
0.006	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (area(^.layer_011.shape) - ^.layer_011.shape.mask.size.i,?) with model Full with color grey at ^.layer_0.pos + (2, 2)
  _01: rectangle with size (^.layer_011.shape.mask.size.i,?) with model ? with color grey at (bottom(^.layer_01) - max(^.layer_011.shape.mask.size.i, ^.layer_0111.shape.mask.size.i),bottom(^.layer_0) - min(^.layer_011.shape.mask.size.i, ^.layer_0111.shape.mask.size.i))
  _011: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at (?,?)
  _01: rectangle with size (?,?) with model ? with color red at (?,?)
  _011: rectangle with size (?,?) with model ? with color grey at (?,?)
  _0111: rectangle with size (?,?) with model ? with color grey at (?,?)

DL input  with Mi: L = 139.2 + 4634.2 = 4773.4
DL output with Mo: L = 318.5 + 1297.0 = 1615.4
DL input+output M: L = 457.6 + 5931.2 = 6388.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (area(^.layer_011.shape) - ^.layer_011.shape.mask.size.i,?) with model Full with color grey at ^.layer_0.pos + (2, 2)
  _01: rectangle with size (^.layer_011.shape.mask.size.i,?) with model ? with color grey at (bottom(^.layer_01) - max(^.layer_011.shape.mask.size.i, ^.layer_0111.shape.mask.size.i),bottom(^.layer_0) - min(^.layer_011.shape.mask.size.i, ^.layer_0111.shape.mask.size.i))
  _011: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 0.0 = 125.8
DL output with Mo: L = 318.5 + 1297.0 = 1615.4
DL input+output M: L = 444.2 + 1297.0 = 1741.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (2,5) with mask 
0 0 0 0 0 
0 . . . 0 
 with color red at (3,2)
  _01: rectangle with size (2,5) with mask 
0 . . . 0 
0 0 0 0 0 
 with color red at (10,2)
  _011: rectangle with size (1,3) with model Full with color grey at (13,3)
  _0111: rectangle with size (2,1) with model Full with color grey at (0,4)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _00: 
2 2 2 2 2 
2 . . . 2 
 at (3,2)
  _0: rectangle with size (2,1) with model Full with color grey at (5,4)
  _01: rectangle with size (1,3) with model Full with color grey at (9,3)
  _011: 
2 . . . 2 
2 2 2 2 2 
 at (10,2)
diff: 
   (12.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (2,5) with mask 
0 0 0 0 0 
0 . . . 0 
 with color red at (3,2)
  _01: rectangle with size (2,5) with mask 
0 . . . 0 
0 0 0 0 0 
 with color red at (10,2)
  _011: rectangle with size (1,3) with model Full with color grey at (13,3)
  _0111: rectangle with size (2,1) with model Full with color grey at (0,4)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (2,5) with mask 
0 . . . 0 
0 0 0 0 0 
 with color red at (10,2)
  _01: rectangle with size (2,5) with mask 
0 0 0 0 0 
0 . . . 0 
 with color red at (3,2)
  _011: rectangle with size (1,3) with model Full with color grey at (13,3)
  _0111: rectangle with size (2,1) with model Full with color grey at (0,4)
diff: 
! 11 wrong pixels (generated / expected)

TRAIN 6855a6e4.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (6,2) with mask 
0 0 
0 . 
0 . 
0 . 
0 . 
0 0 
 with color red at (5,3)
  _01: rectangle with size (6,2) with mask 
0 0 
. 0 
. 0 
. 0 
. 0 
0 0 
 with color red at (5,10)
  _011: rectangle with size (4,2) with mask 
0 . 
0 0 
0 0 
0 . 
 with color grey at (6,13)
  _0111: rectangle with size (2,2) with model Full with color grey at (7,0)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _00: 
2 2 
2 . 
2 . 
2 . 
2 . 
2 2 
 at (5,3)
  _0: rectangle with size (2,2) with model Full with color grey at (7,5)
  _01: rectangle with size (4,2) with mask 
. 0 
0 0 
0 0 
. 0 
 with color grey at (6,8)
  _011: 
2 2 
. 2 
. 2 
. 2 
. 2 
2 2 
 at (5,10)
diff: 
   (19.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (6,2) with mask 
0 0 
0 . 
0 . 
0 . 
0 . 
0 0 
 with color red at (5,3)
  _01: rectangle with size (6,2) with mask 
0 0 
. 0 
. 0 
. 0 
. 0 
0 0 
 with color red at (5,10)
  _011: rectangle with size (4,2) with mask 
0 . 
0 0 
0 0 
0 . 
 with color grey at (6,13)
  _0111: rectangle with size (2,2) with model Full with color grey at (7,0)
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (6,2) with mask 
0 0 
. 0 
. 0 
. 0 
. 0 
0 0 
 with color red at (5,10)
  _01: rectangle with size (6,2) with mask 
0 0 
0 . 
0 . 
0 . 
0 . 
0 0 
 with color red at (5,3)
  _011: rectangle with size (4,2) with mask 
0 . 
0 0 
0 0 
0 . 
 with color grey at (6,13)
  _0111: rectangle with size (2,2) with model Full with color grey at (7,0)
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (6,2) with mask 
0 0 
0 . 
0 . 
0 . 
0 . 
0 0 
 with color red at (5,3)
  _01: rectangle with size (6,2) with mask 
0 0 
. 0 
. 0 
. 0 
. 0 
0 0 
 with color red at (5,10)
  _011: rectangle with size (2,2) with model Full with color grey at (7,0)
  _0111: rectangle with size (4,2) with mask 
0 . 
0 0 
0 0 
0 . 
 with color grey at (6,13)
diff: 
! 4 wrong pixels (generated / expected)

TRAIN 6855a6e4.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (5,2) with mask 
0 0 
0 . 
0 . 
0 . 
0 0 
 with color red at (4,3)
  _01: rectangle with size (5,2) with mask 
0 0 
. 0 
. 0 
. 0 
0 0 
 with color red at (4,9)
  _011: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color grey at (5,0)
  _0111: rectangle with size (3,2) with mask 
0 . 
0 0 
. 0 
 with color grey at (5,12)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _00: 
2 2 
2 . 
2 . 
2 . 
2 2 
 at (4,3)
  _0: rectangle with size (1,4) with model Full with color grey at (6,5)
  _01: rectangle with size (3,1) with model Full with color grey at (5,5)
  _011: 
2 2 
. 2 
. 2 
. 2 
2 2 
 at (4,9)
  + 2 delta pixels
diff: 
   (98.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (5,2) with mask 
0 0 
0 . 
0 . 
0 . 
0 0 
 with color red at (4,3)
  _01: rectangle with size (5,2) with mask 
0 0 
. 0 
. 0 
. 0 
0 0 
 with color red at (4,9)
  _011: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color grey at (5,0)
  _0111: rectangle with size (3,2) with mask 
0 . 
0 0 
. 0 
 with color grey at (5,12)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (5,2) with mask 
0 0 
. 0 
. 0 
. 0 
0 0 
 with color red at (4,9)
  _01: rectangle with size (5,2) with mask 
0 0 
0 . 
0 . 
0 . 
0 0 
 with color red at (4,3)
  _011: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color grey at (5,0)
  _0111: rectangle with size (3,2) with mask 
0 . 
0 0 
. 0 
 with color grey at (5,12)
diff: 
! 8 wrong pixels (generated / expected)

TRAIN 6855a6e4.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (2,7) with mask 
0 0 0 0 0 0 0 
0 . . . . . 0 
 with color red at (3,3)
  _01: rectangle with size (2,7) with mask 
0 . . . . . 0 
0 0 0 0 0 0 0 
 with color red at (10,3)
  _011: rectangle with size (2,5) with mask 
. 0 0 0 . 
0 0 . 0 0 
 with color grey at (0,4)
  _0111: rectangle with size (2,5) with mask 
. . 0 . . 
0 0 0 0 0 
 with color grey at (13,4)
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (2,7) with mask 
0 0 0 0 0 0 0 
0 . . . . . 0 
 with color red at (3,3)
  _01: rectangle with size (2,7) with mask 
0 . . . . . 0 
0 0 0 0 0 0 0 
 with color red at (10,3)
  _011: rectangle with size (2,5) with mask 
. . 0 . . 
0 0 0 0 0 
 with color grey at (13,4)
  _0111: rectangle with size (2,5) with mask 
. 0 0 0 . 
0 0 . 0 0 
 with color grey at (0,4)
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (2,7) with mask 
0 0 0 0 0 0 0 
0 . . . . . 0 
 with color red at (3,3)
  _01: rectangle with size (2,5) with mask 
. 0 0 0 . 
0 0 . 0 0 
 with color grey at (0,4)
  _011: rectangle with size (2,7) with mask 
0 . . . . . 0 
0 0 0 0 0 0 0 
 with color red at (10,3)
  _0111: rectangle with size (2,5) with mask 
. . 0 . . 
0 0 0 0 0 
 with color grey at (13,4)
diff: 
! 31 wrong pixels (generated / expected)

TEST 6855a6e4.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 15.5 sec (15.5 sec/task)
bits-train-error = 1297.0 bits (1297.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-246] Checking task 68b16354.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 38633.6 = 38635.9
DL output with Mo: L = 2.3 + 38633.6 = 38635.9
DL input+output M: L = 4.6 + 77267.2 = 77271.8

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = applySym(flipHeight, ^)
0.756	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.665	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.601	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.546	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.500	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.473	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.455	IN  ADD ^.layer_0110 = point with color ? at (?,?)
0.438	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.421	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.417	IN  SPE ^.layer_011.shape.mask.model = Full
0.415	IN  SPE ^.layer_0111.shape.mask.model = Full
0.413	IN  SPE ^.layer_01111.shape.mask.model = Full
0.006	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
applySym(flipHeight, ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: point with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: point with color ? at (?,?)

DL input  with Mi: L = 217.7 + 15727.8 = 15945.4
DL output with Mo: L = 12.3 + 0.0 = 12.3
DL input+output M: L = 230.0 + 15727.8 = 15957.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
applySym(flipHeight, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 12.3 + 0.0 = 12.3
DL input+output M: L = 14.6 + 0.0 = 14.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
8 1 2 1 4 
4 4 2 4 8 
3 7#2 4 8 
2 7#7#8 7#
8 7#7#4 8 

diff: 
   (0.0 bits)
data: 
8 7#7#4 8 
2 7#7#8 7#
3 7#2 4 8 
4 4 2 4 8 
8 1 2 1 4 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 1 2 1 4 
4 4 2 4 8 
3 7#2 4 8 
2 7#7#8 7#
8 7#7#4 8 

diff: 
correct output grid

TRAIN 68b16354.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
7#3 3 1 2 
1 8 2 4 1 
2 7#8 7#2 
7#7#4 1 8 
8 1 7#7#1 

diff: 
   (0.0 bits)
data: 
8 1 7#7#1 
7#7#4 1 8 
2 7#8 7#2 
1 8 2 4 1 
7#3 3 1 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
7#3 3 1 2 
1 8 2 4 1 
2 7#8 7#2 
7#7#4 1 8 
8 1 7#7#1 

diff: 
correct output grid

TRAIN 68b16354.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
2 7#4 3 4 8 3 
2 3 7#1 2 3 3 
8 7#4 3 2 2 4 
1 1 2 1 4 4 7#
2 4 3 1 1 4 1 
4 8 7#4 4 8 2 
7#3 8 4 3 2 8 

diff: 
   (0.0 bits)
data: 
7#3 8 4 3 2 8 
4 8 7#4 4 8 2 
2 4 3 1 1 4 1 
1 1 2 1 4 4 7#
8 7#4 3 2 2 4 
2 3 7#1 2 3 3 
2 7#4 3 4 8 3 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 7#4 3 4 8 3 
2 3 7#1 2 3 3 
8 7#4 3 2 2 4 
1 1 2 1 4 4 7#
2 4 3 1 1 4 1 
4 8 7#4 4 8 2 
7#3 8 4 3 2 8 

diff: 
correct output grid

TRAIN 68b16354.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 8 1 3 2 4 1 
4 4 1 1 4 3 4 
1 1 1 1 4 7#3 
1 1 2 3 8 1 3 
4 1 1 1 7#8 4 
3 2 8 4 1 8 4 
1 4 7#1 2 3 4 

diff: 
correct output grid

TEST 68b16354.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 2.5 sec (2.5 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-245] Checking task 694f12f3.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79850.6 = 79852.9
DL output with Mo: L = 2.3 + 79850.6 = 79852.9
DL input+output M: L = 4.6 + 159701.1 = 159705.8

# learning a model for train pairs
2.000	
1.390	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.779	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.545	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.386	OUT ADD ^.layer_0 = ^.layer_0
0.255	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.145	OUT ADD ^.layer_01 = ^.layer_01
0.069	OUT ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.046	OUT ADD ^.layer_010 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.041	OUT SPE ^.size = ^.size
0.038	OUT SPE ^.layer_010.pos = ^.layer_01.pos + (1, 1)
0.036	OUT SPE ^.layer_00.pos = ^.layer_0.pos + (1, 1)
0.031	OUT SPE ^.layer_010.shape = scaleTo(coloring(^.layer_01.shape, red), ^.layer_01.shape.mask.size - (2, 2))
0.027	OUT SPE ^.layer_00.shape = scaleTo(coloring(^.layer_01.shape, blue), ^.layer_0.shape.mask.size - (2, 2))
0.026	IN  SPE ^.layer_0.shape.color = yellow
0.025	IN  SPE ^.layer_01.shape.color = yellow
0.024	IN  SPE ^.layer_0.shape.mask.model = Full
0.023	IN  SPE ^.layer_01.shape.mask.model = Full
0.023	IN  SPE ^.color = black
0.022	OUT SPE ^.color = black
0.004	
0.004	IN  GEN ^.layer_01.shape.color = ?
0.004	IN  GEN ^.layer_0.shape.color = ?
0.004	IN  GEN ^.layer_01.shape.mask.model = ?
0.004	IN  GEN ^.layer_0.shape.mask.model = ?
0.004	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: scaleTo(coloring(^.layer_01.shape, blue), ^.layer_0.shape.mask.size - (2, 2)) at ^.layer_0.pos + (1, 1)
  _0: ^.layer_0
  _010: scaleTo(coloring(^.layer_01.shape, red), ^.layer_01.shape.mask.size - (2, 2)) at ^.layer_01.pos + (1, 1)
  _01: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color yellow at (?,?)
  _01: rectangle with size (?,?) with model Full with color yellow at (?,?)

DL input  with Mi: L = 78.0 + 1492.2 = 1570.2
DL output with Mo: L = 185.8 + 0.0 = 185.8
DL input+output M: L = 263.8 + 1492.2 = 1755.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: scaleTo(coloring(^.layer_01.shape, blue), ^.layer_0.shape.mask.size - (2, 2)) at ^.layer_0.pos + (1, 1)
  _0: ^.layer_0
  _010: scaleTo(coloring(^.layer_01.shape, red), ^.layer_01.shape.mask.size - (2, 2)) at ^.layer_01.pos + (1, 1)
  _01: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 40.0 = 110.2
DL output with Mo: L = 185.8 + 0.0 = 185.8
DL input+output M: L = 256.0 + 40.0 = 296.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with model Full with color yellow at (1,1)
  _01: rectangle with size (4,6) with model Full with color yellow at (6,3)
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
1 1 
1 1 
 at (2,2)
  _0: 
4 4 4 4 
4 4 4 4 
4 4 4 4 
4 4 4 4 
 at (1,1)
  _010: 
2 2 2 2 
2 2 2 2 
 at (7,4)
  _01: 
4 4 4 4 4 4 
4 4 4 4 4 4 
4 4 4 4 4 4 
4 4 4 4 4 4 
 at (6,3)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,6) with model Full with color yellow at (6,3)
  _01: rectangle with size (4,4) with model Full with color yellow at (1,1)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with model Full with color yellow at (1,1)
  _01: rectangle with size (4,6) with model Full with color yellow at (6,3)
diff: 
correct output grid

TRAIN 694f12f3.json/1: 1 2nd (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,4) with model Full with color yellow at (7,5)
  _01: rectangle with size (5,5) with model Full with color yellow at (1,1)
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
1 1 
 at (8,6)
  _0: 
4 4 4 4 
4 4 4 4 
4 4 4 4 
 at (7,5)
  _010: 
2 2 2 
2 2 2 
2 2 2 
 at (2,2)
  _01: 
4 4 4 4 4 
4 4 4 4 4 
4 4 4 4 4 
4 4 4 4 4 
4 4 4 4 4 
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with model Full with color yellow at (1,1)
  _01: rectangle with size (3,4) with model Full with color yellow at (7,5)
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,4) with model Full with color yellow at (7,5)
  _01: rectangle with size (5,5) with model Full with color yellow at (1,1)
diff: 
correct output grid

TRAIN 694f12f3.json/2: 1 2nd (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,6) with model Full with color yellow at (0,0)
  _01: rectangle with size (3,6) with model Full with color yellow at (7,4)
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,6) with model Full with color yellow at (7,4)
  _01: rectangle with size (6,6) with model Full with color yellow at (0,0)
diff: 
correct output grid

TEST 694f12f3.json/1: 1 2nd (SUCCESS)

# Performance measures on task
runtime-learning = 6.0 sec (6.0 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 0.50
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 0.50

=====================================
[-244] Checking task 6a1e5592.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 121173.8 = 121176.2
DL output with Mo: L = 2.3 + 121173.8 = 121176.2
DL input+output M: L = 4.6 + 242347.7 = 242352.3

# learning a model for train pairs
2.000	
1.363	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.727	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.501	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.281	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.210	OUT ADD ^.layer_00 = ^.layer_0
0.164	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.133	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.109	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.087	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.069	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.065	OUT SPE ^.size = ^.size
0.062	OUT SPE ^.layer_011.shape = coloring(^.layer_0111.shape, blue)
0.061	OUT SPE ^.layer_01.shape.mask.size.i = ^.layer_01.shape.mask.size.i
0.060	OUT SPE ^.layer_01.shape.mask.size.j = area(^.layer_01.shape.mask) - 3
0.059	IN  SPE ^.layer_0.shape.color = red
0.057	OUT SPE ^.layer_011.pos = projJ(^.layer_01.pos) + (2, 0)
0.057	IN  SPE ^.layer_01.shape.color = grey
0.056	IN  SPE ^.layer_011.shape.color = grey
0.055	IN  SPE ^.layer_0111.shape.color = grey
0.054	OUT SPE ^.layer_0.shape.color = blue
0.053	OUT SPE ^.layer_01.shape.color = blue
0.052	OUT SPE ^.layer_0.pos.i = 1
0.051	OUT SPE ^.layer_01.pos.i = 1
0.050	OUT SPE ^.layer_0.shape.mask.size.i = area(^.layer_0111.shape) - 2
0.050	OUT SPE ^.layer_01.pos.j = right(^.layer_0111) / '2
0.049	OUT SPE ^.layer_0.shape.mask.size.j = 1
0.048	OUT SPE ^.layer_0.pos.j = ^.layer_011.pos.j - ^.layer_011.pos.i - ^.layer_01.pos.i
0.048	OUT SPE ^.layer_0.shape.mask.model = Full
0.048	IN  SPE ^.color = black
0.047	OUT SPE ^.color = black
0.007	
0.007	IN  GEN ^.layer_0111.shape.color = ?
0.007	IN  GEN ^.layer_011.shape.color = ?
0.007	IN  GEN ^.layer_01.shape.color = ?
0.007	IN  GEN ^.layer_0.shape.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (area(^.layer_0111.shape) - 2,1) with model Full with color blue at (1,^.layer_011.pos.j - ^.layer_011.pos.i - ^.layer_01.pos.i)
  _01: rectangle with size (^.layer_01.shape.mask.size.i,area(^.layer_01.shape.mask) - 3) with model ? with color blue at (1,right(^.layer_0111) / '2)
  _011: coloring(^.layer_0111.shape, blue) at projJ(^.layer_01.pos) + (2, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at (?,?)
  _01: rectangle with size (?,?) with model ? with color grey at (?,?)
  _011: rectangle with size (?,?) with model ? with color grey at (?,?)
  _0111: rectangle with size (?,?) with model ? with color grey at (?,?)

DL input  with Mi: L = 139.2 + 4949.8 = 5089.0
DL output with Mo: L = 296.9 + 335.8 = 632.7
DL input+output M: L = 436.1 + 5285.6 = 5721.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (area(^.layer_0111.shape) - 2,1) with model Full with color blue at (1,^.layer_011.pos.j - ^.layer_011.pos.i - ^.layer_01.pos.i)
  _01: rectangle with size (^.layer_01.shape.mask.size.i,area(^.layer_01.shape.mask) - 3) with model ? with color blue at (1,right(^.layer_0111) / '2)
  _011: coloring(^.layer_0111.shape, blue) at projJ(^.layer_01.pos) + (2, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.9 + 40.0 = 165.9
DL output with Mo: L = 296.9 + 335.8 = 632.7
DL input+output M: L = 422.9 + 375.8 = 798.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,15) and color black and layers
  _0: rectangle with size (3,15) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 0 0 0 0 0 0 0 0 . 
0 . . 0 0 0 . . . 0 0 0 0 0 . 
 with color red at (0,0)
  _01: rectangle with size (3,3) with mask 
0 . . 
0 0 . 
0 0 0 
 with color grey at (7,6)
  _011: rectangle with size (4,1) with model Full with color grey at (6,13)
  _0111: rectangle with size (2,3) with model Full with color grey at (8,1)
diff: 
   (2.0 bits)
data: a background with size (10,15) and color black and layers
  _00: 
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 
2 . 2 2 2 2 2 2 2 2 2 2 2 2 . 
2 . . 2 2 2 . . . 2 2 2 2 2 . 
 at (0,0)
  _0: rectangle with size (4,1) with model Full with color blue at (1,14)
  _01: rectangle with size (3,3) with model Full with color blue at (1,1)
  _011: 
1 1 1 
1 1 1 
 at (2,6)
diff: 
   (2.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,15) and color black and layers
  _0: rectangle with size (3,15) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 0 0 0 0 0 0 0 0 . 
0 . . 0 0 0 . . . 0 0 0 0 0 . 
 with color red at (0,0)
  _01: rectangle with size (3,3) with mask 
0 . . 
0 0 . 
0 0 0 
 with color grey at (7,6)
  _011: rectangle with size (2,3) with model Full with color grey at (8,1)
  _0111: rectangle with size (4,1) with model Full with color grey at (6,13)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,15) and color black and layers
  _0: rectangle with size (3,15) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 0 0 0 0 0 0 0 0 . 
0 . . 0 0 0 . . . 0 0 0 0 0 . 
 with color red at (0,0)
  _01: rectangle with size (3,3) with mask 
0 . . 
0 0 . 
0 0 0 
 with color grey at (7,6)
  _011: rectangle with size (4,1) with model Full with color grey at (6,13)
  _0111: rectangle with size (2,3) with model Full with color grey at (8,1)
diff: 
correct output grid

TRAIN 6a1e5592.json/1: 1 2nd (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (10,15) and color black and layers
  _0: rectangle with size (3,15) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 . 0 0 . . 0 0 
0 . . 0 . 0 0 . . . 0 . . 0 0 
 with color red at (0,0)
  _01: rectangle with size (4,4) with mask 
. 0 0 . 
. 0 0 . 
0 0 0 0 
. 0 0 . 
 with color grey at (6,0)
  _011: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color grey at (8,6)
  _0111: rectangle with size (2,3) with mask 
. 0 0 
0 0 0 
 with color grey at (8,12)
  + 3 delta pixels
diff: 
   (2.0 bits)
data: a background with size (10,15) and color black and layers
  _00: 
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 
2 2 2 2 . 2 2 2 . 2 2 . . 2 2 
2 . . 2 . 2 2 . . . 2 . . 2 2 
 at (0,0)
  _0: rectangle with size (3,1) with model Full with color blue at (1,4)
  _01: rectangle with size (4,7) with mask 
. 0 . . 0 0 . 
0 0 0 . 0 0 . 
. . . 0 0 0 0 
. . . . 0 0 . 
 with color blue at (1,7)
  _011: 
. 1 1 
1 1 1 
 at (2,0)
diff: 
   (30.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,15) and color black and layers
  _0: rectangle with size (3,15) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 . 0 0 . . 0 0 
0 . . 0 . 0 0 . . . 0 . . 0 0 
 with color red at (0,0)
  _01: rectangle with size (4,4) with mask 
. 0 0 . 
. 0 0 . 
0 0 0 0 
. 0 0 . 
 with color grey at (6,0)
  _011: rectangle with size (2,3) with mask 
. 0 0 
0 0 0 
 with color grey at (8,12)
  _0111: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color grey at (8,6)
  + 3 delta pixels
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,15) and color black and layers
  _0: rectangle with size (3,15) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 . 0 0 . . 0 0 
0 . . 0 . 0 0 . . . 0 . . 0 0 
 with color red at (0,0)
  _01: rectangle with size (4,4) with mask 
. 0 0 . 
. 0 0 . 
0 0 0 0 
. 0 0 . 
 with color grey at (6,0)
  _011: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color grey at (8,6)
  _0111: rectangle with size (2,3) with mask 
. 0 0 
0 0 0 
 with color grey at (8,12)
  + 3 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,15) and color black and layers
  _0: rectangle with size (3,15) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 . 0 0 . . 0 0 
0 . . 0 . 0 0 . . . 0 . . 0 0 
 with color red at (0,0)
  _01: rectangle with size (4,4) with mask 
. 0 0 . 
. 0 0 . 
0 0 0 0 
. 0 0 . 
 with color grey at (6,0)
  _011: rectangle with size (2,3) with mask 
. 0 0 
0 0 0 
 with color grey at (8,12)
  _0111: rectangle with size (3,1) with model Full with color grey at (7,10)
  + 4 delta pixels
diff: 
! 24 wrong pixels (generated / expected)

TRAIN 6a1e5592.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,15) and color black and layers
  _0: rectangle with size (3,15) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 . 0 . 0 0 . 0 0 0 
0 . . 0 0 0 . . . 0 0 . . . 0 
 with color red at (0,0)
  _01: rectangle with size (4,3) with mask 
0 . 0 
0 0 0 
0 0 0 
0 0 0 
 with color grey at (6,11)
  _011: rectangle with size (3,4) with mask 
0 . . . 
0 0 0 . 
0 0 0 0 
 with color grey at (7,1)
  _0111: rectangle with size (4,2) with mask 
0 . 
0 0 
0 . 
0 0 
 with color grey at (6,7)
diff: 
! 23 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,15) and color black and layers
  _0: rectangle with size (3,15) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 . 0 . 0 0 . 0 0 0 
0 . . 0 0 0 . . . 0 0 . . . 0 
 with color red at (0,0)
  _01: rectangle with size (4,3) with mask 
0 . 0 
0 0 0 
0 0 0 
0 0 0 
 with color grey at (6,11)
  _011: rectangle with size (4,2) with mask 
0 . 
0 0 
0 . 
0 0 
 with color grey at (6,7)
  _0111: rectangle with size (3,4) with mask 
0 . . . 
0 0 0 . 
0 0 0 0 
 with color grey at (7,1)
diff: 
! 23 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,15) and color black and layers
  _0: rectangle with size (3,15) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 . 0 . 0 0 . 0 0 0 
0 . . 0 0 0 . . . 0 0 . . . 0 
 with color red at (0,0)
  _01: rectangle with size (4,3) with model Full with color grey at (6,11)
  _011: rectangle with size (3,4) with mask 
0 . . . 
0 0 0 . 
0 0 0 0 
 with color grey at (7,1)
  _0111: rectangle with size (4,2) with mask 
0 . 
0 0 
0 . 
0 0 
 with color grey at (6,7)
  + 1 delta pixels
diff: 
! 23 wrong pixels (generated / expected)

TEST 6a1e5592.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 22.9 sec (22.9 sec/task)
bits-train-error = 335.8 bits (335.8 bits/task)
acc-train-micro = 0.50 tasks (50.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.25
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-243] Checking task 6aa20dc0.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 526437.8 = 526440.2
DL output with Mo: L = 2.3 + 526437.8 = 526440.2
DL input+output M: L = 4.6 + 1052875.7 = 1052880.3

# learning a model for train pairs
2.000	
1.045	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.160	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.102	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.090	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.075	OUT ADD ^.layer_01 = ^.layer_0
0.062	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.052	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.044	OUT ADD ^.layer_010 = ^.layer_01
0.037	IN  ADD ^.layer_010 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.032	OUT ADD ^.layer_0101 = ^.layer_010
0.031	OUT SPE ^.size = ^.size
0.029	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.028	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.027	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.026	OUT SPE ^.layer_0111 = ^.layer_0111
0.025	OUT SPE ^.layer_0.shape.mask.size = ^.layer_01.shape.mask.size * '3
0.024	OUT SPE ^.color = ^.color
0.024	IN  SPE ^.layer_0111.shape.color = red
0.024	OUT SPE ^.layer_0.pos.j = middle(^.layer_0111)
0.023	IN  SPE ^.layer_010.shape.color = red
0.023	OUT SPE ^.layer_011.shape.color = ^.layer_0.shape.color
0.023	OUT SPE ^.layer_0.pos.i = max(^.layer_011.pos.i, ^.layer_010.pos.i)
0.022	OUT SPE ^.layer_011.pos.j = max(^.layer_01.pos.i, ^.layer_010.pos.i) - 2
0.022	OUT SPE ^.layer_011.pos.i = min(^.layer_01.pos.i, ^.layer_011.pos.i) + ^.layer_0111.pos.j - ^.layer_01.pos.j
0.022	IN  SPE ^.layer_010.shape.mask.model = Full
0.009	
0.009	IN  GEN ^.layer_010.shape.mask.model = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.color and layers
  _0: rectangle with size ^.layer_01.shape.mask.size * '3 with model ? with color ? at (max(^.layer_011.pos.i, ^.layer_010.pos.i),middle(^.layer_0111))
  _010: ^.layer_01
  _0101: ^.layer_010
  _01: ^.layer_0
  _011: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (min(^.layer_01.pos.i, ^.layer_011.pos.i) + ^.layer_0111.pos.j - ^.layer_01.pos.j,max(^.layer_01.pos.i, ^.layer_010.pos.i) - 2)
  _0111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model Full with color red at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color red at (?,?)

DL input  with Mi: L = 140.9 + 6585.3 = 6726.3
DL output with Mo: L = 307.0 + 4505.1 = 4812.1
DL input+output M: L = 447.9 + 11090.4 = 11538.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.color and layers
  _0: rectangle with size ^.layer_01.shape.mask.size * '3 with model ? with color ? at (max(^.layer_011.pos.i, ^.layer_010.pos.i),middle(^.layer_0111))
  _010: ^.layer_01
  _0101: ^.layer_010
  _01: ^.layer_0
  _011: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (min(^.layer_01.pos.i, ^.layer_011.pos.i) + ^.layer_0111.pos.j - ^.layer_01.pos.j,max(^.layer_01.pos.i, ^.layer_010.pos.i) - 2)
  _0111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color red at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color red at (?,?)

DL input  with Mi: L = 140.4 + 0.0 = 140.4
DL output with Mo: L = 307.0 + 4505.1 = 4812.1
DL input+output M: L = 447.4 + 4505.1 = 4952.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (20,19) and color blue and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
0 0 . 
0 . . 
 with color cyan at (4,5)
  _010: rectangle with size (2,2) with model Full with color red at (11,9)
  _01: rectangle with size (2,2) with model Full with color green at (15,5)
  _011: point with color red at (1,13)
  _0111: point with color red at (4,5)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,19) and color blue and layers
  _0: rectangle with size (6,6) with mask 
0 0 0 0 . . 
0 0 0 0 . . 
. . 0 0 0 0 
. . 0 0 0 0 
. . . . 0 0 
. . . . 0 0 
 with color cyan at (11,5)
  _010: 
3 3 
3 3 
 at (15,5)
  _0101: 
2 2 
2 2 
 at (11,9)
  _01: 
. 8 8 
8 8 . 
8 . . 
 at (4,5)
  _011: rectangle with size (3,3) with mask 
. 0 0 
0 0 . 
0 . . 
 with color cyan at (1,13)
  _0111: 
2 
 at (4,5)
  + 3 delta pixels
diff: 
   (196.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,19) and color blue and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
0 0 . 
0 . . 
 with color cyan at (4,5)
  _010: rectangle with size (2,2) with model Full with color red at (11,9)
  _01: rectangle with size (2,2) with model Full with color green at (15,5)
  _011: point with color red at (1,13)
  _0111: point with color red at (4,5)
  + 2 delta pixels
diff: 
! 41 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,19) and color blue and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
0 0 . 
0 . . 
 with color cyan at (4,5)
  _010: rectangle with size (2,2) with model Full with color red at (11,9)
  _01: rectangle with size (2,2) with model Full with color green at (15,5)
  _011: point with color green at (3,15)
  _0111: point with color red at (1,13)
  + 2 delta pixels
diff: 
! 60 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (20,19) and color blue and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
0 0 . 
0 . . 
 with color cyan at (4,5)
  _010: rectangle with size (2,2) with model Full with color red at (11,9)
  _01: rectangle with size (2,2) with model Full with color green at (15,5)
  _011: point with color green at (3,15)
  _0111: point with color red at (4,5)
  + 2 delta pixels
diff: 
! 46 wrong pixels (generated / expected)

TRAIN 6aa20dc0.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (20,21) and color yellow and layers
  _0: rectangle with size (3,3) with model Full with color pink at (13,5)
  _010: rectangle with size (3,3) with model Full with color red at (7,11)
  _01: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 0 
 with color blue at (2,3)
  _011: point with color pink at (2,5)
  _0111: point with color red at (4,3)
diff: 
   (0.0 bits)
data: a background with size (20,21) and color yellow and layers
  _0: rectangle with size (9,9) with mask 
0 0 0 0 0 0 . . . 
0 0 0 0 0 0 . . . 
0 0 0 0 0 0 . . . 
0 0 0 . . . 0 0 0 
0 0 0 . . . 0 0 0 
0 0 0 . . . 0 0 0 
. . . 0 0 0 0 0 0 
. . . 0 0 0 0 0 0 
. . . 0 0 0 0 0 0 
 with color blue at (7,5)
  _010: 
1 1 . 
1 . 1 
. 1 1 
 at (2,3)
  _0101: 
2 2 2 
2 2 2 
2 2 2 
 at (7,11)
  _01: 
6 6 6 
6 6 6 
6 6 6 
 at (13,5)
  _011: rectangle with size (1,1) with model Full with color pink at (2,5)
  _0111: 
2 
 at (4,3)
diff: 
   (93.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,21) and color yellow and layers
  _0: rectangle with size (3,3) with model Full with color pink at (13,5)
  _010: rectangle with size (3,3) with model Full with color red at (7,11)
  _01: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 0 
 with color blue at (2,3)
  _011: point with color pink at (2,5)
  _0111: point with color red at (4,3)
diff: 
! 83 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,21) and color yellow and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 0 
 with color blue at (2,3)
  _010: rectangle with size (3,3) with model Full with color red at (7,11)
  _01: rectangle with size (3,3) with model Full with color pink at (13,5)
  _011: point with color pink at (2,5)
  _0111: point with color red at (4,3)
diff: 
! 86 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (20,21) and color yellow and layers
  _0: rectangle with size (3,3) with model Full with color pink at (13,5)
  _010: rectangle with size (3,3) with model Full with color red at (7,11)
  _01: rectangle with size (1,2) with model Full with color blue at (2,3)
  _011: point with color pink at (2,5)
  _0111: point with color red at (4,3)
  + 4 delta pixels
diff: 
! 60 wrong pixels (generated / expected)

TRAIN 6aa20dc0.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (21,22) and color cyan and layers
  _0: rectangle with size (3,3) with model +-cross with color green at (5,6)
  _010: rectangle with size (1,1) with model Full with color red at (5,6)
  _01: rectangle with size (1,1) with model Full with color yellow at (7,8)
  _011: point with color yellow at (10,13)
  _0111: point with color red at (12,15)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (21,22) and color cyan and layers
  _0: rectangle with size (3,3) with model +-cross with color green at (10,13)
  _010: 
4 
 at (7,8)
  _0101: 
2 
 at (5,6)
  _01: 
. 3 . 
3 3 3 
. 3 . 
 at (5,6)
  _011: rectangle with size (3,3) with model +-cross with color green at (14,5)
  _0111: 
2 
 at (12,15)
  + 3 delta pixels
diff: 
   (161.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (21,22) and color cyan and layers
  _0: rectangle with size (3,3) with model +-cross with color green at (5,6)
  _010: rectangle with size (1,1) with model Full with color red at (5,6)
  _01: rectangle with size (1,1) with model Full with color yellow at (7,8)
  _011: point with color yellow at (10,13)
  _0111: point with color red at (12,15)
  + 2 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (21,22) and color cyan and layers
  _0: rectangle with size (3,3) with model +-cross with color green at (5,6)
  _010: rectangle with size (1,1) with model Full with color red at (5,6)
  _01: rectangle with size (1,1) with model Full with color yellow at (7,8)
  _011: point with color yellow at (10,13)
  _0111: point with color red at (14,7)
  + 2 delta pixels
diff: 
! 23 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (21,22) and color cyan and layers
  _0: rectangle with size (3,3) with model +-cross with color green at (5,6)
  _010: rectangle with size (1,1) with model Full with color red at (5,6)
  _01: rectangle with size (1,1) with model Full with color yellow at (7,8)
  _011: point with color red at (12,15)
  _0111: point with color red at (14,7)
  + 2 delta pixels
diff: 
! 24 wrong pixels (generated / expected)

TRAIN 6aa20dc0.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (22,22) and color green and layers
  _0: rectangle with size (3,3) with model Full with color yellow at (1,10)
  _010: rectangle with size (3,3) with model Full with color blue at (7,16)
  _01: rectangle with size (2,2) with model Full with color blue at (13,15)
  _011: point with color cyan at (4,6)
  _0111: point with color yellow at (4,7)
  + 10 delta pixels
diff:   ^.layer_0111.shape.color  ^.layer_010.shape.color
! 103 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (22,22) and color green and layers
  _0: rectangle with size (3,3) with model Full with color yellow at (1,10)
  _010: rectangle with size (3,3) with model Full with color blue at (7,16)
  _01: rectangle with size (2,2) with model Full with color blue at (13,15)
  _011: point with color cyan at (4,6)
  _0111: point with color cyan at (5,5)
  + 10 delta pixels
diff:   ^.layer_0111.shape.color  ^.layer_010.shape.color
! 103 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (22,22) and color green and layers
  _0: rectangle with size (3,3) with model Full with color yellow at (1,10)
  _010: rectangle with size (3,3) with model Full with color blue at (7,16)
  _01: rectangle with size (2,2) with model Full with color blue at (13,15)
  _011: point with color yellow at (4,7)
  _0111: point with color cyan at (4,6)
  + 10 delta pixels
diff:   ^.layer_0111.shape.color  ^.layer_010.shape.color
! 103 wrong pixels (generated / expected)

TEST 6aa20dc0.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.3 sec (59.3 sec/task)
bits-train-error = 4505.1 bits (4505.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-242] Checking task 6b9890af.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 542883.0 = 542885.4
DL output with Mo: L = 2.3 + 83533.1 = 83535.5
DL input+output M: L = 4.6 + 626416.2 = 626420.8

# learning a model for train pairs
2.000	
1.078	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.662	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.368	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.121	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.059	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.048	OUT SPE ^.layer_0.shape = ^.layer_0.shape
0.039	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.022	OUT SPE ^.layer_01.shape = scaleTo(^.layer_01.shape, ^.layer_0.shape.mask.size - (2, 2))
0.016	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.012	OUT SPE ^.layer_0.pos = '(0, 0)
0.008	OUT SPE ^.layer_01.pos = '(1, 1)
0.007	OUT SPE ^.color = black
0.007	IN  SPE ^.layer_0.shape.mask.model = Border
0.007	IN  SPE ^.layer_0.shape.color = red
0.007	IN  SPE ^.color = black
0.001	
0.001	IN  GEN ^.layer_0.shape.mask.model = ?
0.001	IN  GEN ^.layer_0.shape.color = ?
0.001	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: ^.layer_0.shape at '(0, 0)
  _01: scaleTo(^.layer_01.shape, ^.layer_0.shape.mask.size - (2, 2)) at '(1, 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Border with color red at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 77.0 + 2920.6 = 2997.6
DL output with Mo: L = 91.5 + 0.0 = 91.5
DL input+output M: L = 168.5 + 2920.6 = 3089.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: ^.layer_0.shape at '(0, 0)
  _01: scaleTo(^.layer_01.shape, ^.layer_0.shape.mask.size - (2, 2)) at '(1, 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 91.5 + 0.0 = 91.5
DL input+output M: L = 161.7 + 0.0 = 161.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (18,21) and color black and layers
  _0: rectangle with size (8,8) with model Border with color red at (7,6)
  _01: rectangle with size (3,3) with model +-cross with color cyan at (2,5)
diff: 
   (0.0 bits)
data: a background with size (8,8) and color black and layers
  _0: 
2 2 2 2 2 2 2 2 
2 . . . . . . 2 
2 . . . . . . 2 
2 . . . . . . 2 
2 . . . . . . 2 
2 . . . . . . 2 
2 . . . . . . 2 
2 2 2 2 2 2 2 2 
 at (0,0)
  _01: 
. . 8 8 . . 
. . 8 8 . . 
8 8 8 8 8 8 
8 8 8 8 8 8 
. . 8 8 . . 
. . 8 8 . . 
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,21) and color black and layers
  _0: rectangle with size (8,8) with model Border with color red at (7,6)
  _01: rectangle with size (3,3) with model +-cross with color cyan at (2,5)
diff: 
correct output grid

TRAIN 6b9890af.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (19,22) and color black and layers
  _0: rectangle with size (5,5) with model Border with color red at (2,2)
  _01: rectangle with size (3,3) with mask 
. 0 0 
0 . . 
. 0 0 
 with color blue at (9,10)
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: 
2 2 2 2 2 
2 . . . 2 
2 . . . 2 
2 . . . 2 
2 2 2 2 2 
 at (0,0)
  _01: 
. 1 1 
1 . . 
. 1 1 
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,22) and color black and layers
  _0: rectangle with size (5,5) with model Border with color red at (2,2)
  _01: rectangle with size (3,3) with mask 
. 0 0 
0 . . 
. 0 0 
 with color blue at (9,10)
diff: 
correct output grid

TRAIN 6b9890af.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (21,24) and color black and layers
  _0: rectangle with size (11,11) with model Border with color red at (1,2)
  _01: rectangle with size (3,3) with mask 
. 0 0 
0 . 0 
. . 0 
 with color yellow at (15,13)
diff: 
   (0.0 bits)
data: a background with size (11,11) and color black and layers
  _0: 
2 2 2 2 2 2 2 2 2 2 2 
2 . . . . . . . . . 2 
2 . . . . . . . . . 2 
2 . . . . . . . . . 2 
2 . . . . . . . . . 2 
2 . . . . . . . . . 2 
2 . . . . . . . . . 2 
2 . . . . . . . . . 2 
2 . . . . . . . . . 2 
2 . . . . . . . . . 2 
2 2 2 2 2 2 2 2 2 2 2 
 at (0,0)
  _01: 
. . . 4 4 4 4 4 4 
. . . 4 4 4 4 4 4 
. . . 4 4 4 4 4 4 
4 4 4 . . . 4 4 4 
4 4 4 . . . 4 4 4 
4 4 4 . . . 4 4 4 
. . . . . . 4 4 4 
. . . . . . 4 4 4 
. . . . . . 4 4 4 
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (21,24) and color black and layers
  _0: rectangle with size (11,11) with model Border with color red at (1,2)
  _01: rectangle with size (3,3) with mask 
. 0 0 
0 . 0 
. . 0 
 with color yellow at (15,13)
diff: 
correct output grid

TRAIN 6b9890af.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (24,26) and color black and layers
  _0: rectangle with size (14,14) with model Border with color red at (4,2)
  _01: rectangle with size (3,3) with model Odd Checkboard with color green at (4,20)
diff: 
correct output grid

TEST 6b9890af.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 5.4 sec (5.4 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-241] Checking task 6c434453.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79850.6 = 79852.9
DL output with Mo: L = 2.3 + 79850.6 = 79852.9
DL input+output M: L = 4.6 + 159701.1 = 159705.8

# learning a model for train pairs
2.000	
1.231	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.521	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.430	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.360	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.319	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.270	OUT ADD ^.layer_0 = ^.layer_011
0.229	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.189	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.153	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.130	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.100	OUT ADD ^.layer_01111 = ^.layer_0111
0.094	OUT SPE ^.layer_011.shape = coloring(^.layer_011.shape, red)
0.088	OUT SPE ^.layer_0111.shape = coloring(^.layer_011.shape, red)
0.082	OUT SPE ^.size = ^.size
0.078	IN  SPE ^.layer_011.shape.mask = 
. 0 . 
0 0 0 
. 0 . 

0.073	IN  SPE ^.layer_01.shape.mask = 
0 0 0 
0 . 0 
0 0 0 

0.070	OUT SPE ^.layer_011.pos = ^.layer_01.pos
0.068	OUT SPE ^.layer_0111.pos = corner(^.layer_0111.pos, ^.layer_011.pos) - (1, 3)
0.066	OUT SPE ^.layer_01.shape.mask.size.j = 3
0.065	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.063	IN  SPE ^.layer_0.shape.color = blue
0.062	IN  SPE ^.layer_01.shape.color = blue
0.061	IN  SPE ^.layer_011.shape.color = blue
0.059	IN  SPE ^.layer_0111.shape.color = blue
0.058	OUT SPE ^.layer_01.pos.i = bottom(^.layer_0) + ^.layer_01.pos.i - ^.layer_0.pos.i
0.058	OUT SPE ^.layer_01.pos.j = min(^.layer_01.pos.i, ^.layer_011.pos.i) * '2
0.057	IN  SPE ^.layer_0111.shape.mask.model = Full
0.056	OUT SPE ^.layer_01.shape.mask.size.i = ^.layer_0.shape.mask.size.j - ^.layer_0111.pos.i - ^.layer_0.pos.i
0.056	IN  SPE ^.color = black
0.055	OUT SPE ^.color = black
0.007	
0.007	IN  GEN ^.layer_011.shape.mask = rectangle with size (?,?) with model ?
0.007	IN  GEN ^.layer_01.shape.mask = rectangle with size (?,?) with model ?
0.007	IN  GEN ^.layer_0111.shape.color = ?
0.007	IN  GEN ^.layer_011.shape.color = ?
0.007	IN  GEN ^.layer_01.shape.color = ?
0.007	IN  GEN ^.layer_0.shape.color = ?
0.007	IN  GEN ^.layer_0111.shape.mask.model = ?
0.007	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_011
  _01: rectangle with size (^.layer_0.shape.mask.size.j - ^.layer_0111.pos.i - ^.layer_0.pos.i,3) with model ? with color ^.layer_01.shape.color at (bottom(^.layer_0) + ^.layer_01.pos.i - ^.layer_0.pos.i,min(^.layer_01.pos.i, ^.layer_011.pos.i) * '2)
  _011: coloring(^.layer_011.shape, red) at ^.layer_01.pos
  _0111: coloring(^.layer_011.shape, red) at corner(^.layer_0111.pos, ^.layer_011.pos) - (1, 3)
  _01111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color blue at (?,?)
  _01: 
0 0 0 
0 . 0 
0 0 0 
 with color blue at (?,?)
  _011: 
. 0 . 
0 0 0 
. 0 . 
 with color blue at (?,?)
  _0111: rectangle with size (?,?) with model Full with color blue at (?,?)

DL input  with Mi: L = 152.1 + 3796.7 = 3948.9
DL output with Mo: L = 299.3 + 138.4 = 437.7
DL input+output M: L = 451.5 + 3935.1 = 4386.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_011
  _01: rectangle with size (^.layer_0.shape.mask.size.j - ^.layer_0111.pos.i - ^.layer_0.pos.i,3) with model ? with color ^.layer_01.shape.color at (bottom(^.layer_0) + ^.layer_01.pos.i - ^.layer_0.pos.i,min(^.layer_01.pos.i, ^.layer_011.pos.i) * '2)
  _011: coloring(^.layer_011.shape, red) at ^.layer_01.pos
  _0111: coloring(^.layer_011.shape, red) at corner(^.layer_0111.pos, ^.layer_011.pos) - (1, 3)
  _01111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 0.0 = 125.8
DL output with Mo: L = 299.3 + 138.4 = 437.7
DL input+output M: L = 425.1 + 138.4 = 563.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,6) with mask 
. 0 . . . . 
0 0 0 . . . 
. 0 . 0 0 0 
. . . 0 . 0 
. . . 0 0 0 
 with color blue at (4,0)
  _01: rectangle with size (3,3) with model Border with color blue at (0,0)
  _011: rectangle with size (3,3) with model +-cross with color blue at (1,6)
  _0111: rectangle with size (1,2) with model Full with color blue at (7,8)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
. 1 . 
1 1 1 
. 1 . 
 at (1,6)
  _01: rectangle with size (3,3) with model +-cross with color blue at (4,0)
  _011: 
. 2 . 
2 2 2 
. 2 . 
 at (0,0)
  _0111: 
. 2 . 
2 2 2 
. 2 . 
 at (6,3)
  _01111: 
1 1 
 at (7,8)
diff: 
   (6.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,6) with mask 
. 0 . . . . 
0 0 0 . . . 
. 0 . 0 0 0 
. . . 0 . 0 
. . . 0 0 0 
 with color blue at (4,0)
  _01: rectangle with size (3,3) with model Border with color blue at (0,0)
  _011: rectangle with size (3,3) with model +-cross with color blue at (1,6)
  _0111: rectangle with size (1,2) with model Full with color blue at (7,8)
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,6) with mask 
. 0 . . . . 
0 0 0 . . . 
. 0 . 0 0 0 
. . . 0 . 0 
. . . 0 0 0 
 with color blue at (4,0)
  _01: rectangle with size (3,3) with model +-cross with color blue at (1,6)
  _011: rectangle with size (3,3) with model Border with color blue at (0,0)
  _0111: rectangle with size (1,2) with model Full with color blue at (7,8)
diff: 
! 29 wrong pixels (generated / expected)

TRAIN 6c434453.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Border with color blue at (0,4)
  _01: rectangle with size (3,3) with model Border with color blue at (5,1)
  _011: rectangle with size (3,3) with model +-cross with color blue at (3,7)
  _0111: rectangle with size (2,2) with model Full with color blue at (1,0)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
. 1 . 
1 1 1 
. 1 . 
 at (3,7)
  _01: rectangle with size (2,3) with mask 
0 . . 
0 0 0 
 with color blue at (7,6)
  _011: 
. 2 . 
2 2 2 
. 2 . 
 at (5,1)
  _0111: 
. 2 . 
2 2 2 
. 2 . 
 at (0,4)
  _01111: 
1 1 
1 1 
 at (1,0)
diff: 
   (7.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Border with color blue at (0,4)
  _01: rectangle with size (3,3) with model Border with color blue at (5,1)
  _011: rectangle with size (3,3) with model +-cross with color blue at (3,7)
  _0111: rectangle with size (2,2) with model Full with color blue at (1,0)
  + 4 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Border with color blue at (0,4)
  _01: rectangle with size (3,3) with model +-cross with color blue at (3,7)
  _011: rectangle with size (3,3) with model Border with color blue at (5,1)
  _0111: rectangle with size (2,2) with model Full with color blue at (1,0)
  + 4 delta pixels
diff: 
! 33 wrong pixels (generated / expected)

TRAIN 6c434453.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Border with color blue at (2,1)
  _01: rectangle with size (3,3) with model Border with color blue at (7,1)
  _011: rectangle with size (2,2) with model Full with color blue at (8,8)
  _0111: rectangle with size (3,3) with model +-cross with color blue at (0,7)
  + 2 delta pixels
diff: 
! 12 wrong pixels (generated / expected)

TEST 6c434453.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 21.3 sec (21.3 sec/task)
bits-train-error = 138.4 bits (138.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-240] Checking task 6cdd2623.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 310663.5 = 310665.8
DL output with Mo: L = 2.3 + 310663.5 = 310665.8
DL input+output M: L = 4.6 + 621326.9 = 621331.6

# learning a model for train pairs
2.000	
1.139	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.296	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.199	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.167	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.159	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.152	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.147	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.142	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.139	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.136	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.133	IN  ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.131	IN  ADD ^.layer_01111110 = point with color ? at (?,?)
0.129	OUT SPE ^.size = ^.size
0.127	OUT SPE ^.layer_0.shape.mask.size.j = ^.size.j
0.127	OUT SPE ^.layer_0.pos.j = '0
0.126	OUT SPE ^.layer_01.pos.i = ^.layer_01111110.pos.i
0.126	OUT SPE ^.layer_01.shape.color = ^.layer_01111110.shape.color
0.125	OUT SPE ^.layer_01.pos = corner(^.layer_01111110.pos, ^.layer_011.pos) + translationSym(flipWidth, ^.layer_0, ^)
0.125	OUT SPE ^.layer_0.shape.color = ^.layer_01111110.shape.color
0.125	OUT SPE ^.layer_0.shape.mask.size.i = 1
0.124	IN  SPE ^.layer_01111.shape.mask.model = Full
0.124	IN  SPE ^.layer_0111111.shape.mask.model = Full
0.124	OUT SPE ^.layer_0.shape.mask.model = Full
0.124	OUT SPE ^.layer_01.shape.mask.model = Full
0.123	IN  SPE ^.color = black
0.123	OUT SPE ^.color = black
0.003	
0.003	IN  DEL ^.layer_01111
0.003	IN  GEN ^.layer_0111111.shape.mask.model = ?
0.003	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (1,^.size.j) with model Full with color ^.layer_01111110.shape.color at (?,'0)
  _01: rectangle with size (?,?) with model Full with color ^.layer_01111110.shape.color at corner(^.layer_01111110.pos, ^.layer_011.pos) + translationSym(flipWidth, ^.layer_0, ^)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111110: point with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 227.1 + 37192.7 = 37419.7
DL output with Mo: L = 196.4 + 613.4 = 809.8
DL input+output M: L = 423.5 + 37806.1 = 38229.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (1,^.size.j) with model Full with color ^.layer_01111110.shape.color at (?,'0)
  _01: rectangle with size (?,?) with model Full with color ^.layer_01111110.shape.color at corner(^.layer_01111110.pos, ^.layer_011.pos) + translationSym(flipWidth, ^.layer_0, ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111110: point with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 198.5 + 20.0 = 218.5
DL output with Mo: L = 196.4 + 613.4 = 809.8
DL input+output M: L = 395.0 + 633.4 = 1028.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (11,22) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 . 
. . 0 
 with color red at (0,5)
  _01: rectangle with size (2,3) with mask 
. . 0 
0 0 . 
 with color grey at (2,4)
  _011: rectangle with size (3,2) with mask 
. 0 
. 0 
0 . 
 with color red at (4,2)
  _0111: rectangle with size (3,2) with model Even Checkboard with color red at (5,18)
  _011111: rectangle with size (1,5) with model Full with color grey at (8,3)
  _01111110: point with color green at (0,11)
  _0111111: rectangle with size (2,1) with model Full with color red at (3,14)
  + 33 delta pixels
diff: 
   (0.0 bits)
data: a background with size (11,22) and color black and layers
  _0: rectangle with size (1,22) with model Full with color green at (8,0)
  _01: rectangle with size (11,1) with model Full with color green at (0,11)
diff: 
   (19.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,22) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 . 
. . 0 
 with color red at (0,5)
  _01: rectangle with size (2,3) with mask 
. . 0 
0 0 . 
 with color grey at (2,4)
  _011: rectangle with size (3,2) with mask 
. 0 
. 0 
0 . 
 with color red at (4,2)
  _0111: rectangle with size (3,2) with model Even Checkboard with color red at (5,18)
  _011111: rectangle with size (1,5) with model Full with color grey at (8,3)
  _01111110: point with color green at (0,11)
  _0111111: rectangle with size (2,1) with model Full with color red at (3,14)
  + 33 delta pixels
diff: 
! 52 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,22) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 . 
. . 0 
 with color red at (0,5)
  _01: rectangle with size (2,3) with mask 
. . 0 
0 0 . 
 with color grey at (2,4)
  _011: rectangle with size (3,2) with mask 
. 0 
. 0 
0 . 
 with color red at (4,2)
  _0111: rectangle with size (3,2) with model Even Checkboard with color red at (5,18)
  _011111: rectangle with size (1,5) with model Full with color grey at (8,3)
  _01111110: point with color red at (0,17)
  _0111111: rectangle with size (2,1) with model Full with color red at (3,14)
  + 33 delta pixels
diff: 
! 54 wrong pixels (generated / expected)

TRAIN 6cdd2623.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (13,20) and color black and layers
  _0: rectangle with size (2,1) with model Full with color blue at (1,12)
  _01: rectangle with size (2,2) with model Even Checkboard with color cyan at (8,13)
  _011: rectangle with size (1,1) with model Full with color cyan at (0,5)
  _0111: rectangle with size (1,1) with model Full with color cyan at (1,10)
  _011111: rectangle with size (1,1) with model Full with color blue at (2,8)
  _01111110: point with color red at (3,0)
  _0111111: rectangle with size (1,1) with model Full with color red at (3,19)
  + 16 delta pixels
diff: 
   (0.0 bits)
data: a background with size (13,20) and color black and layers
  _0: rectangle with size (1,20) with model Full with color red at (11,0)
  _01: rectangle with size (1,20) with model Full with color red at (3,0)
diff: 
   (21.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,20) and color black and layers
  _0: rectangle with size (2,1) with model Full with color blue at (1,12)
  _01: rectangle with size (2,2) with model Even Checkboard with color cyan at (8,13)
  _011: rectangle with size (1,1) with model Full with color cyan at (0,5)
  _0111: rectangle with size (1,1) with model Full with color cyan at (1,10)
  _011111: rectangle with size (1,1) with model Full with color blue at (2,8)
  _01111110: point with color red at (3,0)
  _0111111: rectangle with size (1,1) with model Full with color red at (3,19)
  + 16 delta pixels
diff: 
! 60 wrong pixels (generated / expected)

TRAIN 6cdd2623.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (15,17) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color yellow at (0,1)
  _01: rectangle with size (3,2) with mask 
0 . 
. 0 
. 0 
 with color yellow at (11,14)
  _011: rectangle with size (1,5) with model Full with color yellow at (14,0)
  _0111: rectangle with size (2,2) with model Even Checkboard with color yellow at (3,3)
  _011111: rectangle with size (2,1) with model Full with color grey at (4,8)
  _01111110: point with color cyan at (0,13)
  _0111111: rectangle with size (2,1) with model Full with color yellow at (13,8)
  + 27 delta pixels
diff: 
   (2.0 bits)
data: a background with size (15,17) and color black and layers
  _0: rectangle with size (1,17) with model Full with color cyan at (10,0)
  _01: rectangle with size (15,1) with model Full with color cyan at (0,13)
diff: 
   (20.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,17) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color yellow at (0,1)
  _01: rectangle with size (3,2) with mask 
0 . 
. 0 
. 0 
 with color yellow at (11,14)
  _011: rectangle with size (1,5) with model Full with color yellow at (14,0)
  _0111: rectangle with size (2,2) with model Even Checkboard with color yellow at (3,3)
  _011111: rectangle with size (2,1) with model Full with color grey at (4,8)
  _01111110: point with color yellow at (0,7)
  _0111111: rectangle with size (2,1) with model Full with color yellow at (13,8)
  + 27 delta pixels
diff: 
! 48 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,17) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color yellow at (0,1)
  _01: rectangle with size (3,2) with mask 
0 . 
. 0 
. 0 
 with color yellow at (11,14)
  _011: rectangle with size (1,5) with model Full with color yellow at (14,0)
  _0111: rectangle with size (2,2) with model Even Checkboard with color yellow at (3,3)
  _011111: rectangle with size (2,1) with model Full with color grey at (4,8)
  _01111110: point with color cyan at (0,13)
  _0111111: rectangle with size (2,1) with model Full with color yellow at (13,8)
  + 27 delta pixels
diff: 
! 46 wrong pixels (generated / expected)

TRAIN 6cdd2623.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
undefined expression: Corner: vectors on same row/column

TEST 6cdd2623.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 26.3 sec (26.3 sec/task)
bits-train-error = 613.4 bits (613.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-239] Checking task 6cf79266.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 499711.3 = 499713.6
DL output with Mo: L = 2.3 + 499711.3 = 499713.6
DL input+output M: L = 4.6 + 999422.5 = 999427.2

# learning a model for train pairs
2.000	
1.425	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.850	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.463	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.080	OUT ADD ^.layer_0 = ^.layer_0
0.060	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.058	OUT SPE ^.size = ^.size
0.057	OUT ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.054	OUT SPE ^.layer_01.shape.mask = 
0 0 0 
0 0 0 
0 0 0 

0.054	OUT SPE ^.layer_01.shape.color = blue
0.054	OUT SPE ^.layer_00.shape.mask.model = Full
0.054	IN  SPE ^.color = black
0.054	OUT SPE ^.color = black
0.016	
0.016	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0: ^.layer_0
  _01: 
0 0 0 
0 0 0 
0 0 0 
 with color blue at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.1 + 18939.7 = 18981.8
DL output with Mo: L = 75.5 + 7743.9 = 7819.4
DL input+output M: L = 117.6 + 26683.6 = 26801.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0: ^.layer_0
  _01: 
0 0 0 
0 0 0 
0 0 0 
 with color blue at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 75.5 + 7743.9 = 7819.4
DL input+output M: L = 117.5 + 7743.9 = 7861.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (20,20) with mask 
0 . . 0 . . 0 0 0 0 0 0 . . 0 0 0 0 . . 
0 . 0 0 0 0 0 0 . . 0 0 0 0 . 0 0 . 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . 0 0 
. 0 0 0 0 0 . . . 0 . 0 0 . 0 0 . . . 0 
0 0 0 0 0 0 . 0 . . 0 0 0 . . . 0 0 . 0 
. 0 . 0 . 0 . . 0 . 0 . 0 . 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 0 . . 0 . 0 0 0 . . . 0 
. . . 0 0 0 . . . 0 0 0 . 0 . 0 . . . 0 
0 0 . . 0 . . 0 0 0 0 . . 0 . 0 . . . 0 
. . 0 . . . 0 0 . 0 0 0 0 . 0 0 0 . 0 0 
0 0 0 . 0 0 0 0 0 . . 0 . . 0 0 0 0 0 0 
0 . 0 0 0 0 0 . 0 0 0 0 . 0 . 0 0 0 . 0 
0 . . 0 0 0 0 . . 0 0 0 . 0 0 0 0 0 0 0 
0 0 . 0 0 0 0 0 0 0 0 . 0 0 0 . 0 0 . 0 
. . 0 0 0 0 . 0 0 . 0 0 0 0 . 0 0 0 . 0 
0 . . 0 . 0 . . . 0 0 0 . 0 . 0 0 . 0 . 
. 0 . 0 . 0 0 . . 0 . . 0 . 0 . . . 0 . 
0 0 0 0 0 . 0 0 0 0 0 . . . 0 . 0 0 . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 . . 0 0 . 0 0 
0 0 0 . . 0 0 0 0 . 0 0 . 0 . 0 . . . 0 
 with color grey at (0,0)
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _00: rectangle with size (16,1) with model Full with color grey at (1,5)
  _0: 
5#. . 5#. . 5#5#5#5#5#5#. . 5#5#5#5#. . 
5#. 5#5#5#5#5#5#. . 5#5#5#5#. 5#5#. 5#5#
5#5#5#5#5#5#5#5#5#5#5#5#5#5#5#5#. . 5#5#
. 5#5#5#5#5#. . . 5#. 5#5#. 5#5#. . . 5#
5#5#5#5#5#5#. 5#. . 5#5#5#. . . 5#5#. 5#
. 5#. 5#. 5#. . 5#. 5#. 5#. 5#. 5#5#5#5#
5#5#5#5#5#5#5#5#5#. . 5#. 5#5#5#. . . 5#
. . . 5#5#5#. . . 5#5#5#. 5#. 5#. . . 5#
5#5#. . 5#. . 5#5#5#5#. . 5#. 5#. . . 5#
. . 5#. . . 5#5#. 5#5#5#5#. 5#5#5#. 5#5#
5#5#5#. 5#5#5#5#5#. . 5#. . 5#5#5#5#5#5#
5#. 5#5#5#5#5#. 5#5#5#5#. 5#. 5#5#5#. 5#
5#. . 5#5#5#5#. . 5#5#5#. 5#5#5#5#5#5#5#
5#5#. 5#5#5#5#5#5#5#5#. 5#5#5#. 5#5#. 5#
. . 5#5#5#5#. 5#5#. 5#5#5#5#. 5#5#5#. 5#
5#. . 5#. 5#. . . 5#5#5#. 5#. 5#5#. 5#. 
. 5#. 5#. 5#5#. . 5#. . 5#. 5#. . . 5#. 
5#5#5#5#5#. 5#5#5#5#5#. . . 5#. 5#5#. 5#
5#5#5#5#5#5#5#5#5#5#5#5#5#. . 5#5#. 5#5#
5#5#5#. . 5#5#5#5#. 5#5#. 5#. 5#. . . 5#
 at (0,0)
  _01: 
0 0 0 
0 0 0 
0 0 0 
 with color blue at (6,16)
  + 2 delta pixels
diff: 
   (133.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (20,20) with mask 
0 . . 0 . . 0 0 0 0 0 0 . . 0 0 0 0 . . 
0 . 0 0 0 0 0 0 . . 0 0 0 0 . 0 0 . 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . 0 0 
. 0 0 0 0 0 . . . 0 . 0 0 . 0 0 . . . 0 
0 0 0 0 0 0 . 0 . . 0 0 0 . . . 0 0 . 0 
. 0 . 0 . 0 . . 0 . 0 . 0 . 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 0 . . 0 . 0 0 0 . . . 0 
. . . 0 0 0 . . . 0 0 0 . 0 . 0 . . . 0 
0 0 . . 0 . . 0 0 0 0 . . 0 . 0 . . . 0 
. . 0 . . . 0 0 . 0 0 0 0 . 0 0 0 . 0 0 
0 0 0 . 0 0 0 0 0 . . 0 . . 0 0 0 0 0 0 
0 . 0 0 0 0 0 . 0 0 0 0 . 0 . 0 0 0 . 0 
0 . . 0 0 0 0 . . 0 0 0 . 0 0 0 0 0 0 0 
0 0 . 0 0 0 0 0 0 0 0 . 0 0 0 . 0 0 . 0 
. . 0 0 0 0 . 0 0 . 0 0 0 0 . 0 0 0 . 0 
0 . . 0 . 0 . . . 0 0 0 . 0 . 0 0 . 0 . 
. 0 . 0 . 0 0 . . 0 . . 0 . 0 . . . 0 . 
0 0 0 0 0 . 0 0 0 0 0 . . . 0 . 0 0 . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 . . 0 0 . 0 0 
0 0 0 . . 0 0 0 0 . 0 0 . 0 . 0 . . . 0 
 with color grey at (0,0)
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color grey and layers
  _0: rectangle with size (14,20) with mask 
. . . . . . . . . . . . . . . . . . 0 0 
. . . . . . . . . . . . . . . . . 0 . . 
. . . . . . . . . . . . . . . . 0 0 . . 
. . . . . . 0 0 0 . 0 . . 0 . . 0 0 0 . 
. . . . . . 0 . 0 0 . . . 0 0 0 . . 0 . 
. . . . . . 0 0 . 0 . 0 . 0 . 0 . . . . 
. . . . . . . . . 0 0 . 0 . . . 0 0 0 . 
0 0 0 . . . 0 0 0 . . . 0 . 0 . 0 0 0 . 
. . 0 0 . 0 0 . . . . 0 0 . 0 . 0 0 0 . 
0 0 . 0 0 0 . . . . . . . 0 . . . 0 . . 
. . . 0 . . . . . . . . 0 0 . . . . . . 
. . . . . . . . . . . . 0 . 0 . . . . . 
. . . . . . . . . . . . 0 . . . . . . . 
. . . . . . . . . . . 0 . . . . . . . . 
 with color black at (0,0)
  + 72 delta pixels
diff: 
! 273 wrong pixels (generated / expected)

TRAIN 6cf79266.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (20,20) with mask 
0 0 0 0 . 0 . 0 . 0 0 . . 0 0 0 . 0 . . 
. . 0 0 . . 0 . 0 0 . 0 . 0 0 . . 0 0 . 
0 0 0 0 0 . . 0 . . . 0 . 0 0 . 0 0 0 0 
0 . 0 0 . . . . 0 . 0 0 . 0 0 0 . 0 0 . 
. . . 0 . 0 . 0 0 0 . 0 0 0 . 0 0 0 . . 
0 0 . . 0 0 . 0 0 0 0 . . 0 . 0 0 0 0 . 
. 0 . . . . 0 0 . 0 . . 0 . . . 0 . 0 . 
0 . 0 . . . . . . 0 0 0 . 0 0 0 0 0 0 0 
. 0 0 . . . . 0 . 0 0 . 0 0 . . 0 0 0 0 
. . . 0 0 . . 0 0 0 0 0 . 0 . 0 . 0 0 0 
0 . 0 0 . 0 0 0 . . 0 . 0 . . . 0 0 . 0 
0 . . 0 . . . 0 0 0 0 . . 0 . 0 . 0 0 0 
. 0 0 . . . 0 0 . 0 0 0 0 . . 0 . . 0 0 
. . 0 . 0 0 0 0 . . . 0 0 0 . . 0 . 0 . 
. . 0 0 0 . 0 0 . 0 0 0 0 0 0 0 0 . . 0 
. . 0 . 0 0 . . 0 . 0 . 0 0 . 0 0 0 . . 
0 0 . 0 0 . . . . . . . 0 . 0 . . . 0 0 
. 0 . 0 . . . . . . 0 0 0 . . 0 0 . . . 
0 . . 0 . . . . . . . 0 . . 0 0 0 0 0 0 
0 . 0 0 . . . . . . . 0 . 0 . 0 0 0 . 0 
 with color green at (0,0)
  + 10 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _00: rectangle with size (12,1) with model Full with color green at (0,17)
  _0: 
3 3 3 3 . 3 . 3 . 3 3 . . 3 3 3 . 3 . . 
. . 3 3 . . 3 . 3 3 . 3 . 3 3 . . 3 3 . 
3 3 3 3 3 . . 3 . . . 3 . 3 3 . 3 3 3 3 
3 . 3 3 . . . . 3 . 3 3 . 3 3 3 . 3 3 . 
. . . 3 . 3 . 3 3 3 . 3 3 3 . 3 3 3 . . 
3 3 . . 3 3 . 3 3 3 3 . . 3 . 3 3 3 3 . 
. 3 . . . . 3 3 . 3 . . 3 . . . 3 . 3 . 
3 . 3 . . . . . . 3 3 3 . 3 3 3 3 3 3 3 
. 3 3 . . . . 3 . 3 3 . 3 3 . . 3 3 3 3 
. . . 3 3 . . 3 3 3 3 3 . 3 . 3 . 3 3 3 
3 . 3 3 . 3 3 3 . . 3 . 3 . . . 3 3 . 3 
3 . . 3 . . . 3 3 3 3 . . 3 . 3 . 3 3 3 
. 3 3 . . . 3 3 . 3 3 3 3 . . 3 . . 3 3 
. . 3 . 3 3 3 3 . . . 3 3 3 . . 3 . 3 . 
. . 3 3 3 . 3 3 . 3 3 3 3 3 3 3 3 . . 3 
. . 3 . 3 3 . . 3 . 3 . 3 3 . 3 3 3 . . 
3 3 . 3 3 . . . . . . . 3 . 3 . . . 3 3 
. 3 . 3 . . . . . . 3 3 3 . . 3 3 . . . 
3 . . 3 . . . . . . . 3 . . 3 3 3 3 3 3 
3 . 3 3 . . . . . . . 3 . 3 . 3 3 3 . 3 
 at (0,0)
  _01: 
0 0 0 
0 0 0 
0 0 0 
 with color blue at (6,3)
  + 11 delta pixels
diff: 
   (509.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (20,20) with mask 
0 0 0 0 . 0 . 0 . 0 0 . . 0 0 0 . 0 . . 
. . 0 0 . . 0 . 0 0 . 0 . 0 0 . . 0 0 . 
0 0 0 0 0 . . 0 . . . 0 . 0 0 . 0 0 0 0 
0 . 0 0 . . . . 0 . 0 0 . 0 0 0 . 0 0 . 
. . . 0 . 0 . 0 0 0 . 0 0 0 . 0 0 0 . . 
0 0 . . 0 0 . 0 0 0 0 . . 0 . 0 0 0 0 . 
. 0 . . . . 0 0 . 0 . . 0 . . . 0 . 0 . 
0 . 0 . . . . . . 0 0 0 . 0 0 0 0 0 0 0 
. 0 0 . . . . 0 . 0 0 . 0 0 . . 0 0 0 0 
. . . 0 0 . . 0 0 0 0 0 . 0 . 0 . 0 0 0 
0 . 0 0 . 0 0 0 . . 0 . 0 . . . 0 0 . 0 
0 . . 0 . . . 0 0 0 0 . . 0 . 0 . 0 0 0 
. 0 0 . . . 0 0 . 0 0 0 0 . . 0 . . 0 0 
. . 0 . 0 0 0 0 . . . 0 0 0 . . 0 . 0 . 
. . 0 0 0 . 0 0 . 0 0 0 0 0 0 0 0 . . 0 
. . 0 . 0 0 . . 0 . 0 . 0 0 . 0 0 0 . . 
0 0 . 0 0 . . . . . . . 0 . 0 . . . 0 0 
. 0 . 0 . . . . . . 0 0 0 . . 0 0 . . . 
0 . . 0 . . . . . . . 0 . . 0 0 0 0 0 0 
0 . 0 0 . . . . . . . 0 . 0 . 0 0 0 . 0 
 with color green at (0,0)
  + 10 delta pixels
diff: 
! 23 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color green and layers
  _0: rectangle with size (20,20) with mask 
. . . . 0 . 0 . 0 . . 0 0 . . . . . . . 
. . . . 0 0 . 0 . . 0 . 0 . . . . . . . 
. . . . . 0 0 . 0 0 0 . 0 . . . . . . . 
. 0 . . 0 0 0 0 . 0 . . 0 . . . . . . . 
0 0 0 . 0 . 0 . . . 0 . . . 0 . . . . . 
. . 0 0 . . 0 . . . . 0 0 . 0 . . . . . 
0 . 0 0 0 0 . . 0 . 0 0 . 0 0 0 . . . . 
. 0 . 0 0 0 0 0 0 . . . 0 . . . . . . . 
0 . . 0 0 0 0 . 0 . . 0 . . 0 0 . . . . 
0 0 0 . . 0 0 . . . . . 0 . 0 . 0 . . . 
. 0 . . 0 . . . . . . 0 . 0 0 0 . . . . 
. 0 0 . 0 0 0 . . . . 0 0 . 0 . 0 . . . 
0 . . 0 0 0 . . . . . . . 0 0 . 0 0 . . 
0 0 . 0 . . . . . . . . . . 0 0 . 0 . 0 
. 0 . . . . . . . . . . . . . . . 0 0 . 
0 0 . 0 . . . . . . . . . . 0 . . . 0 0 
. . 0 . . . . . . . . . . 0 . 0 0 0 . . 
0 . 0 . . . . . . . . . . 0 0 . . 0 0 0 
. 0 0 . . . . . . . . . 0 0 . . . . . . 
. 0 . . . . . . . . . . 0 . 0 . . . . . 
 with color black at (0,0)
  + 48 delta pixels
diff: 
! 233 wrong pixels (generated / expected)

TRAIN 6cf79266.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (20,20) with mask 
. . 0 0 0 0 . 0 0 . . 0 0 . . 0 . 0 0 0 
. . 0 . 0 . 0 . 0 0 0 . . . . 0 0 . . 0 
. . . . . 0 . . 0 0 0 0 . 0 . . . . 0 . 
. . 0 . 0 . 0 0 . . . 0 0 . . 0 0 . 0 . 
. . 0 . . 0 . . 0 . 0 0 0 0 . . 0 . . 0 
0 0 0 0 0 0 0 0 . 0 0 . 0 0 . . . 0 . 0 
. . . 0 . 0 . . 0 0 . 0 . 0 . . . . 0 0 
. 0 0 0 0 . 0 . 0 . . 0 0 0 . . . . . 0 
. . . 0 . . . . 0 0 0 . . 0 0 . . . 0 0 
0 0 . 0 0 0 . 0 . . 0 . 0 0 . 0 0 . 0 . 
0 . . . . . . . . 0 . . 0 . . . . 0 0 . 
0 0 . . 0 0 0 . 0 0 0 0 . 0 . . 0 0 0 0 
. 0 . 0 0 0 . . . 0 0 . 0 0 . 0 . . 0 0 
. . 0 0 . 0 0 0 0 0 . 0 0 . 0 0 0 . 0 0 
. . 0 0 0 . 0 . 0 0 . 0 . 0 0 0 . 0 0 0 
0 . 0 0 0 . 0 . 0 0 0 0 0 . . 0 0 0 . . 
0 0 0 . . . 0 0 0 . 0 0 . 0 . 0 . . . . 
0 0 0 . . . 0 . 0 0 . 0 . . 0 . . . . . 
0 . . . . . 0 0 . 0 . . . 0 . 0 0 0 . 0 
. 0 0 . 0 0 . 0 . . 0 0 0 0 . . 0 . 0 0 
 with color orange at (0,0)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _00: rectangle with size (3,3) with model Full with color blue at (5,14)
  _0: 
. . 7#7#7#7#. 7#7#. . 7#7#. . 7#. 7#7#7#
. . 7#. 7#. 7#. 7#7#7#. . . . 7#7#. . 7#
. . . . . 7#. . 7#7#7#7#. 7#. . . . 7#. 
. . 7#. 7#. 7#7#. . . 7#7#. . 7#7#. 7#. 
. . 7#. . 7#. . 7#. 7#7#7#7#. . 7#. . 7#
7#7#7#7#7#7#7#7#. 7#7#. 7#7#. . . 7#. 7#
. . . 7#. 7#. . 7#7#. 7#. 7#. . . . 7#7#
. 7#7#7#7#. 7#. 7#. . 7#7#7#. . . . . 7#
. . . 7#. . . . 7#7#7#. . 7#7#. . . 7#7#
7#7#. 7#7#7#. 7#. . 7#. 7#7#. 7#7#. 7#. 
7#. . . . . . . . 7#. . 7#. . . . 7#7#. 
7#7#. . 7#7#7#. 7#7#7#7#. 7#. . 7#7#7#7#
. 7#. 7#7#7#. . . 7#7#. 7#7#. 7#. . 7#7#
. . 7#7#. 7#7#7#7#7#. 7#7#. 7#7#7#. 7#7#
. . 7#7#7#. 7#. 7#7#. 7#. 7#7#7#. 7#7#7#
7#. 7#7#7#. 7#. 7#7#7#7#7#. . 7#7#7#. . 
7#7#7#. . . 7#7#7#. 7#7#. 7#. 7#. . . . 
7#7#7#. . . 7#. 7#7#. 7#. . 7#. . . . . 
7#. . . . . 7#7#. 7#. . . 7#. 7#7#7#. 7#
. 7#7#. 7#7#. 7#. . 7#7#7#7#. . 7#. 7#7#
 at (0,0)
  _01: 
0 0 0 
0 0 0 
0 0 0 
 with color blue at (16,3)
  + 2 delta pixels
diff: 
   (131.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (20,20) with mask 
. . 0 0 0 0 . 0 0 . . 0 0 . . 0 . 0 0 0 
. . 0 . 0 . 0 . 0 0 0 . . . . 0 0 . . 0 
. . . . . 0 . . 0 0 0 0 . 0 . . . . 0 . 
. . 0 . 0 . 0 0 . . . 0 0 . . 0 0 . 0 . 
. . 0 . . 0 . . 0 . 0 0 0 0 . . 0 . . 0 
0 0 0 0 0 0 0 0 . 0 0 . 0 0 . . . 0 . 0 
. . . 0 . 0 . . 0 0 . 0 . 0 . . . . 0 0 
. 0 0 0 0 . 0 . 0 . . 0 0 0 . . . . . 0 
. . . 0 . . . . 0 0 0 . . 0 0 . . . 0 0 
0 0 . 0 0 0 . 0 . . 0 . 0 0 . 0 0 . 0 . 
0 . . . . . . . . 0 . . 0 . . . . 0 0 . 
0 0 . . 0 0 0 . 0 0 0 0 . 0 . . 0 0 0 0 
. 0 . 0 0 0 . . . 0 0 . 0 0 . 0 . . 0 0 
. . 0 0 . 0 0 0 0 0 . 0 0 . 0 0 0 . 0 0 
. . 0 0 0 . 0 . 0 0 . 0 . 0 0 0 . 0 0 0 
0 . 0 0 0 . 0 . 0 0 0 0 0 . . 0 0 0 . . 
0 0 0 . . . 0 0 0 . 0 0 . 0 . 0 . . . . 
0 0 0 . . . 0 . 0 0 . 0 . . 0 . . . . . 
0 . . . . . 0 0 . 0 . . . 0 . 0 0 0 . 0 
. 0 0 . 0 0 . 0 . . 0 0 0 0 . . 0 . 0 0 
 with color orange at (0,0)
  + 2 delta pixels
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color orange and layers
  _0: rectangle with size (20,20) with mask 
. 0 . . . . 0 . . 0 0 . . 0 0 . 0 . . . 
0 0 . 0 . 0 . 0 . . . 0 0 0 0 . . 0 0 . 
0 0 0 0 0 . 0 0 . . . . 0 . 0 0 0 0 . 0 
. 0 . 0 . 0 . . 0 0 0 . . 0 0 . . 0 . 0 
0 0 . 0 0 . 0 0 . 0 . . . . 0 0 . 0 0 . 
. . . . . . . . 0 . . 0 . . 0 0 0 . 0 . 
0 0 0 . 0 . 0 0 . . 0 . 0 . 0 0 0 0 . . 
0 . . . . 0 . 0 . 0 0 . . . 0 0 0 0 0 . 
0 0 0 . 0 0 0 0 . . . 0 0 . . 0 0 0 . . 
. . 0 . . . 0 . 0 0 . 0 . . 0 . . 0 . . 
. 0 0 0 0 0 0 0 0 . 0 0 . 0 0 0 0 . . . 
. . 0 0 . . . 0 . . . . 0 . 0 0 . . . . 
0 . 0 . . . 0 0 0 . . 0 . . 0 . 0 0 . . 
0 0 . . . . . . . . 0 . . 0 . . . 0 . . 
0 0 . . . . . . . . 0 . 0 . . . 0 . . . 
. 0 . . . . . . . . . . . 0 0 . . . 0 0 
. . . . . . . . . 0 . . 0 . 0 . 0 0 0 0 
. . . . . . . 0 . . 0 . 0 0 . 0 0 0 0 0 
. . . . . . . . 0 . 0 0 0 . 0 . . . 0 . 
. . . . . . . . 0 0 . . . . 0 0 . 0 . . 
 with color black at (0,0)
  + 21 delta pixels
diff: 
! 230 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (20,20) and color orange and layers
  _0: rectangle with size (7,7) with mask 
. . . . 0 . . 
. . . . . 0 . 
. . . . . 0 . 
. . . 0 0 0 . 
. . . 0 0 0 . 
. 0 0 0 0 0 . 
0 . . 0 . . 0 
 with color black at (13,0)
  + 174 delta pixels
diff: 
! 233 wrong pixels (generated / expected)

TRAIN 6cf79266.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color yellow and layers
  _0: rectangle with size (20,20) with mask 
. . . . . 0 . . . 0 0 0 . 0 . . . . . 0 
. . . . 0 0 . 0 . . 0 0 0 0 . . . . . 0 
. . . 0 0 . 0 . 0 . 0 . . . . . . 0 . 0 
. . 0 . 0 0 . 0 0 0 0 0 0 . . . 0 . 0 0 
. 0 0 . . 0 . . . . . . . 0 . . 0 . 0 . 
. . 0 0 . 0 0 . . . . . . 0 0 . . 0 . 0 
0 0 0 . 0 0 0 0 . . . . . 0 . 0 . . 0 . 
. 0 . . 0 0 0 . . 0 0 0 0 . . 0 0 0 0 0 
0 . . . 0 0 0 . . . 0 0 . 0 . . . 0 0 0 
. 0 0 0 . . 0 0 . 0 0 . 0 . . . 0 . 0 . 
0 0 0 . 0 . 0 . . . 0 0 . 0 . . . 0 . . 
0 . . 0 0 . . . . 0 0 0 . . . . . 0 . . 
0 0 . 0 0 . 0 0 . 0 0 . 0 . . 0 0 0 . . 
. 0 . . 0 . 0 0 . . . 0 0 0 0 . . . 0 0 
0 . . . . 0 0 . 0 . 0 0 . . 0 . . . . . 
. 0 0 . . 0 . 0 . 0 0 . 0 . 0 . 0 . 0 0 
. . 0 . 0 . 0 . . 0 0 . . . 0 0 0 0 . . 
. 0 0 0 0 . . 0 . . 0 . 0 . 0 0 0 . . . 
0 0 0 0 0 . . . . 0 . 0 0 . 0 0 0 0 0 0 
. . 0 0 0 0 0 . . 0 0 0 . 0 . 0 . 0 . . 
 with color black at (0,0)
  + 5 delta pixels
diff: 
! 236 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (20,20) with mask 
. 0 . 0 0 . 0 0 0 . . . . . 0 0 0 0 0 . 
. . 0 0 . . 0 . 0 0 . . . . 0 0 0 0 0 . 
0 0 0 . . 0 . 0 . 0 . 0 0 0 0 0 0 . 0 . 
0 0 . 0 . . 0 . . . . . . 0 0 0 . 0 . . 
0 . . 0 0 . 0 0 0 0 0 0 0 . 0 0 . 0 . 0 
0 0 . . 0 . . 0 0 0 0 0 0 . . 0 0 . 0 . 
. . . 0 . . . . 0 0 0 0 0 . 0 . 0 0 . 0 
0 . 0 0 . . . 0 0 . . . . 0 0 . . . . . 
. 0 0 0 . . . 0 0 0 . . 0 . 0 0 0 . . . 
0 . . . 0 0 . . 0 . . 0 . 0 0 0 . 0 . 0 
. . . 0 . 0 . 0 0 0 . . 0 . 0 0 0 . 0 0 
. 0 0 . . 0 0 0 0 . . . 0 0 0 0 0 . 0 . 
. . 0 . . 0 . . 0 . . 0 . 0 0 . . . 0 0 
0 . 0 0 . 0 . . 0 0 0 . . . . 0 0 0 . . 
. 0 0 0 0 . . 0 . 0 . . 0 0 . 0 0 0 0 0 
0 . . 0 0 . 0 . 0 . . 0 . 0 . 0 . 0 . . 
0 0 . 0 . 0 . 0 0 . . 0 0 0 . . . . 0 0 
0 . . . . 0 0 . 0 0 . 0 . 0 . . . 0 0 0 
. . . . . 0 0 0 0 . 0 . . 0 . . . . . . 
. . . . . . . 0 0 . . . 0 . 0 . . . . . 
 with color yellow at (0,0)
  + 6 delta pixels
diff: 
! 38 wrong pixels (generated / expected)

TEST 6cf79266.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 57.8 sec (57.8 sec/task)
bits-train-error = 7743.9 bits (7743.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-238] Checking task 6d0160f0.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 194274.3 = 194276.6
DL output with Mo: L = 2.3 + 194274.3 = 194276.6
DL input+output M: L = 4.6 + 388548.5 = 388553.2

# learning a model for train pairs
2.000	
1.363	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.891	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.594	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.322	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.294	OUT SPE ^.layer_0.shape.mask = applySym(rotate180, ^.layer_0.shape.mask) and ^.layer_0.shape.mask
0.288	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.283	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.278	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.273	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.269	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.264	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.260	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.255	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.250	IN  ADD ^.layer_010 = point with color ? at (?,?)
0.246	OUT SPE ^.size = ^.size
0.244	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.241	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.238	IN  SPE ^.layer_0.shape.color = grey
0.237	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.236	OUT SPE ^.layer_0111.shape.color = orange
0.235	OUT SPE ^.layer_01.shape.color = yellow
0.234	OUT SPE ^.layer_011.pos.j = center(^.layer_01111) - ^.layer_011111.pos.i - ^.layer_01.pos.i
0.233	OUT SPE ^.layer_01.pos.j = center(^.layer_01111) - ^.layer_01111.pos.i - ^.layer_0.pos.i
0.232	IN  SPE ^.layer_01.shape.mask.model = Full
0.232	IN  SPE ^.color = black
0.231	OUT SPE ^.color = black
0.012	
0.012	IN  DEL ^.layer_0111111
0.012	IN  GEN ^.layer_0.shape.color = ?
0.012	IN  GEN ^.layer_01.shape.mask.model = ?
0.012	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: applySym(rotate180, ^.layer_0.shape.mask) and ^.layer_0.shape.mask with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: point with color yellow at (?,center(^.layer_01111) - ^.layer_01111.pos.i - ^.layer_0.pos.i)
  _011: point with color ? at (?,center(^.layer_01111) - ^.layer_011111.pos.i - ^.layer_01.pos.i)
  _0111: point with color orange at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)
  _010: point with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)

DL input  with Mi: L = 180.9 + 42542.7 = 42723.5
DL output with Mo: L = 234.2 + 1986.1 = 2220.4
DL input+output M: L = 415.1 + 44528.8 = 44943.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: applySym(rotate180, ^.layer_0.shape.mask) and ^.layer_0.shape.mask with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: point with color yellow at (?,center(^.layer_01111) - ^.layer_01111.pos.i - ^.layer_0.pos.i)
  _011: point with color ? at (?,center(^.layer_01111) - ^.layer_011111.pos.i - ^.layer_01.pos.i)
  _0111: point with color orange at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: point with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)

DL input  with Mi: L = 159.3 + 0.0 = 159.3
DL output with Mo: L = 234.2 + 1986.1 = 2220.4
DL input+output M: L = 393.5 + 1986.1 = 2379.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 0 . . 0 . . . 
. . . 0 0 . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. 0 . 0 . . 0 0 0 . . 
. . . 0 0 . . 0 . 0 . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 0 . . 0 . 0 . 
. 0 0 0 . 0 . 0 0 0 . 
. . . 0 0 . . 0 . . . 
 with color grey at (0,0)
  _010: point with color green at (0,0)
  _01: rectangle with size (10,1) with model Full with color orange at (0,4)
  _011: point with color pink at (0,6)
  _0111: point with color cyan at (0,8)
  _01111: point with color grey at (0,9)
  _011111: point with color orange at (0,10)
  + 30 delta pixels
diff: 
   (0.0 bits)
data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: point with color yellow at (0,10)
  _011: point with color red at (2,10)
  _0111: point with color orange at (1,8)
  + 1 delta pixels
diff: 
   (70.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 0 . . 0 . . . 
. . . 0 0 . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. 0 . 0 . . 0 0 0 . . 
. . . 0 0 . . 0 . 0 . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 0 . . 0 . 0 . 
. 0 0 0 . 0 . 0 0 0 . 
. . . 0 0 . . 0 . . . 
 with color grey at (0,0)
  _010: point with color green at (0,0)
  _01: rectangle with size (10,1) with model Full with color orange at (0,4)
  _011: point with color pink at (0,6)
  _0111: point with color cyan at (0,8)
  _01111: point with color grey at (0,9)
  _011111: point with color orange at (0,10)
  + 30 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 0 . . 0 . . . 
. . . 0 0 . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. 0 . 0 . . 0 0 0 . . 
. . . 0 0 . . 0 . 0 . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 0 . . 0 . 0 . 
. 0 0 0 . 0 . 0 0 0 . 
. . . 0 0 . . 0 . . . 
 with color grey at (0,0)
  _010: point with color green at (0,0)
  _01: rectangle with size (8,1) with model Full with color orange at (2,0)
  _011: point with color orange at (0,4)
  _0111: point with color pink at (0,6)
  _01111: point with color cyan at (0,8)
  _011111: point with color grey at (0,9)
  + 31 delta pixels
diff: 
! 5 wrong pixels (generated / expected)

TRAIN 6d0160f0.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _010: point with color green at (0,0)
  _01: rectangle with size (1,1) with model Full with color red at (0,5)
  _011: point with color pink at (0,9)
  _0111: point with color orange at (1,2)
  _01111: point with color brown at (1,10)
  _011111: point with color pink at (2,1)
  + 14 delta pixels
diff: 
   (0.0 bits)
data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: point with color yellow at (5,10)
  _011: point with color brown at (4,9)
  _0111: point with color orange at (6,8)
diff: 
   (28.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _010: point with color green at (0,0)
  _01: rectangle with size (1,1) with model Full with color red at (0,5)
  _011: point with color pink at (0,9)
  _0111: point with color orange at (1,2)
  _01111: point with color brown at (1,10)
  _011111: point with color pink at (2,1)
  + 14 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _010: point with color green at (0,0)
  _01: rectangle with size (1,1) with model Full with color red at (0,5)
  _011: point with color pink at (0,9)
  _0111: point with color orange at (1,2)
  _01111: point with color pink at (2,1)
  _011111: point with color brown at (1,10)
  + 14 delta pixels
diff: 
! 5 wrong pixels (generated / expected)

TRAIN 6d0160f0.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _010: point with color orange at (0,1)
  _01: rectangle with size (3,1) with model Full with color green at (2,5)
  _011: point with color pink at (0,5)
  _0111: point with color orange at (0,8)
  _01111: point with color cyan at (1,0)
  _011111: point with color green at (1,1)
  + 20 delta pixels
diff: 
   (0.0 bits)
data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: point with color yellow at (5,0)
  _011: point with color cyan at (5,2)
  _0111: point with color orange at (6,2)
  + 1 delta pixels
diff: 
   (70.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _010: point with color orange at (0,1)
  _01: rectangle with size (3,1) with model Full with color green at (2,5)
  _011: point with color pink at (0,5)
  _0111: point with color orange at (0,8)
  _01111: point with color cyan at (1,0)
  _011111: point with color green at (1,1)
  + 20 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _010: point with color orange at (0,1)
  _01: rectangle with size (3,1) with model Full with color green at (2,5)
  _011: point with color pink at (0,5)
  _0111: point with color orange at (0,8)
  _01111: point with color green at (1,1)
  _011111: point with color cyan at (1,0)
  + 20 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 6d0160f0.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _010: point with color green at (0,0)
  _01: rectangle with size (1,1) with model Full with color blue at (0,5)
  _011: point with color red at (0,10)
  _0111: point with color red at (1,1)
  _01111: point with color green at (1,5)
  _011111: point with color pink at (1,9)
  + 16 delta pixels
diff: 
   (0.0 bits)
data: a background with size (11,11) and color black and layers
  _0: 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _01: point with color yellow at (0,5)
  _011: point with color green at (2,5)
  _0111: point with color orange at (1,5)
diff: 
   (28.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _010: point with color green at (0,0)
  _01: rectangle with size (1,1) with model Full with color blue at (0,5)
  _011: point with color red at (0,10)
  _0111: point with color red at (1,1)
  _01111: point with color green at (1,5)
  _011111: point with color pink at (1,9)
  + 16 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _010: point with color green at (0,0)
  _01: rectangle with size (4,1) with model Full with color orange at (5,0)
  _011: point with color blue at (0,5)
  _0111: point with color red at (0,10)
  _01111: point with color red at (1,1)
  _011111: point with color green at (1,5)
  + 16 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 6d0160f0.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _010: point with color red at (0,0)
  _01: rectangle with size (4,1) with model Full with color pink at (1,8)
  _011: point with color green at (0,2)
  _0111: point with color red at (0,4)
  _01111: point with color green at (0,9)
  _011111: point with color orange at (1,0)
  + 27 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color grey at (0,0)
  _010: point with color green at (0,2)
  _01: rectangle with size (1,5) with model Full with color red at (0,0)
  _011: point with color green at (0,9)
  _0111: point with color orange at (1,0)
  _01111: point with color pink at (1,1)
  _011111: point with color orange at (1,5)
  + 27 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TEST 6d0160f0.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 42.6 sec (42.6 sec/task)
bits-train-error = 1986.1 bits (1986.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-237] Checking task 6d0aefbc.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 14046.4 = 14048.7
DL output with Mo: L = 2.3 + 27897.7 = 27900.0
DL input+output M: L = 4.6 + 41944.1 = 41948.8

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = unfoldSym( [ id flipWidth ], ^)
0.514	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.289	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.246	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.005	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
unfoldSym( [ id flipWidth ], ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 60.4 + 3384.3 = 3444.7
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 71.7 + 3384.3 = 3456.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
unfoldSym( [ id flipWidth ], ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 13.6 + 0.0 = 13.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
6 6 6 
1 6 1 
8 8 6 

diff: 
   (0.0 bits)
data: 
6 6 6 6 6 6 
1 6 1 1 6 1 
8 8 6 6 8 8 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
6 6 6 
1 6 1 
8 8 6 

diff: 
correct output grid

TRAIN 6d0aefbc.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
6 8 1 
6 1 1 
1 1 6 

diff: 
   (0.0 bits)
data: 
6 8 1 1 8 6 
6 1 1 1 1 6 
1 1 6 6 1 1 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
6 8 1 
6 1 1 
1 1 6 

diff: 
correct output grid

TRAIN 6d0aefbc.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
1 1 1 
8 1 6 
6 8 8 

diff: 
   (0.0 bits)
data: 
1 1 1 1 1 1 
8 1 6 6 1 8 
6 8 8 8 8 6 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 1 
8 1 6 
6 8 8 

diff: 
correct output grid

TRAIN 6d0aefbc.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: 
1 1 1 
1 6 6 
6 6 6 

diff: 
   (0.0 bits)
data: 
1 1 1 1 1 1 
1 6 6 6 6 1 
6 6 6 6 6 6 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 1 
1 6 6 
6 6 6 

diff: 
correct output grid

TRAIN 6d0aefbc.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
6 8 6 
8 6 8 
1 6 1 

diff: 
correct output grid

TEST 6d0aefbc.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 0.6 sec (0.6 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-236] Checking task 6d58a25d.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 499711.3 = 499713.6
DL output with Mo: L = 2.3 + 499711.3 = 499713.6
DL input+output M: L = 4.6 + 999422.5 = 999427.2

# learning a model for train pairs
2.000	
1.059	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.177	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.136	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.110	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.089	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.070	OUT ADD ^.layer_00 = ^.layer_0
0.068	IN  SPE ^.layer_0.shape.mask = 
. . . 0 . . . 
. . 0 0 0 . . 
. 0 0 . 0 0 . 
0 . . . . . 0 

0.066	OUT SPE ^.size = ^.size
0.065	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.064	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.062	OUT ADD ^.layer_01111 = point with color ? at (?,?)
0.061	OUT ADD ^.layer_011111 = point with color ? at (?,?)
0.060	OUT ADD ^.layer_0111111 = point with color ? at (?,?)
0.058	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.057	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.056	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.054	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.053	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.052	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.050	IN  ADD ^.layer_01111111 = point with color ? at (?,?)
0.049	OUT SPE ^.layer_0111111 = ^.layer_011111
0.048	OUT SPE ^.layer_01111 = ^.layer_01111
0.048	OUT SPE ^.layer_011111.shape = ^.layer_011111.shape
0.047	OUT SPE ^.layer_0111.shape = ^.layer_0111.shape
0.047	OUT SPE ^.layer_011.shape = ^.layer_011.shape
0.021	
0.021	IN  GEN ^.layer_0.shape.mask = rectangle with size (?,?) with model ?
0.021	IN  DEL ^.layer_01111111
0.021	IN  DEL ^.layer_0111111
0.021	IN  DEL ^.layer_01
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: ^.layer_011.shape at (?,?)
  _0111: ^.layer_0111.shape at (?,?)
  _01111: ^.layer_01111
  _011111: ^.layer_011111.shape at (?,?)
  _0111111: ^.layer_011111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
. . . 0 . . . 
. . 0 0 0 . . 
. 0 0 . 0 0 . 
0 . . . . . 0 
 with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)

DL input  with Mi: L = 197.0 + 12948.3 = 13145.3
DL output with Mo: L = 126.8 + 10142.7 = 10269.5
DL input+output M: L = 323.8 + 23091.0 = 23414.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: ^.layer_011.shape at (?,?)
  _0111: ^.layer_0111.shape at (?,?)
  _01111: ^.layer_01111
  _011111: ^.layer_011111.shape at (?,?)
  _0111111: ^.layer_011111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)

DL input  with Mi: L = 114.2 + 0.0 = 114.2
DL output with Mo: L = 126.8 + 10142.7 = 10269.5
DL input+output M: L = 241.0 + 10142.7 = 10383.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (4,7) with mask 
. . . 0 . . . 
. . 0 0 0 . . 
. 0 0 . 0 0 . 
0 . . . . . 0 
 with color brown at (5,6)
  _011: point with color cyan at (2,5)
  _0111: point with color cyan at (3,16)
  _01111: point with color cyan at (4,3)
  _011111: point with color cyan at (10,1)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _00: 
. . . 9#. . . 
. . 9#9#9#. . 
. 9#9#. 9#9#. 
9#. . . . . 9#
 at (5,6)
  _0: rectangle with size (13,1) with model Full with color cyan at (7,9)
  _01: rectangle with size (1,1) with model Full with color cyan at (2,5)
  _011: 
8 
 at (3,16)
  _0111: 
8 
 at (10,18)
  _01111: 
8 
 at (4,3)
  _011111: 
8 
 at (18,15)
  _0111111: 
8 
 at (10,1)
  + 1 delta pixels
diff: 
   (150.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (4,7) with mask 
. . . 0 . . . 
. . 0 0 0 . . 
. 0 0 . 0 0 . 
0 . . . . . 0 
 with color brown at (5,6)
  _011: point with color cyan at (2,5)
  _0111: point with color cyan at (3,16)
  _01111: point with color cyan at (4,3)
  _011111: point with color cyan at (10,1)
  + 4 delta pixels
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (4,7) with mask 
. . . 0 . . . 
. . 0 0 0 . . 
. 0 0 . 0 0 . 
0 . . . . . 0 
 with color brown at (5,6)
  _011: point with color cyan at (2,5)
  _0111: point with color cyan at (3,16)
  _01111: point with color cyan at (4,3)
  _011111: point with color cyan at (10,18)
  + 4 delta pixels
diff: 
! 22 wrong pixels (generated / expected)

TRAIN 6d58a25d.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (4,7) with mask 
. . . 0 . . . 
. . 0 0 0 . . 
. 0 0 . 0 0 . 
0 . . . . . 0 
 with color orange at (5,4)
  _011: point with color red at (1,8)
  _0111: point with color red at (2,2)
  _01111: point with color red at (4,13)
  _011111: point with color red at (4,16)
  + 7 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _00: 
. . . 7#. . . 
. . 7#7#7#. . 
. 7#7#. 7#7#. 
7#. . . . . 7#
 at (5,4)
  _0: rectangle with size (12,1) with model Full with color red at (8,6)
  _01: rectangle with size (12,1) with model Full with color red at (8,9)
  _011: 
2 
 at (1,8)
  _0111: 
2 
 at (2,2)
  _01111: 
2 
 at (4,13)
  _011111: 
2 
 at (9,17)
  _0111111: 
2 
 at (4,16)
  + 4 delta pixels
diff: 
   (284.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (4,7) with mask 
. . . 0 . . . 
. . 0 0 0 . . 
. 0 0 . 0 0 . 
0 . . . . . 0 
 with color orange at (5,4)
  _011: point with color red at (1,8)
  _0111: point with color red at (2,2)
  _01111: point with color red at (4,13)
  _011111: point with color red at (4,16)
  + 7 delta pixels
diff: 
! 35 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (4,7) with mask 
. . . 0 . . . 
. . 0 0 0 . . 
. 0 0 . 0 0 . 
0 . . . . . 0 
 with color orange at (5,4)
  _011: point with color red at (1,8)
  _0111: point with color red at (2,2)
  _01111: point with color red at (4,13)
  _011111: point with color red at (9,17)
  + 7 delta pixels
diff: 
! 35 wrong pixels (generated / expected)

TRAIN 6d58a25d.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (4,7) with mask 
. . . 0 . . . 
. . 0 0 0 . . 
. 0 0 . 0 0 . 
0 . . . . . 0 
 with color yellow at (4,9)
  _011: point with color green at (1,14)
  _0111: point with color green at (2,5)
  _01111: point with color green at (2,10)
  _011111: point with color green at (4,1)
  + 16 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _00: 
. . . 4 . . . 
. . 4 4 4 . . 
. 4 4 . 4 4 . 
4 . . . . . 4 
 at (4,9)
  _0: rectangle with size (14,2) with model Full with color green at (6,12)
  _01: rectangle with size (13,1) with model Full with color green at (7,10)
  _011: 
3 
 at (1,14)
  _0111: 
3 
 at (2,5)
  _01111: 
3 
 at (2,10)
  _011111: 
3 
 at (5,7)
  _0111111: 
3 
 at (4,1)
  + 11 delta pixels
diff: 
   (580.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (4,7) with mask 
. . . 0 . . . 
. . 0 0 0 . . 
. 0 0 . 0 0 . 
0 . . . . . 0 
 with color yellow at (4,9)
  _011: point with color green at (1,14)
  _0111: point with color green at (2,5)
  _01111: point with color green at (2,10)
  _011111: point with color green at (4,1)
  + 16 delta pixels
diff: 
! 58 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (4,7) with mask 
. . . 0 . . . 
. . 0 0 0 . . 
. 0 0 . 0 0 . 
0 . . . . . 0 
 with color yellow at (4,9)
  _011: point with color green at (1,14)
  _0111: point with color green at (2,5)
  _01111: point with color green at (2,10)
  _011111: point with color green at (5,7)
  + 16 delta pixels
diff: 
! 58 wrong pixels (generated / expected)

TRAIN 6d58a25d.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (4,7) with mask 
. . . 0 . . . 
. . 0 0 0 . . 
. 0 0 . 0 0 . 
0 . . . . . 0 
 with color blue at (3,3)
  _011: point with color pink at (1,4)
  _0111: point with color pink at (1,10)
  _01111: point with color pink at (1,18)
  _011111: point with color pink at (2,11)
  + 16 delta pixels
diff: 
! 60 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (4,7) with mask 
. . . 0 . . . 
. . 0 0 0 . . 
. 0 0 . 0 0 . 
0 . . . . . 0 
 with color blue at (3,3)
  _011: point with color pink at (1,4)
  _0111: point with color pink at (1,10)
  _01111: point with color pink at (1,18)
  _011111: point with color pink at (3,2)
  + 16 delta pixels
diff: 
! 60 wrong pixels (generated / expected)

TEST 6d58a25d.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 60.9 sec (60.9 sec/task)
bits-train-error = 10142.7 bits (10142.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-235] Checking task 6d75e8bb.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 106966.1 = 106968.4
DL output with Mo: L = 2.3 + 106966.1 = 106968.4
DL input+output M: L = 4.6 + 213932.1 = 213936.8

# learning a model for train pairs
2.000	
1.218	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.558	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.358	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.165	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.045	OUT ADD ^.layer_00 = ^.layer_0
0.039	OUT SPE ^.size = ^.size
0.038	IN  SPE ^.layer_0.shape.color = cyan
0.036	OUT SPE ^.layer_0.shape.color = red
0.035	OUT SPE ^.layer_0.pos.i = 2
0.033	OUT SPE ^.layer_0.pos.j = ^.layer_0.pos.i
0.032	OUT SPE ^.layer_0.shape.mask.model = Full
0.032	IN  SPE ^.color = black
0.031	OUT SPE ^.color = black
0.009	
0.009	IN  GEN ^.layer_0.shape.color = ?
0.009	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model Full with color red at (2,^.layer_0.pos.i)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color cyan at (?,?)

DL input  with Mi: L = 45.4 + 2339.7 = 2385.2
DL output with Mo: L = 63.1 + 861.2 = 924.3
DL input+output M: L = 108.5 + 3200.9 = 3309.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model Full with color red at (2,^.layer_0.pos.i)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 63.1 + 861.2 = 924.3
DL input+output M: L = 105.1 + 861.2 = 966.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (14,10) and color black and layers
  _0: rectangle with size (9,4) with mask 
0 0 0 . 
0 . . . 
0 0 0 0 
0 0 . . 
0 0 0 . 
0 . . . 
0 0 0 . 
0 0 0 . 
0 0 . . 
 with color cyan at (2,1)
diff: 
   (0.0 bits)
data: a background with size (14,10) and color black and layers
  _00: 
8 8 8 . 
8 . . . 
8 8 8 8 
8 8 . . 
8 8 8 . 
8 . . . 
8 8 8 . 
8 8 8 . 
8 8 . . 
 at (2,1)
  _0: rectangle with size (9,3) with model Full with color red at (2,2)
diff: 
   (16.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,10) and color black and layers
  _0: rectangle with size (9,4) with mask 
0 0 0 . 
0 . . . 
0 0 0 0 
0 0 . . 
0 0 0 . 
0 . . . 
0 0 0 . 
0 0 0 . 
0 0 . . 
 with color cyan at (2,1)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,10) and color black and layers
  _0: rectangle with size (7,2) with model Full with color cyan at (4,1)
  + 11 delta pixels
diff: 
! 23 wrong pixels (generated / expected)

TRAIN 6d75e8bb.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (7,8) and color black and layers
  _0: rectangle with size (4,6) with mask 
0 0 0 0 0 0 
0 . 0 0 . 0 
0 . 0 . . 0 
. . 0 . 0 0 
 with color cyan at (1,1)
diff: 
   (0.0 bits)
data: a background with size (7,8) and color black and layers
  _00: 
8 8 8 8 8 8 
8 . 8 8 . 8 
8 . 8 . . 8 
. . 8 . 8 8 
 at (1,1)
  _0: rectangle with size (3,5) with model Full with color red at (2,1)
diff: 
   (14.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,8) and color black and layers
  _0: rectangle with size (4,6) with mask 
0 0 0 0 0 0 
0 . 0 0 . 0 
0 . 0 . . 0 
. . 0 . 0 0 
 with color cyan at (1,1)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,8) and color black and layers
  _0: rectangle with size (4,6) with model Full with color cyan at (1,1)
  + 8 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (7,8) and color black and layers
  _0: rectangle with size (1,6) with model Full with color cyan at (1,1)
  + 10 delta pixels
diff: 
! 16 wrong pixels (generated / expected)

TRAIN 6d75e8bb.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (9,8) and color black and layers
  _0: rectangle with size (6,5) with mask 
0 0 0 0 0 
. . 0 . 0 
. 0 0 0 0 
. . 0 0 0 
. . . 0 0 
. . 0 0 0 
 with color cyan at (1,1)
diff: 
   (0.0 bits)
data: a background with size (9,8) and color black and layers
  _00: 
8 8 8 8 8 
. . 8 . 8 
. 8 8 8 8 
. . 8 8 8 
. . . 8 8 
. . 8 8 8 
 at (1,1)
  _0: rectangle with size (5,3) with model Full with color red at (2,1)
  + 1 delta pixels
diff: 
   (55.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,8) and color black and layers
  _0: rectangle with size (6,5) with mask 
0 0 0 0 0 
. . 0 . 0 
. 0 0 0 0 
. . 0 0 0 
. . . 0 0 
. . 0 0 0 
 with color cyan at (1,1)
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,8) and color black and layers
  _0: rectangle with size (4,2) with model Full with color cyan at (3,4)
  + 11 delta pixels
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,8) and color black and layers
  _0: rectangle with size (4,3) with model Full with color cyan at (3,3)
  + 11 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TRAIN 6d75e8bb.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,11) and color black and layers
  _0: rectangle with size (6,7) with mask 
0 . . . . . . 
0 . . . 0 0 . 
0 . 0 . . 0 . 
0 0 0 . . 0 . 
0 0 0 0 . 0 0 
0 0 0 0 0 0 0 
 with color cyan at (2,2)
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,11) and color black and layers
  _0: rectangle with size (2,7) with model Full with color cyan at (6,2)
  + 13 delta pixels
diff: 
! 27 wrong pixels (generated / expected)

TEST 6d75e8bb.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 4.6 sec (4.6 sec/task)
bits-train-error = 861.2 bits (861.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-234] Checking task 6e02f1e3.json: 5 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 17558.0 = 17560.3
DL output with Mo: L = 2.3 + 17558.0 = 17560.3
DL input+output M: L = 4.6 + 35116.0 = 35120.7

# learning a model for train pairs
2.000	
1.338	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.702	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.477	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.341	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.303	OUT SPE ^.size = ^.size
0.281	OUT SPE ^.layer_0.pos = '(0, 0)
0.263	OUT SPE ^.layer_0.shape.mask.size.j = ^.layer_0.shape.mask.size.j
0.247	OUT SPE ^.layer_0.shape.color = grey
0.240	OUT SPE ^.color = black
0.041	

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,^.layer_0.shape.mask.size.j) with model ? with color grey at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 3504.5 = 3546.5
DL output with Mo: L = 45.1 + 624.5 = 669.6
DL input+output M: L = 87.1 + 4129.0 = 4216.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,^.layer_0.shape.mask.size.j) with model ? with color grey at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 45.1 + 624.5 = 669.6
DL input+output M: L = 87.1 + 624.5 = 711.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color red and layers
  _0: rectangle with size (2,3) with mask 
0 . 0 
0 0 0 
 with color green at (1,0)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
. 0 . 
. . 0 
 with color grey at (0,0)
diff: 
   (16.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color red and layers
  _0: rectangle with size (2,3) with mask 
0 . 0 
0 0 0 
 with color green at (1,0)
diff: 
! 5 wrong pixels (generated / expected)

TRAIN 6e02f1e3.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,3) and color red and layers
  _0: rectangle with size (1,3) with model Full with color green at (0,0)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
. 0 . 
0 . . 
 with color grey at (0,0)
diff: 
   (16.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color red and layers
  _0: rectangle with size (1,3) with model Full with color green at (0,0)
  + 3 delta pixels
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color green and layers
  _0: rectangle with size (2,2) with model Full with color yellow at (1,0)
  + 3 delta pixels
diff: 
! 5 wrong pixels (generated / expected)

TRAIN 6e02f1e3.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with model Full with color yellow at (0,0)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color grey at (0,0)
diff: 
   (6.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with model Full with color yellow at (0,0)
diff: 
! 3 wrong pixels (generated / expected)

TRAIN 6e02f1e3.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with model Full with color green at (0,0)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color grey at (0,0)
diff: 
   (6.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with model Full with color green at (0,0)
diff: 
! 3 wrong pixels (generated / expected)

TRAIN 6e02f1e3.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: a background with size (3,3) and color yellow and layers
  _0: rectangle with size (1,3) with model Full with color green at (2,0)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
. 0 . 
. . 0 
 with color grey at (0,0)
diff: 
   (16.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color yellow and layers
  _0: rectangle with size (1,3) with model Full with color green at (2,0)
diff: 
! 5 wrong pixels (generated / expected)

TRAIN 6e02f1e3.json/5: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color red and layers
  _0: rectangle with size (1,3) with model Full with color yellow at (0,0)
  + 3 delta pixels
diff: 
! 5 wrong pixels (generated / expected)

TEST 6e02f1e3.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.1 sec (3.1 sec/task)
bits-train-error = 624.5 bits (624.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-233] Checking task 6e19193c.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79850.6 = 79852.9
DL output with Mo: L = 2.3 + 79850.6 = 79852.9
DL input+output M: L = 4.6 + 159701.1 = 159705.8

# learning a model for train pairs
2.000	
1.067	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.203	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.171	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.149	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.120	OUT ADD ^.layer_01 = ^.layer_0
0.097	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.067	OUT ADD ^.layer_011 = ^.layer_01
0.051	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.046	OUT SPE ^.size = ^.size
0.042	IN  SPE ^.layer_0.shape.mask = 
0 0 
. 0 

0.038	IN  SPE ^.layer_01.shape.mask = 
0 . 
0 0 

0.037	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.036	OUT SPE ^.layer_0.pos.i = ^.layer_0.pos.j
0.034	OUT SPE ^.layer_0111.shape.color = majorityColor(^)
0.033	OUT SPE ^.layer_0111.pos.j = right(^.layer_01) + 1
0.032	OUT SPE ^.layer_0.pos.j = ^.layer_0.pos.i / '2
0.031	OUT SPE ^.layer_0111.pos.i = ^.layer_01.pos.j / '2
0.030	IN  SPE ^.color = black
0.030	OUT SPE ^.color = black
0.016	
0.016	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (^.layer_0.pos.j,^.layer_0.pos.i / '2)
  _01: ^.layer_0
  _011: ^.layer_01
  _0111: rectangle with size (?,?) with model ? with color majorityColor(^) at (^.layer_01.pos.j / '2,right(^.layer_01) + 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
0 0 
. 0 
 with color ? at (?,?)
  _01: 
0 . 
0 0 
 with color ? at (?,?)

DL input  with Mi: L = 70.1 + 1075.3 = 1145.4
DL output with Mo: L = 168.3 + 1071.1 = 1239.4
DL input+output M: L = 238.4 + 2146.5 = 2384.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (^.layer_0.pos.j,^.layer_0.pos.i / '2)
  _01: ^.layer_0
  _011: ^.layer_01
  _0111: rectangle with size (?,?) with model ? with color majorityColor(^) at (^.layer_01.pos.j / '2,right(^.layer_01) + 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 0 
. 0 
 with color ? at (?,?)
  _01: 
0 . 
0 0 
 with color ? at (?,?)

DL input  with Mi: L = 70.0 + 0.0 = 70.0
DL output with Mo: L = 168.3 + 1071.1 = 1239.4
DL input+output M: L = 238.3 + 1071.1 = 1309.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: 
0 0 
. 0 
 with color orange at (4,6)
  _01: 
0 . 
0 0 
 with color orange at (2,1)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . 0 . 
. 0 . . 
0 . . . 
 with color orange at (6,2)
  _01: 
7#7#
. 7#
 at (4,6)
  _011: 
7#. 
7#7#
 at (2,1)
  _0111: rectangle with size (2,2) with model Odd Checkboard with color orange at (0,3)
diff: 
   (47.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
. 0 
 with color orange at (4,6)
  _01: 
0 . 
0 0 
 with color orange at (2,1)
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: 
0 . 
0 0 
 with color orange at (2,1)
  _01: 
0 0 
. 0 
 with color orange at (4,6)
diff:   ^.layer_01.shape.mask  ^.layer_0.shape.mask
! 13 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
. 0 
 with color orange at (4,6)
  _01: 
0 
0 
 with color orange at (2,1)
  + 1 delta pixels
diff:   ^.layer_01.shape.mask
! 13 wrong pixels (generated / expected)

TRAIN 6e19193c.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: 
0 0 
. 0 
 with color brown at (1,3)
  _01: 
0 . 
0 0 
 with color brown at (6,3)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
. 0 . 
0 . . 
 with color brown at (3,0)
  _01: 
9#9#
. 9#
 at (1,3)
  _011: 
9#. 
9#9#
 at (6,3)
  _0111: rectangle with size (5,5) with mask 
. . . . 0 
. . . 0 . 
. . 0 . . 
. 0 . . . 
0 . . . . 
 with color brown at (1,5)
diff: 
   (59.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
. 0 
 with color brown at (1,3)
  _01: 
0 . 
0 0 
 with color brown at (6,3)
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: 
0 . 
0 0 
 with color brown at (6,3)
  _01: 
0 0 
. 0 
 with color brown at (1,3)
diff:   ^.layer_01.shape.mask  ^.layer_0.shape.mask
! 16 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
. 0 
 with color brown at (1,3)
  _01: 
0 
0 
 with color brown at (6,3)
  + 1 delta pixels
diff:   ^.layer_01.shape.mask
! 13 wrong pixels (generated / expected)

TRAIN 6e19193c.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
. 0 
 with color cyan at (6,2)
  _01: 
. 0 
0 0 
 with color cyan at (2,3)
  + 3 delta pixels
diff:   ^.layer_01.shape.mask
! 13 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
. 0 
 with color cyan at (6,2)
  _01: 
0 0 
0 . 
 with color cyan at (4,7)
  + 3 delta pixels
diff:   ^.layer_01.shape.mask
! 8 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: 
. 0 
0 0 
 with color cyan at (2,3)
  _01: 
0 0 
0 . 
 with color cyan at (4,7)
  + 3 delta pixels
diff:   ^.layer_01.shape.mask  ^.layer_0.shape.mask
! 14 wrong pixels (generated / expected)

TEST 6e19193c.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 12.0 sec (12.0 sec/task)
bits-train-error = 1071.1 bits (1071.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-232] Checking task 6e82a1ae.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.156	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.312	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.281	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.249	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.222	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.194	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.175	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.156	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.137	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.118	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.111	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.104	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.103	IN  SPE ^.layer_0.shape.color = grey
0.102	IN  SPE ^.layer_01.shape.color = grey
0.093	OUT SPE ^.layer_01 = coloring(^.layer_01, blue)
0.086	OUT SPE ^.layer_01111 = coloring(^.layer_01111, green)
0.038	
0.038	IN  GEN ^.layer_01.shape.color = ?
0.038	IN  GEN ^.layer_0.shape.color = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: coloring(^.layer_01, blue)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: coloring(^.layer_01111, green)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)
  _01: rectangle with size (?,?) with model ? with color grey at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 160.0 + 5788.3 = 5948.2
DL output with Mo: L = 125.8 + 4283.5 = 4409.4
DL input+output M: L = 285.8 + 10071.8 = 10357.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: coloring(^.layer_01, blue)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: coloring(^.layer_01111, green)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 153.4 + 31.7 = 185.1
DL output with Mo: L = 125.8 + 4283.5 = 4409.4
DL input+output M: L = 279.2 + 4315.2 = 4594.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color grey at (1,7)
  _01: rectangle with size (2,3) with mask 
0 0 . 
. 0 0 
 with color grey at (2,1)
  _011: rectangle with size (3,1) with model Full with color grey at (5,9)
  _0111: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color grey at (8,3)
  _01111: rectangle with size (1,2) with model Full with color grey at (6,5)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color blue at (1,7)
  _01: 
1 1 . 
. 1 1 
 at (2,1)
  _011: rectangle with size (3,1) with model Full with color red at (5,9)
  _0111: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color red at (8,3)
  _01111: 
3 3 
 at (6,5)
  + 2 delta pixels
diff: 
   (196.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color grey at (1,7)
  _01: rectangle with size (2,3) with mask 
0 0 . 
. 0 0 
 with color grey at (2,1)
  _011: rectangle with size (3,1) with model Full with color grey at (5,9)
  _0111: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color grey at (8,3)
  _01111: rectangle with size (1,2) with model Full with color grey at (6,5)
  + 2 delta pixels
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color grey at (1,7)
  _01: rectangle with size (2,3) with mask 
0 0 . 
. 0 0 
 with color grey at (2,1)
  _011: rectangle with size (3,1) with model Full with color grey at (5,9)
  _0111: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color grey at (8,3)
  _01111: rectangle with size (2,1) with model Full with color grey at (7,1)
  + 2 delta pixels
diff: 
! 16 wrong pixels (generated / expected)

TRAIN 6e82a1ae.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color grey at (7,6)
  _01: rectangle with size (2,2) with model Full with color grey at (8,1)
  _011: rectangle with size (1,3) with model Full with color grey at (2,1)
  _0111: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color grey at (5,3)
  _01111: rectangle with size (2,1) with model Full with color grey at (2,7)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color blue at (7,6)
  _01: 
1 1 
1 1 
 at (8,1)
  _011: rectangle with size (1,3) with model Full with color red at (2,1)
  _0111: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color red at (5,3)
  _01111: 
3 
3 
 at (2,7)
diff: 
   (120.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color grey at (7,6)
  _01: rectangle with size (2,2) with model Full with color grey at (8,1)
  _011: rectangle with size (1,3) with model Full with color grey at (2,1)
  _0111: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color grey at (5,3)
  _01111: rectangle with size (2,1) with model Full with color grey at (2,7)
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color grey at (7,6)
  _01: rectangle with size (2,2) with model Full with color grey at (8,1)
  _011: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color grey at (5,3)
  _0111: rectangle with size (2,1) with model Full with color grey at (2,7)
  _01111: rectangle with size (1,3) with model Full with color grey at (2,1)
diff: 
! 16 wrong pixels (generated / expected)

TRAIN 6e82a1ae.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color grey at (1,6)
  _01: rectangle with size (3,1) with model Full with color grey at (6,0)
  _011: rectangle with size (2,1) with model Full with color grey at (1,2)
  _0111: rectangle with size (1,2) with model Full with color grey at (7,0)
  _01111: rectangle with size (1,2) with model Full with color grey at (5,4)
diff: 
   (3.2 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color red at (1,6)
  _01: 
1 
1 
1 
 at (6,0)
  _011: rectangle with size (2,1) with model Full with color green at (1,2)
  _0111: rectangle with size (1,2) with model Full with color blue at (7,0)
  _01111: 
3 3 
 at (5,4)
diff: 
   (111.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color grey at (1,6)
  _01: rectangle with size (3,1) with model Full with color grey at (6,0)
  _011: rectangle with size (2,1) with model Full with color grey at (1,2)
  _0111: rectangle with size (1,2) with model Full with color grey at (5,4)
  _01111: rectangle with size (1,2) with model Full with color grey at (7,0)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,1) with model Full with color grey at (6,0)
  _01: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color grey at (1,6)
  _011: rectangle with size (2,1) with model Full with color grey at (1,2)
  _0111: rectangle with size (1,2) with model Full with color grey at (5,4)
  _01111: rectangle with size (1,2) with model Full with color grey at (7,0)
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color grey at (1,6)
  _01: rectangle with size (3,1) with model Full with color grey at (6,0)
  _011: rectangle with size (2,1) with model Full with color grey at (1,2)
  _0111: rectangle with size (1,2) with model Full with color grey at (7,0)
  _01111: rectangle with size (1,2) with model Full with color grey at (5,4)
diff: 
! 10 wrong pixels (generated / expected)

TRAIN 6e82a1ae.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with mask 
. 0 0 
0 0 . 
 with color grey at (2,1)
  _01: rectangle with size (4,1) with model Full with color grey at (0,9)
  _011: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color grey at (2,5)
  _0111: rectangle with size (3,1) with model Full with color grey at (6,0)
  _01111: rectangle with size (1,2) with model Full with color grey at (7,3)
  + 2 delta pixels
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with mask 
. 0 0 
0 0 . 
 with color grey at (2,1)
  _01: rectangle with size (4,1) with model Full with color grey at (0,9)
  _011: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color grey at (2,5)
  _0111: rectangle with size (3,1) with model Full with color grey at (6,0)
  _01111: rectangle with size (2,1) with model Full with color grey at (7,7)
  + 2 delta pixels
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with mask 
. 0 0 
0 0 . 
 with color grey at (2,1)
  _01: rectangle with size (4,1) with model Full with color grey at (0,9)
  _011: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color grey at (2,5)
  _0111: rectangle with size (1,2) with model Full with color grey at (7,3)
  _01111: rectangle with size (3,1) with model Full with color grey at (6,0)
  + 2 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TEST 6e82a1ae.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.9 sec (59.9 sec/task)
bits-train-error = 4283.5 bits (4283.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-231] Checking task 6ecd11f4.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 727457.6 = 727459.9
DL output with Mo: L = 2.3 + 13222.9 = 13225.2
DL input+output M: L = 4.6 + 740680.5 = 740685.1

# learning a model for train pairs
2.000	
1.217	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.846	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.660	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.590	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.539	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.488	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.435	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.399	OUT ADD ^.layer_01111 = point with color ? at (?,?)
0.386	OUT SPE ^.layer_01111.shape.color = pink
0.368	OUT SPE ^.layer_011.pos = '(0, 2)
0.350	OUT SPE ^.layer_01.pos = '(0, 0)
0.341	OUT SPE ^.layer_0111.pos.i = 1
0.332	OUT SPE ^.layer_0.pos.j = '0
0.325	OUT SPE ^.layer_0.shape.mask.size.i = 1
0.318	OUT SPE ^.layer_0.shape.mask.model = Full
0.313	OUT SPE ^.color = black
0.311	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.302	OUT SPE ^.layer_0.shape.mask = ^.layer_01.shape.mask
0.295	OUT SPE ^.layer_0111.pos.j = ^.layer_01.pos.j / colorCount(^)
0.293	IN  ADD ^.layer_010 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.292	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.266	OUT SPE ^.size = ^.layer_01.shape.mask.size + span(^.layer_011.pos, ^.layer_010.pos)
0.265	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.253	OUT SPE ^.layer_011.shape = ^.layer_0111.shape
0.248	OUT SPE ^.layer_01111.pos.j = span(^.layer_0111.pos.j, ^.layer_010.pos.j) - ^.layer_010.shape.mask.size.j
0.244	OUT SPE ^.layer_01111.pos.i = span(^.layer_011.pos.j, ^.layer_0111.pos.j) + ^.layer_0111.pos.i - ^.layer_01.pos.i
0.244	IN  SPE ^.layer_011.shape.mask.model = Full
0.244	IN  SPE ^.color = black
0.219	
0.219	IN  GEN ^.layer_011.shape.mask.model = ?
0.219	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_01.shape.mask.size + span(^.layer_011.pos, ^.layer_010.pos) and color black and layers
  _0: ^.layer_01.shape.mask with color ? at (?,'0)
  _01: point with color ? at '(0, 0)
  _011: ^.layer_0111.shape at '(0, 2)
  _0111: point with color ? at (1,^.layer_01.pos.j / colorCount(^))
  _01111: point with color pink at (span(^.layer_011.pos.j, ^.layer_0111.pos.j) + ^.layer_0111.pos.i - ^.layer_01.pos.i,span(^.layer_0111.pos.j, ^.layer_010.pos.j) - ^.layer_010.shape.mask.size.j)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 144.2 + 18172.5 = 18316.7
DL output with Mo: L = 360.9 + 2530.0 = 2891.0
DL input+output M: L = 505.2 + 20702.5 = 21207.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_01.shape.mask.size + span(^.layer_011.pos, ^.layer_010.pos) and color black and layers
  _0: ^.layer_01.shape.mask with color ? at (?,'0)
  _01: point with color ? at '(0, 0)
  _011: ^.layer_0111.shape at '(0, 2)
  _0111: point with color ? at (1,^.layer_01.pos.j / colorCount(^))
  _01111: point with color pink at (span(^.layer_011.pos.j, ^.layer_0111.pos.j) + ^.layer_0111.pos.i - ^.layer_01.pos.i,span(^.layer_0111.pos.j, ^.layer_010.pos.j) - ^.layer_010.shape.mask.size.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 143.6 + 63.4 = 207.0
DL output with Mo: L = 360.9 + 2530.0 = 2891.0
DL input+output M: L = 504.5 + 2593.4 = 3098.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (27,21) and color black and layers
  _0: rectangle with size (15,15) with mask 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
 with color blue at (1,1)
  _010: rectangle with size (3,1) with model Full with color green at (19,7)
  _01: rectangle with size (1,1) with model Full with color blue at (19,8)
  _011: rectangle with size (1,1) with model Full with color cyan at (20,8)
  _0111: point with color orange at (19,9)
  + 4 delta pixels
diff: 
   (3.2 bits)
data: a background with size (3,3) and color black and layers
  _0: 
0 
 with color green at (2,0)
  _01: point with color green at (0,0)
  _011: 
7#
 at (0,2)
  _0111: point with color cyan at (1,1)
  _01111: point with color pink at (2,2)
diff: 
   (20.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (27,21) and color black and layers
  _0: rectangle with size (15,15) with mask 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
 with color blue at (1,1)
  _010: rectangle with size (3,1) with model Full with color green at (19,7)
  _01: rectangle with size (1,1) with model Full with color blue at (19,8)
  _011: rectangle with size (1,1) with model Full with color orange at (19,9)
  _0111: point with color cyan at (20,8)
  + 4 delta pixels
diff: 
! size mismatch, 2x4 instead of 3x3
>> Trial 2
data: a background with size (27,21) and color black and layers
  _0: rectangle with size (15,15) with mask 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
. . . . . 0 0 0 0 0 . . . . . 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
0 0 0 0 0 . . . . . 0 0 0 0 0 
 with color blue at (1,1)
  _010: rectangle with size (3,1) with model Full with color green at (19,7)
  _01: rectangle with size (1,1) with model Full with color blue at (19,8)
  _011: rectangle with size (1,1) with model Full with color cyan at (20,8)
  _0111: point with color orange at (19,9)
  + 4 delta pixels
diff: 
! 3 wrong pixels (generated / expected)

TRAIN 6ecd11f4.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (27,25) and color black and layers
  _0: rectangle with size (9,9) with mask 
0 0 0 . . . 0 0 0 
0 0 0 . . . 0 0 0 
0 0 0 . . . 0 0 0 
0 0 0 0 0 0 . . . 
0 0 0 0 0 0 . . . 
0 0 0 0 0 0 . . . 
. . . 0 0 0 0 0 0 
. . . 0 0 0 0 0 0 
. . . 0 0 0 0 0 0 
 with color green at (3,9)
  _010: rectangle with size (2,2) with model Odd Checkboard with color cyan at (20,8)
  _01: rectangle with size (1,1) with model Full with color red at (19,8)
  _011: rectangle with size (1,1) with model Full with color blue at (19,9)
  _0111: point with color orange at (19,10)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
0 
 with color yellow at (1,0)
  _01: point with color red at (0,0)
  _011: 
7#
 at (0,2)
  _0111: point with color cyan at (1,1)
  _01111: point with color pink at (2,1)
  + 1 delta pixels
diff: 
   (58.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (27,25) and color black and layers
  _0: rectangle with size (9,9) with mask 
0 0 0 . . . 0 0 0 
0 0 0 . . . 0 0 0 
0 0 0 . . . 0 0 0 
0 0 0 0 0 0 . . . 
0 0 0 0 0 0 . . . 
0 0 0 0 0 0 . . . 
. . . 0 0 0 0 0 0 
. . . 0 0 0 0 0 0 
. . . 0 0 0 0 0 0 
 with color green at (3,9)
  _010: rectangle with size (2,2) with model Odd Checkboard with color cyan at (20,8)
  _01: rectangle with size (1,1) with model Full with color red at (19,8)
  _011: rectangle with size (1,1) with model Full with color blue at (19,9)
  _0111: point with color orange at (19,10)
  + 4 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (27,25) and color black and layers
  _0: rectangle with size (9,9) with mask 
0 0 0 . . . 0 0 0 
0 0 0 . . . 0 0 0 
0 0 0 . . . 0 0 0 
0 0 0 0 0 0 . . . 
0 0 0 0 0 0 . . . 
0 0 0 0 0 0 . . . 
. . . 0 0 0 0 0 0 
. . . 0 0 0 0 0 0 
. . . 0 0 0 0 0 0 
 with color green at (3,9)
  _010: rectangle with size (2,2) with model Odd Checkboard with color cyan at (20,8)
  _01: rectangle with size (1,1) with model Full with color red at (19,8)
  _011: rectangle with size (1,1) with model Full with color orange at (19,10)
  _0111: point with color blue at (19,9)
  + 4 delta pixels
diff: 
! size mismatch, 3x4 instead of 3x3

TRAIN 6ecd11f4.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (22,22) and color black and layers
  _0: rectangle with size (16,16) with mask 
0 0 0 0 . . . . 0 0 0 0 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 . . . . 
0 0 0 0 . . . . 0 0 0 0 . . . . 
0 0 0 0 . . . . 0 0 0 0 . . . . 
0 0 0 0 . . . . 0 0 0 0 . . . . 
0 0 0 0 . . . . . . . . 0 0 0 0 
0 0 0 0 . . . . . . . . 0 0 0 0 
0 0 0 0 . . . . . . . . 0 0 0 0 
0 0 0 0 . . . . . . . . 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
 with color cyan at (1,2)
  _010: rectangle with size (1,3) with model Full with color pink at (17,17)
  _01: rectangle with size (1,3) with model Full with color grey at (18,18)
  _011: rectangle with size (1,3) with model Full with color red at (19,17)
  _0111: point with color brown at (16,19)
  + 9 delta pixels
diff: 
   (3.2 bits)
data: a background with size (4,4) and color black and layers
  _0: 
0 0 0 
 with color red at (3,0)
  _01: point with color yellow at (0,0)
  _011: 
9#
 at (0,2)
  _0111: point with color pink at (1,2)
  _01111: point with color pink at (1,0)
  + 4 delta pixels
diff: 
   (173.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (22,22) and color black and layers
  _0: rectangle with size (16,16) with mask 
0 0 0 0 . . . . 0 0 0 0 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 . . . . 
0 0 0 0 . . . . 0 0 0 0 . . . . 
0 0 0 0 . . . . 0 0 0 0 . . . . 
0 0 0 0 . . . . 0 0 0 0 . . . . 
0 0 0 0 . . . . . . . . 0 0 0 0 
0 0 0 0 . . . . . . . . 0 0 0 0 
0 0 0 0 . . . . . . . . 0 0 0 0 
0 0 0 0 . . . . . . . . 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
 with color cyan at (1,2)
  _010: rectangle with size (1,3) with model Full with color pink at (17,17)
  _01: rectangle with size (1,3) with model Full with color grey at (18,18)
  _011: rectangle with size (1,3) with model Full with color red at (19,17)
  _0111: point with color blue at (16,18)
  + 9 delta pixels
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (22,22) and color black and layers
  _0: rectangle with size (16,16) with mask 
0 0 0 0 . . . . 0 0 0 0 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 0 0 0 0 
0 0 0 0 . . . . 0 0 0 0 . . . . 
0 0 0 0 . . . . 0 0 0 0 . . . . 
0 0 0 0 . . . . 0 0 0 0 . . . . 
0 0 0 0 . . . . 0 0 0 0 . . . . 
0 0 0 0 . . . . . . . . 0 0 0 0 
0 0 0 0 . . . . . . . . 0 0 0 0 
0 0 0 0 . . . . . . . . 0 0 0 0 
0 0 0 0 . . . . . . . . 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
 with color cyan at (1,2)
  _010: rectangle with size (1,3) with model Full with color pink at (17,17)
  _01: rectangle with size (1,3) with model Full with color grey at (18,18)
  _011: rectangle with size (1,3) with model Full with color red at (19,17)
  _0111: point with color brown at (16,19)
  + 9 delta pixels
diff: 
! 10 wrong pixels (generated / expected)

TRAIN 6ecd11f4.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
undefined expression: ScaleDown: not an integer

TEST 6ecd11f4.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 34.9 sec (34.9 sec/task)
bits-train-error = 2530.0 bits (2530.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-230] Checking task 6f8cd79b.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 27592.2 = 27594.5
DL output with Mo: L = 2.3 + 27592.2 = 27594.5
DL input+output M: L = 4.6 + 55184.3 = 55188.9

# learning a model for train pairs
2.000	
1.025	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.351	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.100	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.079	OUT SPE ^.size = ^.size
0.059	OUT SPE ^.layer_0.shape.mask.size = ^.size
0.047	OUT SPE ^.layer_0.pos = '(0, 0)
0.039	OUT SPE ^.layer_0.shape.mask.model = Border
0.031	OUT SPE ^.layer_0.shape.color = cyan
0.027	IN  SPE ^.color = black
0.024	OUT SPE ^.color = black
0.002	
0.002	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size ^.size with model Border with color cyan at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers

DL input  with Mi: L = 13.1 + 585.4 = 598.5
DL output with Mo: L = 50.6 + 0.0 = 50.6
DL input+output M: L = 63.7 + 585.4 = 649.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size ^.size with model Border with color cyan at '(0, 0)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 50.6 + 0.0 = 50.6
DL input+output M: L = 52.9 + 0.0 = 52.9

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 
0 0 0 
0 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with model Border with color cyan at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 
0 0 0 
0 0 0 

diff: 
correct output grid

TRAIN 6f8cd79b.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 0 0 
0 0 0 
0 0 0 
0 0 0 

diff: 
   (0.0 bits)
data: a background with size (4,3) and color black and layers
  _0: rectangle with size (4,3) with model Border with color cyan at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 
0 0 0 
0 0 0 
0 0 0 

diff: 
correct output grid

TRAIN 6f8cd79b.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (5,4) and color black and layers
  _0: rectangle with size (5,4) with model Border with color cyan at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 

diff: 
correct output grid

TRAIN 6f8cd79b.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (5,6) and color black and layers
  _0: rectangle with size (5,6) with model Border with color cyan at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 6f8cd79b.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 

diff: 
correct output grid

TEST 6f8cd79b.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 0.4 sec (0.4 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-229] Checking task 6fa7a44f.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 14046.4 = 14048.7
DL output with Mo: L = 2.3 + 27897.7 = 27900.0
DL input+output M: L = 4.6 + 41944.1 = 41948.8

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = unfoldSym( [ id ] [ flipHeight ], ^)
0.618	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.420	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.331	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.284	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.276	IN  SPE ^.layer_01.shape.mask.model = Full
0.007	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
unfoldSym( [ id ] [ flipHeight ], ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 88.8 + 3786.5 = 3875.3
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 100.1 + 3786.5 = 3886.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
unfoldSym( [ id ] [ flipHeight ], ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 13.6 + 0.0 = 13.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
9#1 4 
9#1 4 
2 1 1 

diff: 
   (0.0 bits)
data: 
9#1 4 
9#1 4 
2 1 1 
2 1 1 
9#1 4 
9#1 4 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
9#1 4 
9#1 4 
2 1 1 

diff: 
correct output grid

TRAIN 6fa7a44f.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
4 8 4 
7#6 7#
8 7#8 

diff: 
   (0.0 bits)
data: 
4 8 4 
7#6 7#
8 7#8 
8 7#8 
7#6 7#
4 8 4 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 8 4 
7#6 7#
8 7#8 

diff: 
correct output grid

TRAIN 6fa7a44f.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
7#7#7#
9#5#5#
5#1 7#

diff: 
   (0.0 bits)
data: 
7#7#7#
9#5#5#
5#1 7#
5#1 7#
9#5#5#
7#7#7#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
7#7#7#
9#5#5#
5#1 7#

diff: 
correct output grid

TRAIN 6fa7a44f.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: 
2 6 9#
2 6 9#
2 9#2 

diff: 
   (0.0 bits)
data: 
2 6 9#
2 6 9#
2 9#2 
2 9#2 
2 6 9#
2 6 9#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 6 9#
2 6 9#
2 9#2 

diff: 
correct output grid

TRAIN 6fa7a44f.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 9#2 
8 5#2 
2 2 8 

diff: 
correct output grid

TEST 6fa7a44f.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.1 sec (1.1 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-228] Checking task 72322fa7.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 290258.0 = 290260.4
DL output with Mo: L = 2.3 + 290258.0 = 290260.4
DL input+output M: L = 4.6 + 580516.1 = 580520.7

# learning a model for train pairs
2.000	
1.051	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.135	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.127	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.116	OUT ADD ^.layer_0 = ^.layer_0
0.106	OUT ADD ^.layer_01 = ^.layer_0.shape at (?,?)
0.096	OUT ADD ^.layer_00 = ^.layer_0.shape at (?,?)
0.088	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.082	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.076	OUT ADD ^.layer_010 = ^.layer_01
0.073	OUT ADD ^.layer_0110 = point with color ? at (?,?)
0.071	OUT ADD ^.layer_001 = point with color ? at (?,?)
0.069	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.066	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.062	OUT ADD ^.layer_000 = ^.layer_0111
0.060	IN  ADD ^.layer_01110 = point with color ? at (?,?)
0.057	IN  ADD ^.layer_00 = point with color ? at (?,?)
0.055	OUT SPE ^.size = ^.size
0.054	OUT SPE ^.layer_01.pos.j = span(^.layer_01.pos.j, ^.layer_011.pos.j) - 2
0.054	OUT SPE ^.layer_011.pos.j = ^.layer_0.pos.j - area(^.layer_01.shape)
0.053	OUT SPE ^.layer_001.shape = ^.layer_0111.shape
0.053	OUT SPE ^.layer_001.pos.j = ^.layer_0.pos.j + 1
0.052	OUT SPE ^.layer_001.pos.i = middle(^.layer_0) - 1
0.052	OUT SPE ^.layer_011.pos.i = span(^.layer_011.pos.j, ^.layer_00.pos.j) + ^.layer_011.pos.i - ^.layer_0.pos.i
0.051	OUT SPE ^.layer_00.pos.j = span(^.layer_01.pos.i, ^.layer_011.pos.i) - ^.layer_01110.pos.j - ^.layer_00.pos.j
0.051	OUT SPE ^.layer_00.pos.i = span(^.layer_01.pos.j, ^.layer_011.pos.j) - ^.layer_01.pos.i - ^.layer_0.pos.i
0.051	OUT SPE ^.layer_011.shape.mask.model = Full
0.050	IN  SPE ^.color = black
0.050	OUT SPE ^.color = black
0.050	OUT SPE ^.layer_011.shape.mask.size.i = ^.layer_01.shape.mask.size.i - ^.layer_0.pos.i - ^.layer_00.pos.i
0.023	
0.023	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _000: ^.layer_0111
  _00: ^.layer_0.shape at (span(^.layer_01.pos.j, ^.layer_011.pos.j) - ^.layer_01.pos.i - ^.layer_0.pos.i,span(^.layer_01.pos.i, ^.layer_011.pos.i) - ^.layer_01110.pos.j - ^.layer_00.pos.j)
  _001: ^.layer_0111.shape at (middle(^.layer_0) - 1,^.layer_0.pos.j + 1)
  _0: ^.layer_0
  _010: ^.layer_01
  _01: ^.layer_0.shape at (?,span(^.layer_01.pos.j, ^.layer_011.pos.j) - 2)
  _0110: point with color ? at (?,?)
  _011: rectangle with size (^.layer_01.shape.mask.size.i - ^.layer_0.pos.i - ^.layer_00.pos.i,?) with model Full with color ? at (span(^.layer_011.pos.j, ^.layer_00.pos.j) + ^.layer_011.pos.i - ^.layer_0.pos.i,^.layer_0.pos.j - area(^.layer_01.shape))
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _01110: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 141.8 + 7781.1 = 7922.9
DL output with Mo: L = 537.2 + 6048.5 = 6585.7
DL input+output M: L = 679.0 + 13829.6 = 14508.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _000: ^.layer_0111
  _00: ^.layer_0.shape at (span(^.layer_01.pos.j, ^.layer_011.pos.j) - ^.layer_01.pos.i - ^.layer_0.pos.i,span(^.layer_01.pos.i, ^.layer_011.pos.i) - ^.layer_01110.pos.j - ^.layer_00.pos.j)
  _001: ^.layer_0111.shape at (middle(^.layer_0) - 1,^.layer_0.pos.j + 1)
  _0: ^.layer_0
  _010: ^.layer_01
  _01: ^.layer_0.shape at (?,span(^.layer_01.pos.j, ^.layer_011.pos.j) - 2)
  _0110: point with color ? at (?,?)
  _011: rectangle with size (^.layer_01.shape.mask.size.i - ^.layer_0.pos.i - ^.layer_00.pos.i,?) with model Full with color ? at (span(^.layer_011.pos.j, ^.layer_00.pos.j) + ^.layer_011.pos.i - ^.layer_0.pos.i,^.layer_0.pos.j - area(^.layer_01.shape))
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _01110: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 141.7 + 31.7 = 173.4
DL output with Mo: L = 537.2 + 6048.5 = 6585.7
DL input+output M: L = 678.9 + 6080.2 = 6759.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (13,22) and color black and layers
  _00: point with color green at (1,13)
  _0: rectangle with size (3,3) with model Odd Checkboard with color cyan at (3,5)
  _01: rectangle with size (3,3) with model Odd Checkboard with color cyan at (9,15)
  _011: point with color pink at (4,6)
  _01110: point with color blue at (9,1)
  _0111: point with color pink at (5,19)
  + 5 delta pixels
diff: 
   (3.2 bits)
data: a background with size (13,22) and color black and layers
  _000: 
6 
 at (5,19)
  _00: 
. 8 . 
8 . 8 
. 8 . 
 at (4,18)
  _001: 
6 
 at (4,6)
  _0: 
. 8 . 
8 . 8 
. 8 . 
 at (3,5)
  _010: 
. 8 . 
8 . 8 
. 8 . 
 at (9,15)
  _01: 
. 8 . 
8 . 8 
. 8 . 
 at (9,8)
  _0110: point with color blue at (0,12)
  _011: rectangle with size (1,1) with model Full with color blue at (9,1)
  + 10 delta pixels
diff: 
   (450.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,22) and color black and layers
  _00: point with color green at (1,13)
  _0: rectangle with size (3,3) with model Odd Checkboard with color cyan at (3,5)
  _01: rectangle with size (3,3) with model Odd Checkboard with color cyan at (9,15)
  _011: point with color pink at (4,6)
  _01110: point with color pink at (5,19)
  _0111: point with color blue at (9,1)
  + 5 delta pixels
diff: 
! 31 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,22) and color black and layers
  _00: point with color green at (1,13)
  _0: rectangle with size (3,3) with model Odd Checkboard with color cyan at (3,5)
  _01: rectangle with size (3,3) with model Odd Checkboard with color cyan at (9,15)
  _011: point with color pink at (4,6)
  _01110: point with color pink at (5,19)
  _0111: point with color blue at (9,3)
  + 5 delta pixels
diff: 
! 31 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (13,22) and color black and layers
  _00: point with color green at (1,13)
  _0: rectangle with size (3,3) with model Odd Checkboard with color cyan at (3,5)
  _01: rectangle with size (3,3) with model Odd Checkboard with color cyan at (9,15)
  _011: point with color pink at (4,6)
  _01110: point with color blue at (9,1)
  _0111: point with color pink at (5,19)
  + 5 delta pixels
diff: 
! 22 wrong pixels (generated / expected)

TRAIN 72322fa7.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (13,12) and color black and layers
  _00: point with color cyan at (3,2)
  _0: rectangle with size (1,3) with model Full with color yellow at (3,1)
  _01: rectangle with size (1,1) with model Full with color cyan at (4,10)
  _011: point with color yellow at (9,0)
  _01110: point with color yellow at (9,2)
  _0111: point with color cyan at (10,7)
diff: 
   (0.0 bits)
data: a background with size (13,12) and color black and layers
  _000: 
8 
 at (10,7)
  _00: 
4 4 4 
 at (10,6)
  _001: 
8 
 at (3,2)
  _0: 
4 4 4 
 at (3,1)
  _010: 
8 
 at (4,10)
  _01: 
4 4 4 
 at (4,9)
  _0110: point with color cyan at (9,1)
  _011: rectangle with size (1,3) with model Full with color yellow at (9,0)
diff: 
   (35.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,12) and color black and layers
  _00: point with color cyan at (3,2)
  _0: rectangle with size (1,3) with model Full with color yellow at (3,1)
  _01: rectangle with size (1,1) with model Full with color cyan at (4,10)
  _011: point with color yellow at (9,0)
  _01110: point with color yellow at (9,2)
  _0111: point with color cyan at (10,7)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,12) and color black and layers
  _00: point with color cyan at (3,2)
  _0: rectangle with size (1,3) with model Full with color yellow at (3,1)
  _01: rectangle with size (1,1) with model Full with color cyan at (4,10)
  _011: point with color yellow at (9,0)
  _01110: point with color cyan at (10,7)
  _0111: point with color yellow at (9,2)
diff: 
! 15 wrong pixels (generated / expected)

TRAIN 72322fa7.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (14,19) and color black and layers
  _00: point with color red at (1,16)
  _0: rectangle with size (1,3) with model Full with color cyan at (1,15)
  _01: rectangle with size (3,1) with model Full with color blue at (4,3)
  _011: point with color cyan at (3,8)
  _01110: point with color cyan at (3,10)
  _0111: point with color red at (11,5)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (14,19) and color black and layers
  _000: 
2 
 at (11,5)
  _00: 
8 8 8 
 at (3,8)
  _001: 
2 
 at (1,16)
  _0: 
8 8 8 
 at (1,15)
  _010: 
1 
1 
1 
 at (4,3)
  _01: 
8 8 8 
 at (11,4)
  _0110: point with color green at (12,12)
  _011: rectangle with size (3,1) with model Full with color blue at (11,12)
  + 2 delta pixels
diff: 
   (118.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,19) and color black and layers
  _00: point with color red at (1,16)
  _0: rectangle with size (1,3) with model Full with color cyan at (1,15)
  _01: rectangle with size (3,1) with model Full with color blue at (4,3)
  _011: point with color cyan at (3,8)
  _01110: point with color cyan at (3,10)
  _0111: point with color red at (11,5)
  + 2 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,19) and color black and layers
  _00: point with color red at (1,16)
  _0: rectangle with size (1,3) with model Full with color cyan at (1,15)
  _01: rectangle with size (3,1) with model Full with color blue at (4,3)
  _011: point with color cyan at (3,8)
  _01110: point with color cyan at (3,10)
  _0111: point with color green at (12,12)
  + 2 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (14,19) and color black and layers
  _00: point with color red at (1,16)
  _0: rectangle with size (1,3) with model Full with color cyan at (1,15)
  _01: rectangle with size (3,1) with model Full with color blue at (4,3)
  _011: point with color cyan at (3,8)
  _01110: point with color red at (11,5)
  _0111: point with color cyan at (3,10)
  + 2 delta pixels
diff: 
! 20 wrong pixels (generated / expected)

TRAIN 72322fa7.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
Invalid_argument("Model2.mask_rectangle: negative or null mask size")

TEST 72322fa7.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 57.7 sec (57.7 sec/task)
bits-train-error = 6048.5 bits (6048.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-227] Checking task 72ca375d.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 7881.2 = 7883.5
DL input+output M: L = 4.6 + 127657.0 = 127661.7

# learning a model for train pairs
2.000	
1.176	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.447	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.352	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.290	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.219	OUT SPE ^.layer_0.shape = ^.layer_0.shape
0.160	IN  ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.115	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.077	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.050	OUT SPE ^.layer_0.pos = '(0, 0)
0.040	OUT SPE ^.color = black
0.040	IN  SPE ^.color = black
0.006	
0.006	IN  DEL ^.layer_01
0.006	IN  DEL ^.layer_00
0.006	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: ^.layer_0.shape at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.2 + 4077.2 = 4175.4
DL output with Mo: L = 37.8 + 0.0 = 37.8
DL input+output M: L = 136.1 + 4077.2 = 4213.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: ^.layer_0.shape at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 51.7 = 93.7
DL output with Mo: L = 37.8 + 0.0 = 37.8
DL input+output M: L = 79.8 + 51.7 = 131.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,4) with mask 
0 0 0 0 
. 0 0 . 
 with color pink at (6,3)
  + 9 delta pixels
diff: 
   (0.0 bits)
data: a background with size (2,4) and color black and layers
  _0: 
6 6 6 6 
. 6 6 . 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,4) with mask 
0 0 0 0 
. 0 0 . 
 with color pink at (6,3)
  + 9 delta pixels
diff: 
correct output grid

TRAIN 72ca375d.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color yellow at (1,2)
  + 13 delta pixels
diff: 
   (3.2 bits)
data: a background with size (2,2) and color black and layers
  _0: 
4 4 
4 4 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,5) with mask 
. 0 0 0 0 
0 0 0 . . 
 with color red at (7,1)
  + 10 delta pixels
diff: 
! size mismatch, 2x5 instead of 2x2
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,4) with mask 
0 0 0 . 
0 . 0 0 
 with color cyan at (2,6)
  + 11 delta pixels
diff: 
! size mismatch, 2x4 instead of 2x2
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color yellow at (1,2)
  + 13 delta pixels
diff: 
correct output grid

TRAIN 72ca375d.json/2: 1 3rd (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,4) with mask 
0 . . 0 
0 0 0 0 
 with color grey at (2,5)
  + 13 delta pixels
diff: 
   (2.0 bits)
data: a background with size (2,4) and color black and layers
  _0: 
5#. . 5#
5#5#5#5#
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,7) with mask 
. . . 0 0 0 . 
0 0 0 0 . 0 0 
 with color cyan at (7,0)
  + 10 delta pixels
diff: 
! size mismatch, 2x7 instead of 2x4
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,4) with mask 
0 . . 0 
0 0 0 0 
 with color grey at (2,5)
  + 13 delta pixels
diff: 
correct output grid

TRAIN 72ca375d.json/3: 1 2nd (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,5) with mask 
0 0 0 0 0 
0 . . 0 0 
 with color yellow at (7,4)
  + 15 delta pixels
diff: 
! size mismatch, 2x5 instead of 3x4
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,4) with mask 
. 0 0 . 
. 0 0 . 
0 0 0 0 
 with color brown at (2,0)
  + 15 delta pixels
diff: 
correct output grid

TEST 72ca375d.json/1: 1 2nd (SUCCESS)

# Performance measures on task
runtime-learning = 2.0 sec (2.0 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 0.61
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 0.50

=====================================
[-226] Checking task 73251a56.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 552662.4 = 552664.8
DL output with Mo: L = 2.3 + 552662.4 = 552664.8
DL input+output M: L = 4.6 + 1105324.9 = 1105329.5

# learning a model for train pairs
2.000	
1.490	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.058	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.837	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.672	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.603	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.560	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.523	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.485	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.456	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.195	
0.195	IN  GEN ^ = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 143901.9 = 144027.7
DL output with Mo: L = 98.1 + 107729.5 = 107827.6
DL input+output M: L = 223.9 + 251631.4 = 251855.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 98.1 + 107729.5 = 107827.6
DL input+output M: L = 100.4 + 107729.5 = 107829.9

# train input/output grids

## instance 1

> Input and output best reading:

data: 
1 6 1 1 2 2 3 3 4 4 5#5#6 6 1 1 2 2 3 3 4 
6 1 6 6 1 1 1 2 2 2 3 3 3 4 4 4 5#5#5#6 6 
1 6 1 6 6 6 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 
1 6 6 1 6 6 6 6 1 1 1 1 1 2 2 2 2 2 3 3 3 
2 1 6 6 1 6 6 6 6 6 1 0 0 0 1 1 2 2 2 2 2 
2 1 6 6 6 1 6 6 6 6 6 0 0 0 1 1 1 1 1 2 2 
3 1 1 6 6 6 1 6 6 6 6 6 6 6 1 1 1 1 1 1 1 
3 2 1 6 6 6 6 1 0 0 0 6 6 6 6 6 1 1 1 1 1 
4 2 1 1 6 6 6 6 0 0 0 6 6 6 6 6 6 6 1 1 1 
4 2 1 1 6 6 6 6 0 0 0 6 6 6 6 6 6 6 6 6 1 
5#3 2 1 1 6 6 6 6 6 1 6 6 6 6 6 6 6 6 6 6 
5#3 2 1 1 6 6 6 6 6 0 0 0 0 0 0 0 6 6 6 6 
6 3 2 1 1 1 6 6 6 6 0 0 0 0 0 0 0 6 6 6 6 
6 4 2 2 1 1 6 6 6 6 6 6 0 0 0 0 0 6 6 6 6 
1 4 3 2 1 1 1 6 6 6 6 6 0 0 0 0 0 6 6 6 6 
1 4 3 2 1 1 1 6 6 6 6 6 6 6 6 1 6 6 6 6 6 
2 5#3 2 2 1 1 1 6 6 6 6 6 6 6 6 1 6 6 6 6 
2 5#3 2 2 1 1 1 6 6 6 6 6 6 6 6 6 1 6 6 6 
3 5#4 3 2 1 1 1 1 6 0 0 0 0 6 6 6 6 1 6 6 
3 6 4 3 2 2 1 1 1 6 0 0 0 0 6 6 6 6 6 1 6 
4 6 4 3 2 2 1 1 1 1 6 6 6 6 6 6 6 6 6 6 1 

diff: 
   (0.0 bits)
data: a background with size (21,21) and color pink and layers
  _0: rectangle with size (21,21) with mask 
0 . 0 0 . . . . . . . . . . . . . . . . . 
. 0 . . 0 0 0 . . . . . . . . . . . . . . 
0 . 0 . . . 0 0 0 0 . . . . . . . . . . . 
0 . . 0 . . . . 0 0 0 0 0 . . . . . . . . 
. 0 . . 0 . . . . . 0 0 0 0 0 0 . . . . . 
. 0 . . . 0 . . . . . . 0 0 0 0 0 0 0 . . 
. 0 0 . . . 0 . . . . . . . 0 0 0 0 0 0 0 
. . 0 . . . . 0 . . . . . . . . 0 0 0 0 0 
. . 0 0 . . . . 0 . . . . . . . . . 0 0 0 
. . 0 0 . . . . . 0 . . . . . . . . . . 0 
. . . 0 0 . . . . . 0 . . . . . . . . . . 
. . . 0 0 . . . . . . 0 . . . . . . . . . 
. . . 0 0 0 . . . . . . 0 . . . . . . . . 
. . . . 0 0 . . . . . . . 0 . . . . . . . 
. . . . 0 0 0 . . . . . . . 0 . . . . . . 
. . . . 0 0 0 . . . . . . . . 0 . . . . . 
. . . . . 0 0 0 . . . . . . . . 0 . . . . 
. . . . . 0 0 0 . . . . . . . . . 0 . . . 
. . . . . 0 0 0 0 . . . . . . . . . 0 . . 
. . . . . . 0 0 0 . . . . . . . . . . 0 . 
. . . . . . 0 0 0 0 . . . . . . . . . . 0 
 with color blue at (0,0)
  _01: rectangle with size (5,14) with mask 
0 0 0 . . . . . . . . . . . 
. . . 0 0 0 0 . . . . . . . 
. . . . . . 0 0 0 0 0 . . . 
. . . . . . . . . 0 0 0 0 0 
. . . . . . . . . . . . 0 0 
 with color red at (1,7)
  _011: rectangle with size (14,5) with mask 
0 . . . . 
0 . . . . 
0 . . . . 
. 0 . . . 
. 0 . . . 
. 0 . . . 
. 0 0 . . 
. . 0 . . 
. . 0 . . 
. . 0 0 . 
. . 0 0 . 
. . . 0 . 
. . . 0 0 
. . . 0 0 
 with color red at (7,1)
  + 68 delta pixels
diff: 
   (3479.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 6 1 1 2 2 3 3 4 4 5#5#6 6 1 1 2 2 3 3 4 
6 1 6 6 1 1 1 2 2 2 3 3 3 4 4 4 5#5#5#6 6 
1 6 1 6 6 6 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 
1 6 6 1 6 6 6 6 1 1 1 1 1 2 2 2 2 2 3 3 3 
2 1 6 6 1 6 6 6 6 6 1 0 0 0 1 1 2 2 2 2 2 
2 1 6 6 6 1 6 6 6 6 6 0 0 0 1 1 1 1 1 2 2 
3 1 1 6 6 6 1 6 6 6 6 6 6 6 1 1 1 1 1 1 1 
3 2 1 6 6 6 6 1 0 0 0 6 6 6 6 6 1 1 1 1 1 
4 2 1 1 6 6 6 6 0 0 0 6 6 6 6 6 6 6 1 1 1 
4 2 1 1 6 6 6 6 0 0 0 6 6 6 6 6 6 6 6 6 1 
5#3 2 1 1 6 6 6 6 6 1 6 6 6 6 6 6 6 6 6 6 
5#3 2 1 1 6 6 6 6 6 0 0 0 0 0 0 0 6 6 6 6 
6 3 2 1 1 1 6 6 6 6 0 0 0 0 0 0 0 6 6 6 6 
6 4 2 2 1 1 6 6 6 6 6 6 0 0 0 0 0 6 6 6 6 
1 4 3 2 1 1 1 6 6 6 6 6 0 0 0 0 0 6 6 6 6 
1 4 3 2 1 1 1 6 6 6 6 6 6 6 6 1 6 6 6 6 6 
2 5#3 2 2 1 1 1 6 6 6 6 6 6 6 6 1 6 6 6 6 
2 5#3 2 2 1 1 1 6 6 6 6 6 6 6 6 6 1 6 6 6 
3 5#4 3 2 1 1 1 1 6 0 0 0 0 6 6 6 6 1 6 6 
3 6 4 3 2 2 1 1 1 6 0 0 0 0 6 6 6 6 6 1 6 
4 6 4 3 2 2 1 1 1 1 6 6 6 6 6 6 6 6 6 6 1 

diff: 
! size mismatch, 10x10 instead of 21x21

TRAIN 73251a56.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
6 5#6 6 7#7#1 1 2 2 3 3 4 4 5#5#6 6 7#7#1 
5#6 5#5#6 6 6 7#7#7#1 1 1 2 2 2 3 3 3 4 4 
6 5#6 5#5#5#6 6 6 6 7#7#7#7#1 1 1 1 2 2 2 
6 5#5#0 0 0 5#5#6 6 6 6 6 7#7#7#7#7#1 1 1 
7#6 5#0 0 0 5#5#5#5#6 6 6 6 6 6 7#7#7#7#7#
7#6 5#0 0 0 5#5#5#5#5#5#6 6 6 6 6 6 6 7#7#
1 6 6 0 0 0 6 5#5#0 0 0 5#5#6 6 6 6 6 6 6 
1 7#6 0 0 0 5#6 5#0 0 0 5#5#5#5#6 6 6 6 6 
2 7#6 6 5#5#5#5#6 0 0 0 0 0 0 0 0 5#6 6 6 
2 7#6 6 5#5#5#5#5#6 5#5#0 0 0 0 0 5#5#5#6 
3 1 7#6 6 5#5#5#5#5#6 5#5#5#5#5#5#5#5#5#5#
3 1 7#6 6 5#5#5#5#5#5#6 5#5#5#5#5#5#5#5#5#
4 1 7#6 6 6 5#5#5#5#5#5#6 5#5#5#5#5#5#5#5#
4 2 7#7#6 6 5#5#5#5#5#5#5#6 5#5#5#5#5#5#5#
5#2 0 0 0 0 6 5#5#5#5#5#5#5#6 5#5#5#5#5#5#
5#2 0 0 0 0 6 5#5#5#5#5#5#5#5#6 5#5#5#5#5#
6 3 1 7#7#6 6 6 5#5#5#5#5#5#5#5#6 5#5#5#5#
6 3 1 7#7#6 6 6 0 0 0 0 5#5#5#5#5#6 5#5#5#
7#3 2 1 7#6 6 6 0 0 0 0 5#5#5#5#5#5#6 5#5#
7#4 2 1 7#7#6 6 6 5#5#5#5#5#5#5#5#5#5#6 5#
1 4 2 1 7#7#6 6 6 6 5#5#5#5#5#5#5#5#5#5#6 

diff: 
   (0.0 bits)
data: a background with size (21,21) and color grey and layers
  _0: rectangle with size (21,21) with mask 
0 . 0 0 . . . . . . . . . . . . . . . . . 
. 0 . . 0 0 0 . . . . . . . . . . . . . . 
0 . 0 . . . 0 0 0 0 . . . . . . . . . . . 
0 . . 0 . . . . 0 0 0 0 0 . . . . . . . . 
. 0 . . 0 . . . . . 0 0 0 0 0 0 . . . . . 
. 0 . . . 0 . . . . . . 0 0 0 0 0 0 0 . . 
. 0 0 . . . 0 . . . . . . . 0 0 0 0 0 0 0 
. . 0 . . . . 0 . . . . . . . . 0 0 0 0 0 
. . 0 0 . . . . 0 . . . . . . . . . 0 0 0 
. . 0 0 . . . . . 0 . . . . . . . . . . 0 
. . . 0 0 . . . . . 0 . . . . . . . . . . 
. . . 0 0 . . . . . . 0 . . . . . . . . . 
. . . 0 0 0 . . . . . . 0 . . . . . . . . 
. . . . 0 0 . . . . . . . 0 . . . . . . . 
. . . . 0 0 0 . . . . . . . 0 . . . . . . 
. . . . 0 0 0 . . . . . . . . 0 . . . . . 
. . . . . 0 0 0 . . . . . . . . 0 . . . . 
. . . . . 0 0 0 . . . . . . . . . 0 . . . 
. . . . . 0 0 0 0 . . . . . . . . . 0 . . 
. . . . . . 0 0 0 . . . . . . . . . . 0 . 
. . . . . . 0 0 0 0 . . . . . . . . . . 0 
 with color pink at (0,0)
  _01: rectangle with size (5,14) with mask 
0 0 0 . . . . . . . . . . . 
. . . 0 0 0 0 . . . . . . . 
. . . . . . 0 0 0 0 0 . . . 
. . . . . . . . . 0 0 0 0 0 
. . . . . . . . . . . . 0 0 
 with color orange at (1,7)
  _011: rectangle with size (14,5) with mask 
0 . . . . 
0 . . . . 
0 . . . . 
. 0 . . . 
. 0 . . . 
. 0 . . . 
. 0 0 . . 
. . 0 . . 
. . 0 . . 
. . 0 0 . 
. . 0 0 . 
. . . 0 . 
. . . 0 0 
. . . 0 0 
 with color orange at (7,1)
  + 72 delta pixels
diff: 
   (3646.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
6 5#6 6 7#7#1 1 2 2 3 3 4 4 5#5#6 6 7#7#1 
5#6 5#5#6 6 6 7#7#7#1 1 1 2 2 2 3 3 3 4 4 
6 5#6 5#5#5#6 6 6 6 7#7#7#7#1 1 1 1 2 2 2 
6 5#5#0 0 0 5#5#6 6 6 6 6 7#7#7#7#7#1 1 1 
7#6 5#0 0 0 5#5#5#5#6 6 6 6 6 6 7#7#7#7#7#
7#6 5#0 0 0 5#5#5#5#5#5#6 6 6 6 6 6 6 7#7#
1 6 6 0 0 0 6 5#5#0 0 0 5#5#6 6 6 6 6 6 6 
1 7#6 0 0 0 5#6 5#0 0 0 5#5#5#5#6 6 6 6 6 
2 7#6 6 5#5#5#5#6 0 0 0 0 0 0 0 0 5#6 6 6 
2 7#6 6 5#5#5#5#5#6 5#5#0 0 0 0 0 5#5#5#6 
3 1 7#6 6 5#5#5#5#5#6 5#5#5#5#5#5#5#5#5#5#
3 1 7#6 6 5#5#5#5#5#5#6 5#5#5#5#5#5#5#5#5#
4 1 7#6 6 6 5#5#5#5#5#5#6 5#5#5#5#5#5#5#5#
4 2 7#7#6 6 5#5#5#5#5#5#5#6 5#5#5#5#5#5#5#
5#2 0 0 0 0 6 5#5#5#5#5#5#5#6 5#5#5#5#5#5#
5#2 0 0 0 0 6 5#5#5#5#5#5#5#5#6 5#5#5#5#5#
6 3 1 7#7#6 6 6 5#5#5#5#5#5#5#5#6 5#5#5#5#
6 3 1 7#7#6 6 6 0 0 0 0 5#5#5#5#5#6 5#5#5#
7#3 2 1 7#6 6 6 0 0 0 0 5#5#5#5#5#5#6 5#5#
7#4 2 1 7#7#6 6 6 5#5#5#5#5#5#5#5#5#5#6 5#
1 4 2 1 7#7#6 6 6 6 5#5#5#5#5#5#5#5#5#5#6 

diff: 
! size mismatch, 10x10 instead of 21x21

TRAIN 73251a56.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
5#4 5#5#6 6 7#7#8 8 1 1 2 2 3 3 4 4 5#5#6 
4 5#4 4 5#5#5#6 6 6 7#7#7#8 8 8 1 1 1 2 2 
5#4 5#4 4 4 5#5#5#5#6 6 6 6 7#7#0 0 8 8 8 
5#4 4 5#4 4 4 4 5#5#5#5#5#6 6 6 0 0 7#7#7#
6 5#4 4 5#4 4 4 4 4 5#5#5#5#5#5#0 0 6 6 6 
6 5#4 4 4 5#4 4 4 4 4 4 5#5#5#5#0 0 5#6 6 
7#5#5#4 4 4 5#4 4 4 4 4 4 4 5#5#0 0 5#5#5#
7#6 5#4 4 4 4 5#4 4 4 4 4 4 4 4 5#5#5#5#5#
8 6 5#5#4 4 4 4 5#4 4 4 4 4 4 4 4 4 5#5#5#
8 6 5#5#4 4 4 4 4 5#4 4 4 4 4 4 4 4 4 4 5#
1 7#6 5#5#4 4 4 4 4 5#0 0 4 4 4 4 4 4 4 4 
1 7#6 5#5#4 4 4 4 4 4 0 0 4 4 4 4 4 4 4 4 
2 7#6 5#5#5#4 4 4 4 4 0 0 4 4 4 4 4 4 4 4 
2 8 6 6 5#5#4 4 4 4 0 0 0 0 0 4 4 4 4 4 4 
3 8 7#6 5#5#5#4 4 0 0 0 0 0 0 4 4 4 4 4 4 
3 8 7#6 5#5#5#4 4 0 0 0 0 0 0 5#4 4 4 4 4 
4 1 7#6 6 5#5#5#4 0 0 0 4 4 4 4 5#4 4 4 4 
4 1 7#6 6 5#5#5#4 0 0 0 4 4 4 4 4 5#4 4 4 
5#1 8 7#6 5#5#5#5#0 0 0 4 4 4 4 4 4 5#4 4 
5#2 8 7#6 6 5#5#5#4 4 4 4 4 4 4 4 4 4 5#4 
6 2 8 7#6 6 5#5#5#5#4 4 4 4 4 4 4 4 4 4 5#

diff: 
   (0.0 bits)
data: a background with size (21,21) and color yellow and layers
  _0: rectangle with size (21,21) with mask 
0 . 0 0 . . . . . . . . . . . . . . . . . 
. 0 . . 0 0 0 . . . . . . . . . . . . . . 
0 . 0 . . . 0 0 0 0 . . . . . . . . . . . 
0 . . 0 . . . . 0 0 0 0 0 . . . . . . . . 
. 0 . . 0 . . . . . 0 0 0 0 0 0 . . . . . 
. 0 . . . 0 . . . . . . 0 0 0 0 0 0 0 . . 
. 0 0 . . . 0 . . . . . . . 0 0 0 0 0 0 0 
. . 0 . . . . 0 . . . . . . . . 0 0 0 0 0 
. . 0 0 . . . . 0 . . . . . . . . . 0 0 0 
. . 0 0 . . . . . 0 . . . . . . . . . . 0 
. . . 0 0 . . . . . 0 . . . . . . . . . . 
. . . 0 0 . . . . . . 0 . . . . . . . . . 
. . . 0 0 0 . . . . . . 0 . . . . . . . . 
. . . . 0 0 . . . . . . . 0 . . . . . . . 
. . . . 0 0 0 . . . . . . . 0 . . . . . . 
. . . . 0 0 0 . . . . . . . . 0 . . . . . 
. . . . . 0 0 0 . . . . . . . . 0 . . . . 
. . . . . 0 0 0 . . . . . . . . . 0 . . . 
. . . . . 0 0 0 0 . . . . . . . . . 0 . . 
. . . . . . 0 0 0 . . . . . . . . . . 0 . 
. . . . . . 0 0 0 0 . . . . . . . . . . 0 
 with color grey at (0,0)
  _01: rectangle with size (5,14) with mask 
0 0 0 . . . . . . . . . . . 
. . . 0 0 0 0 . . . . . . . 
. . . . . . 0 0 0 0 0 . . . 
. . . . . . . . . 0 0 0 0 0 
. . . . . . . . . . . . 0 0 
 with color pink at (1,7)
  _011: rectangle with size (14,5) with mask 
0 . . . . 
0 . . . . 
0 . . . . 
. 0 . . . 
. 0 . . . 
. 0 . . . 
. 0 0 . . 
. . 0 . . 
. . 0 . . 
. . 0 0 . 
. . 0 0 . 
. . . 0 . 
. . . 0 0 
. . . 0 0 
 with color pink at (7,1)
  + 72 delta pixels
diff: 
   (3646.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#4 5#5#6 6 7#7#8 8 1 1 2 2 3 3 4 4 5#5#6 
4 5#4 4 5#5#5#6 6 6 7#7#7#8 8 8 1 1 1 2 2 
5#4 5#4 4 4 5#5#5#5#6 6 6 6 7#7#0 0 8 8 8 
5#4 4 5#4 4 4 4 5#5#5#5#5#6 6 6 0 0 7#7#7#
6 5#4 4 5#4 4 4 4 4 5#5#5#5#5#5#0 0 6 6 6 
6 5#4 4 4 5#4 4 4 4 4 4 5#5#5#5#0 0 5#6 6 
7#5#5#4 4 4 5#4 4 4 4 4 4 4 5#5#0 0 5#5#5#
7#6 5#4 4 4 4 5#4 4 4 4 4 4 4 4 5#5#5#5#5#
8 6 5#5#4 4 4 4 5#4 4 4 4 4 4 4 4 4 5#5#5#
8 6 5#5#4 4 4 4 4 5#4 4 4 4 4 4 4 4 4 4 5#
1 7#6 5#5#4 4 4 4 4 5#0 0 4 4 4 4 4 4 4 4 
1 7#6 5#5#4 4 4 4 4 4 0 0 4 4 4 4 4 4 4 4 
2 7#6 5#5#5#4 4 4 4 4 0 0 4 4 4 4 4 4 4 4 
2 8 6 6 5#5#4 4 4 4 0 0 0 0 0 4 4 4 4 4 4 
3 8 7#6 5#5#5#4 4 0 0 0 0 0 0 4 4 4 4 4 4 
3 8 7#6 5#5#5#4 4 0 0 0 0 0 0 5#4 4 4 4 4 
4 1 7#6 6 5#5#5#4 0 0 0 4 4 4 4 5#4 4 4 4 
4 1 7#6 6 5#5#5#4 0 0 0 4 4 4 4 4 5#4 4 4 
5#1 8 7#6 5#5#5#5#0 0 0 4 4 4 4 4 4 5#4 4 
5#2 8 7#6 6 5#5#5#4 4 4 4 4 4 4 4 4 4 5#4 
6 2 8 7#6 6 5#5#5#5#4 4 4 4 4 4 4 4 4 4 5#

diff: 
! size mismatch, 10x10 instead of 21x21

TRAIN 73251a56.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 3 4 4 5#5#6 6 7#7#8 8 9#9#1 1 2 2 3 3 4 
3 4 3 3 4 4 4 5#5#5#0 0 6 7#7#7#8 8 8 9#9#
4 3 4 3 3 3 4 4 4 4 0 0 5#5#6 6 6 6 7#7#7#
4 3 3 4 3 3 3 3 4 4 0 0 4 5#5#5#5#5#6 6 6 
5#4 3 3 4 3 3 3 3 3 0 0 4 4 4 4 5#5#5#5#5#
5#4 3 3 3 4 3 3 3 3 0 0 4 4 4 4 4 4 4 5#5#
6 4 4 3 3 3 4 3 3 3 3 3 3 3 4 4 4 4 4 4 4 
6 5#4 3 3 3 3 4 3 3 3 3 3 3 3 3 4 4 4 4 4 
0 0 0 0 0 3 3 3 4 3 3 3 3 3 3 3 3 3 4 4 4 
0 0 0 0 0 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 4 
8 6 5#4 4 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 
8 6 5#4 4 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 
9#6 5#4 4 4 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 
9#7#5#5#4 4 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 
1 7#6 5#4 4 4 3 3 3 3 3 3 3 4 3 3 3 3 3 3 
1 7#6 5#0 0 0 0 0 3 3 3 3 3 3 0 0 0 0 0 3 
2 8 6 5#0 0 0 0 0 3 3 3 3 3 3 0 0 0 0 0 3 
2 8 6 5#0 0 0 0 0 3 3 3 3 3 3 3 3 4 3 3 3 
3 8 7#6 5#4 4 4 4 3 3 3 0 0 0 0 0 3 4 3 3 
3 9#7#6 5#5#4 4 4 3 3 3 0 0 0 0 0 3 3 4 3 
4 9#7#6 5#5#4 4 4 4 3 3 3 3 3 3 3 3 3 3 4 

diff: 
! size mismatch, 10x10 instead of 21x21

TEST 73251a56.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.8 sec (59.8 sec/task)
bits-train-error = 107729.5 bits (107729.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-225] Checking task 7447852a.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 50524.2 = 50526.5
DL output with Mo: L = 2.3 + 50524.2 = 50526.5
DL input+output M: L = 4.6 + 101048.4 = 101053.0

# learning a model for train pairs
2.000	
1.343	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.915	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.629	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.301	OUT ADD ^.layer_0 = ^.layer_0
0.228	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.162	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.132	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.121	OUT SPE ^.size = ^.size
0.113	OUT SPE ^.layer_01.shape.mask = 
0 0 0 
0 0 0 

0.107	OUT SPE ^.layer_0111.pos = '(1, 0)
0.103	IN  SPE ^.layer_0.shape.color = red
0.100	OUT SPE ^.layer_01.shape.color = yellow
0.097	OUT SPE ^.layer_011.shape.color = yellow
0.094	OUT SPE ^.layer_0111.shape.color = yellow
0.090	OUT SPE ^.layer_01.pos.j = bottom(^.layer_0) + 3
0.087	OUT SPE ^.layer_0111.shape.mask.size.i = 2
0.085	OUT SPE ^.layer_01.pos.i = '0
0.083	OUT SPE ^.layer_011.shape.mask.model = Full
0.082	OUT SPE ^.layer_0111.shape.mask.model = Full
0.080	IN  SPE ^.color = black
0.079	OUT SPE ^.color = black
0.027	
0.027	IN  GEN ^.layer_0.shape.color = ?
0.027	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: 
0 0 0 
0 0 0 
 with color yellow at ('0,bottom(^.layer_0) + 3)
  _011: rectangle with size (?,?) with model Full with color yellow at (?,?)
  _0111: rectangle with size (2,?) with model Full with color yellow at '(1, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at (?,?)

DL input  with Mi: L = 45.4 + 2621.1 = 2666.5
DL output with Mo: L = 141.5 + 1169.6 = 1311.1
DL input+output M: L = 186.9 + 3790.6 = 3977.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: 
0 0 0 
0 0 0 
 with color yellow at ('0,bottom(^.layer_0) + 3)
  _011: rectangle with size (?,?) with model Full with color yellow at (?,?)
  _0111: rectangle with size (2,?) with model Full with color yellow at '(1, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 141.5 + 1169.6 = 1311.1
DL input+output M: L = 183.5 + 1169.6 = 1353.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,10) and color black and layers
  _0: rectangle with size (3,10) with mask 
0 . . . 0 . . . 0 . 
. 0 . 0 . 0 . 0 . 0 
. . 0 . . . 0 . . . 
 with color red at (0,0)
diff: 
   (0.0 bits)
data: a background with size (3,10) and color black and layers
  _0: 
2 . . . 2 . . . 2 . 
. 2 . 2 . 2 . 2 . 2 
. . 2 . . . 2 . . . 
 at (0,0)
  _01: 
0 0 0 
0 0 0 
 with color yellow at (0,5)
  _011: rectangle with size (1,2) with model Full with color yellow at (2,0)
  _0111: rectangle with size (2,1) with model Full with color yellow at (1,0)
diff: 
   (21.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,10) and color black and layers
  _0: rectangle with size (3,10) with mask 
0 . . . 0 . . . 0 . 
. 0 . 0 . 0 . 0 . 0 
. . 0 . . . 0 . . . 
 with color red at (0,0)
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,0)
  + 9 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,4)
  + 9 delta pixels
diff: 
! 15 wrong pixels (generated / expected)

TRAIN 7447852a.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,15) and color black and layers
  _0: rectangle with size (3,15) with mask 
0 . . . 0 . . . 0 . . . 0 . . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
. . 0 . . . 0 . . . 0 . . . 0 
 with color red at (0,0)
diff: 
   (0.0 bits)
data: a background with size (3,15) and color black and layers
  _0: 
2 . . . 2 . . . 2 . . . 2 . . 
. 2 . 2 . 2 . 2 . 2 . 2 . 2 . 
. . 2 . . . 2 . . . 2 . . . 2 
 at (0,0)
  _01: 
0 0 0 
0 0 0 
 with color yellow at (0,5)
  _011: rectangle with size (2,3) with model Full with color yellow at (1,11)
  _0111: rectangle with size (2,2) with model Full with color yellow at (1,0)
diff: 
   (27.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,15) and color black and layers
  _0: rectangle with size (3,15) with mask 
0 . . . 0 . . . 0 . . . 0 . . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
. . 0 . . . 0 . . . 0 . . . 0 
 with color red at (0,0)
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,15) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,0)
  + 14 delta pixels
diff: 
! 24 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,15) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,4)
  + 14 delta pixels
diff: 
! 24 wrong pixels (generated / expected)

TRAIN 7447852a.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,18) and color black and layers
  _0: rectangle with size (3,18) with mask 
0 . . . 0 . . . 0 . . . 0 . . . 0 . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 
. . 0 . . . 0 . . . 0 . . . 0 . . . 
 with color red at (0,0)
diff: 
   (0.0 bits)
data: a background with size (3,18) and color black and layers
  _0: 
2 . . . 2 . . . 2 . . . 2 . . . 2 . 
. 2 . 2 . 2 . 2 . 2 . 2 . 2 . 2 . 2 
. . 2 . . . 2 . . . 2 . . . 2 . . . 
 at (0,0)
  _01: 
0 0 0 
0 0 0 
 with color yellow at (0,5)
  _011: rectangle with size (2,3) with model Full with color yellow at (1,11)
  _0111: rectangle with size (2,2) with model Full with color yellow at (1,0)
  + 1 delta pixels
diff: 
   (68.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,18) and color black and layers
  _0: rectangle with size (3,18) with mask 
0 . . . 0 . . . 0 . . . 0 . . . 0 . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 
. . 0 . . . 0 . . . 0 . . . 0 . . . 
 with color red at (0,0)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,18) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,0)
  + 17 delta pixels
diff: 
! 28 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,18) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,4)
  + 17 delta pixels
diff: 
! 28 wrong pixels (generated / expected)

TRAIN 7447852a.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,25) and color black and layers
  _0: rectangle with size (3,25) with mask 
0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
. . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . 
 with color red at (0,0)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,25) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,0)
  + 24 delta pixels
diff: 
! 41 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,25) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,4)
  + 24 delta pixels
diff: 
! 41 wrong pixels (generated / expected)

TEST 7447852a.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 10.4 sec (10.4 sec/task)
bits-train-error = 1169.6 bits (1169.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-224] Checking task 7468f01a.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 243398.3 = 243400.7
DL output with Mo: L = 2.3 + 31477.2 = 31479.5
DL input+output M: L = 4.6 + 274875.5 = 274880.2

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = applySym(flipWidth, strip(^))
0.139	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.036	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.016	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.016	IN  SPE ^.layer_01.shape.mask.model = Full
0.015	IN  SPE ^.color = black
0.001	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
applySym(flipWidth, strip(^))
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 70.9 + 3540.8 = 3611.7
DL output with Mo: L = 17.9 + 0.0 = 17.9
DL input+output M: L = 88.7 + 3540.8 = 3629.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
applySym(flipWidth, strip(^))
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 17.9 + 0.0 = 17.9
DL input+output M: L = 20.2 + 0.0 = 20.2

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 8 8 8 8 8 8 2 8 0 0 0 0 0 
0 0 8 2 2 8 8 8 8 8 0 0 0 0 0 
0 0 8 8 2 2 8 8 8 8 0 0 0 0 0 
0 0 8 8 8 8 8 8 8 8 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
8 2 8 8 8 8 8 8 
8 8 8 8 8 2 2 8 
8 8 8 8 2 2 8 8 
8 8 8 8 8 8 8 8 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 8 8 8 8 8 8 2 8 0 0 0 0 0 
0 0 8 2 2 8 8 8 8 8 0 0 0 0 0 
0 0 8 8 2 2 8 8 8 8 0 0 0 0 0 
0 0 8 8 8 8 8 8 8 8 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 7468f01a.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 4 4 4 4 4 0 0 0 0 0 0 0 0 
0 0 0 4 4 4 4 4 0 0 0 0 0 0 0 0 
0 0 0 4 1 1 4 4 0 0 0 0 0 0 0 0 
0 0 0 4 4 1 1 4 0 0 0 0 0 0 0 0 
0 0 0 4 4 1 4 4 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
4 4 4 4 4 
4 4 4 4 4 
4 4 1 1 4 
4 1 1 4 4 
4 4 1 4 4 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 4 4 4 4 4 0 0 0 0 0 0 0 0 
0 0 0 4 4 4 4 4 0 0 0 0 0 0 0 0 
0 0 0 4 1 1 4 4 0 0 0 0 0 0 0 0 
0 0 0 4 4 1 1 4 0 0 0 0 0 0 0 0 
0 0 0 4 4 1 4 4 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 7468f01a.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 6 6 6 3 6 6 0 0 0 0 0 0 0 0 0 
0 0 6 3 3 3 6 6 0 0 0 0 0 0 0 0 0 
0 0 6 6 6 6 3 6 0 0 0 0 0 0 0 0 0 
0 0 6 6 6 6 3 6 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
6 6 3 6 6 6 
6 6 3 3 3 6 
6 3 6 6 6 6 
6 3 6 6 6 6 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 6 6 6 3 6 6 0 0 0 0 0 0 0 0 0 
0 0 6 3 3 3 6 6 0 0 0 0 0 0 0 0 0 
0 0 6 6 6 6 3 6 0 0 0 0 0 0 0 0 0 
0 0 6 6 6 6 3 6 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 7468f01a.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 1 1 1 1 8 1 1 1 0 0 0 0 0 0 
0 0 0 1 1 1 1 1 8 8 1 0 0 0 0 0 0 
0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 
0 0 0 8 8 8 1 1 1 1 1 0 0 0 0 0 0 
0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 
0 0 0 1 1 8 8 8 1 1 1 0 0 0 0 0 0 
0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TEST 7468f01a.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.4 sec (1.4 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-223] Checking task 746b3537.json: 5 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 25280.7 = 25283.1
DL output with Mo: L = 2.3 + 6967.2 = 6969.5
DL input+output M: L = 4.6 + 32247.9 = 32252.5

# learning a model for train pairs
2.000	
1.610	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.320	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.094	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.926	OUT ADD ^.layer_0 = point with color ? at (?,?)
0.800	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.681	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.598	OUT SPE ^.layer_0 = fillResizeAlike(transparent, '(1, 1), ^.layer_0)
0.537	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.475	OUT SPE ^.color = ^.layer_01.shape.color
0.436	OUT SPE ^.layer_01.shape.color = ^.layer_011.shape.color
0.414	OUT SPE ^.layer_01.pos.i = right(^.layer_0)
0.396	OUT SPE ^.layer_01.pos.j = ^.layer_01.pos.j / '2
0.390	IN  SPE ^.layer_0.shape.mask.model = Full
0.385	IN  SPE ^.layer_01.shape.mask.model = Full
0.379	IN  SPE ^.layer_011.shape.mask.model = Full
0.200	
0.200	IN  GEN ^.layer_011.shape.mask.model = ?
0.200	IN  GEN ^.layer_01.shape.mask.model = ?
0.200	IN  GEN ^.layer_0.shape.mask.model = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ^.layer_01.shape.color and layers
  _0: fillResizeAlike(transparent, '(1, 1), ^.layer_0)
  _01: point with color ^.layer_011.shape.color at (right(^.layer_0),^.layer_01.pos.j / '2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 99.6 + 4559.7 = 4659.4
DL output with Mo: L = 112.9 + 1244.8 = 1357.8
DL input+output M: L = 212.6 + 5804.6 = 6017.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ^.layer_01.shape.color and layers
  _0: fillResizeAlike(transparent, '(1, 1), ^.layer_0)
  _01: point with color ^.layer_011.shape.color at (right(^.layer_0),^.layer_01.pos.j / '2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 40.0 = 138.1
DL output with Mo: L = 112.9 + 1244.8 = 1357.8
DL input+output M: L = 211.0 + 1284.8 = 1495.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color blue at (0,0)
  _01: rectangle with size (1,3) with model Full with color red at (1,0)
  _011: rectangle with size (1,3) with model Full with color blue at (2,0)
diff: 
   (0.0 bits)
data: a background with size (3,1) and color red and layers
  _0: 
1 
 at (0,0)
  _01: point with color blue at (2,0)
diff: 
   (9.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color blue at (0,0)
  _01: rectangle with size (1,3) with model Full with color red at (1,0)
  _011: rectangle with size (1,3) with model Full with color blue at (2,0)
diff: 
! size mismatch, 10x10 instead of 3x1
>> Trial 2
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color blue at (0,0)
  _01: rectangle with size (1,3) with model Full with color blue at (2,0)
  _011: rectangle with size (1,3) with model Full with color red at (1,0)
diff: 
! size mismatch, 10x10 instead of 3x1
>> Trial 3
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (1,0)
  _01: rectangle with size (1,3) with model Full with color blue at (0,0)
  _011: rectangle with size (1,3) with model Full with color blue at (2,0)
diff: 
! size mismatch, 10x10 instead of 3x1

TRAIN 746b3537.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,1) with model Full with color green at (0,0)
  _01: rectangle with size (3,1) with model Full with color pink at (0,2)
  _011: rectangle with size (3,1) with model Full with color yellow at (0,1)
diff: 
   (2.0 bits)
data: a background with size (1,3) and color pink and layers
  _0: 
3 
 at (0,0)
  _01: point with color yellow at (0,1)
diff: 
   (9.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,1) with model Full with color green at (0,0)
  _01: rectangle with size (3,1) with model Full with color yellow at (0,1)
  _011: rectangle with size (3,1) with model Full with color pink at (0,2)
diff: 
! size mismatch, 10x10 instead of 1x3
>> Trial 2
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,1) with model Full with color green at (0,0)
  _01: rectangle with size (3,1) with model Full with color pink at (0,2)
  _011: rectangle with size (3,1) with model Full with color yellow at (0,1)
diff: 
! size mismatch, 10x10 instead of 1x3
>> Trial 3
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,1) with model Full with color yellow at (0,1)
  _01: rectangle with size (3,1) with model Full with color green at (0,0)
  _011: rectangle with size (3,1) with model Full with color pink at (0,2)
diff: 
! size mismatch, 10x10 instead of 1x3

TRAIN 746b3537.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,5) and color green and layers
  _0: rectangle with size (3,1) with model Full with color red at (0,0)
  _01: rectangle with size (3,1) with model Full with color blue at (0,4)
  _011: rectangle with size (3,1) with model Full with color cyan at (0,3)
diff: 
   (2.0 bits)
data: a background with size (1,4) and color blue and layers
  _0: 
2 
 at (0,0)
  _01: point with color cyan at (0,2)
  + 1 delta pixels
diff: 
   (47.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,5) and color green and layers
  _0: rectangle with size (3,1) with model Full with color red at (0,0)
  _01: rectangle with size (3,1) with model Full with color cyan at (0,3)
  _011: rectangle with size (3,1) with model Full with color blue at (0,4)
diff: 
! size mismatch, 10x10 instead of 1x4
>> Trial 2
data: a background with size (3,5) and color green and layers
  _0: rectangle with size (3,1) with model Full with color red at (0,0)
  _01: rectangle with size (3,1) with model Full with color blue at (0,4)
  _011: rectangle with size (3,1) with model Full with color cyan at (0,3)
diff: 
! size mismatch, 10x10 instead of 1x4
>> Trial 3
data: a background with size (3,5) and color green and layers
  _0: rectangle with size (3,1) with model Full with color cyan at (0,3)
  _01: rectangle with size (3,1) with model Full with color red at (0,0)
  _011: rectangle with size (3,1) with model Full with color blue at (0,4)
diff: 
! size mismatch, 10x10 instead of 1x4

TRAIN 746b3537.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (4,2) and color black and layers
  _0: rectangle with size (2,2) with model Full with color cyan at (2,0)
  _01: rectangle with size (1,2) with model Full with color red at (0,0)
  _011: rectangle with size (1,2) with model Full with color pink at (1,0)
diff: 
   (0.0 bits)
data: a background with size (3,1) and color red and layers
  _0: 
8 
 at (2,0)
  _01: point with color pink at (1,0)
diff: 
   (9.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,2) and color black and layers
  _0: rectangle with size (2,2) with model Full with color cyan at (2,0)
  _01: rectangle with size (1,2) with model Full with color red at (0,0)
  _011: rectangle with size (1,2) with model Full with color pink at (1,0)
diff: 
! size mismatch, 10x10 instead of 3x1
>> Trial 2
data: a background with size (4,2) and color black and layers
  _0: rectangle with size (2,2) with model Full with color cyan at (2,0)
  _01: rectangle with size (1,2) with model Full with color pink at (1,0)
  _011: rectangle with size (1,2) with model Full with color red at (0,0)
diff: 
! size mismatch, 10x10 instead of 3x1
>> Trial 3
data: a background with size (4,2) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (0,0)
  _01: rectangle with size (2,2) with model Full with color cyan at (2,0)
  _011: rectangle with size (1,2) with model Full with color pink at (1,0)
diff: 
! size mismatch, 10x10 instead of 3x1

TRAIN 746b3537.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: a background with size (6,4) and color red and layers
  _0: rectangle with size (2,4) with model Full with color yellow at (0,0)
  _01: rectangle with size (1,4) with model Full with color cyan at (4,0)
  _011: rectangle with size (1,4) with model Full with color green at (5,0)
diff: 
   (0.0 bits)
data: a background with size (4,1) and color cyan and layers
  _0: 
4 
 at (0,0)
  _01: point with color green at (3,0)
  + 1 delta pixels
diff: 
   (47.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,4) and color red and layers
  _0: rectangle with size (2,4) with model Full with color yellow at (0,0)
  _01: rectangle with size (1,4) with model Full with color cyan at (4,0)
  _011: rectangle with size (1,4) with model Full with color green at (5,0)
diff: 
! size mismatch, 10x10 instead of 4x1
>> Trial 2
data: a background with size (6,4) and color yellow and layers
  _0: rectangle with size (2,4) with model Full with color red at (2,0)
  _01: rectangle with size (1,4) with model Full with color cyan at (4,0)
  _011: rectangle with size (1,4) with model Full with color green at (5,0)
diff: 
! size mismatch, 10x10 instead of 4x1
>> Trial 3
data: a background with size (6,4) and color red and layers
  _0: rectangle with size (2,4) with model Full with color yellow at (0,0)
  _01: rectangle with size (1,4) with model Full with color green at (5,0)
  _011: rectangle with size (1,4) with model Full with color cyan at (4,0)
diff: 
! size mismatch, 10x10 instead of 4x1

TRAIN 746b3537.json/5: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,9) and color green and layers
  _0: rectangle with size (4,2) with model Full with color blue at (0,0)
  _01: rectangle with size (4,2) with model Full with color cyan at (0,6)
  _011: rectangle with size (4,1) with model Full with color red at (0,2)
  + 4 delta pixels
diff: 
! size mismatch, 10x10 instead of 1x5
>> Trial 2
data: a background with size (4,9) and color green and layers
  _0: rectangle with size (4,2) with model Full with color blue at (0,0)
  _01: rectangle with size (4,2) with model Full with color cyan at (0,6)
  _011: rectangle with size (4,1) with model Full with color yellow at (0,8)
  + 4 delta pixels
diff: 
! size mismatch, 10x10 instead of 1x5
>> Trial 3
data: a background with size (4,9) and color green and layers
  _0: rectangle with size (4,2) with model Full with color blue at (0,0)
  _01: rectangle with size (4,1) with model Full with color red at (0,2)
  _011: rectangle with size (4,2) with model Full with color cyan at (0,6)
  + 4 delta pixels
diff: 
! size mismatch, 10x10 instead of 1x5

TEST 746b3537.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 6.1 sec (6.1 sec/task)
bits-train-error = 1244.8 bits (1244.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-222] Checking task 74dd1130.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 14046.4 = 14048.7
DL output with Mo: L = 2.3 + 14046.4 = 14048.7
DL input+output M: L = 4.6 + 28092.8 = 28097.5

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = applySym(flipDiag1, ^)
0.592	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.392	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.285	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.258	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.249	IN  SPE ^.layer_0.shape.mask.model = Full
0.007	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
applySym(flipDiag1, ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 88.8 + 3404.0 = 3492.8
DL output with Mo: L = 12.3 + 0.0 = 12.3
DL input+output M: L = 101.1 + 3404.0 = 3505.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
applySym(flipDiag1, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 12.3 + 0.0 = 12.3
DL input+output M: L = 14.6 + 0.0 = 14.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
2 2 1 
1 5#1 
5#2 2 

diff: 
   (0.0 bits)
data: 
2 1 5#
2 5#2 
1 1 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 2 1 
1 5#1 
5#2 2 

diff: 
correct output grid

TRAIN 74dd1130.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
2 2 5#
6 2 2 
5#5#5#

diff: 
   (0.0 bits)
data: 
2 6 5#
2 2 5#
5#2 5#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 2 5#
6 2 2 
5#5#5#

diff: 
correct output grid

TRAIN 74dd1130.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
9#9#5#
5#5#8 
5#8 9#

diff: 
   (0.0 bits)
data: 
9#5#5#
9#5#8 
5#8 9#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
9#9#5#
5#5#8 
5#8 9#

diff: 
correct output grid

TRAIN 74dd1130.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: 
2 6 6 
2 1 1 
2 6 2 

diff: 
   (0.0 bits)
data: 
2 2 2 
6 1 6 
6 1 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 6 6 
2 1 1 
2 6 2 

diff: 
correct output grid

TRAIN 74dd1130.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
9#3 4 
9#4 4 
9#3 4 

diff: 
correct output grid

TEST 74dd1130.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.0 sec (1.0 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-221] Checking task 75b8110e.json: 5 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 126298.9 = 126301.2
DL output with Mo: L = 2.3 + 30998.4 = 31000.7
DL input+output M: L = 4.6 + 157297.3 = 157301.9

# learning a model for train pairs
2.000	
1.446	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.043	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.860	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.740	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.649	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.560	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.507	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.456	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.420	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.383	OUT ADD ^.layer_010 = ^.layer_011.shape at (?,?)
0.360	OUT SPE ^.size = ^.size / '2
0.342	OUT ADD ^.layer_0100 = point with color ? at (?,?)
0.329	OUT SPE ^.layer_010.pos = ^.layer_011.pos - projJ(^.layer_0.shape.mask.size)
0.319	OUT SPE ^.layer_011.shape.mask.size = '(1, 1)
0.309	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.303	OUT SPE ^.layer_011.pos.j = 1
0.296	OUT SPE ^.layer_01.shape.mask.size.i = average(^.layer_01.shape.mask.size.i, ^.layer_011.shape.mask.size.i) - ^.layer_0111.shape.mask.size.j
0.290	OUT SPE ^.layer_01.shape.mask.size.j = ^.layer_0111.shape.mask.size.j
0.285	OUT SPE ^.layer_011.shape.mask = 
0 

0.280	OUT SPE ^.layer_01.pos.i = ^.layer_0.pos.i - min(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i)
0.277	IN  SPE ^.layer_011.shape.color = grey
0.258	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.249	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.133	
0.133	IN  DEL ^.layer_01111
0.133	IN  DEL ^.layer_011111
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size / '2 and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (?,?)
  _0100: point with color ? at (?,?)
  _010: ^.layer_011.shape at ^.layer_011.pos - projJ(^.layer_0.shape.mask.size)
  _01: rectangle with size (average(^.layer_01.shape.mask.size.i, ^.layer_011.shape.mask.size.i) - ^.layer_0111.shape.mask.size.j,^.layer_0111.shape.mask.size.j) with model ? with color ? at (^.layer_0.pos.i - min(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i),?)
  _011: 
0 
 with color ? at (?,1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color grey at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: point with color ? at (?,?)

DL input  with Mi: L = 174.4 + 14628.1 = 14802.5
DL output with Mo: L = 334.5 + 3743.2 = 4077.7
DL input+output M: L = 508.9 + 18371.3 = 18880.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size / '2 and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (?,?)
  _0100: point with color ? at (?,?)
  _010: ^.layer_011.shape at ^.layer_011.pos - projJ(^.layer_0.shape.mask.size)
  _01: rectangle with size (average(^.layer_01.shape.mask.size.i, ^.layer_011.shape.mask.size.i) - ^.layer_0111.shape.mask.size.j,^.layer_0111.shape.mask.size.j) with model ? with color ? at (^.layer_0.pos.i - min(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i),?)
  _011: 
0 
 with color ? at (?,1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color grey at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 129.1 + 0.0 = 129.1
DL output with Mo: L = 334.5 + 3743.2 = 4077.7
DL input+output M: L = 463.6 + 3743.2 = 4206.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (8,8) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . 0 . 
0 0 0 . 
0 . 0 0 
. 0 0 . 
 with color pink at (4,0)
  _01: rectangle with size (4,3) with mask 
0 0 . 
0 0 . 
. . 0 
. 0 . 
 with color yellow at (0,0)
  _011: rectangle with size (2,3) with mask 
. . 0 
0 0 . 
 with color grey at (2,4)
  _0111: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color brown at (6,4)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (3,4) with mask 
0 0 0 . 
0 . . 0 
. . 0 . 
 with color pink at (1,0)
  _0100: point with color grey at (0,2)
  _010: 
. . 5#
5#5#. 
 at (2,0)
  _01: rectangle with size (1,2) with model Full with color yellow at (0,0)
  _011: 
0 
 with color brown at (2,1)
  + 1 delta pixels
diff: 
   (115.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . 0 . 
0 0 0 . 
0 . 0 0 
. 0 0 . 
 with color pink at (4,0)
  _01: rectangle with size (4,3) with mask 
0 0 . 
0 0 . 
. . 0 
. 0 . 
 with color yellow at (0,0)
  _011: rectangle with size (2,3) with mask 
. . 0 
0 0 . 
 with color grey at (2,4)
  _0111: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color brown at (6,4)
  + 3 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 0 . 
0 0 . 
. . 0 
. 0 . 
 with color yellow at (0,0)
  _01: rectangle with size (4,4) with mask 
. . 0 . 
0 0 0 . 
0 . 0 0 
. 0 0 . 
 with color pink at (4,0)
  _011: rectangle with size (2,3) with mask 
. . 0 
0 0 . 
 with color grey at (2,4)
  _0111: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color brown at (6,4)
  + 3 delta pixels
diff: 
! 11 wrong pixels (generated / expected)

TRAIN 75b8110e.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (8,8) and color black and layers
  _0: rectangle with size (2,4) with mask 
0 0 . 0 
0 . 0 0 
 with color yellow at (2,0)
  _01: rectangle with size (4,2) with mask 
. 0 
0 . 
. 0 
0 0 
 with color pink at (4,2)
  _011: rectangle with size (4,4) with mask 
0 0 . . 
. . 0 0 
. 0 . . 
. 0 0 0 
 with color grey at (0,4)
  _0111: rectangle with size (3,1) with model Full with color brown at (4,5)
  + 6 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (1,1) with model Full with color yellow at (3,0)
  _0100: point with color pink at (2,0)
  _010: 
5#5#. . 
. . 5#5#
. 5#. . 
. 5#5#5#
 at (0,0)
  _01: rectangle with size (3,1) with model Full with color pink at (0,3)
  _011: 
0 
 with color brown at (1,1)
diff: 
   (57.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (2,4) with mask 
0 0 . 0 
0 . 0 0 
 with color yellow at (2,0)
  _01: rectangle with size (4,2) with mask 
. 0 
0 . 
. 0 
0 0 
 with color pink at (4,2)
  _011: rectangle with size (4,4) with mask 
0 0 . . 
. . 0 0 
. 0 . . 
. 0 0 0 
 with color grey at (0,4)
  _0111: rectangle with size (3,1) with model Full with color brown at (4,5)
  + 6 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (4,2) with mask 
. 0 
0 . 
. 0 
0 0 
 with color pink at (4,2)
  _01: rectangle with size (2,4) with mask 
0 0 . 0 
0 . 0 0 
 with color yellow at (2,0)
  _011: rectangle with size (4,4) with mask 
0 0 . . 
. . 0 0 
. 0 . . 
. 0 0 0 
 with color grey at (0,4)
  _0111: rectangle with size (3,1) with model Full with color brown at (4,5)
  + 6 delta pixels
diff: 
! 14 wrong pixels (generated / expected)

TRAIN 75b8110e.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (8,8) and color black and layers
  _0: rectangle with size (3,4) with mask 
. 0 0 . 
. 0 . 0 
0 0 0 . 
 with color brown at (4,4)
  _01: rectangle with size (4,1) with model Full with color pink at (4,0)
  _011: rectangle with size (4,3) with mask 
0 . . 
. 0 . 
. . 0 
. . 0 
 with color grey at (0,4)
  _0111: rectangle with size (2,1) with model Full with color yellow at (2,3)
  + 5 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color yellow and layers
  _0: rectangle with size (2,3) with mask 
0 0 . 
. . 0 
 with color brown at (0,1)
  _0100: point with color black at (1,2)
  _010: 
5#. . 
. 5#. 
. . 5#
. . 5#
 at (0,0)
  _01: rectangle with size (3,1) with model Full with color pink at (1,0)
  _011: 
0 
 with color brown at (2,1)
diff: 
   (74.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (3,4) with mask 
. 0 0 . 
. 0 . 0 
0 0 0 . 
 with color brown at (4,4)
  _01: rectangle with size (4,1) with model Full with color pink at (4,0)
  _011: rectangle with size (4,3) with mask 
0 . . 
. 0 . 
. . 0 
. . 0 
 with color grey at (0,4)
  _0111: rectangle with size (2,1) with model Full with color yellow at (2,3)
  + 5 delta pixels
diff: 
! 12 wrong pixels (generated / expected)

TRAIN 75b8110e.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (8,8) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . 0 0 
. 0 0 0 
0 0 . 0 
0 . 0 0 
 with color brown at (4,4)
  _01: rectangle with size (4,4) with mask 
0 0 0 . 
0 0 0 . 
0 . . 0 
0 0 . 0 
 with color pink at (4,0)
  _011: rectangle with size (4,2) with mask 
. 0 
. 0 
0 0 
. 0 
 with color grey at (0,6)
  _0111: rectangle with size (3,2) with mask 
. 0 
0 . 
0 0 
 with color yellow at (0,2)
  + 5 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color pink and layers
  _0: rectangle with size (1,1) with model Full with color brown at (3,2)
  _0100: point with color grey at (3,0)
  _010: 
. 5#
. 5#
5#5#
. 5#
 at (0,2)
  _01: rectangle with size (2,2) with model Odd Checkboard with color grey at (0,0)
  _011: 
0 
 with color brown at (2,1)
diff: 
   (67.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . 0 0 
. 0 0 0 
0 0 . 0 
0 . 0 0 
 with color brown at (4,4)
  _01: rectangle with size (4,4) with mask 
0 0 0 . 
0 0 0 . 
0 . . 0 
0 0 . 0 
 with color pink at (4,0)
  _011: rectangle with size (4,2) with mask 
. 0 
. 0 
0 0 
. 0 
 with color grey at (0,6)
  _0111: rectangle with size (3,2) with mask 
. 0 
0 . 
0 0 
 with color yellow at (0,2)
  + 5 delta pixels
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 . 
0 0 0 . 
0 . . 0 
0 0 . 0 
 with color pink at (4,0)
  _01: rectangle with size (4,4) with mask 
0 . 0 0 
. 0 0 0 
0 0 . 0 
0 . 0 0 
 with color brown at (4,4)
  _011: rectangle with size (4,2) with mask 
. 0 
. 0 
0 0 
. 0 
 with color grey at (0,6)
  _0111: rectangle with size (3,2) with mask 
. 0 
0 . 
0 0 
 with color yellow at (0,2)
  + 5 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . 0 0 
. 0 0 0 
0 0 . 0 
0 . 0 0 
 with color brown at (4,4)
  _01: rectangle with size (4,4) with mask 
0 0 0 . 
0 0 0 . 
0 . . 0 
0 0 . 0 
 with color pink at (4,0)
  _011: rectangle with size (4,1) with model Full with color grey at (0,7)
  _0111: rectangle with size (3,2) with mask 
. 0 
0 . 
0 0 
 with color yellow at (0,2)
  + 6 delta pixels
diff: 
! 12 wrong pixels (generated / expected)

TRAIN 75b8110e.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: a background with size (8,8) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . 0 0 
0 . 0 . 
0 . 0 0 
. 0 . 0 
 with color brown at (4,4)
  _01: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color yellow at (0,1)
  _011: rectangle with size (4,4) with mask 
. 0 0 0 
0 0 . 0 
0 . . . 
0 . . . 
 with color grey at (0,4)
  _0111: rectangle with size (4,1) with model Full with color pink at (4,3)
  + 5 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (2,1) with model Full with color brown at (1,2)
  _0100: point with color pink at (0,0)
  _010: 
. 5#5#5#
5#5#. 5#
5#. . . 
5#. . . 
 at (0,0)
  _01: rectangle with size (2,1) with model Full with color pink at (2,3)
  _011: 
0 
 with color pink at (3,1)
diff: 
   (59.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . 0 0 
0 . 0 . 
0 . 0 0 
. 0 . 0 
 with color brown at (4,4)
  _01: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color yellow at (0,1)
  _011: rectangle with size (4,4) with mask 
. 0 0 0 
0 0 . 0 
0 . . . 
0 . . . 
 with color grey at (0,4)
  _0111: rectangle with size (4,1) with model Full with color pink at (4,3)
  + 5 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color yellow at (0,1)
  _01: rectangle with size (4,4) with mask 
. . 0 0 
0 . 0 . 
0 . 0 0 
. 0 . 0 
 with color brown at (4,4)
  _011: rectangle with size (4,4) with mask 
. 0 0 0 
0 0 . 0 
0 . . . 
0 . . . 
 with color grey at (0,4)
  _0111: rectangle with size (4,1) with model Full with color pink at (4,3)
  + 5 delta pixels
diff: 
! 13 wrong pixels (generated / expected)

TRAIN 75b8110e.json/5: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (3,4) with mask 
. 0 . 0 
. 0 0 0 
0 0 0 . 
 with color yellow at (0,0)
  _01: rectangle with size (4,4) with mask 
0 0 0 . 
. 0 . . 
. . 0 0 
. 0 . . 
 with color brown at (4,4)
  _011: rectangle with size (4,4) with mask 
0 . . . 
0 . 0 0 
. 0 0 0 
0 . . . 
 with color grey at (0,4)
  _0111: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color pink at (4,2)
  + 3 delta pixels
diff: 
! 8 wrong pixels (generated / expected)

TEST 75b8110e.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.2 sec (59.2 sec/task)
bits-train-error = 3743.2 bits (3743.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-220] Checking task 760b3cac.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 63689.7 = 63692.0
DL output with Mo: L = 2.3 + 63689.7 = 63692.0
DL input+output M: L = 4.6 + 127379.4 = 127384.1

# learning a model for train pairs
2.000	
1.201	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.500	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.329	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.243	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.164	OUT ADD ^.layer_01 = ^.layer_0
0.082	IN  ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.074	OUT SPE ^.size = ^.size
0.067	OUT SPE ^.layer_0.shape.mask.size = tiling(^.layer_0.shape.mask.size, 1, 2)
0.064	IN  SPE ^.layer_00.shape.color = cyan
0.061	IN  SPE ^.layer_0.shape.color = yellow
0.059	OUT SPE ^.layer_0.shape.color = cyan
0.056	OUT SPE ^.layer_0.pos.i = '0
0.055	IN  SPE ^.color = black
0.054	OUT SPE ^.color = black
0.014	
0.013	IN  DEL ^.layer_00
0.013	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size tiling(^.layer_0.shape.mask.size, 1, 2) with model ? with color cyan at ('0,?)
  _01: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: rectangle with size (?,?) with model ? with color cyan at (?,?)
  _0: rectangle with size (?,?) with model ? with color yellow at (?,?)

DL input  with Mi: L = 77.0 + 2579.5 = 2656.5
DL output with Mo: L = 61.6 + 732.1 = 793.7
DL input+output M: L = 138.6 + 3311.6 = 3450.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size tiling(^.layer_0.shape.mask.size, 1, 2) with model ? with color cyan at ('0,?)
  _01: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color yellow at (?,?)

DL input  with Mi: L = 45.3 + 0.0 = 45.3
DL output with Mo: L = 61.6 + 732.1 = 793.7
DL input+output M: L = 106.9 + 732.1 = 839.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (6,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
0 0 0 
. 0 . 
 with color yellow at (3,3)
  + 5 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,9) and color black and layers
  _0: rectangle with size (3,6) with mask 
0 . 0 0 . 0 
0 0 . . 0 0 
0 . . . . 0 
 with color cyan at (0,0)
  _01: 
4 . . 
4 4 4 
. 4 . 
 at (3,3)
diff: 
   (25.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
0 0 0 
. 0 . 
 with color yellow at (3,3)
  + 5 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
. 0 0 
. . 0 
 with color cyan at (0,3)
  + 5 delta pixels
diff:   ^.layer_0.shape.color
! 13 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (6,9) and color black and layers
  _0: rectangle with size (1,3) with model Full with color yellow at (4,3)
  + 7 delta pixels
diff: 
! 10 wrong pixels (generated / expected)

TRAIN 760b3cac.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (6,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. 0 . 
 with color yellow at (3,3)
  + 7 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,9) and color black and layers
  _0: rectangle with size (3,6) with mask 
0 . 0 0 . 0 
0 0 0 0 0 0 
0 0 . . 0 0 
 with color cyan at (0,3)
  _01: 
. . 4 
4 4 4 
. 4 . 
 at (3,3)
diff: 
   (21.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 0 
0 0 . 
 with color cyan at (0,3)
  + 5 delta pixels
diff:   ^.layer_0.shape.color
! 23 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. 0 . 
 with color yellow at (3,3)
  + 7 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TRAIN 760b3cac.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (6,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
0 0 0 
. 0 . 
 with color yellow at (3,3)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,9) and color black and layers
  _0: rectangle with size (3,6) with mask 
. . 0 0 . . 
0 0 . . 0 0 
. . 0 0 . . 
 with color cyan at (0,0)
  _01: 
4 . . 
4 4 4 
. 4 . 
 at (3,3)
diff: 
   (25.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
0 0 0 
. 0 . 
 with color yellow at (3,3)
  + 4 delta pixels
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
. 0 0 
0 . . 
 with color cyan at (0,3)
  + 5 delta pixels
diff:   ^.layer_0.shape.color
! 15 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (6,9) and color black and layers
  _0: rectangle with size (1,3) with model Full with color yellow at (4,3)
  + 6 delta pixels
diff: 
! 12 wrong pixels (generated / expected)

TRAIN 760b3cac.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. 0 . 
 with color yellow at (3,3)
  + 5 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
. 0 0 
0 . . 
 with color cyan at (0,3)
  + 5 delta pixels
diff:   ^.layer_0.shape.color
! 23 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (6,9) and color black and layers
  _0: rectangle with size (1,3) with model Full with color yellow at (4,3)
  + 7 delta pixels
diff: 
! 14 wrong pixels (generated / expected)

TEST 760b3cac.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 4.9 sec (4.9 sec/task)
bits-train-error = 732.1 bits (732.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-219] Checking task 776ffc46.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 666281.7 = 666284.0
DL output with Mo: L = 2.3 + 666281.7 = 666284.0
DL input+output M: L = 4.6 + 1332563.4 = 1332568.0

# learning a model for train pairs
2.000	
1.163	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.326	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.269	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.209	OUT ADD ^.layer_0 = ^.layer_0
0.187	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.161	OUT ADD ^.layer_01 = ^.layer_01
0.145	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.129	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.113	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.097	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.082	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.067	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.057	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.054	OUT ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.051	OUT ADD ^.layer_01111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.049	OUT SPE ^.size = ^.size
0.048	IN  SPE ^.layer_0.shape.mask = 
0 0 0 0 0 0 0 
0 . . . . . 0 
0 . . . . . 0 
0 . . . . . 0 
0 . . . . . 0 
0 . . . . . 0 
0 0 0 0 0 0 0 

0.038	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.035	IN  ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.032	IN  ADD ^.layer_01111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.013	
0.013	IN  DEL ^.layer_01111111
0.013	IN  DEL ^.layer_0111111
0.013	IN  DEL ^.layer_011111
0.013	IN  GEN ^.layer_0.shape.mask = rectangle with size (?,?) with model ?
0.013	IN  DEL ^.layer_01111
0.013	IN  DEL ^.layer_0111
0.013	IN  DEL ^.layer_011
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: ^.layer_0
  _01: ^.layer_01
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 0 0 0 0 0 0 
0 . . . . . 0 
0 . . . . . 0 
0 . . . . . 0 
0 . . . . . 0 
0 . . . . . 0 
0 0 0 0 0 0 0 
 with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 290.3 + 12281.5 = 12571.8
DL output with Mo: L = 185.9 + 8408.7 = 8594.5
DL input+output M: L = 476.1 + 20690.2 = 21166.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: ^.layer_0
  _01: ^.layer_01
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 31.7 = 101.9
DL output with Mo: L = 185.9 + 8370.6 = 8556.4
DL input+output M: L = 256.1 + 8402.3 = 8658.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (7,7) with model Border with color grey at (0,0)
  _01: rectangle with size (3,3) with model +-cross with color red at (2,2)
  + 23 delta pixels
diff: 
   (3.2 bits)
data: a background with size (20,20) and color black and layers
  _0: 
5#5#5#5#5#5#5#
5#. . . . . 5#
5#. . . . . 5#
5#. . . . . 5#
5#. . . . . 5#
5#. . . . . 5#
5#5#5#5#5#5#5#
 at (0,0)
  _01: 
. 2 . 
2 2 2 
. 2 . 
 at (2,2)
  _011: rectangle with size (3,3) with model Full with color blue at (1,13)
  _0111: rectangle with size (3,1) with model Full with color red at (7,11)
  _01111: rectangle with size (3,1) with model Full with color red at (15,14)
  _011111: rectangle with size (1,4) with model Full with color blue at (12,3)
  _0111111: rectangle with size (1,3) with model Full with color red at (8,10)
  _01111111: rectangle with size (1,3) with model Full with color red at (16,13)
diff: 
   (195.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (7,7) with model Border with color grey at (0,0)
  _01: rectangle with size (3,3) with model Full with color blue at (1,13)
  + 19 delta pixels
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (7,7) with model Border with color grey at (0,0)
  _01: rectangle with size (3,3) with model +-cross with color red at (2,2)
  + 23 delta pixels
diff: 
! 24 wrong pixels (generated / expected)

TRAIN 776ffc46.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (7,7) with model Border with color grey at (1,5)
  _01: rectangle with size (3,3) with model Full with color green at (3,7)
  + 30 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _0: 
5#5#5#5#5#5#5#
5#. . . . . 5#
5#. . . . . 5#
5#. . . . . 5#
5#. . . . . 5#
5#. . . . . 5#
5#5#5#5#5#5#5#
 at (1,5)
  _01: 
3 3 3 
3 3 3 
3 3 3 
 at (3,7)
  _011: rectangle with size (3,3) with model Full with color green at (9,15)
  _0111: rectangle with size (3,3) with model Full with color green at (12,3)
  _01111: rectangle with size (2,3) with model Full with color blue at (17,11)
  _011111: rectangle with size (3,1) with model Full with color blue at (11,11)
  _0111111: rectangle with size (1,5) with model Full with color blue at (18,10)
  _01111111: rectangle with size (3,1) with model Full with color blue at (16,12)
diff: 
   (201.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (7,7) with model Border with color grey at (1,5)
  _01: rectangle with size (3,3) with model Full with color green at (3,7)
  + 30 delta pixels
diff: 
! 34 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (7,7) with model Border with color grey at (1,5)
  _01: rectangle with size (3,3) with model Full with color blue at (9,15)
  + 30 delta pixels
diff: 
! 43 wrong pixels (generated / expected)

TRAIN 776ffc46.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (7,7) with model Border with color grey at (0,13)
  _01: rectangle with size (6,6) with mask 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
0 0 0 0 0 0 
 with color grey at (0,0)
  + 29 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _0: 
5#5#5#5#5#5#5#
5#. . . . . 5#
5#. . . . . 5#
5#. . . . . 5#
5#. . . . . 5#
5#. . . . . 5#
5#5#5#5#5#5#5#
 at (0,13)
  _01: 
. . . . . 5#
. . . . . 5#
. . . . . 5#
. . . . . 5#
. . . . . 5#
5#5#5#5#5#5#
 at (0,0)
  _011: rectangle with size (2,3) with model Full with color red at (2,15)
  _0111: rectangle with size (2,3) with model Full with color red at (11,10)
  _01111: rectangle with size (2,3) with model Full with color red at (16,2)
  _011111: rectangle with size (3,3) with model +-cross with color blue at (15,7)
  _0111111: rectangle with size (3,1) with model Full with color red at (1,2)
  _01111111: rectangle with size (3,1) with model Full with color blue at (10,4)
diff: 
   (204.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (7,7) with model Border with color grey at (0,13)
  _01: rectangle with size (6,6) with mask 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
0 0 0 0 0 0 
 with color grey at (0,0)
  + 29 delta pixels
diff: 
! 33 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (7,7) with model Border with color grey at (0,13)
  _01: rectangle with size (6,1) with model Full with color grey at (0,5)
  + 34 delta pixels
diff: 
! 38 wrong pixels (generated / expected)

TRAIN 776ffc46.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (7,7) with model Border with color grey at (3,1)
  _01: rectangle with size (6,7) with mask 
0 . . . . . . 
0 . . . . . . 
0 . . . . . . 
0 . . . . . . 
0 . . . . . . 
0 0 0 0 0 0 0 
 with color grey at (0,13)
  + 43 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _0: 
5#5#5#5#5#5#5#
5#. . . . . 5#
5#. . . . . 5#
5#. . . . . 5#
5#. . . . . 5#
5#. . . . . 5#
5#5#5#5#5#5#5#
 at (3,1)
  _01: 
5#. . . . . . 
5#. . . . . . 
5#. . . . . . 
5#. . . . . . 
5#. . . . . . 
5#5#5#5#5#5#5#
 at (0,13)
  _011: rectangle with size (3,3) with model Full with color green at (5,3)
  _0111: rectangle with size (3,3) with model Full with color green at (9,10)
  _01111: rectangle with size (3,4) with mask 
. 0 0 . 
. 0 0 . 
0 0 0 0 
 with color green at (1,15)
  _011111: rectangle with size (3,4) with mask 
. 0 0 . 
. 0 0 . 
0 0 0 0 
 with color blue at (8,15)
  _0111111: rectangle with size (3,3) with model +-cross with color blue at (15,10)
  _01111111: rectangle with size (4,1) with model Full with color blue at (12,5)
diff: 
   (234.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (7,7) with model Border with color grey at (3,1)
  _01: rectangle with size (6,7) with mask 
0 . . . . . . 
0 . . . . . . 
0 . . . . . . 
0 . . . . . . 
0 . . . . . . 
0 0 0 0 0 0 0 
 with color grey at (0,13)
  + 43 delta pixels
diff: 
! 47 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (7,7) with model Border with color grey at (3,1)
  _01: rectangle with size (3,3) with model Full with color green at (5,3)
  + 46 delta pixels
diff: 
! 50 wrong pixels (generated / expected)

TRAIN 776ffc46.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (7,7) with model Border with color grey at (13,12)
  _01: rectangle with size (6,8) with mask 
0 . . . . . . . 
0 . . . . . . . 
0 . . . . . . . 
0 . . . . . . . 
0 . . . . . . . 
0 0 0 0 0 0 0 0 
 with color grey at (0,12)
  + 71 delta pixels
diff: 
! 75 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (7,7) with model Border with color grey at (13,12)
  _01: rectangle with size (7,7) with mask 
0 0 0 0 0 0 0 
. . . . . . 0 
. . . . . . 0 
. . . . . . 0 
. . . . . . 0 
. . . . . . 0 
. . . . . . 0 
 with color grey at (13,0)
  + 71 delta pixels
diff: 
! 75 wrong pixels (generated / expected)

TEST 776ffc46.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 62.5 sec (62.5 sec/task)
bits-train-error = 8370.6 bits (8370.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-218] Checking task 77fdfe62.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 64561.8 = 64564.2
DL output with Mo: L = 2.3 + 14018.4 = 14020.7
DL input+output M: L = 4.6 + 78580.2 = 78584.8

# learning a model for train pairs
2.000	
1.545	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.167	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.881	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.756	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.630	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.523	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.445	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.418	OUT SPE ^.size = ^.layer_01.shape.mask.size
0.398	OUT SPE ^.layer_01.shape.mask.size = ^.layer_01.shape.mask.size / '2
0.381	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.363	OUT SPE ^.layer_0.shape.mask.size = ^.layer_01.shape.mask.size / '2
0.351	OUT SPE ^.layer_011.shape.color = yellow
0.341	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.330	OUT SPE ^.layer_0.shape.color = ^.layer_011.shape.color
0.319	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.309	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.298	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.288	OUT SPE ^.layer_01.shape.color = ^.layer_011111.shape.color
0.281	OUT SPE ^.layer_01.pos.i = right(^.layer_01) / '2
0.275	OUT SPE ^.layer_01.pos.j = min(^.layer_01.pos.j, ^.layer_011111.pos.j)
0.270	OUT SPE ^.color = black
0.267	IN  SPE ^.layer_0.shape.color = blue
0.264	IN  SPE ^.layer_01.shape.color = cyan
0.263	IN  SPE ^.color = black
0.162	
0.162	IN  GEN ^.layer_01.shape.color = ?
0.162	IN  GEN ^.layer_0.shape.color = ?
0.162	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_01.shape.mask.size and color black and layers
  _0: rectangle with size ^.layer_01.shape.mask.size / '2 with model ? with color ^.layer_011.shape.color at ^.layer_0.pos
  _01: rectangle with size ^.layer_01.shape.mask.size / '2 with model ? with color ^.layer_011111.shape.color at (right(^.layer_01) / '2,min(^.layer_01.pos.j, ^.layer_011111.pos.j))
  _011: rectangle with size (?,?) with model ? with color yellow at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color blue at (?,?)
  _01: rectangle with size (?,?) with model ? with color cyan at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)

DL input  with Mi: L = 148.4 + 6608.6 = 6757.1
DL output with Mo: L = 239.6 + 1984.0 = 2223.6
DL input+output M: L = 388.0 + 8592.7 = 8980.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_01.shape.mask.size and color black and layers
  _0: rectangle with size ^.layer_01.shape.mask.size / '2 with model ? with color ^.layer_011.shape.color at ^.layer_0.pos
  _01: rectangle with size ^.layer_01.shape.mask.size / '2 with model ? with color ^.layer_011111.shape.color at (right(^.layer_01) / '2,min(^.layer_01.pos.j, ^.layer_011111.pos.j))
  _011: rectangle with size (?,?) with model ? with color yellow at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)

DL input  with Mi: L = 141.7 + 60.0 = 201.7
DL output with Mo: L = 239.6 + 1984.0 = 2223.6
DL input+output M: L = 381.3 + 2044.0 = 2425.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (8,8) and color black and layers
  _0: rectangle with size (8,8) with mask 
. 0 . . . . 0 . 
0 0 0 0 0 0 0 0 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
0 0 0 0 0 0 0 0 
. 0 . . . . 0 . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
. 0 . . 
0 0 . 0 
. . 0 . 
. . 0 0 
 with color cyan at (2,2)
  _011: point with color red at (0,0)
  _0111: point with color green at (0,7)
  _01111: point with color cyan at (5,2)
  _011111: point with color pink at (7,7)
  + 1 delta pixels
diff: 
   (2.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color red at (0,0)
  _01: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color pink at (2,2)
  _011: rectangle with size (1,1) with model Full with color yellow at (3,0)
  + 1 delta pixels
diff: 
   (66.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (8,8) with mask 
. 0 . . . . 0 . 
0 0 0 0 0 0 0 0 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
0 0 0 0 0 0 0 0 
. 0 . . . . 0 . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
. 0 . . 
0 0 . 0 
. . 0 . 
. . 0 0 
 with color cyan at (2,2)
  _011: point with color red at (0,0)
  _0111: point with color green at (0,7)
  _01111: point with color cyan at (5,2)
  _011111: point with color yellow at (7,0)
  + 1 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (8,8) with mask 
. 0 . . . . 0 . 
0 0 0 0 0 0 0 0 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
0 0 0 0 0 0 0 0 
. 0 . . . . 0 . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
. 0 . . 
0 0 . 0 
. . 0 . 
. . 0 0 
 with color cyan at (2,2)
  _011: point with color red at (0,0)
  _0111: point with color green at (0,7)
  _01111: point with color cyan at (5,2)
  _011111: point with color pink at (7,7)
  + 1 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (8,8) with mask 
. 0 . . . . 0 . 
0 0 0 0 0 0 0 0 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
0 0 0 0 0 0 0 0 
. 0 . . . . 0 . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
. 0 . . 
0 0 . 0 
. . 0 . 
. . 0 0 
 with color cyan at (2,2)
  _011: point with color red at (0,0)
  _0111: point with color green at (0,7)
  _01111: point with color yellow at (7,0)
  _011111: point with color cyan at (5,2)
  + 1 delta pixels
diff: 
! 7 wrong pixels (generated / expected)

TRAIN 77fdfe62.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _0: rectangle with size (6,6) with mask 
. 0 . . 0 . 
0 0 0 0 0 0 
. 0 . . 0 . 
. 0 . . 0 . 
0 0 0 0 0 0 
. 0 . . 0 . 
 with color blue at (0,0)
  _01: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color cyan at (2,2)
  _011: point with color brown at (0,0)
  _0111: point with color yellow at (0,5)
  _01111: point with color green at (5,5)
  _011111: point with color red at (5,0)
diff: 
   (2.0 bits)
data: a background with size (2,2) and color black and layers
  _0: rectangle with size (1,1) with model Full with color brown at (0,0)
  _01: rectangle with size (1,1) with model Full with color red at (1,0)
  _011: rectangle with size (1,1) with model Full with color yellow at (0,1)
diff: 
   (21.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (6,6) with mask 
. 0 . . 0 . 
0 0 0 0 0 0 
. 0 . . 0 . 
. 0 . . 0 . 
0 0 0 0 0 0 
. 0 . . 0 . 
 with color blue at (0,0)
  _01: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color cyan at (2,2)
  _011: point with color brown at (0,0)
  _0111: point with color yellow at (0,5)
  _01111: point with color red at (5,0)
  _011111: point with color green at (5,5)
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (6,6) with mask 
. 0 . . 0 . 
0 0 0 0 0 0 
. 0 . . 0 . 
. 0 . . 0 . 
0 0 0 0 0 0 
. 0 . . 0 . 
 with color blue at (0,0)
  _01: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color cyan at (2,2)
  _011: point with color brown at (0,0)
  _0111: point with color yellow at (0,5)
  _01111: point with color green at (5,5)
  _011111: point with color red at (5,0)
diff: 
! 1 wrong pixels (generated / expected)

TRAIN 77fdfe62.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (8,8) and color black and layers
  _0: rectangle with size (8,8) with mask 
. 0 . . . . 0 . 
0 0 0 0 0 0 0 0 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
0 0 0 0 0 0 0 0 
. 0 . . . . 0 . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
. 0 . 0 
0 0 0 . 
0 . 0 0 
0 0 0 . 
 with color cyan at (2,2)
  _011: point with color pink at (0,0)
  _0111: point with color red at (0,7)
  _01111: point with color yellow at (7,7)
  _011111: point with color orange at (7,0)
diff: 
   (2.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color pink at (0,0)
  _01: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color orange at (2,0)
  _011: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color yellow at (2,2)
  + 2 delta pixels
diff: 
   (110.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (8,8) with mask 
. 0 . . . . 0 . 
0 0 0 0 0 0 0 0 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
0 0 0 0 0 0 0 0 
. 0 . . . . 0 . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
. 0 . 0 
0 0 0 . 
0 . 0 0 
0 0 0 . 
 with color cyan at (2,2)
  _011: point with color pink at (0,0)
  _0111: point with color red at (0,7)
  _01111: point with color orange at (7,0)
  _011111: point with color yellow at (7,7)
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (8,8) with mask 
. 0 . . . . 0 . 
0 0 0 0 0 0 0 0 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
. 0 . . . . 0 . 
0 0 0 0 0 0 0 0 
. 0 . . . . 0 . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
. 0 . 0 
0 0 0 . 
0 . 0 0 
0 0 0 . 
 with color cyan at (2,2)
  _011: point with color pink at (0,0)
  _0111: point with color red at (0,7)
  _01111: point with color yellow at (7,7)
  _011111: point with color orange at (7,0)
diff: 
! 7 wrong pixels (generated / expected)

TRAIN 77fdfe62.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
. 0 . . . . . . 0 . 
0 0 0 0 0 0 0 0 0 0 
. 0 . . . . . . 0 . 
. 0 . . . . . . 0 . 
. 0 . . . . . . 0 . 
. 0 . . . . . . 0 . 
. 0 . . . . . . 0 . 
. 0 . . . . . . 0 . 
0 0 0 0 0 0 0 0 0 0 
. 0 . . . . . . 0 . 
 with color blue at (0,0)
  _01: rectangle with size (6,6) with mask 
. 0 0 . . . 
0 0 0 . 0 . 
. . 0 . 0 . 
. 0 . 0 0 . 
0 0 . 0 . 0 
. 0 . . 0 . 
 with color cyan at (2,2)
  _011: point with color green at (0,0)
  _0111: point with color yellow at (0,9)
  _01111: point with color orange at (9,0)
  _011111: point with color grey at (9,9)
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
. 0 . . . . . . 0 . 
0 0 0 0 0 0 0 0 0 0 
. 0 . . . . . . 0 . 
. 0 . . . . . . 0 . 
. 0 . . . . . . 0 . 
. 0 . . . . . . 0 . 
. 0 . . . . . . 0 . 
. 0 . . . . . . 0 . 
0 0 0 0 0 0 0 0 0 0 
. 0 . . . . . . 0 . 
 with color blue at (0,0)
  _01: rectangle with size (6,6) with mask 
. 0 0 . . . 
0 0 0 . 0 . 
. . 0 . 0 . 
. 0 . 0 0 . 
0 0 . 0 . 0 
. 0 . . 0 . 
 with color cyan at (2,2)
  _011: point with color green at (0,0)
  _0111: point with color yellow at (0,9)
  _01111: point with color grey at (9,9)
  _011111: point with color orange at (9,0)
diff: 
! 15 wrong pixels (generated / expected)

TEST 77fdfe62.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 22.7 sec (22.7 sec/task)
bits-train-error = 1984.0 bits (1984.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-217] Checking task 780d0b14.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 494125.8 = 494128.1
DL output with Mo: L = 2.3 + 6365.2 = 6367.5
DL input+output M: L = 4.6 + 500490.9 = 500495.6

# learning a model for train pairs
2.000	
1.628	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.357	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.182	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
1.056	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.938	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.831	OUT ADD ^.layer_0 = point with color ? at (?,?)
0.722	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.643	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.591	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.527	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.478	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.436	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.403	OUT SPE ^.layer_0.pos = '(0, 0)
0.371	OUT SPE ^.layer_011.pos = '(1, 0)
0.339	OUT SPE ^.layer_0111.pos = '(1, 1)
0.315	OUT SPE ^.layer_0.shape.color = ^.layer_0111.shape.color
0.294	OUT SPE ^.size.i = ^.layer_01.shape.mask.size.j / '3
0.278	OUT SPE ^.layer_01.pos.i = '0
0.278	IN  SPE ^.color = black
0.239	
0.239	IN  DEL ^.layer_011111
0.239	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (^.layer_01.shape.mask.size.j / '3,?) and color ? and layers
  _0: point with color ^.layer_0111.shape.color at '(0, 0)
  _01: point with color ? at ('0,?)
  _011: point with color ? at '(1, 0)
  _0111: point with color ? at '(1, 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 181.0 + 19319.4 = 19500.4
DL output with Mo: L = 155.3 + 1362.0 = 1517.3
DL input+output M: L = 336.3 + 20681.4 = 21017.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (^.layer_01.shape.mask.size.j / '3,?) and color ? and layers
  _0: point with color ^.layer_0111.shape.color at '(0, 0)
  _01: point with color ? at ('0,?)
  _011: point with color ? at '(1, 0)
  _0111: point with color ? at '(1, 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 153.4 + 83.4 = 236.8
DL output with Mo: L = 155.3 + 1362.0 = 1517.3
DL input+output M: L = 308.6 + 1445.4 = 1754.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (11,11) with mask 
0 . 0 0 . 0 0 0 . . . 
. 0 . 0 0 . . 0 0 0 . 
0 0 . . . 0 . 0 0 . 0 
0 0 . 0 . 0 0 0 . 0 0 
0 0 0 0 . 0 0 . 0 . 0 
0 . 0 . 0 0 0 0 0 0 0 
0 . 0 . 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 . . 0 0 
. . 0 0 . 0 0 0 0 0 . 
0 0 0 0 0 . 0 0 0 0 0 
0 . 0 . 0 . 0 0 0 0 . 
 with color blue at (9,9)
  _01: rectangle with size (11,8) with mask 
0 0 0 0 0 . 0 0 
0 0 0 0 0 0 0 . 
. 0 . 0 0 0 . 0 
0 0 0 . 0 0 0 0 
0 . 0 0 . 0 . 0 
0 0 0 0 0 . 0 0 
0 0 0 0 0 . 0 . 
0 0 0 . 0 0 . 0 
. 0 0 0 . . 0 . 
0 . . . 0 . 0 . 
0 0 . 0 . 0 0 0 
 with color pink at (9,0)
  _011: rectangle with size (8,11) with mask 
. . 0 0 0 0 0 . 0 0 0 
. . 0 0 0 0 0 0 0 0 0 
. 0 0 0 0 0 0 0 0 0 0 
. 0 . 0 0 0 0 0 0 0 0 
0 . 0 0 . 0 0 0 . 0 0 
0 0 0 0 0 0 0 0 0 . 0 
0 0 0 . 0 0 0 . 0 . . 
. 0 0 . 0 0 0 . . . . 
 with color cyan at (0,9)
  _0111: rectangle with size (8,8) with mask 
0 0 0 0 . . 0 0 
0 0 0 . 0 . 0 0 
0 0 . 0 0 0 . 0 
0 0 . 0 . 0 0 0 
. 0 0 . 0 0 0 0 
0 . 0 0 0 0 . . 
0 0 . 0 0 0 0 0 
0 0 . 0 0 . 0 0 
 with color blue at (0,0)
  _01111: rectangle with size (1,1) with model Full with color cyan at (7,19)
diff: 
   (3.2 bits)
data: a background with size (2,2) and color black and layers
  _0: point with color blue at (0,0)
  _01: point with color cyan at (0,1)
  _011: point with color pink at (1,0)
  _0111: point with color blue at (1,1)
diff: 
   (28.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (11,11) with mask 
0 . 0 0 . 0 0 0 . . . 
. 0 . 0 0 . . 0 0 0 . 
0 0 . . . 0 . 0 0 . 0 
0 0 . 0 . 0 0 0 . 0 0 
0 0 0 0 . 0 0 . 0 . 0 
0 . 0 . 0 0 0 0 0 0 0 
0 . 0 . 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 . . 0 0 
. . 0 0 . 0 0 0 0 0 . 
0 0 0 0 0 . 0 0 0 0 0 
0 . 0 . 0 . 0 0 0 0 . 
 with color blue at (9,9)
  _01: rectangle with size (8,11) with mask 
. . 0 0 0 0 0 . 0 0 0 
. . 0 0 0 0 0 0 0 0 0 
. 0 0 0 0 0 0 0 0 0 0 
. 0 . 0 0 0 0 0 0 0 0 
0 . 0 0 . 0 0 0 . 0 0 
0 0 0 0 0 0 0 0 0 . 0 
0 0 0 . 0 0 0 . 0 . . 
. 0 0 . 0 0 0 . . . . 
 with color cyan at (0,9)
  _011: rectangle with size (11,8) with mask 
0 0 0 0 0 . 0 0 
0 0 0 0 0 0 0 . 
. 0 . 0 0 0 . 0 
0 0 0 . 0 0 0 0 
0 . 0 0 . 0 . 0 
0 0 0 0 0 . 0 0 
0 0 0 0 0 . 0 . 
0 0 0 . 0 0 . 0 
. 0 0 0 . . 0 . 
0 . . . 0 . 0 . 
0 0 . 0 . 0 0 0 
 with color pink at (9,0)
  _0111: rectangle with size (8,8) with mask 
0 0 0 0 . . 0 0 
0 0 0 . 0 . 0 0 
0 0 . 0 0 0 . 0 
0 0 . 0 . 0 0 0 
. 0 0 . 0 0 0 0 
0 . 0 0 0 0 . . 
0 0 . 0 0 0 0 0 
0 0 . 0 0 . 0 0 
 with color blue at (0,0)
  _01111: rectangle with size (1,1) with model Full with color cyan at (7,19)
diff: 
! size mismatch, 3x10 instead of 2x2
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (11,11) with mask 
0 . 0 0 . 0 0 0 . . . 
. 0 . 0 0 . . 0 0 0 . 
0 0 . . . 0 . 0 0 . 0 
0 0 . 0 . 0 0 0 . 0 0 
0 0 0 0 . 0 0 . 0 . 0 
0 . 0 . 0 0 0 0 0 0 0 
0 . 0 . 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 . . 0 0 
. . 0 0 . 0 0 0 0 0 . 
0 0 0 0 0 . 0 0 0 0 0 
0 . 0 . 0 . 0 0 0 0 . 
 with color blue at (9,9)
  _01: rectangle with size (8,11) with mask 
. . 0 0 0 0 0 . 0 0 0 
. . 0 0 0 0 0 0 0 0 0 
. 0 0 0 0 0 0 0 0 0 0 
. 0 . 0 0 0 0 0 0 0 0 
0 . 0 0 . 0 0 0 . 0 0 
0 0 0 0 0 0 0 0 0 . 0 
0 0 0 . 0 0 0 . 0 . . 
. 0 0 . 0 0 0 . . . . 
 with color cyan at (0,9)
  _011: rectangle with size (8,8) with mask 
0 0 0 0 . . 0 0 
0 0 0 . 0 . 0 0 
0 0 . 0 0 0 . 0 
0 0 . 0 . 0 0 0 
. 0 0 . 0 0 0 0 
0 . 0 0 0 0 . . 
0 0 . 0 0 0 0 0 
0 0 . 0 0 . 0 0 
 with color blue at (0,0)
  _0111: rectangle with size (11,8) with mask 
0 0 0 0 0 . 0 0 
0 0 0 0 0 0 0 . 
. 0 . 0 0 0 . 0 
0 0 0 . 0 0 0 0 
0 . 0 0 . 0 . 0 
0 0 0 0 0 . 0 0 
0 0 0 0 0 . 0 . 
0 0 0 . 0 0 . 0 
. 0 0 0 . . 0 . 
0 . . . 0 . 0 . 
0 0 . 0 . 0 0 0 
 with color pink at (9,0)
  _01111: rectangle with size (1,1) with model Full with color cyan at (7,19)
diff: 
! size mismatch, 3x10 instead of 2x2
>> Trial 3
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (11,11) with mask 
0 . 0 0 . 0 0 0 . . . 
. 0 . 0 0 . . 0 0 0 . 
0 0 . . . 0 . 0 0 . 0 
0 0 . 0 . 0 0 0 . 0 0 
0 0 0 0 . 0 0 . 0 . 0 
0 . 0 . 0 0 0 0 0 0 0 
0 . 0 . 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 . . 0 0 
. . 0 0 . 0 0 0 0 0 . 
0 0 0 0 0 . 0 0 0 0 0 
0 . 0 . 0 . 0 0 0 0 . 
 with color blue at (9,9)
  _01: rectangle with size (11,8) with mask 
0 0 0 0 0 . 0 0 
0 0 0 0 0 0 0 . 
. 0 . 0 0 0 . 0 
0 0 0 . 0 0 0 0 
0 . 0 0 . 0 . 0 
0 0 0 0 0 . 0 0 
0 0 0 0 0 . 0 . 
0 0 0 . 0 0 . 0 
. 0 0 0 . . 0 . 
0 . . . 0 . 0 . 
0 0 . 0 . 0 0 0 
 with color pink at (9,0)
  _011: rectangle with size (8,11) with mask 
. . 0 0 0 0 0 . 0 0 0 
. . 0 0 0 0 0 0 0 0 0 
. 0 0 0 0 0 0 0 0 0 0 
. 0 . 0 0 0 0 0 0 0 0 
0 . 0 0 . 0 0 0 . 0 0 
0 0 0 0 0 0 0 0 0 . 0 
0 0 0 . 0 0 0 . 0 . . 
. 0 0 . 0 0 0 . . . . 
 with color cyan at (0,9)
  _0111: rectangle with size (8,8) with mask 
0 0 0 0 . . 0 0 
0 0 0 . 0 . 0 0 
0 0 . 0 0 0 . 0 
0 0 . 0 . 0 0 0 
. 0 0 . 0 0 0 0 
0 . 0 0 0 0 . . 
0 0 . 0 0 0 0 0 
0 0 . 0 0 . 0 0 
 with color blue at (0,0)
  _01111: rectangle with size (1,1) with model Full with color cyan at (7,19)
diff: 
! size mismatch, 2x10 instead of 2x2

TRAIN 780d0b14.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (18,22) and color black and layers
  _0: rectangle with size (10,8) with mask 
0 . 0 . . 0 0 0 
0 0 0 . . 0 0 0 
0 0 0 0 0 0 0 0 
. . 0 0 0 . 0 0 
. 0 . 0 0 0 0 . 
0 0 . . 0 . 0 0 
0 0 . . . 0 0 0 
0 . 0 0 . . . 0 
. 0 0 . . . 0 . 
0 . 0 0 . . 0 0 
 with color cyan at (8,14)
  _01: rectangle with size (10,6) with mask 
. 0 0 0 0 0 
0 . 0 0 . 0 
0 0 0 . 0 . 
0 0 . 0 . 0 
0 0 0 . 0 . 
0 0 0 0 0 0 
0 0 0 . . . 
0 . . 0 . 0 
0 0 0 0 . 0 
0 0 . 0 0 0 
 with color blue at (8,0)
  _011: rectangle with size (10,6) with mask 
0 . 0 0 0 0 
0 . 0 0 0 . 
0 . 0 0 0 . 
0 0 0 0 . 0 
0 0 . 0 0 . 
. 0 0 0 . 0 
0 . 0 0 0 0 
0 0 . 0 0 . 
. 0 0 0 . 0 
0 0 0 . 0 . 
 with color red at (8,7)
  _0111: rectangle with size (7,6) with mask 
0 0 0 0 0 . 
0 0 0 . . 0 
0 0 0 0 . . 
0 0 . . 0 0 
0 0 0 0 0 0 
. . 0 0 0 0 
0 0 . 0 0 . 
 with color yellow at (0,0)
  _01111: rectangle with size (7,8) with mask 
0 0 0 . . 0 0 0 
0 0 0 0 . 0 0 . 
0 0 0 . 0 . 0 0 
0 0 0 0 . 0 0 0 
0 . 0 . 0 . 0 . 
0 . 0 0 0 0 0 0 
0 . . 0 0 0 0 . 
 with color green at (0,14)
  + 31 delta pixels
diff: 
   (3.2 bits)
data: a background with size (2,3) and color cyan and layers
  _0: point with color yellow at (0,0)
  _01: point with color green at (0,2)
  _011: point with color blue at (1,0)
  _0111: point with color red at (1,1)
diff: 
   (36.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,22) and color black and layers
  _0: rectangle with size (10,8) with mask 
0 . 0 . . 0 0 0 
0 0 0 . . 0 0 0 
0 0 0 0 0 0 0 0 
. . 0 0 0 . 0 0 
. 0 . 0 0 0 0 . 
0 0 . . 0 . 0 0 
0 0 . . . 0 0 0 
0 . 0 0 . . . 0 
. 0 0 . . . 0 . 
0 . 0 0 . . 0 0 
 with color cyan at (8,14)
  _01: rectangle with size (10,6) with mask 
. 0 0 0 0 0 
0 . 0 0 . 0 
0 0 0 . 0 . 
0 0 . 0 . 0 
0 0 0 . 0 . 
0 0 0 0 0 0 
0 0 0 . . . 
0 . . 0 . 0 
0 0 0 0 . 0 
0 0 . 0 0 0 
 with color blue at (8,0)
  _011: rectangle with size (10,6) with mask 
0 . 0 0 0 0 
0 . 0 0 0 . 
0 . 0 0 0 . 
0 0 0 0 . 0 
0 0 . 0 0 . 
. 0 0 0 . 0 
0 . 0 0 0 0 
0 0 . 0 0 . 
. 0 0 0 . 0 
0 0 0 . 0 . 
 with color red at (8,7)
  _0111: rectangle with size (7,8) with mask 
0 0 0 . . 0 0 0 
0 0 0 0 . 0 0 . 
0 0 0 . 0 . 0 0 
0 0 0 0 . 0 0 0 
0 . 0 . 0 . 0 . 
0 . 0 0 0 0 0 0 
0 . . 0 0 0 0 . 
 with color green at (0,14)
  _01111: rectangle with size (7,6) with mask 
0 0 0 0 0 . 
0 0 0 . . 0 
0 0 0 0 . . 
0 0 . . 0 0 
0 0 0 0 0 0 
. . 0 0 0 0 
0 0 . 0 0 . 
 with color yellow at (0,0)
  + 31 delta pixels
diff: 
! size mismatch, 2x10 instead of 2x3
>> Trial 2
data: a background with size (18,22) and color black and layers
  _0: rectangle with size (10,8) with mask 
0 . 0 . . 0 0 0 
0 0 0 . . 0 0 0 
0 0 0 0 0 0 0 0 
. . 0 0 0 . 0 0 
. 0 . 0 0 0 0 . 
0 0 . . 0 . 0 0 
0 0 . . . 0 0 0 
0 . 0 0 . . . 0 
. 0 0 . . . 0 . 
0 . 0 0 . . 0 0 
 with color cyan at (8,14)
  _01: rectangle with size (10,6) with mask 
. 0 0 0 0 0 
0 . 0 0 . 0 
0 0 0 . 0 . 
0 0 . 0 . 0 
0 0 0 . 0 . 
0 0 0 0 0 0 
0 0 0 . . . 
0 . . 0 . 0 
0 0 0 0 . 0 
0 0 . 0 0 0 
 with color blue at (8,0)
  _011: rectangle with size (10,6) with mask 
0 . 0 0 0 0 
0 . 0 0 0 . 
0 . 0 0 0 . 
0 0 0 0 . 0 
0 0 . 0 0 . 
. 0 0 0 . 0 
0 . 0 0 0 0 
0 0 . 0 0 . 
. 0 0 0 . 0 
0 0 0 . 0 . 
 with color red at (8,7)
  _0111: rectangle with size (7,6) with mask 
0 0 0 0 0 . 
0 0 0 . . 0 
0 0 0 0 . . 
0 0 . . 0 0 
0 0 0 0 0 0 
. . 0 0 0 0 
0 0 . 0 0 . 
 with color yellow at (0,0)
  _01111: rectangle with size (7,8) with mask 
0 0 0 . . 0 0 0 
0 0 0 0 . 0 0 . 
0 0 0 . 0 . 0 0 
0 0 0 0 . 0 0 0 
0 . 0 . 0 . 0 . 
0 . 0 0 0 0 0 0 
0 . . 0 0 0 0 . 
 with color green at (0,14)
  + 31 delta pixels
diff: 
! size mismatch, 2x10 instead of 2x3

TRAIN 780d0b14.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (23,17) and color black and layers
  _0: rectangle with size (9,9) with mask 
. 0 . 0 0 0 0 0 0 
0 . 0 0 0 0 0 0 0 
. 0 . 0 0 . 0 . 0 
0 0 . 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 . 
0 0 0 0 0 0 0 0 0 
0 0 0 . . 0 0 0 . 
0 0 . 0 0 0 0 . 0 
. 0 . . 0 . 0 0 0 
 with color cyan at (7,8)
  _01: rectangle with size (6,9) with mask 
0 0 . 0 0 . 0 0 0 
0 0 0 . 0 0 0 0 . 
0 0 0 0 . 0 0 0 0 
0 0 0 . 0 0 0 0 0 
0 0 0 0 0 . . 0 0 
0 0 0 0 0 0 0 0 0 
 with color pink at (17,8)
  _011: rectangle with size (9,7) with mask 
. 0 0 0 0 0 . 
0 . 0 0 . 0 . 
0 . . 0 . 0 0 
0 0 . . . . 0 
0 0 0 0 . . . 
0 0 0 0 . 0 0 
0 0 0 0 0 0 . 
. 0 0 0 . 0 0 
. . . . 0 0 0 
 with color yellow at (7,0)
  _0111: rectangle with size (6,7) with mask 
0 0 0 0 0 . . 
0 0 . . 0 . 0 
0 0 0 0 . 0 0 
0 . 0 0 . 0 0 
0 0 0 . 0 0 0 
0 . 0 . 0 0 0 
 with color red at (0,0)
  _01111: rectangle with size (6,7) with mask 
. 0 0 0 0 0 0 
. 0 0 0 0 0 . 
0 0 0 0 0 . 0 
0 . . . 0 0 0 
0 . 0 0 0 . . 
0 0 0 0 0 0 0 
 with color blue at (17,0)
  + 29 delta pixels
diff: 
   (2.0 bits)
data: a background with size (3,2) and color blue and layers
  _0: point with color red at (0,0)
  _01: point with color orange at (0,1)
  _011: point with color yellow at (1,0)
  _0111: point with color cyan at (1,1)
  + 1 delta pixels
diff: 
   (72.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (23,17) and color black and layers
  _0: rectangle with size (9,9) with mask 
. 0 . 0 0 0 0 0 0 
0 . 0 0 0 0 0 0 0 
. 0 . 0 0 . 0 . 0 
0 0 . 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 . 
0 0 0 0 0 0 0 0 0 
0 0 0 . . 0 0 0 . 
0 0 . 0 0 0 0 . 0 
. 0 . . 0 . 0 0 0 
 with color cyan at (7,8)
  _01: rectangle with size (6,9) with mask 
0 0 . 0 0 . 0 0 0 
0 0 0 . 0 0 0 0 . 
0 0 0 0 . 0 0 0 0 
0 0 0 . 0 0 0 0 0 
0 0 0 0 0 . . 0 0 
0 0 0 0 0 0 0 0 0 
 with color pink at (17,8)
  _011: rectangle with size (9,7) with mask 
. 0 0 0 0 0 . 
0 . 0 0 . 0 . 
0 . . 0 . 0 0 
0 0 . . . . 0 
0 0 0 0 . . . 
0 0 0 0 . 0 0 
0 0 0 0 0 0 . 
. 0 0 0 . 0 0 
. . . . 0 0 0 
 with color yellow at (7,0)
  _0111: rectangle with size (6,7) with mask 
. 0 0 0 0 0 0 
. 0 0 0 0 0 . 
0 0 0 0 0 . 0 
0 . . . 0 0 0 
0 . 0 0 0 . . 
0 0 0 0 0 0 0 
 with color blue at (17,0)
  _01111: rectangle with size (6,7) with mask 
0 0 0 0 0 . . 
0 0 . . 0 . 0 
0 0 0 0 . 0 0 
0 . 0 0 . 0 0 
0 0 0 . 0 0 0 
0 . 0 . 0 0 0 
 with color red at (0,0)
  + 29 delta pixels
diff: 
! size mismatch, 3x10 instead of 3x2
>> Trial 2
data: a background with size (23,17) and color black and layers
  _0: rectangle with size (9,9) with mask 
. 0 . 0 0 0 0 0 0 
0 . 0 0 0 0 0 0 0 
. 0 . 0 0 . 0 . 0 
0 0 . 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 . 
0 0 0 0 0 0 0 0 0 
0 0 0 . . 0 0 0 . 
0 0 . 0 0 0 0 . 0 
. 0 . . 0 . 0 0 0 
 with color cyan at (7,8)
  _01: rectangle with size (6,9) with mask 
0 0 . 0 0 . 0 0 0 
0 0 0 . 0 0 0 0 . 
0 0 0 0 . 0 0 0 0 
0 0 0 . 0 0 0 0 0 
0 0 0 0 0 . . 0 0 
0 0 0 0 0 0 0 0 0 
 with color pink at (17,8)
  _011: rectangle with size (9,7) with mask 
. 0 0 0 0 0 . 
0 . 0 0 . 0 . 
0 . . 0 . 0 0 
0 0 . . . . 0 
0 0 0 0 . . . 
0 0 0 0 . 0 0 
0 0 0 0 0 0 . 
. 0 0 0 . 0 0 
. . . . 0 0 0 
 with color yellow at (7,0)
  _0111: rectangle with size (6,7) with mask 
0 0 0 0 0 . . 
0 0 . . 0 . 0 
0 0 0 0 . 0 0 
0 . 0 0 . 0 0 
0 0 0 . 0 0 0 
0 . 0 . 0 0 0 
 with color red at (0,0)
  _01111: rectangle with size (6,7) with mask 
. 0 0 0 0 0 0 
. 0 0 0 0 0 . 
0 0 0 0 0 . 0 
0 . . . 0 0 0 
0 . 0 0 0 . . 
0 0 0 0 0 0 0 
 with color blue at (17,0)
  + 29 delta pixels
diff: 
! size mismatch, 3x10 instead of 3x2
>> Trial 3
data: a background with size (23,17) and color black and layers
  _0: rectangle with size (9,9) with mask 
. 0 . 0 0 0 0 0 0 
0 . 0 0 0 0 0 0 0 
. 0 . 0 0 . 0 . 0 
0 0 . 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 . 
0 0 0 0 0 0 0 0 0 
0 0 0 . . 0 0 0 . 
0 0 . 0 0 0 0 . 0 
. 0 . . 0 . 0 0 0 
 with color cyan at (7,8)
  _01: rectangle with size (6,9) with mask 
0 0 . 0 0 . 0 0 0 
0 0 0 . 0 0 0 0 . 
0 0 0 0 . 0 0 0 0 
0 0 0 . 0 0 0 0 0 
0 0 0 0 0 . . 0 0 
0 0 0 0 0 0 0 0 0 
 with color pink at (17,8)
  _011: rectangle with size (6,7) with mask 
. 0 0 0 0 0 0 
. 0 0 0 0 0 . 
0 0 0 0 0 . 0 
0 . . . 0 0 0 
0 . 0 0 0 . . 
0 0 0 0 0 0 0 
 with color blue at (17,0)
  _0111: rectangle with size (9,7) with mask 
. 0 0 0 0 0 . 
0 . 0 0 . 0 . 
0 . . 0 . 0 0 
0 0 . . . . 0 
0 0 0 0 . . . 
0 0 0 0 . 0 0 
0 0 0 0 0 0 . 
. 0 0 0 . 0 0 
. . . . 0 0 0 
 with color yellow at (7,0)
  _01111: rectangle with size (6,7) with mask 
0 0 0 0 0 . . 
0 0 . . 0 . 0 
0 0 0 0 . 0 0 
0 . 0 0 . 0 0 
0 0 0 . 0 0 0 
0 . 0 . 0 0 0 
 with color red at (0,0)
  + 29 delta pixels
diff: 
! size mismatch, 3x10 instead of 3x2

TRAIN 780d0b14.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (23,28) and color black and layers
  _0: rectangle with size (14,7) with mask 
0 0 . . 0 0 0 
0 0 0 0 . 0 0 
0 0 0 0 0 0 0 
0 0 0 0 0 . 0 
0 . . 0 0 0 0 
. 0 0 0 . 0 0 
0 0 0 0 0 . 0 
0 0 0 0 0 . . 
. 0 0 0 0 . 0 
0 0 0 0 0 0 0 
0 0 . 0 0 0 0 
. 0 . 0 0 0 0 
0 0 0 0 0 . 0 
0 0 0 . 0 0 . 
 with color blue at (5,8)
  _01: rectangle with size (14,12) with mask 
0 0 0 . 0 0 0 0 0 . 0 . 
0 0 0 0 0 0 . 0 . 0 0 . 
0 0 0 0 0 0 0 . 0 0 0 0 
0 0 0 . 0 0 0 0 0 0 . 0 
. . 0 0 0 . 0 0 . 0 0 0 
0 0 0 0 0 0 . 0 . 0 0 . 
0 0 0 0 0 . . . 0 0 0 0 
0 0 0 0 . 0 0 0 0 0 . 0 
. 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 . 0 . 
0 . 0 . 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 . 0 . 0 0 0 
0 . 0 0 0 0 0 0 0 0 . 0 
0 . 0 0 0 0 0 . 0 0 0 0 
 with color cyan at (5,16)
  _011: rectangle with size (14,7) with mask 
0 0 0 0 0 . 0 
0 0 0 . 0 . 0 
0 . 0 0 0 0 0 
0 0 . 0 0 0 . 
. . . 0 0 . 0 
0 0 0 . 0 0 . 
0 0 0 . . . 0 
0 0 0 0 0 0 0 
0 0 0 . . 0 0 
0 . 0 0 . 0 0 
0 0 0 . 0 . 0 
0 0 0 0 0 0 0 
0 . 0 0 0 0 0 
. 0 . 0 0 0 0 
 with color blue at (5,0)
  _0111: rectangle with size (4,12) with mask 
. . 0 0 0 0 . 0 0 0 0 0 
0 . 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 . . 0 0 0 0 0 0 0 0 0 
 with color yellow at (0,16)
  _01111: rectangle with size (3,12) with mask 
0 . 0 0 0 0 . 0 0 . 0 0 
0 0 0 0 0 . 0 0 0 0 0 . 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color red at (20,16)
  + 79 delta pixels
diff: 
! size mismatch, 4x10 instead of 3x3

TEST 780d0b14.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 33.7 sec (33.7 sec/task)
bits-train-error = 1362.0 bits (1362.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-216] Checking task 7837ac64.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 1336530.0 = 1336532.3
DL output with Mo: L = 2.3 + 14046.4 = 14048.7
DL input+output M: L = 4.6 + 1350576.4 = 1350581.0

# learning a model for train pairs
2.000	
1.447	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.921	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.516	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.307	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.239	OUT ADD ^.layer_00 = point with color ? at (?,?)
0.203	OUT SPE ^.size = '(3, 3)
0.186	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.183	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.179	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.177	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.163	OUT SPE ^.layer_00.shape.color = ^.layer_0111.shape.color
0.161	IN  ADD ^.layer_01110 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.156	OUT SPE ^.layer_00.pos.i = average(^.layer_011.pos.i, ^.layer_01110.pos.i) - ^.layer_01.pos.i - ^.layer_0.pos.i
0.156	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.156	IN  SPE ^.layer_01.shape.mask.model = Full
0.156	IN  SPE ^.layer_011.shape.mask.model = Full
0.155	IN  SPE ^.layer_01110.shape.mask.model = Full
0.155	IN  SPE ^.layer_0111.shape.mask.model = Full
0.155	IN  SPE ^.layer_01111.shape.mask.model = Full
0.155	IN  SPE ^.color = black
0.125	
0.125	IN  DEL ^.layer_01111
0.125	IN  GEN ^.layer_0111.shape.mask.model = ?
0.125	IN  GEN ^.layer_01110.shape.mask.model = ?
0.125	IN  GEN ^.layer_011.shape.mask.model = ?
0.125	IN  GEN ^.layer_01.shape.mask.model = ?
0.125	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color ? and layers
  _00: point with color ^.layer_0111.shape.color at (average(^.layer_011.pos.i, ^.layer_01110.pos.i) - ^.layer_01.pos.i - ^.layer_0.pos.i,?)
  _0: rectangle with size (?,?) with model ? with color ? at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01110: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 183.6 + 40961.8 = 41145.4
DL output with Mo: L = 174.0 + 1574.1 = 1748.1
DL input+output M: L = 357.6 + 42536.0 = 42893.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color ? and layers
  _00: point with color ^.layer_0111.shape.color at (average(^.layer_011.pos.i, ^.layer_01110.pos.i) - ^.layer_01.pos.i - ^.layer_0.pos.i,?)
  _0: rectangle with size (?,?) with model ? with color ? at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01110: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 153.4 + 20.0 = 173.4
DL output with Mo: L = 174.0 + 1574.1 = 1748.1
DL input+output M: L = 327.4 + 1594.1 = 1921.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (29,29) and color black and layers
  _0: rectangle with size (29,29) with mask 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 . 0 0 . 0 0 . 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 . 0 0 . 0 0 . 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 . 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 . 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color yellow at (0,0)
  _01: rectangle with size (10,1) with model Full with color blue at (5,5)
  _011: rectangle with size (10,1) with model Full with color blue at (5,8)
  _01110: rectangle with size (1,4) with model Full with color green at (5,11)
  _0111: rectangle with size (1,4) with model Full with color green at (8,11)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _00: point with color green at (0,2)
  _0: rectangle with size (3,1) with model Full with color blue at (0,0)
diff: 
   (24.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (29,29) and color black and layers
  _0: rectangle with size (29,29) with mask 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 . 0 0 . 0 0 . 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 . 0 0 . 0 0 . 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 . 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 . 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color yellow at (0,0)
  _01: rectangle with size (10,1) with model Full with color blue at (5,5)
  _011: rectangle with size (10,1) with model Full with color blue at (5,8)
  _01110: rectangle with size (1,4) with model Full with color green at (5,11)
  _0111: rectangle with size (1,4) with model Full with color green at (8,11)
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 7837ac64.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (27,27) and color black and layers
  _0: rectangle with size (27,27) with mask 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
 with color green at (0,0)
  _01: rectangle with size (9,1) with model Full with color red at (7,7)
  _011: rectangle with size (5,1) with model Full with color red at (7,11)
  _01110: rectangle with size (5,1) with model Full with color red at (11,3)
  _0111: rectangle with size (1,5) with model Full with color cyan at (15,11)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _00: point with color cyan at (2,2)
  _0: rectangle with size (2,2) with model Odd Checkboard with color red at (0,0)
diff: 
   (29.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (27,27) and color black and layers
  _0: rectangle with size (27,27) with mask 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
 with color green at (0,0)
  _01: rectangle with size (9,1) with model Full with color red at (7,7)
  _011: rectangle with size (5,1) with model Full with color red at (7,11)
  _01110: rectangle with size (5,1) with model Full with color red at (11,3)
  _0111: rectangle with size (1,5) with model Full with color cyan at (15,11)
  + 2 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (27,27) and color black and layers
  _0: rectangle with size (27,27) with mask 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
 with color green at (0,0)
  _01: rectangle with size (9,1) with model Full with color red at (7,7)
  _011: rectangle with size (5,1) with model Full with color red at (7,11)
  _01110: rectangle with size (1,5) with model Full with color cyan at (15,11)
  _0111: rectangle with size (5,1) with model Full with color red at (11,3)
  + 2 delta pixels
diff: 
! 5 wrong pixels (generated / expected)

TRAIN 7837ac64.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (29,29) and color black and layers
  _0: rectangle with size (29,29) with mask 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 . 0 0 . 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 . 0 0 . 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 . 0 0 . 0 0 . 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 . 0 0 . 0 0 . 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color blue at (0,0)
  _01: rectangle with size (1,10) with model Full with color green at (17,14)
  _011: rectangle with size (1,10) with model Full with color green at (20,14)
  _01110: rectangle with size (1,7) with model Full with color pink at (14,14)
  _0111: rectangle with size (1,7) with model Full with color pink at (11,14)
diff: 
   (2.0 bits)
data: a background with size (3,3) and color green and layers
  _00: point with color pink at (0,0)
  _0: rectangle with size (2,3) with model Full with color black at (0,0)
  + 1 delta pixels
diff: 
   (71.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (29,29) and color black and layers
  _0: rectangle with size (29,29) with mask 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 . 0 0 . 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 . 0 0 . 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 . 0 0 . 0 0 . 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 . 0 0 . 0 0 . 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color blue at (0,0)
  _01: rectangle with size (1,10) with model Full with color green at (17,14)
  _011: rectangle with size (1,10) with model Full with color green at (20,14)
  _01110: rectangle with size (1,7) with model Full with color pink at (14,14)
  _0111: rectangle with size (1,7) with model Full with color pink at (11,14)
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 7837ac64.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (27,27) and color black and layers
  _0: rectangle with size (27,27) with mask 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
 with color cyan at (0,0)
  _01: rectangle with size (13,1) with model Full with color red at (7,15)
  _011: rectangle with size (13,1) with model Full with color red at (7,19)
  _01110: rectangle with size (1,5) with model Full with color blue at (7,7)
  _0111: rectangle with size (1,5) with model Full with color blue at (11,7)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color red and layers
  _00: point with color blue at (0,0)
  _0: rectangle with size (2,2) with model Full with color black at (0,0)
diff: 
   (32.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (27,27) and color black and layers
  _0: rectangle with size (27,27) with mask 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
 with color cyan at (0,0)
  _01: rectangle with size (13,1) with model Full with color red at (7,15)
  _011: rectangle with size (13,1) with model Full with color red at (7,19)
  _01110: rectangle with size (1,5) with model Full with color blue at (7,7)
  _0111: rectangle with size (1,5) with model Full with color blue at (11,7)
  + 4 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (27,27) and color black and layers
  _0: rectangle with size (27,27) with mask 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
 with color cyan at (0,0)
  _01: rectangle with size (13,1) with model Full with color red at (7,15)
  _011: rectangle with size (13,1) with model Full with color red at (7,19)
  _01110: rectangle with size (1,5) with model Full with color blue at (7,7)
  _0111: rectangle with size (1,5) with model Full with color red at (15,7)
  + 4 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 7837ac64.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
undefined expression: Average: not an integer

TEST 7837ac64.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 49.9 sec (49.9 sec/task)
bits-train-error = 1574.1 bits (1574.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-215] Checking task 794b24be.json: 10 train, 2 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 35116.0 = 35118.3
DL output with Mo: L = 2.3 + 35116.0 = 35118.3
DL input+output M: L = 4.6 + 70232.0 = 70236.7

# learning a model for train pairs
2.000	
1.321	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.643	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.443	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.276	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.239	OUT SPE ^.size = ^.size
0.216	OUT SPE ^.layer_0.pos = '(0, 0)
0.200	OUT SPE ^.layer_0.shape.color = red
0.193	OUT SPE ^.color = black
0.041	
0.040	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 5348.0 = 5389.9
DL output with Mo: L = 43.7 + 1357.2 = 1400.9
DL input+output M: L = 85.7 + 6705.2 = 6790.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at '(0, 0)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 43.7 + 1357.2 = 1400.9
DL input+output M: L = 46.1 + 1357.2 = 1403.3

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 
1 0 0 
0 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,0)
diff: 
   (9.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 
1 0 0 
0 0 0 

diff: 
! 3 wrong pixels (generated / expected)

TRAIN 794b24be.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
0 1 0 
1 0 0 
0 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (0,0)
diff: 
   (11.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 1 0 
1 0 0 
0 0 0 

diff: 
! 2 wrong pixels (generated / expected)

TRAIN 794b24be.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
0 0 1 
0 0 0 
1 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (0,0)
diff: 
   (11.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 1 
0 0 0 
1 0 0 

diff: 
! 2 wrong pixels (generated / expected)

TRAIN 794b24be.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: 
0 1 0 
0 0 1 
0 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (0,0)
diff: 
   (11.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 1 0 
0 0 1 
0 0 0 

diff: 
! 2 wrong pixels (generated / expected)

TRAIN 794b24be.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: 
0 0 1 
0 0 0 
0 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,0)
diff: 
   (9.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 1 
0 0 0 
0 0 0 

diff: 
! 3 wrong pixels (generated / expected)

TRAIN 794b24be.json/5: 0 - (FAILURE)

## instance 6

> Input and output best reading:

data: 
1 1 0 
0 0 0 
1 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (0,0)
diff: 
   (12.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 0 
0 0 0 
1 0 0 

diff: 
! 3 wrong pixels (generated / expected)

TRAIN 794b24be.json/6: 0 - (FAILURE)

## instance 7

> Input and output best reading:

data: 
0 1 0 
1 1 0 
0 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (0,0)
diff: 
   (12.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 1 0 
1 1 0 
0 0 0 

diff: 
! 3 wrong pixels (generated / expected)

TRAIN 794b24be.json/7: 0 - (FAILURE)

## instance 8

> Input and output best reading:

data: 
1 1 0 
0 0 0 
1 0 1 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color red at (0,0)
diff: 
   (19.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 0 
0 0 0 
1 0 1 

diff: 
! 2 wrong pixels (generated / expected)

TRAIN 794b24be.json/8: 0 - (FAILURE)

## instance 9

> Input and output best reading:

data: 
0 1 0 
1 1 0 
1 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color red at (0,0)
diff: 
   (19.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 1 0 
1 1 0 
1 0 0 

diff: 
! 2 wrong pixels (generated / expected)

TRAIN 794b24be.json/9: 0 - (FAILURE)

## instance 10

> Input and output best reading:

data: 
1 0 0 
0 0 1 
0 1 1 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color red at (0,0)
diff: 
   (19.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 0 0 
0 0 1 
0 1 1 

diff: 
! 2 wrong pixels (generated / expected)

TRAIN 794b24be.json/10: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 1 0 
0 0 0 
0 1 0 

diff: 
! 2 wrong pixels (generated / expected)

TEST 794b24be.json/1: 0 - (FAILURE)

## instance 2

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 1 0 
0 1 1 
1 0 0 

diff: 
! 2 wrong pixels (generated / expected)

TEST 794b24be.json/2: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 0.7 sec (0.7 sec/task)
bits-train-error = 1357.2 bits (1357.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-214] Checking task 7b6016b9.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 665128.1 = 665130.4
DL output with Mo: L = 2.3 + 665128.1 = 665130.4
DL input+output M: L = 4.6 + 1330256.2 = 1330260.9

# learning a model for train pairs
2.000	
1.204	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.535	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.350	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.148	OUT ADD ^.layer_0 = ^.layer_0
0.051	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.033	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.026	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.025	OUT SPE ^.size = ^.size
0.025	OUT SPE ^.color = green
0.025	OUT SPE ^.layer_011.shape.mask.size.i = 3
0.024	OUT SPE ^.layer_01.shape.color = red
0.024	OUT SPE ^.layer_011.shape.color = red
0.024	OUT SPE ^.layer_0111.shape.color = red
0.024	OUT SPE ^.layer_01.shape.mask.model = Full
0.024	OUT SPE ^.layer_011.shape.mask.model = Full
0.024	OUT SPE ^.layer_0111.shape.mask.model = Full
0.023	IN  SPE ^.color = black
0.004	
0.004	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color green and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model Full with color red at (?,?)
  _011: rectangle with size (3,?) with model Full with color red at (?,?)
  _0111: rectangle with size (?,?) with model Full with color red at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.1 + 13052.0 = 13094.1
DL output with Mo: L = 119.2 + 2376.5 = 2495.7
DL input+output M: L = 161.3 + 15428.5 = 15589.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color green and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model Full with color red at (?,?)
  _011: rectangle with size (3,?) with model Full with color red at (?,?)
  _0111: rectangle with size (?,?) with model Full with color red at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 119.2 + 2376.5 = 2495.7
DL input+output M: L = 161.2 + 2376.5 = 2537.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (23,23) and color black and layers
  _0: rectangle with size (22,22) with mask 
. . . . . . . . . . 0 . . . . . . . . . . . 
. . . . . . . . . . 0 . . . . . 0 . . . . . 
. . . . . . . . . . 0 . . . . . 0 . . . . . 
. . . . . . 0 . . . 0 . . . . . 0 . . . . . 
. . . 0 0 0 0 0 0 0 0 0 0 . . . 0 . . . . . 
. . . . . . 0 . . . 0 . . . . . 0 . . . 0 . 
. . . . . . 0 . . . 0 . . . . . 0 . . . 0 . 
. . . . . . 0 . . . 0 . . . . . 0 . . . 0 . 
. . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . 0 . . . 0 . . . . . 0 . . . 0 . 
. . . . . . 0 . . . 0 . . . . . 0 . . . 0 . 
. . . . . . 0 . . . . . . . . . 0 . . . 0 . 
. . . . . . 0 . . . . . . . . . 0 . . . . . 
. . . . . . 0 . . . . . . . . . 0 . . . . . 
. . . . . . 0 . . . . . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
. . . . . . 0 . . . . . . 0 . . 0 . . . . . 
. . . . . . 0 . . . . . . 0 . . 0 . . . . . 
. . . . . . 0 . . . . . . 0 . . 0 . . . . . 
. . . . . . 0 . . . . . 0 0 0 0 0 0 0 0 0 . 
. . . . . . . . . . . . . 0 . . 0 . . . . . 
. . . . . . . . . . . . . 0 . . 0 . . . . . 
 with color cyan at (0,0)
diff: 
   (0.0 bits)
data: a background with size (23,23) and color green and layers
  _0: 
. . . . . . . . . . 8 . . . . . . . . . . . 
. . . . . . . . . . 8 . . . . . 8 . . . . . 
. . . . . . . . . . 8 . . . . . 8 . . . . . 
. . . . . . 8 . . . 8 . . . . . 8 . . . . . 
. . . 8 8 8 8 8 8 8 8 8 8 . . . 8 . . . . . 
. . . . . . 8 . . . 8 . . . . . 8 . . . 8 . 
. . . . . . 8 . . . 8 . . . . . 8 . . . 8 . 
. . . . . . 8 . . . 8 . . . . . 8 . . . 8 . 
. . . 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . . . . . 8 . . . 8 . . . . . 8 . . . 8 . 
. . . . . . 8 . . . 8 . . . . . 8 . . . 8 . 
. . . . . . 8 . . . . . . . . . 8 . . . 8 . 
. . . . . . 8 . . . . . . . . . 8 . . . . . 
. . . . . . 8 . . . . . . . . . 8 . . . . . 
. . . . . . 8 . . . . . . . . . 8 . . . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 . . . . 
. . . . . . 8 . . . . . . 8 . . 8 . . . . . 
. . . . . . 8 . . . . . . 8 . . 8 . . . . . 
. . . . . . 8 . . . . . . 8 . . 8 . . . . . 
. . . . . . 8 . . . . . 8 8 8 8 8 8 8 8 8 . 
. . . . . . . . . . . . . 8 . . 8 . . . . . 
. . . . . . . . . . . . . 8 . . 8 . . . . . 
 at (0,0)
  _01: rectangle with size (6,9) with model Full with color red at (9,7)
  _011: rectangle with size (3,3) with model Full with color red at (5,7)
  _0111: rectangle with size (3,2) with model Full with color red at (16,14)
diff: 
   (77.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (22,22) with mask 
. . . . . . . . . . 0 . . . . . . . . . . . 
. . . . . . . . . . 0 . . . . . 0 . . . . . 
. . . . . . . . . . 0 . . . . . 0 . . . . . 
. . . . . . 0 . . . 0 . . . . . 0 . . . . . 
. . . 0 0 0 0 0 0 0 0 0 0 . . . 0 . . . . . 
. . . . . . 0 . . . 0 . . . . . 0 . . . 0 . 
. . . . . . 0 . . . 0 . . . . . 0 . . . 0 . 
. . . . . . 0 . . . 0 . . . . . 0 . . . 0 . 
. . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . 0 . . . 0 . . . . . 0 . . . 0 . 
. . . . . . 0 . . . 0 . . . . . 0 . . . 0 . 
. . . . . . 0 . . . . . . . . . 0 . . . 0 . 
. . . . . . 0 . . . . . . . . . 0 . . . . . 
. . . . . . 0 . . . . . . . . . 0 . . . . . 
. . . . . . 0 . . . . . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
. . . . . . 0 . . . . . . 0 . . 0 . . . . . 
. . . . . . 0 . . . . . . 0 . . 0 . . . . . 
. . . . . . 0 . . . . . . 0 . . 0 . . . . . 
. . . . . . 0 . . . . . 0 0 0 0 0 0 0 0 0 . 
. . . . . . . . . . . . . 0 . . 0 . . . . . 
. . . . . . . . . . . . . 0 . . 0 . . . . . 
 with color cyan at (0,0)
diff: 
! 73 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (21,1) with model Full with color cyan at (1,16)
  + 87 delta pixels
diff: 
! 160 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (1,19) with model Full with color cyan at (8,3)
  + 89 delta pixels
diff: 
! 162 wrong pixels (generated / expected)

TRAIN 7b6016b9.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (22,25) and color black and layers
  _0: rectangle with size (19,25) with mask 
. . . . 0 . . . . . . . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . . . . . . . 0 . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . 0 0 0 0 0 0 0 0 0 0 0 0 . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. 0 0 0 0 0 0 0 0 0 0 0 0 . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . 0 0 0 0 0 0 0 . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . . . . . . . 0 . . . . . 0 . . . . . . . . 
 with color blue at (1,0)
diff: 
   (0.0 bits)
data: a background with size (22,25) and color green and layers
  _0: 
. . . . 1 . . . . . . . . . . . 1 . . . . . . . . 
. . . . 1 . . . . . . . . . . . 1 . . . . . . . . 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
. . . . 1 . . . . . 1 . . . . . 1 . . . . . . . . 
. . . . 1 . . . . . 1 . . . . . 1 . . . . . . . . 
. . . . 1 . . . . . 1 . . . . . 1 . . . . . . . . 
. . . . 1 . . . 1 1 1 1 1 1 1 1 1 1 1 1 . . . . . 
. . . . 1 . . . . . 1 . . . . . 1 . . . . . . . . 
. . . . 1 . . . . . 1 . . . . . 1 . . . . . . . . 
. . . . 1 . . . . . 1 . . . . . 1 . . . . . . . . 
. . . . 1 . . . . . 1 . . . . . 1 . . . . . . . . 
. 1 1 1 1 1 1 1 1 1 1 1 1 . . . 1 . . . . . . . . 
. . . . 1 . . . . . 1 . . . . . 1 . . . . . . . . 
. . . . 1 . . . . . 1 . . . . . 1 . . . . . . . . 
. . . . 1 . . . . . 1 . . . . . 1 . . . . . . . . 
. . . . 1 . . . . . 1 . . . 1 1 1 1 1 1 1 . . . . 
. . . . 1 . . . . . 1 . . . . . 1 . . . . . . . . 
. . . . 1 . . . . . 1 . . . . . 1 . . . . . . . . 
. . . . . . . . . . 1 . . . . . 1 . . . . . . . . 
 at (1,0)
  _01: rectangle with size (8,3) with model Full with color red at (4,5)
  _011: rectangle with size (3,5) with model Full with color red at (4,11)
  _0111: rectangle with size (8,5) with model Full with color red at (4,5)
diff: 
   (82.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (22,25) and color black and layers
  _0: rectangle with size (19,25) with mask 
. . . . 0 . . . . . . . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . . . . . . . 0 . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . 0 0 0 0 0 0 0 0 0 0 0 0 . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. 0 0 0 0 0 0 0 0 0 0 0 0 . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . 0 0 0 0 0 0 0 . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . 0 . . . . . 0 . . . . . 0 . . . . . . . . 
. . . . . . . . . . 0 . . . . . 0 . . . . . . . . 
 with color blue at (1,0)
diff: 
! 59 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (22,25) and color black and layers
  _0: rectangle with size (1,25) with model Full with color blue at (3,0)
  + 77 delta pixels
diff: 
! 136 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (22,25) and color black and layers
  _0: rectangle with size (19,1) with model Full with color blue at (1,16)
  + 83 delta pixels
diff: 
! 142 wrong pixels (generated / expected)

TRAIN 7b6016b9.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (24,21) and color black and layers
  _0: rectangle with size (22,20) with mask 
. . . 0 . . . . . . . . . . . . . . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . 0 0 0 0 0 0 0 0 0 . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
. . . 0 . . 0 . . . . . 0 . . . . 0 . . 
. . . 0 . . 0 . . . . . 0 . . . . 0 . . 
. 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . 
. . . 0 . . 0 . . . . . 0 . . . . 0 . . 
. . . 0 . . 0 . . . . . 0 . . . . 0 . . 
. . . 0 . . 0 . . . . 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 . . . 0 . . . . 0 . . 
. . . 0 . . 0 . . . . . 0 . . . . 0 . . 
. . . 0 . . 0 . . . . . 0 . . . . 0 . . 
. . . 0 . . 0 . . . . . 0 . . . . . . . 
 with color yellow at (1,1)
diff: 
   (0.0 bits)
data: a background with size (24,21) and color green and layers
  _0: 
. . . 4 . . . . . . . . . . . . . . . . 
. . . 4 . . . . . . . . 4 . . . . . . . 
. . . 4 . . . . . . . . 4 . . . . . . . 
. . . 4 . . . . . . . . 4 . . . . . . . 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 . . . . 
. . . 4 . . . . . . . . 4 . . . . . . . 
. . . 4 . . . . . . . . 4 . . . . . . . 
. . . 4 . . . . 4 4 4 4 4 4 4 4 4 . . . 
. . . 4 . . . . . . . . 4 . . . . . . . 
. . . 4 . . . . . . . . 4 . . . . . . . 
. . . 4 . . . . . . . . 4 . . . . . . . 
. . . 4 . . . . . . . . 4 . . . . . . . 
. . . 4 . . 4 . . . . . 4 . . . . 4 . . 
. . . 4 . . 4 . . . . . 4 . . . . 4 . . 
. 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 . . 
. . . 4 . . 4 . . . . . 4 . . . . 4 . . 
. . . 4 . . 4 . . . . . 4 . . . . 4 . . 
. . . 4 . . 4 . . . . 4 4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 4 . . . 4 . . . . 4 . . 
. . . 4 . . 4 . . . . . 4 . . . . 4 . . 
. . . 4 . . 4 . . . . . 4 . . . . 4 . . 
. . . 4 . . 4 . . . . . 4 . . . . . . . 
 at (1,1)
  _01: rectangle with size (9,8) with model Full with color red at (6,5)
  _011: rectangle with size (3,2) with model Full with color red at (16,5)
  _0111: rectangle with size (2,4) with model Full with color red at (16,14)
diff: 
   (77.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (24,21) and color black and layers
  _0: rectangle with size (22,20) with mask 
. . . 0 . . . . . . . . . . . . . . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . 0 0 0 0 0 0 0 0 0 . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . . . . . 0 . . . . . . . 
. . . 0 . . 0 . . . . . 0 . . . . 0 . . 
. . . 0 . . 0 . . . . . 0 . . . . 0 . . 
. 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . 
. . . 0 . . 0 . . . . . 0 . . . . 0 . . 
. . . 0 . . 0 . . . . . 0 . . . . 0 . . 
. . . 0 . . 0 . . . . 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 . . . 0 . . . . 0 . . 
. . . 0 . . 0 . . . . . 0 . . . . 0 . . 
. . . 0 . . 0 . . . . . 0 . . . . 0 . . 
. . . 0 . . 0 . . . . . 0 . . . . . . . 
 with color yellow at (1,1)
diff: 
! 86 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (24,21) and color black and layers
  _0: rectangle with size (22,1) with model Full with color yellow at (1,4)
  + 89 delta pixels
diff: 
! 175 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (24,21) and color black and layers
  _0: rectangle with size (21,1) with model Full with color yellow at (2,13)
  + 90 delta pixels
diff: 
! 176 wrong pixels (generated / expected)

TRAIN 7b6016b9.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (22,25) and color black and layers
  _0: rectangle with size (21,22) with mask 
. . . 0 . . . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . . 0 . . . . 0 . . . . . 0 . 
. . . 0 . . . . . 0 . . . . 0 . . . . . 0 . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . . . 0 . . . . 0 . . . . . 0 . 
. . . 0 . . . . . 0 . . . . 0 . . . . . 0 . 
. . . 0 . . . . . 0 . . . . 0 . . . . . 0 . 
. . . 0 . . . . . 0 . . . . 0 . . . . . 0 . 
. . . 0 . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . . . 0 . . . . 0 . . . . . 0 . 
. . . 0 . . . . . 0 . . . . 0 . . . . . 0 . 
. . . 0 . . . . . . . . . . 0 . . . . . 0 . 
. . . 0 . . . . . . . . . . 0 . . . . . . . 
. 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
. . . 0 . . . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . . . 0 0 0 0 0 0 0 0 0 . . . 
. 0 0 0 0 0 . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . . . . . . . 0 . . . . . . . 
. . . 0 . . . . . . . . . . . . . . . . . . 
. . . 0 . . . . . . . . . . . . . . . . . . 
 with color orange at (1,2)
diff: 
! 104 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (22,25) and color black and layers
  _0: rectangle with size (1,22) with model Full with color orange at (4,2)
  + 95 delta pixels
diff: 
! 199 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (22,25) and color black and layers
  _0: rectangle with size (21,1) with model Full with color orange at (1,5)
  + 96 delta pixels
diff: 
! 200 wrong pixels (generated / expected)

TEST 7b6016b9.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 26.6 sec (26.6 sec/task)
bits-train-error = 2376.5 bits (2376.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-213] Checking task 7b7f7511.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 24092.4 = 24094.7
DL output with Mo: L = 2.3 + 12084.4 = 12086.7
DL input+output M: L = 4.6 + 36176.8 = 36181.4

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = periodicFactor(black, ^)
0.522	IN  SPE ^ = tiling to size (?,?)
of grid ?
0.312	IN  SPE ^.grid = a background with size (?,?) and color ? and layers
0.185	IN  ADD ^.grid.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.141	IN  ADD ^.grid.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.138	IN  SPE ^.grid.layer_01.shape.mask.model = Full
0.134	IN  ADD ^.grid.layer_011 = point with color ? at (?,?)
0.005	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
periodicFactor(black, ^)
WHERE (Mi)
tiling to size (?,?)
of grid a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 100.4 + 3106.6 = 3207.0
DL output with Mo: L = 16.0 + 0.0 = 16.0
DL input+output M: L = 116.4 + 3106.6 = 3223.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
periodicFactor(black, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 16.0 + 0.0 = 16.0
DL input+output M: L = 18.3 + 0.0 = 18.3

# train input/output grids

## instance 1

> Input and output best reading:

data: 
1 1 3 2 1 1 3 2 
1 1 3 3 1 1 3 3 
3 3 1 1 3 3 1 1 
2 3 1 1 2 3 1 1 

diff: 
   (0.0 bits)
data: 
1 1 3 2 
1 1 3 3 
3 3 1 1 
2 3 1 1 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 3 2 1 1 3 2 
1 1 3 3 1 1 3 3 
3 3 1 1 3 3 1 1 
2 3 1 1 2 3 1 1 

diff: 
correct output grid

TRAIN 7b7f7511.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
4 4 4 4 4 4 
6 4 8 6 4 8 
6 6 8 6 6 8 

diff: 
   (0.0 bits)
data: 
4 4 4 
6 4 8 
6 6 8 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 4 4 4 4 4 
6 4 8 6 4 8 
6 6 8 6 6 8 

diff: 
correct output grid

TRAIN 7b7f7511.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
2 3 
3 2 
4 4 
2 3 
3 2 
4 4 

diff: 
   (0.0 bits)
data: 
2 3 
3 2 
4 4 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 3 
3 2 
4 4 
2 3 
3 2 
4 4 

diff: 
correct output grid

TRAIN 7b7f7511.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#4 5#
4 5#4 
6 6 4 
2 6 2 
5#4 5#
4 5#4 
6 6 4 
2 6 2 

diff: 
correct output grid

TEST 7b7f7511.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.3 sec (1.3 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-212] Checking task 7c008303.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 96473.4 = 96475.7
DL output with Mo: L = 2.3 + 42126.8 = 42129.1
DL input+output M: L = 4.6 + 138600.2 = 138604.9

# learning a model for train pairs
2.000	
1.470	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.941	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.749	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.621	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.521	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.421	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.352	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.301	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.273	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.261	OUT SPE ^.size = ^.size - (3, 3)
0.251	OUT SPE ^.layer_0.shape.mask.size = '(3, 3)
0.242	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.233	OUT SPE ^.layer_01.shape.mask.size = '(3, 3)
0.225	IN  ADD ^.layer_01110 = point with color ? at (?,?)
0.218	OUT SPE ^.layer_0.pos = '(0, 0)
0.212	OUT SPE ^.layer_01.pos = projI(^.layer_01.pos) + (0, 3)
0.207	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.204	OUT SPE ^.layer_0111.pos.j = 3
0.200	OUT SPE ^.layer_01.shape.color = ^.layer_0111.shape.color
0.197	OUT SPE ^.layer_011.pos.j = min(^.layer_011.pos.j, ^.layer_0111.pos.j)
0.195	OUT SPE ^.layer_0111.pos.i = max(^.layer_0.pos.j, ^.layer_01.pos.j)
0.192	OUT SPE ^.layer_011.pos.i = ^.layer_01.pos.j + area(^.layer_0111.shape)
0.190	OUT SPE ^.color = black
0.189	IN  SPE ^.layer_0111.shape.mask.model = Full
0.189	IN  SPE ^.color = black
0.093	
0.093	IN  GEN ^.layer_0111.shape.mask.model = ?
0.093	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size - (3, 3) and color black and layers
  _0: rectangle with size '(3, 3) with model ? with color ? at '(0, 0)
  _01: rectangle with size '(3, 3) with model ? with color ^.layer_0111.shape.color at projI(^.layer_01.pos) + (0, 3)
  _011: rectangle with size (?,?) with model ? with color ? at (^.layer_01.pos.j + area(^.layer_0111.shape),min(^.layer_011.pos.j, ^.layer_0111.pos.j))
  _0111: rectangle with size (?,?) with model ? with color ? at (max(^.layer_0.pos.j, ^.layer_01.pos.j),3)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01110: point with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 161.9 + 9324.8 = 9486.7
DL output with Mo: L = 288.5 + 3515.5 = 3804.0
DL input+output M: L = 450.4 + 12840.4 = 13290.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size - (3, 3) and color black and layers
  _0: rectangle with size '(3, 3) with model ? with color ? at '(0, 0)
  _01: rectangle with size '(3, 3) with model ? with color ^.layer_0111.shape.color at projI(^.layer_01.pos) + (0, 3)
  _011: rectangle with size (?,?) with model ? with color ? at (^.layer_01.pos.j + area(^.layer_0111.shape),min(^.layer_011.pos.j, ^.layer_0111.pos.j))
  _0111: rectangle with size (?,?) with model ? with color ? at (max(^.layer_0.pos.j, ^.layer_01.pos.j),3)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01110: point with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 161.3 + 63.4 = 224.7
DL output with Mo: L = 288.5 + 3515.5 = 3804.0
DL input+output M: L = 449.7 + 3578.9 = 4028.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: rectangle with size (6,6) with mask 
. 0 . . 0 . 
0 0 0 0 0 0 
. 0 . . 0 . 
. 0 . . 0 . 
0 0 0 0 0 0 
. 0 . . 0 . 
 with color green at (3,3)
  _01: rectangle with size (9,1) with model Full with color cyan at (0,2)
  _011: rectangle with size (1,9) with model Full with color cyan at (2,0)
  _01110: point with color red at (0,0)
  _0111: rectangle with size (1,1) with model Full with color yellow at (0,1)
  _01111: point with color blue at (1,0)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (3,3) with model +-cross with color red at (0,0)
  _01: rectangle with size (3,3) with model +-cross with color yellow at (0,3)
  _011: rectangle with size (3,3) with model +-cross with color blue at (3,0)
  _0111: rectangle with size (3,3) with model +-cross with color pink at (3,3)
diff: 
   (69.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (6,6) with mask 
. 0 . . 0 . 
0 0 0 0 0 0 
. 0 . . 0 . 
. 0 . . 0 . 
0 0 0 0 0 0 
. 0 . . 0 . 
 with color green at (3,3)
  _01: rectangle with size (9,1) with model Full with color cyan at (0,2)
  _011: rectangle with size (1,9) with model Full with color cyan at (2,0)
  _01110: point with color red at (0,0)
  _0111: rectangle with size (1,1) with model Full with color yellow at (0,1)
  _01111: point with color blue at (1,0)
  + 1 delta pixels
diff: 
! 25 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (6,6) with mask 
. 0 . . 0 . 
0 0 0 0 0 0 
. 0 . . 0 . 
. 0 . . 0 . 
0 0 0 0 0 0 
. 0 . . 0 . 
 with color green at (3,3)
  _01: rectangle with size (9,1) with model Full with color cyan at (0,2)
  _011: rectangle with size (1,9) with model Full with color cyan at (2,0)
  _01110: point with color red at (0,0)
  _0111: rectangle with size (1,1) with model Full with color blue at (1,0)
  _01111: point with color yellow at (0,1)
  + 1 delta pixels
diff: 
! 30 wrong pixels (generated / expected)

TRAIN 7c008303.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,9) with mask 
. . . . . . 0 . . 
. . . . . . 0 . . 
0 0 0 0 0 0 0 0 0 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
 with color cyan at (0,0)
  _01: rectangle with size (3,4) with mask 
. . 0 0 
0 0 . . 
0 0 . . 
 with color green at (3,0)
  _011: rectangle with size (4,6) with mask 
. . . 0 . 0 
. . . . 0 . 
0 0 0 0 0 0 
. . . . 0 . 
 with color green at (5,0)
  _01110: point with color red at (0,8)
  _0111: rectangle with size (2,2) with model Full with color blue at (0,7)
  _01111: point with color green at (3,5)
  + 1 delta pixels
diff: 
   (3.2 bits)
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
0 0 . 
 with color blue at (0,0)
  _01: rectangle with size (3,3) with model +-cross with color blue at (3,3)
  _011: rectangle with size (1,3) with model Full with color yellow at (4,0)
  _0111: rectangle with size (1,1) with model Full with color red at (0,3)
  + 3 delta pixels
diff: 
   (174.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,9) with mask 
. . . . . . 0 . . 
. . . . . . 0 . . 
0 0 0 0 0 0 0 0 0 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
 with color cyan at (0,0)
  _01: rectangle with size (4,6) with mask 
. . . 0 . 0 
. . . . 0 . 
0 0 0 0 0 0 
. . . . 0 . 
 with color green at (5,0)
  _011: rectangle with size (3,4) with mask 
. . 0 0 
0 0 . . 
0 0 . . 
 with color green at (3,0)
  _01110: point with color red at (0,8)
  _0111: rectangle with size (2,2) with model Full with color blue at (0,7)
  _01111: point with color green at (3,5)
  + 1 delta pixels
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,9) with mask 
. . . . . . 0 . . 
. . . . . . 0 . . 
0 0 0 0 0 0 0 0 0 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
 with color cyan at (0,0)
  _01: rectangle with size (3,4) with mask 
. . 0 0 
0 0 . . 
0 0 . . 
 with color green at (3,0)
  _011: rectangle with size (4,6) with mask 
. . . 0 . 0 
. . . . 0 . 
0 0 0 0 0 0 
. . . . 0 . 
 with color green at (5,0)
  _01110: point with color red at (0,8)
  _0111: rectangle with size (2,2) with model Full with color blue at (0,7)
  _01111: point with color green at (3,5)
  + 1 delta pixels
diff: 
! 25 wrong pixels (generated / expected)

TRAIN 7c008303.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,9) with mask 
. . 0 . . . . . . 
. . 0 . . . . . . 
. . 0 . . . . . . 
. . 0 . . . . . . 
. . 0 . . . . . . 
. . 0 . . . . . . 
0 0 0 0 0 0 0 0 0 
. . 0 . . . . . . 
. . 0 . . . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (5,6) with mask 
. . 0 . . 0 
. . 0 . . 0 
0 0 . 0 0 . 
. . . . 0 . 
. . . 0 . . 
 with color green at (0,3)
  _011: rectangle with size (2,1) with model Full with color green at (4,4)
  _01110: point with color green at (5,8)
  _0111: rectangle with size (1,1) with model Full with color yellow at (7,1)
  _01111: point with color red at (7,0)
  + 2 delta pixels
diff: 
   (3.2 bits)
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
. . 0 
0 0 . 
 with color red at (0,0)
  _01: rectangle with size (3,3) with mask 
. . 0 
. . 0 
0 0 . 
 with color yellow at (0,3)
  _011: rectangle with size (2,1) with model Full with color pink at (4,1)
  _0111: rectangle with size (2,2) with model Odd Checkboard with color grey at (3,3)
  + 1 delta pixels
diff: 
   (107.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,9) with mask 
. . 0 . . . . . . 
. . 0 . . . . . . 
. . 0 . . . . . . 
. . 0 . . . . . . 
. . 0 . . . . . . 
. . 0 . . . . . . 
0 0 0 0 0 0 0 0 0 
. . 0 . . . . . . 
. . 0 . . . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (5,6) with mask 
. . 0 . . 0 
. . 0 . . 0 
0 0 . 0 0 . 
. . . . 0 . 
. . . 0 . . 
 with color green at (0,3)
  _011: rectangle with size (2,1) with model Full with color green at (4,4)
  _01110: point with color green at (5,8)
  _0111: rectangle with size (1,1) with model Full with color red at (7,0)
  _01111: point with color yellow at (7,1)
  + 2 delta pixels
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,9) with mask 
. . 0 . . . . . . 
. . 0 . . . . . . 
. . 0 . . . . . . 
. . 0 . . . . . . 
. . 0 . . . . . . 
. . 0 . . . . . . 
0 0 0 0 0 0 0 0 0 
. . 0 . . . . . . 
. . 0 . . . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (5,6) with mask 
. . 0 . . 0 
. . 0 . . 0 
0 0 . 0 0 . 
. . . . 0 . 
. . . 0 . . 
 with color green at (0,3)
  _011: rectangle with size (2,1) with model Full with color green at (4,4)
  _01110: point with color green at (5,8)
  _0111: rectangle with size (1,1) with model Full with color yellow at (7,1)
  _01111: point with color red at (7,0)
  + 2 delta pixels
diff: 
! 23 wrong pixels (generated / expected)

TRAIN 7c008303.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,9) with mask 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
0 0 0 0 0 0 0 0 0 
. . . . . . 0 . . 
. . . . . . 0 . . 
 with color cyan at (0,0)
  _01: rectangle with size (6,4) with mask 
. . . 0 
0 0 . 0 
. 0 . 0 
. 0 0 0 
. 0 . . 
. . 0 . 
 with color green at (0,0)
  _011: rectangle with size (2,1) with model Full with color green at (1,5)
  _01110: point with color green at (4,5)
  _0111: rectangle with size (1,1) with model Full with color red at (7,7)
  _01111: point with color blue at (7,8)
  + 2 delta pixels
diff: 
! 24 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,9) with mask 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
0 0 0 0 0 0 0 0 0 
. . . . . . 0 . . 
. . . . . . 0 . . 
 with color cyan at (0,0)
  _01: rectangle with size (6,4) with mask 
. . . 0 
0 0 . 0 
. 0 . 0 
. 0 0 0 
. 0 . . 
. . 0 . 
 with color green at (0,0)
  _011: rectangle with size (2,1) with model Full with color green at (1,5)
  _01110: point with color green at (4,5)
  _0111: rectangle with size (1,1) with model Full with color blue at (7,8)
  _01111: point with color red at (7,7)
  + 2 delta pixels
diff: 
! 19 wrong pixels (generated / expected)

TEST 7c008303.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 37.2 sec (37.2 sec/task)
bits-train-error = 3515.5 bits (3515.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-211] Checking task 7ddcd7ec.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.063	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.173	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.089	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.043	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.038	OUT SPE ^.size = ^.size
0.037	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.036	IN  SPE ^.color = black
0.035	OUT SPE ^.color = black
0.019	
0.019	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.1 + 1946.3 = 1988.4
DL output with Mo: L = 40.3 + 2214.9 = 2255.2
DL input+output M: L = 82.4 + 4161.2 = 4243.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 40.3 + 2214.9 = 2255.2
DL input+output M: L = 82.3 + 2214.9 = 2297.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
0 0 . 
. . 0 
 with color green at (2,2)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (8,8) with mask 
0 0 . . . . . . 
0 0 . . . . . . 
. . 0 . . . . . 
. . . 0 . . . . 
. . . . 0 . . . 
. . . . . 0 . . 
. . . . . . 0 . 
. . . . . . . 0 
 with color green at (2,2)
diff: 
   (73.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
0 0 . 
. . 0 
 with color green at (2,2)
diff: 
! 14 wrong pixels (generated / expected)

TRAIN 7ddcd7ec.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,3) with mask 
. . 0 
0 0 . 
0 0 . 
. . 0 
 with color yellow at (1,4)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (8,6) with mask 
. . . 0 . . 
. . 0 . . . 
0 0 . . . . 
0 0 . . . . 
. . 0 . . . 
. . . 0 . . 
. . . . 0 . 
. . . . . 0 
 with color yellow at (0,4)
diff: 
   (67.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,3) with mask 
. . 0 
0 0 . 
0 0 . 
. . 0 
 with color yellow at (1,4)
diff: 
! 14 wrong pixels (generated / expected)

TRAIN 7ddcd7ec.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. 0 0 . 
. 0 0 . 
0 . . . 
 with color orange at (2,3)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (9,9) with mask 
. . . . . . . . 0 
. . . . . . . 0 . 
. . . . . . 0 . . 
. . . . 0 0 . . . 
. . . . 0 0 . . . 
. . . 0 . . . . . 
. . 0 . . . . . . 
. 0 . . . . . . . 
0 . . . . . . . . 
 with color orange at (0,0)
diff: 
   (80.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. 0 0 . 
. 0 0 . 
0 . . . 
 with color orange at (2,3)
diff: 
! 15 wrong pixels (generated / expected)

TRAIN 7ddcd7ec.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. 0 0 . 
. 0 0 . 
0 . . 0 
 with color cyan at (3,2)
diff: 
! 19 wrong pixels (generated / expected)

TEST 7ddcd7ec.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 5.1 sec (5.1 sec/task)
bits-train-error = 2214.9 bits (2214.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-210] Checking task 7df24a62.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 889131.7 = 889134.0
DL output with Mo: L = 2.3 + 889131.7 = 889134.0
DL input+output M: L = 4.6 + 1778263.4 = 1778268.0

# learning a model for train pairs
2.000	
1.093	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.240	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.207	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.175	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.147	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.132	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.130	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.126	OUT ADD ^.layer_010 = ^.layer_01
0.124	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.121	OUT ADD ^.layer_0101 = ^.layer_011
0.119	OUT ADD ^.layer_0110 = ^.layer_01.shape at (?,?)
0.117	OUT ADD ^.layer_01010 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.057	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _01010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0101: ^.layer_011
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: ^.layer_01.shape at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 53802.3 = 53900.4
DL output with Mo: L = 169.0 + 50390.6 = 50559.5
DL input+output M: L = 267.1 + 104192.9 = 104459.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _01010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0101: ^.layer_011
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: ^.layer_01.shape at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 60.0 = 158.1
DL output with Mo: L = 169.0 + 50390.6 = 50559.5
DL input+output M: L = 267.1 + 50450.6 = 50717.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (23,23) and color black and layers
  _0: rectangle with size (5,5) with model Full with color blue at (1,3)
  _01: rectangle with size (1,1) with model Full with color yellow at (1,13)
  _011: rectangle with size (1,1) with model Full with color yellow at (4,20)
  + 15 delta pixels
diff: 
   (0.0 bits)
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (5,5) with model Full with color blue at (1,3)
  _010: 
4 
 at (1,13)
  _01010: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 . 0 . 0 
0 0 0 0 0 
0 0 . 0 0 
0 0 0 0 0 
 with color blue at (12,10)
  _0101: 
4 
 at (4,20)
  _01: rectangle with size (1,3) with model Full with color yellow at (13,11)
  _0110: 
4 
 at (5,18)
  _011: rectangle with size (1,1) with model Full with color yellow at (7,7)
  + 11 delta pixels
diff: 
   (659.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (5,5) with model Full with color blue at (1,3)
  _01: rectangle with size (1,1) with model Full with color yellow at (1,13)
  _011: rectangle with size (1,1) with model Full with color yellow at (4,20)
  + 15 delta pixels
diff: 
! size mismatch, 10x10 instead of 23x23
>> Trial 2
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (5,5) with model Full with color blue at (1,3)
  _01: rectangle with size (3,1) with model Full with color yellow at (12,4)
  _011: rectangle with size (1,1) with model Full with color yellow at (1,13)
  + 15 delta pixels
diff: 
! size mismatch, 10x10 instead of 23x23

TRAIN 7df24a62.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (23,23) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 0 
0 . 0 0 
0 0 . 0 
0 0 0 0 
 with color blue at (6,15)
  _01: rectangle with size (2,2) with model Full with color yellow at (7,16)
  _011: rectangle with size (2,1) with model Full with color yellow at (21,11)
  + 22 delta pixels
diff: 
   (2.0 bits)
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 0 
0 . 0 0 
0 0 . 0 
0 0 0 0 
 with color blue at (6,15)
  _010: 
4 4 
4 4 
 at (7,16)
  _01010: rectangle with size (4,4) with mask 
0 0 0 0 
0 0 . 0 
0 . 0 0 
0 0 0 0 
 with color blue at (13,13)
  _0101: 
4 
4 
 at (21,11)
  _01: rectangle with size (1,1) with model Full with color yellow at (0,0)
  _0110: 
4 4 
4 4 
 at (14,14)
  _011: rectangle with size (1,1) with model Full with color yellow at (0,10)
  + 18 delta pixels
diff: 
   (951.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (4,4) with model Full with color blue at (6,15)
  _01: rectangle with size (2,2) with model Odd Checkboard with color yellow at (14,14)
  _011: rectangle with size (2,1) with model Full with color yellow at (21,11)
  + 22 delta pixels
diff: 
! size mismatch, 10x10 instead of 23x23

TRAIN 7df24a62.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (23,23) and color black and layers
  _0: rectangle with size (3,4) with model Border with color blue at (14,5)
  _01: rectangle with size (2,1) with model Full with color yellow at (3,14)
  _011: rectangle with size (1,4) with model Full with color yellow at (15,4)
  + 42 delta pixels
diff: 
   (2.0 bits)
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (8,4) with mask 
0 0 0 . 
0 . 0 . 
0 . 0 . 
0 0 0 . 
. 0 0 0 
. 0 . 0 
. 0 . 0 
. 0 0 0 
 with color blue at (2,13)
  _010: 
4 
4 
 at (3,14)
  _01010: rectangle with size (4,7) with mask 
. . . . 0 0 0 
0 0 0 0 0 . 0 
0 . . 0 0 . 0 
0 0 0 0 0 0 0 
 with color blue at (13,5)
  _0101: 
4 4 4 4 
 at (15,4)
  _01: rectangle with size (4,7) with mask 
0 0 0 0 0 0 0 
0 . . 0 0 . 0 
0 0 0 0 0 . 0 
. . . . 0 0 0 
 with color blue at (11,13)
  _0110: 
4 
4 
 at (7,15)
  _011: rectangle with size (2,2) with model Odd Checkboard with color yellow at (2,11)
  + 38 delta pixels
diff: 
   (1875.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (3,4) with model Border with color blue at (14,5)
  _01: rectangle with size (1,4) with model Full with color yellow at (15,4)
  _011: rectangle with size (2,1) with model Full with color yellow at (3,14)
  + 42 delta pixels
diff: 
! size mismatch, 10x10 instead of 23x23
>> Trial 2
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (3,4) with model Border with color blue at (14,5)
  _01: rectangle with size (2,1) with model Full with color yellow at (3,14)
  _011: rectangle with size (1,4) with model Full with color yellow at (15,4)
  + 42 delta pixels
diff: 
! size mismatch, 10x10 instead of 23x23

TRAIN 7df24a62.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (23,23) and color black and layers
  _0: rectangle with size (5,4) with model Full with color blue at (8,6)
  _01: rectangle with size (1,2) with model Full with color yellow at (7,16)
  _011: rectangle with size (2,1) with model Full with color yellow at (0,2)
  + 36 delta pixels
diff: 
   (2.0 bits)
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (5,4) with mask 
0 0 0 0 
0 . . 0 
0 0 0 0 
0 . 0 0 
0 0 0 0 
 with color blue at (8,6)
  _010: 
4 4 
 at (7,16)
  _01010: rectangle with size (5,4) with model Full with color blue at (4,15)
  _0101: 
4 
4 
 at (0,2)
  _01: rectangle with size (3,5) with model Full with color blue at (0,1)
  _0110: 
4 4 
 at (9,7)
  _011: rectangle with size (2,2) with model Odd Checkboard with color yellow at (3,2)
  + 32 delta pixels
diff: 
   (1552.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (5,4) with model Full with color blue at (8,6)
  _01: rectangle with size (2,1) with model Full with color yellow at (0,2)
  _011: rectangle with size (1,2) with model Full with color yellow at (7,16)
  + 36 delta pixels
diff: 
! size mismatch, 10x10 instead of 23x23
>> Trial 2
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (5,4) with model Full with color blue at (8,6)
  _01: rectangle with size (2,1) with model Full with color yellow at (0,2)
  _011: rectangle with size (2,2) with model Odd Checkboard with color yellow at (3,2)
  + 36 delta pixels
diff: 
! size mismatch, 10x10 instead of 23x23

TRAIN 7df24a62.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (5,5) with model Full with color blue at (0,9)
  _01: rectangle with size (1,1) with model Full with color yellow at (1,5)
  _011: rectangle with size (1,1) with model Full with color yellow at (3,6)
  + 23 delta pixels
diff: 
! size mismatch, 10x10 instead of 23x23
>> Trial 2
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (5,5) with model Full with color blue at (0,9)
  _01: rectangle with size (1,1) with model Full with color yellow at (1,5)
  _011: rectangle with size (1,1) with model Full with color yellow at (4,3)
  + 23 delta pixels
diff: 
! size mismatch, 10x10 instead of 23x23

TEST 7df24a62.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.8 sec (59.8 sec/task)
bits-train-error = 50390.6 bits (50390.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-209] Checking task 7e0986d6.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 158788.6 = 158790.9
DL output with Mo: L = 2.3 + 158788.6 = 158790.9
DL input+output M: L = 4.6 + 317577.1 = 317581.8

# learning a model for train pairs
2.000	
1.459	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.948	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.780	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.631	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.484	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.348	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.245	OUT ADD ^.layer_011 = ^.layer_01
0.153	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.133	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.128	IN  ADD ^.layer_010 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.125	OUT SPE ^.layer_01 = ^.layer_010
0.122	OUT SPE ^.size = ^.size
0.120	OUT SPE ^.layer_0.shape.mask.size = ^.layer_0.shape.mask.size
0.118	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.118	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.117	IN  SPE ^.layer_010.shape.mask.model = Full
0.112	IN  ADD ^.layer_01110 = point with color ? at (?,?)
0.109	IN  ADD ^.layer_011101 = point with color ? at (?,?)
0.106	IN  ADD ^.layer_0101 = point with color ? at (?,?)
0.105	IN  SPE ^.layer_01.shape.mask.model = Full
0.105	IN  SPE ^.layer_011.shape.mask.model = Full
0.105	IN  SPE ^.layer_0111.shape.mask.model = Full
0.104	IN  SPE ^.color = black
0.104	OUT SPE ^.color = black
0.028	
0.028	IN  DEL ^.layer_0111
0.028	IN  DEL ^.layer_011
0.028	IN  DEL ^.layer_011101
0.028	IN  DEL ^.layer_01110
0.028	IN  DEL ^.layer_0101
0.028	IN  GEN ^.layer_01.shape.mask.model = ?
0.028	IN  GEN ^.layer_010.shape.mask.model = ?
0.028	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size ^.layer_0.shape.mask.size with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: ^.layer_010
  _011: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0101: point with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01110: point with color ? at (?,?)
  _011101: point with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 208.5 + 12052.9 = 12261.4
DL output with Mo: L = 53.7 + 4225.6 = 4279.3
DL input+output M: L = 262.2 + 16278.5 = 16540.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size ^.layer_0.shape.mask.size with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: ^.layer_010
  _011: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 0.0 = 98.1
DL output with Mo: L = 53.7 + 4225.6 = 4279.3
DL input+output M: L = 151.8 + 4225.6 = 4377.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (13,14) and color black and layers
  _0: rectangle with size (6,8) with mask 
. . . 0 0 0 . 0 
. . . 0 . 0 0 0 
. . . 0 0 0 0 0 
0 0 0 0 . 0 0 0 
0 0 0 . . . . . 
0 . 0 . . . . . 
 with color green at (7,0)
  _010: rectangle with size (5,5) with model Full with color green at (0,6)
  _01: rectangle with size (4,5) with model Full with color green at (6,9)
  + 24 delta pixels
diff: 
   (0.0 bits)
data: a background with size (13,14) and color black and layers
  _0: rectangle with size (6,8) with mask 
. . . 0 0 0 0 0 
. . . 0 0 0 0 0 
. . . 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 . . . . . 
0 0 0 . . . . . 
 with color green at (7,0)
  _01: 
3 3 3 3 3 
3 3 3 3 3 
3 3 3 3 3 
3 3 3 3 3 
3 3 3 3 3 
 at (0,6)
  _011: 
3 3 3 3 3 
3 3 3 3 3 
3 3 3 3 3 
3 3 3 3 3 
 at (6,9)
  + 9 delta pixels
diff: 
   (419.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,14) and color black and layers
  _0: rectangle with size (6,8) with mask 
. . . 0 0 0 . 0 
. . . 0 . 0 0 0 
. . . 0 0 0 0 0 
0 0 0 0 . 0 0 0 
0 0 0 . . . . . 
0 . 0 . . . . . 
 with color green at (7,0)
  _010: rectangle with size (5,5) with model Full with color green at (0,6)
  _01: rectangle with size (4,5) with model Full with color green at (6,9)
  + 24 delta pixels
diff: 
! 28 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,14) and color black and layers
  _0: rectangle with size (5,5) with model Full with color green at (0,6)
  _010: rectangle with size (6,8) with mask 
. . . 0 0 0 . 0 
. . . 0 . 0 0 0 
. . . 0 0 0 0 0 
0 0 0 0 . 0 0 0 
0 0 0 . . . . . 
0 . 0 . . . . . 
 with color green at (7,0)
  _01: rectangle with size (4,5) with model Full with color green at (6,9)
  + 24 delta pixels
diff: 
! 13 wrong pixels (generated / expected)

TRAIN 7e0986d6.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (13,16) and color black and layers
  _0: rectangle with size (4,10) with model Full with color red at (9,3)
  _010: rectangle with size (5,7) with model Full with color red at (2,9)
  _01: rectangle with size (5,4) with model Full with color red at (1,1)
  + 12 delta pixels
diff: 
   (0.0 bits)
data: a background with size (13,16) and color black and layers
  _0: rectangle with size (4,10) with model Full with color red at (9,3)
  _01: 
2 2 2 2 2 2 2 
2 2 2 2 2 2 2 
2 2 2 2 2 2 2 
2 2 2 2 2 2 2 
2 2 2 2 2 2 2 
 at (2,9)
  _011: 
2 2 2 2 
2 2 2 2 
2 2 2 2 
2 2 2 2 
2 2 2 2 
 at (1,1)
diff: 
   (2.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,16) and color black and layers
  _0: rectangle with size (4,10) with model Full with color red at (9,3)
  _010: rectangle with size (5,7) with model Full with color red at (2,9)
  _01: rectangle with size (5,4) with model Full with color red at (1,1)
  + 12 delta pixels
diff: 
correct output grid

TRAIN 7e0986d6.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,17) and color black and layers
  _0: rectangle with size (6,8) with model Full with color grey at (2,1)
  _010: rectangle with size (7,4) with model Full with color grey at (0,12)
  _01: rectangle with size (2,6) with model Full with color grey at (10,6)
  + 13 delta pixels
diff: 
correct output grid

TEST 7e0986d6.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 13.5 sec (13.5 sec/task)
bits-train-error = 4225.6 bits (4225.6 bits/task)
acc-train-micro = 0.50 tasks (50.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.50
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-208] Checking task 7f4411dc.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 206836.2 = 206838.5
DL output with Mo: L = 2.3 + 206836.2 = 206838.5
DL input+output M: L = 4.6 + 413672.3 = 413677.0

# learning a model for train pairs
2.000	
1.169	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.381	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.300	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.222	OUT ADD ^.layer_0 = ^.layer_0
0.219	OUT SPE ^.size = ^.size
0.219	IN  SPE ^.layer_0.shape.mask.model = Full
0.216	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.212	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.209	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.162	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.139	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.139	IN  SPE ^.color = black
0.139	OUT SPE ^.color = black
0.084	
0.084	IN  DEL ^.layer_011111
0.084	IN  DEL ^.layer_01111
0.084	IN  DEL ^.layer_0111
0.084	IN  DEL ^.layer_011
0.084	IN  DEL ^.layer_01
0.084	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 152.1 + 11229.4 = 11381.6
DL output with Mo: L = 15.6 + 17280.7 = 17296.3
DL input+output M: L = 167.7 + 28510.1 = 28677.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 42.5 + 0.0 = 42.5
DL output with Mo: L = 15.6 + 17280.7 = 17296.3
DL input+output M: L = 58.1 + 17280.7 = 17338.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,5) with model Full with color orange at (0,8)
  + 24 delta pixels
diff: 
   (0.0 bits)
data: a background with size (13,13) and color black and layers
  _0: 
7#7#7#7#7#
7#7#7#7#7#
7#7#7#7#7#
 at (0,8)
  + 18 delta pixels
diff: 
   (733.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,5) with model Full with color orange at (0,8)
  + 24 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,4) with model Full with color orange at (3,2)
  + 27 delta pixels
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (4,4) with model Full with color orange at (2,2)
  + 29 delta pixels
diff: 
! 25 wrong pixels (generated / expected)

TRAIN 7f4411dc.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (17,17) and color black and layers
  _0: rectangle with size (3,5) with model Full with color pink at (10,9)
  + 35 delta pixels
diff: 
   (0.0 bits)
data: a background with size (17,17) and color black and layers
  _0: 
6 6 6 6 6 
6 6 6 6 6 
6 6 6 6 6 
 at (10,9)
  + 24 delta pixels
diff: 
   (994.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (3,5) with model Full with color pink at (10,9)
  + 35 delta pixels
diff: 
! 24 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (3,4) with model Full with color pink at (5,3)
  + 38 delta pixels
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (4,5) with model Full with color pink at (9,9)
  + 38 delta pixels
diff: 
! 29 wrong pixels (generated / expected)

TRAIN 7f4411dc.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (7,7) and color black and layers
  _0: rectangle with size (3,4) with model Full with color grey at (2,1)
  + 5 delta pixels
diff: 
   (0.0 bits)
data: a background with size (7,7) and color black and layers
  _0: 
5#5#5#5#
5#5#5#5#
5#5#5#5#
 at (2,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (3,4) with model Full with color grey at (2,1)
  + 5 delta pixels
diff: 
correct output grid

TRAIN 7f4411dc.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,5) with model Full with color cyan at (5,4)
  + 16 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,6) with model Full with color cyan at (5,4)
  + 17 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with model Full with color cyan at (2,1)
  + 25 delta pixels
diff: 
! 15 wrong pixels (generated / expected)

TEST 7f4411dc.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 4.8 sec (4.8 sec/task)
bits-train-error = 17280.7 bits (17280.7 bits/task)
acc-train-micro = 0.33 tasks (33.33%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.33
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-207] Checking task 7fe24cdd.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 10534.8 = 10537.1
DL output with Mo: L = 2.3 + 42126.8 = 42129.1
DL input+output M: L = 4.6 + 52661.6 = 52666.3

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = unfoldSym( [ id rotate90 ] [ rotate270 rotate180 ], ^)
0.649	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.480	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.377	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.340	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.332	IN  SPE ^.layer_0.shape.mask.model = Full
0.324	IN  SPE ^.layer_01.shape.mask.model = Full
0.316	IN  SPE ^.layer_011.shape.mask.model = Full
0.010	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
unfoldSym( [ id rotate90 ] [ rotate270 rotate180 ], ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 99.6 + 3228.8 = 3328.5
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 110.9 + 3228.8 = 3339.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
unfoldSym( [ id rotate90 ] [ rotate270 rotate180 ], ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 13.6 + 0.0 = 13.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
8 5#0 
8 5#3 
0 3 2 

diff: 
   (0.0 bits)
data: 
8 5#0 0 8 8 
8 5#3 3 5#5#
0 3 2 2 3 0 
0 3 2 2 3 0 
5#5#3 3 5#8 
8 8 0 0 5#8 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 5#0 
8 5#3 
0 3 2 

diff: 
correct output grid

TRAIN 7fe24cdd.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
3 8 2 
3 2 2 
8 5#2 

diff: 
   (0.0 bits)
data: 
3 8 2 8 3 3 
3 2 2 5#2 8 
8 5#2 2 2 2 
2 2 2 2 5#8 
8 2 5#2 2 3 
3 3 8 2 8 3 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 8 2 
3 2 2 
8 5#2 

diff: 
correct output grid

TRAIN 7fe24cdd.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 3 0 
6 6 6 
0 3 0 

diff: 
   (0.0 bits)
data: 
0 3 0 0 6 0 
6 6 6 3 6 3 
0 3 0 0 6 0 
0 6 0 0 3 0 
3 6 3 6 6 6 
0 6 0 0 3 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 3 0 
6 6 6 
0 3 0 

diff: 
correct output grid

TRAIN 7fe24cdd.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 5#0 
2 5#1 
3 1 1 

diff: 
correct output grid

TEST 7fe24cdd.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.5 sec (1.5 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-206] Checking task 80af3007.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 356046.5 = 356048.8
DL output with Mo: L = 2.3 + 96473.4 = 96475.7
DL input+output M: L = 4.6 + 452519.9 = 452524.6

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = compose(grey, strip(^) / '3, strip(^) / '3)
0.180	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.013	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.012	IN  SPE ^.layer_0.shape.color = grey
0.012	IN  SPE ^.color = black
0.001	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
compose(grey, strip(^) / '3, strip(^) / '3)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)

DL input  with Mi: L = 45.4 + 3983.2 = 4028.6
DL output with Mo: L = 60.8 + 0.0 = 60.8
DL input+output M: L = 106.2 + 3983.2 = 4089.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
compose(grey, strip(^) / '3, strip(^) / '3)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 60.8 + 0.0 = 60.8
DL input+output M: L = 63.1 + 0.0 = 63.1

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 0 0 
0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 0 0 
0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 0 0 
0 0 0 0 5#5#5#0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 5#5#5#0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 5#5#5#0 0 0 0 0 0 0 0 0 0 0 
0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 0 0 
0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 0 0 
0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
5#0 5#0 0 0 5#0 5#
0 5#0 0 0 0 0 5#0 
5#0 5#0 0 0 5#0 5#
0 0 0 5#0 5#0 0 0 
0 0 0 0 5#0 0 0 0 
0 0 0 5#0 5#0 0 0 
5#0 5#0 0 0 5#0 5#
0 5#0 0 0 0 0 5#0 
5#0 5#0 0 0 5#0 5#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 0 0 
0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 0 0 
0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 0 0 
0 0 0 0 5#5#5#0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 5#5#5#0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 5#5#5#0 0 0 0 0 0 0 0 0 0 0 
0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 0 0 
0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 0 0 
0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 80af3007.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 
0 0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 
0 0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 5#5#5#0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 5#5#5#0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 5#5#5#0 0 
0 0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 
0 0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 
0 0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
5#5#0 5#5#0 0 0 0 
0 0 5#0 0 5#0 0 0 
5#5#0 5#5#0 0 0 0 
0 0 0 0 0 0 5#5#0 
0 0 0 0 0 0 0 0 5#
0 0 0 0 0 0 5#5#0 
5#5#0 5#5#0 0 0 0 
0 0 5#0 0 5#0 0 0 
5#5#0 5#5#0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 
0 0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 
0 0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 5#5#5#0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 5#5#5#0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 5#5#5#0 0 
0 0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 
0 0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 
0 0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 80af3007.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 5#5#5#5#5#5#5#5#5#0 0 0 0 0 0 
0 0 0 5#5#5#5#5#5#5#5#5#0 0 0 0 0 0 
0 0 0 5#5#5#5#5#5#5#5#5#0 0 0 0 0 0 
0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 0 
0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 0 
0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 0 
0 0 0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 
0 0 0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 
0 0 0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
5#5#5#5#5#5#5#5#5#
0 5#5#0 5#5#0 5#5#
5#0 5#5#0 5#5#0 5#
0 0 0 5#5#5#5#5#5#
0 0 0 0 5#5#0 5#5#
0 0 0 5#0 5#5#0 5#
5#5#5#0 0 0 5#5#5#
0 5#5#0 0 0 0 5#5#
5#0 5#0 0 0 5#0 5#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 5#5#5#5#5#5#5#5#5#0 0 0 0 0 0 
0 0 0 5#5#5#5#5#5#5#5#5#0 0 0 0 0 0 
0 0 0 5#5#5#5#5#5#5#5#5#0 0 0 0 0 0 
0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 0 
0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 0 
0 0 0 0 0 0 5#5#5#5#5#5#0 0 0 0 0 0 
0 0 0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 
0 0 0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 
0 0 0 5#5#5#0 0 0 5#5#5#0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 80af3007.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 5#5#5#5#5#5#5#5#5#0 0 0 
0 0 0 0 0 0 0 5#5#5#5#5#5#5#5#5#0 0 0 
0 0 0 0 0 0 0 5#5#5#5#5#5#5#5#5#0 0 0 
0 0 0 0 0 0 0 0 0 0 5#5#5#0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 5#5#5#0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 5#5#5#0 0 0 0 0 0 
0 0 0 0 0 0 0 5#5#5#0 0 0 5#5#5#0 0 0 
0 0 0 0 0 0 0 5#5#5#0 0 0 5#5#5#0 0 0 
0 0 0 0 0 0 0 5#5#5#0 0 0 5#5#5#0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TEST 80af3007.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 2.1 sec (2.1 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-205] Checking task 810b9b61.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 216170.8 = 216173.1
DL output with Mo: L = 2.3 + 216170.8 = 216173.1
DL input+output M: L = 4.6 + 432341.5 = 432346.2

# learning a model for train pairs
2.000	
1.179	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.357	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.301	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.245	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.209	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.173	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.151	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.129	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.112	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.095	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.090	OUT SPE ^.layer_0 = coloring(^.layer_0, green)
0.087	OUT SPE ^.size = ^.size
0.085	OUT SPE ^.layer_01.shape.mask = ^.layer_01.shape.mask
0.083	OUT SPE ^.layer_011.shape.mask = ^.layer_011.shape.mask
0.081	OUT SPE ^.layer_0111.shape.mask = ^.layer_0111.shape.mask
0.079	OUT SPE ^.layer_0111.pos = ^.layer_0111.pos
0.077	OUT SPE ^.layer_011.pos = ^.layer_011.pos
0.076	OUT SPE ^.layer_01.pos = ^.layer_01.pos
0.075	IN  SPE ^.layer_0.shape.mask.model = Border
0.074	IN  SPE ^.layer_0.shape.color = blue
0.073	IN  SPE ^.layer_01.shape.color = blue
0.072	IN  SPE ^.layer_011.shape.color = blue
0.072	IN  SPE ^.layer_0111.shape.color = blue
0.071	IN  SPE ^.color = black
0.071	OUT SPE ^.color = black
0.028	
0.028	IN  GEN ^.layer_0111.shape.color = ?
0.028	IN  GEN ^.layer_011.shape.color = ?
0.028	IN  GEN ^.layer_01.shape.color = ?
0.028	IN  GEN ^.layer_0.shape.color = ?
0.028	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, green)
  _01: ^.layer_01.shape.mask with color ? at ^.layer_01.pos
  _011: ^.layer_011.shape.mask with color ? at ^.layer_011.pos
  _0111: ^.layer_0111.shape.mask with color ? at ^.layer_0111.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Border with color blue at (?,?)
  _01: rectangle with size (?,?) with model ? with color blue at (?,?)
  _011: rectangle with size (?,?) with model ? with color blue at (?,?)
  _0111: rectangle with size (?,?) with model ? with color blue at (?,?)

DL input  with Mi: L = 142.5 + 9268.0 = 9410.5
DL output with Mo: L = 71.1 + 5872.7 = 5943.8
DL input+output M: L = 213.6 + 15140.8 = 15354.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, green)
  _01: ^.layer_01.shape.mask with color ? at ^.layer_01.pos
  _011: ^.layer_011.shape.mask with color ? at ^.layer_011.pos
  _0111: ^.layer_0111.shape.mask with color ? at ^.layer_0111.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model Border with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 129.1 + 0.0 = 129.1
DL output with Mo: L = 71.1 + 5872.7 = 5943.8
DL input+output M: L = 200.2 + 5872.7 = 6072.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (4,4) with model Border with color blue at (7,6)
  _01: rectangle with size (3,4) with model Border with color blue at (2,2)
  _011: rectangle with size (4,3) with model Border with color blue at (10,0)
  _0111: rectangle with size (3,4) with model Border with color blue at (12,10)
  + 13 delta pixels
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: 
3 3 3 3 
3 . . 3 
3 . . 3 
3 3 3 3 
 at (7,6)
  _01: 
0 0 0 0 
0 . . 0 
0 0 0 0 
 with color green at (2,2)
  _011: 
0 0 0 
0 . 0 
0 . 0 
0 0 0 
 with color green at (10,0)
  _0111: 
0 0 0 0 
0 . . 0 
0 0 0 0 
 with color green at (12,10)
  + 13 delta pixels
diff: 
   (553.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (4,4) with model Border with color blue at (7,6)
  _01: rectangle with size (3,4) with model Border with color blue at (2,2)
  _011: rectangle with size (4,3) with model Border with color blue at (10,0)
  _0111: rectangle with size (3,4) with model Border with color blue at (12,10)
  + 13 delta pixels
diff: 
! 43 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (3,4) with model Border with color blue at (2,2)
  _01: rectangle with size (4,4) with model Border with color blue at (7,6)
  _011: rectangle with size (4,3) with model Border with color blue at (10,0)
  _0111: rectangle with size (3,4) with model Border with color blue at (12,10)
  + 13 delta pixels
diff: 
! 45 wrong pixels (generated / expected)

TRAIN 810b9b61.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (3,3) with model Border with color blue at (3,4)
  _01: rectangle with size (3,4) with mask 
0 . 0 0 
0 . . 0 
0 0 0 0 
 with color blue at (8,9)
  _011: rectangle with size (2,1) with model Full with color blue at (3,10)
  _0111: rectangle with size (1,1) with model Full with color blue at (8,4)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: 
3 3 3 
3 . 3 
3 3 3 
 at (3,4)
  _01: 
0 . 0 0 
0 . . 0 
0 0 0 0 
 with color blue at (8,9)
  _011: 
0 
0 
 with color blue at (3,10)
  _0111: 
0 
 with color blue at (8,4)
diff: 
   (16.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (3,3) with model Border with color blue at (3,4)
  _01: rectangle with size (3,4) with mask 
0 . 0 0 
0 . . 0 
0 0 0 0 
 with color blue at (8,9)
  _011: rectangle with size (2,1) with model Full with color blue at (3,10)
  _0111: rectangle with size (1,1) with model Full with color blue at (8,4)
diff: 
! 12 wrong pixels (generated / expected)

TRAIN 810b9b61.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: rectangle with size (3,5) with model Border with color blue at (2,1)
  _01: rectangle with size (3,1) with model Full with color blue at (6,1)
  _011: rectangle with size (1,2) with model Full with color blue at (7,4)
  _0111: rectangle with size (1,2) with model Full with color blue at (6,0)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: 
3 3 3 3 3 
3 . . . 3 
3 3 3 3 3 
 at (2,1)
  _01: 
0 
0 
0 
 with color blue at (6,1)
  _011: 
0 0 
 with color blue at (7,4)
  _0111: 
0 0 
 with color blue at (6,0)
diff: 
   (16.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (3,5) with model Border with color blue at (2,1)
  _01: rectangle with size (3,1) with model Full with color blue at (6,1)
  _011: rectangle with size (1,2) with model Full with color blue at (7,4)
  _0111: rectangle with size (1,2) with model Full with color blue at (6,0)
diff: 
! 6 wrong pixels (generated / expected)

TRAIN 810b9b61.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (4,5) with model Border with color blue at (7,4)
  _01: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 . . . 0 
0 . . . 0 
0 . . . 0 
0 0 . 0 0 
 with color blue at (0,7)
  _011: rectangle with size (3,4) with model Border with color blue at (1,1)
  _0111: rectangle with size (1,2) with model Full with color blue at (6,1)
  + 2 delta pixels
diff: 
! 29 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (3,4) with model Border with color blue at (1,1)
  _01: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 . . . 0 
0 . . . 0 
0 . . . 0 
0 0 . 0 0 
 with color blue at (0,7)
  _011: rectangle with size (4,5) with model Border with color blue at (7,4)
  _0111: rectangle with size (1,2) with model Full with color blue at (6,1)
  + 2 delta pixels
diff: 
! 33 wrong pixels (generated / expected)

TEST 810b9b61.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 30.4 sec (30.4 sec/task)
bits-train-error = 5872.7 bits (5872.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-204] Checking task 82819916.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 120610.3 = 120612.6
DL output with Mo: L = 2.3 + 120610.3 = 120612.6
DL input+output M: L = 4.6 + 241220.6 = 241225.3

# learning a model for train pairs
2.000	
1.182	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.504	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.456	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.397	OUT ADD ^.layer_0 = ^.layer_0
0.349	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.304	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.281	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.262	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.245	OUT ADD ^.layer_010 = ^.layer_01
0.231	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.221	OUT ADD ^.layer_0110 = ^.layer_011
0.210	IN  ADD ^.layer_0110 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.203	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.193	OUT ADD ^.layer_01101 = ^.layer_0110
0.188	OUT ADD ^.layer_01110 = point with color ? at (?,?)
0.182	OUT SPE ^.size = ^.size
0.180	OUT SPE ^.layer_01110.pos.i = ^.layer_0111.pos.i
0.179	OUT SPE ^.layer_011.pos.i = ^.layer_011.pos.i
0.178	OUT SPE ^.layer_01.shape.mask.size.i = 1
0.177	OUT SPE ^.layer_011.shape.mask.size.i = 1
0.175	OUT SPE ^.layer_0111.shape.mask.size.i = 1
0.174	OUT SPE ^.layer_01.pos.j = right(^.layer_011) + 1
0.173	IN  SPE ^.layer_0.shape.mask.model = Full
0.172	IN  SPE ^.layer_01.shape.mask.model = Full
0.171	IN  SPE ^.layer_0110.shape.mask.model = Full
0.170	IN  SPE ^.layer_011.shape.mask.model = Full
0.169	OUT SPE ^.layer_011.pos.j = right(^.layer_0) - ^.layer_0110.pos.i - ^.layer_01.pos.i
0.168	OUT SPE ^.layer_01.shape.mask.model = Full
0.167	OUT SPE ^.layer_011.shape.mask.model = Full
0.087	
0.087	IN  GEN ^.layer_011.shape.mask.model = ?
0.087	IN  GEN ^.layer_0110.shape.mask.model = ?
0.087	IN  GEN ^.layer_01.shape.mask.model = ?
0.087	IN  GEN ^.layer_0.shape.mask.model = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: ^.layer_0
  _010: ^.layer_01
  _01: rectangle with size (1,?) with model Full with color ? at (?,right(^.layer_011) + 1)
  _0110: ^.layer_011
  _01101: ^.layer_0110
  _011: rectangle with size (1,?) with model Full with color ? at (^.layer_011.pos.i,right(^.layer_0) - ^.layer_0110.pos.i - ^.layer_01.pos.i)
  _01110: point with color ? at (^.layer_0111.pos.i,?)
  _0111: rectangle with size (1,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0110: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 145.6 + 9785.1 = 9930.7
DL output with Mo: L = 230.0 + 10005.0 = 10235.0
DL input+output M: L = 375.6 + 19790.1 = 20165.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: ^.layer_0
  _010: ^.layer_01
  _01: rectangle with size (1,?) with model Full with color ? at (?,right(^.layer_011) + 1)
  _0110: ^.layer_011
  _01101: ^.layer_0110
  _011: rectangle with size (1,?) with model Full with color ? at (^.layer_011.pos.i,right(^.layer_0) - ^.layer_0110.pos.i - ^.layer_01.pos.i)
  _01110: point with color ? at (^.layer_0111.pos.i,?)
  _0111: rectangle with size (1,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 143.6 + 91.7 = 235.3
DL output with Mo: L = 230.0 + 10005.0 = 10235.0
DL input+output M: L = 373.5 + 10096.7 = 10470.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,8) and color black and layers
  _0: rectangle with size (1,8) with model Full with color green at (1,0)
  _01: rectangle with size (1,2) with model Full with color cyan at (4,0)
  _0110: rectangle with size (1,2) with model Full with color blue at (6,0)
  _011: rectangle with size (1,1) with model Full with color pink at (6,2)
  _0111: point with color yellow at (4,2)
  + 2 delta pixels
diff: 
   (2.0 bits)
data: a background with size (10,8) and color black and layers
  _0: 
3 3 3 3 3 3 3 3 
 at (1,0)
  _010: 
8 8 
 at (4,0)
  _01: rectangle with size (1,5) with model Full with color cyan at (4,3)
  _0110: 
6 
 at (6,2)
  _01101: 
1 1 
 at (6,0)
  _011: rectangle with size (1,1) with model Full with color pink at (6,5)
  _01110: point with color yellow at (4,2)
  _0111: rectangle with size (1,5) with model Full with color blue at (6,3)
  + 3 delta pixels
diff: 
   (190.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,8) and color black and layers
  _0: rectangle with size (1,8) with model Full with color green at (1,0)
  _01: rectangle with size (1,2) with model Full with color cyan at (4,0)
  _0110: rectangle with size (1,2) with model Full with color blue at (6,0)
  _011: rectangle with size (1,1) with model Full with color yellow at (4,2)
  _0111: point with color pink at (6,2)
  + 2 delta pixels
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,8) and color black and layers
  _0: rectangle with size (1,8) with model Full with color green at (1,0)
  _01: rectangle with size (1,2) with model Full with color cyan at (4,0)
  _0110: rectangle with size (1,2) with model Full with color blue at (6,0)
  _011: rectangle with size (1,1) with model Full with color pink at (6,2)
  _0111: point with color yellow at (4,2)
  + 2 delta pixels
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,8) and color black and layers
  _0: rectangle with size (1,8) with model Full with color green at (1,0)
  _01: rectangle with size (1,2) with model Full with color cyan at (4,0)
  _0110: rectangle with size (1,1) with model Full with color yellow at (4,2)
  _011: rectangle with size (1,2) with model Full with color blue at (6,0)
  _0111: point with color pink at (6,2)
  + 2 delta pixels
diff: 
! 17 wrong pixels (generated / expected)

TRAIN 82819916.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,8) and color black and layers
  _0: rectangle with size (1,6) with model Full with color red at (1,0)
  _01: rectangle with size (1,2) with model Full with color blue at (1,6)
  _0110: rectangle with size (1,2) with model Full with color green at (3,0)
  _011: rectangle with size (1,2) with model Full with color cyan at (7,0)
  _0111: point with color red at (7,2)
  + 3 delta pixels
diff: 
   (2.0 bits)
data: a background with size (10,8) and color black and layers
  _0: 
2 2 2 2 2 2 
 at (1,0)
  _010: 
1 1 
 at (1,6)
  _01: rectangle with size (1,6) with model Full with color blue at (3,2)
  _0110: 
8 8 
 at (7,0)
  _01101: 
3 3 
 at (3,0)
  _011: rectangle with size (1,1) with model Full with color cyan at (7,3)
  _01110: point with color cyan at (7,5)
  _0111: rectangle with size (1,6) with model Full with color red at (7,2)
  + 4 delta pixels
diff: 
   (231.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,8) and color black and layers
  _0: rectangle with size (1,6) with model Full with color red at (1,0)
  _01: rectangle with size (1,2) with model Full with color blue at (1,6)
  _0110: rectangle with size (1,2) with model Full with color green at (3,0)
  _011: rectangle with size (1,2) with model Full with color cyan at (7,0)
  _0111: point with color blue at (3,2)
  + 3 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,8) and color black and layers
  _0: rectangle with size (1,6) with model Full with color red at (1,0)
  _01: rectangle with size (1,2) with model Full with color blue at (1,6)
  _0110: rectangle with size (1,2) with model Full with color cyan at (7,0)
  _011: rectangle with size (1,2) with model Full with color green at (3,0)
  _0111: point with color blue at (3,2)
  + 3 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TRAIN 82819916.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (12,8) and color black and layers
  _0: rectangle with size (1,2) with model Full with color yellow at (1,3)
  _01: rectangle with size (1,8) with model Full with color blue at (1,0)
  _0110: rectangle with size (1,1) with model Full with color red at (4,0)
  _011: rectangle with size (1,1) with model Full with color cyan at (6,0)
  _0111: point with color green at (4,1)
  + 5 delta pixels
diff: 
   (3.2 bits)
data: a background with size (12,8) and color black and layers
  _0: 
4 4 
 at (1,3)
  _010: 
1 1 1 1 1 1 1 1 
 at (1,0)
  _01: rectangle with size (1,6) with model Full with color green at (4,1)
  _0110: 
8 
 at (6,0)
  _01101: 
2 
 at (4,0)
  _011: rectangle with size (1,6) with model Full with color red at (6,1)
  _01110: point with color red at (4,7)
  _0111: rectangle with size (1,6) with model Full with color grey at (8,1)
  + 11 delta pixels
diff: 
   (517.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,8) and color black and layers
  _0: rectangle with size (1,2) with model Full with color yellow at (1,3)
  _01: rectangle with size (1,8) with model Full with color blue at (1,0)
  _0110: rectangle with size (1,1) with model Full with color red at (4,0)
  _011: rectangle with size (1,1) with model Full with color green at (4,1)
  _0111: point with color cyan at (6,0)
  + 5 delta pixels
diff: 
! 28 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,8) and color black and layers
  _0: rectangle with size (1,2) with model Full with color yellow at (1,3)
  _01: rectangle with size (1,8) with model Full with color blue at (1,0)
  _0110: rectangle with size (1,1) with model Full with color red at (4,0)
  _011: rectangle with size (1,1) with model Full with color cyan at (6,0)
  _0111: point with color green at (4,1)
  + 5 delta pixels
diff: 
! 27 wrong pixels (generated / expected)

TRAIN 82819916.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (6,8) and color black and layers
  _0: rectangle with size (1,1) with model Full with color green at (1,5)
  _01: rectangle with size (1,5) with model Full with color yellow at (1,2)
  _0110: rectangle with size (1,8) with model Full with color green at (1,0)
  _011: rectangle with size (1,2) with model Full with color cyan at (4,0)
  _0111: point with color red at (4,2)
diff: 
   (2.0 bits)
data: a background with size (6,8) and color black and layers
  _0: 
3 
 at (1,5)
  _010: 
4 4 4 4 4 
 at (1,2)
  _01: rectangle with size (1,3) with model Full with color red at (4,2)
  _0110: 
8 8 
 at (4,0)
  _01101: 
3 3 3 3 3 3 3 3 
 at (1,0)
  _011: rectangle with size (1,1) with model Full with color cyan at (4,5)
  _01110: point with color red at (4,6)
  _0111: rectangle with size (1,1) with model Full with color cyan at (4,7)
diff: 
   (61.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,8) and color black and layers
  _0: rectangle with size (1,3) with model Full with color yellow at (1,2)
  _01: rectangle with size (1,1) with model Full with color yellow at (1,6)
  _0110: rectangle with size (1,8) with model Full with color green at (1,0)
  _011: rectangle with size (1,2) with model Full with color cyan at (4,0)
  _0111: point with color red at (4,2)
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,8) and color black and layers
  _0: rectangle with size (1,1) with model Full with color green at (1,5)
  _01: rectangle with size (1,5) with model Full with color yellow at (1,2)
  _0110: rectangle with size (1,8) with model Full with color green at (1,0)
  _011: rectangle with size (1,2) with model Full with color cyan at (4,0)
  _0111: point with color red at (4,2)
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (6,8) and color black and layers
  _0: rectangle with size (1,5) with model Full with color yellow at (1,2)
  _01: rectangle with size (1,2) with model Full with color green at (1,0)
  _0110: rectangle with size (1,2) with model Full with color cyan at (4,0)
  _011: rectangle with size (1,1) with model Full with color green at (1,7)
  _0111: point with color red at (4,2)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 82819916.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,10) and color black and layers
  _0: rectangle with size (1,8) with model Full with color blue at (1,2)
  _01: rectangle with size (1,2) with model Full with color red at (1,0)
  _0110: rectangle with size (1,2) with model Full with color cyan at (3,0)
  _011: rectangle with size (1,2) with model Full with color blue at (6,0)
  _0111: point with color green at (3,2)
  + 10 delta pixels
diff: 
! 43 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,10) and color black and layers
  _0: rectangle with size (1,8) with model Full with color blue at (1,2)
  _01: rectangle with size (1,2) with model Full with color red at (1,0)
  _0110: rectangle with size (1,2) with model Full with color cyan at (3,0)
  _011: rectangle with size (1,2) with model Full with color pink at (9,0)
  _0111: point with color green at (3,2)
  + 10 delta pixels
diff: 
! 43 wrong pixels (generated / expected)

TEST 82819916.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.1 sec (59.1 sec/task)
bits-train-error = 10005.0 bits (10005.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-203] Checking task 83302e8f.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 751277.4 = 751279.7
DL output with Mo: L = 2.3 + 751277.4 = 751279.7
DL input+output M: L = 4.6 + 1502554.8 = 1502559.5

# learning a model for train pairs
2.000	
1.262	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.800	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.591	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.384	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.207	OUT ADD ^.layer_00 = ^.layer_0
0.135	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.109	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.088	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.033	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 41516.7 = 41558.7
DL output with Mo: L = 133.2 + 24693.7 = 24827.0
DL input+output M: L = 175.2 + 66210.5 = 66385.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 133.2 + 24693.7 = 24827.0
DL input+output M: L = 175.2 + 24693.7 = 24869.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (24,24) and color black and layers
  _0: rectangle with size (24,24) with mask 
. . . . 0 . . . . 0 . . . . 0 . . . . . . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . . . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . . . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . . . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . . . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . . . . . . 
. . . . . . . . . 0 . . . . 0 . . . . . . . . . 
. . . . . . . . . 0 . . . . 0 . . . . . . . . . 
. . . . . . . . . 0 0 0 0 . 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . 0 . . . . . . . . . 0 . . . . 
. . . . . . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . . . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . . . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . . . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
 with color cyan at (0,0)
  + 26 delta pixels
diff: 
   (0.0 bits)
data: a background with size (24,24) and color green and layers
  _00: 
. . . . 8 . . . . 8 . . . . 8 . . . . . . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . . . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . . . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . . . . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 . . . . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . . . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . . . . . . 
. . . . . . . . . 8 . . . . 8 . . . . . . . . . 
. . . . . . . . . 8 . . . . 8 . . . . . . . . . 
. . . . . . . . . 8 8 8 8 . 8 8 8 8 8 8 8 8 8 8 
. . . . . . . . . 8 . . . . . . . . . 8 . . . . 
. . . . . . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . . . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . . . . . . 8 . . . . 8 . . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . . . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
. . . . 8 . . . . 8 . . . . 8 . . . . 8 . . . . 
 at (0,0)
  _0: rectangle with size (9,19) with mask 
0 0 0 0 . 0 0 0 0 . 0 0 0 0 . . . . . 
0 0 0 0 . 0 0 0 0 . 0 0 0 0 . . . . . 
0 0 0 0 0 0 0 0 0 . 0 0 0 0 . . . . . 
0 0 0 0 . 0 0 0 0 . 0 0 0 0 . . . . . 
. . . . . . . . 0 . . . . 0 . . . . . 
0 0 0 0 . 0 0 0 0 . 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 . 0 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 0 . 0 0 0 0 . 0 0 0 0 
0 0 0 0 . 0 0 0 0 0 0 0 0 0 . 0 0 0 0 
 with color yellow at (5,0)
  _01: rectangle with size (9,9) with mask 
0 0 0 0 . . . . . 
0 0 0 0 . . . . . 
0 0 0 0 . . . . . 
0 0 0 0 . . . . . 
. . 0 . . . . . . 
0 0 0 0 . 0 0 0 0 
0 0 0 0 . 0 0 0 0 
0 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color yellow at (0,15)
  _011: rectangle with size (9,4) with model Full with color yellow at (10,20)
  _0111: rectangle with size (4,9) with model Full with color yellow at (15,5)
  + 26 delta pixels
diff: 
   (1532.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (24,24) and color black and layers
  _0: rectangle with size (24,24) with mask 
. . . . 0 . . . . 0 . . . . 0 . . . . . . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . . . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . . . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . . . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . . . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . . . . . . 
. . . . . . . . . 0 . . . . 0 . . . . . . . . . 
. . . . . . . . . 0 . . . . 0 . . . . . . . . . 
. . . . . . . . . 0 0 0 0 . 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . 0 . . . . . . . . . 0 . . . . 
. . . . . . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . . . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . . . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . . . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 0 . . . . 
 with color cyan at (0,0)
  + 26 delta pixels
diff: 
! size mismatch, 10x10 instead of 24x24
>> Trial 2
data: a background with size (24,24) and color black and layers
  _0: rectangle with size (1,24) with model Full with color cyan at (19,0)
  + 141 delta pixels
diff: 
! size mismatch, 10x10 instead of 24x24

TRAIN 83302e8f.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (29,29) and color black and layers
  _0: rectangle with size (29,29) with mask 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . . . . . . . 0 . . . . . 0 . . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . . . . . . . 0 . . . . . . . . . . . 0 . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . . . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 0 0 0 . 0 0 0 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
 with color blue at (0,0)
  + 18 delta pixels
diff: 
   (0.0 bits)
data: a background with size (29,29) and color yellow and layers
  _00: 
. . . . . 1 . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
. . . . . 1 . . . . . . . . . . . 1 . . . . . 1 . . . . . 
. . . . . . . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. . . . . . . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. . . . . . . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. . . . . . . . . . . 1 . . . . . . . . . . . 1 . . . . . 
. . . . . . . . . 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 . . . . . 
. . . . . . . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. . . . . . . . . . . . . . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . . . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 . 1 1 1 1 1 . 1 1 1 1 . . . . 
. . . . . 1 . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
. . . . . 1 . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
. . . . . 1 . . . . . 1 . . . . . 1 . . . . . 1 . . . . . 
 at (0,0)
  _0: rectangle with size (5,29) with model Full with color green at (0,0)
  _01: rectangle with size (5,23) with model Full with color green at (24,6)
  _011: rectangle with size (5,5) with model Full with color green at (18,6)
  _0111: rectangle with size (4,8) with mask 
. . . . . 0 . . 
. . . . . 0 . . 
0 0 0 0 0 0 0 0 
. . . . . 0 . . 
 with color blue at (9,0)
  + 7 delta pixels
diff: 
   (534.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (29,29) and color black and layers
  _0: rectangle with size (29,29) with mask 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . . . . . . . 0 . . . . . 0 . . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . . . . . . . 0 . . . . . . . . . . . 0 . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . . . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 0 0 0 . 0 0 0 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
 with color blue at (0,0)
  + 18 delta pixels
diff: 
! size mismatch, 10x10 instead of 29x29
>> Trial 2
data: a background with size (29,29) and color black and layers
  _0: rectangle with size (29,1) with model Full with color blue at (0,23)
  + 174 delta pixels
diff: 
! size mismatch, 10x10 instead of 29x29
>> Trial 3
data: a background with size (29,29) and color black and layers
  _0: rectangle with size (1,29) with model Full with color blue at (5,0)
  + 174 delta pixels
diff: 
! size mismatch, 10x10 instead of 29x29

TRAIN 83302e8f.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (19,19) and color black and layers
  _0: rectangle with size (19,19) with mask 
. . . . . . . . . . . . . . 0 . . . . 
. . . . . . . . . . . . . . 0 . . . . 
. . . . . . . . . . . . . . 0 . . . . 
. . . . . . . . . 0 . . . . 0 . . . . 
. . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . 0 . . . . 0 . . . . 
. . . . . . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 . 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 
. . . . 0 . . . . 0 . . . . . . . . . 
. . . . 0 . . . . 0 . . . . . . . . . 
. . . . . . . . . 0 . . . . . . . . . 
. . . . . . . . . 0 . . . . . . . . . 
 with color brown at (0,0)
  + 16 delta pixels
diff: 
   (0.0 bits)
data: a background with size (19,19) and color yellow and layers
  _00: 
. . . . . . . . . . . . . . 9#. . . . 
. . . . . . . . . . . . . . 9#. . . . 
. . . . . . . . . . . . . . 9#. . . . 
. . . . . . . . . 9#. . . . 9#. . . . 
. . . . . . . . 9#9#9#9#9#9#9#9#9#9#9#
. . . . . . . . . 9#. . . . 9#. . . . 
. . . . . . . . . 9#. . . . 9#. . . . 
. . . . 9#. . . . 9#. . . . 9#. . . . 
. . . . 9#. . . . 9#. . . . 9#. . . . 
9#9#9#9#9#9#9#9#9#9#. 9#9#9#9#9#9#9#9#
. . . . 9#. . . . 9#. . . . 9#. . . . 
. . . . 9#. . . . 9#. . . . 9#. . . . 
. . . . 9#. . . . 9#. . . . 9#. . . . 
. . . . 9#. . . . 9#. . . . 9#. . . . 
9#9#9#9#9#9#9#9#9#9#9#9#9#9#9#9#9#9#. 
. . . . 9#. . . . 9#. . . . . . . . . 
. . . . 9#. . . . 9#. . . . . . . . . 
. . . . . . . . . 9#. . . . . . . . . 
. . . . . . . . . 9#. . . . . . . . . 
 at (0,0)
  _0: rectangle with size (9,4) with model Full with color green at (0,15)
  _01: rectangle with size (4,9) with model Full with color green at (10,0)
  _011: rectangle with size (2,7) with mask 
0 0 0 0 0 0 0 
. . . . 0 . . 
 with color brown at (4,0)
  _0111: rectangle with size (3,1) with model Full with color brown at (16,14)
  + 5 delta pixels
diff: 
   (402.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,19) and color black and layers
  _0: rectangle with size (19,19) with mask 
. . . . . . . . . . . . . . 0 . . . . 
. . . . . . . . . . . . . . 0 . . . . 
. . . . . . . . . . . . . . 0 . . . . 
. . . . . . . . . 0 . . . . 0 . . . . 
. . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . 0 . . . . 0 . . . . 
. . . . . . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 . 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 
. . . . 0 . . . . 0 . . . . . . . . . 
. . . . 0 . . . . 0 . . . . . . . . . 
. . . . . . . . . 0 . . . . . . . . . 
. . . . . . . . . 0 . . . . . . . . . 
 with color brown at (0,0)
  + 16 delta pixels
diff: 
! size mismatch, 10x10 instead of 19x19
>> Trial 2
data: a background with size (19,19) and color black and layers
  _0: rectangle with size (1,18) with model Full with color brown at (14,0)
  + 78 delta pixels
diff: 
! size mismatch, 10x10 instead of 19x19
>> Trial 3
data: a background with size (19,19) and color black and layers
  _0: rectangle with size (19,1) with model Full with color brown at (0,9)
  + 79 delta pixels
diff: 
! size mismatch, 10x10 instead of 19x19

TRAIN 83302e8f.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (27,27) and color black and layers
  _0: rectangle with size (26,27) with mask 
. . . . . . . . . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . . . . . . . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . . . . . . . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 
. . . . . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . . . . . . . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . . . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 . . 0 0 0 . 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . 0 . . . . . . . 0 . . . . . . . 0 . . . 
. . . . . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . . . . . 0 . . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 0 0 
. . . 0 . . . 0 . . . 0 . . . . . . . . . . . 0 . . . 
. . . 0 . . . 0 . . . 0 . . . . . . . . . . . . . . . 
. . . 0 . . . 0 . . . . . . . 0 . . . . . . . . . . . 
0 0 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 . . . . . . . . . 
. . . 0 . . . 0 . . . . . . . 0 . . . . . . . . . . . 
. . . . . . . 0 . . . . . . . 0 . . . . . . . . . . . 
 with color grey at (0,0)
  + 32 delta pixels
diff: 
! size mismatch, 10x10 instead of 27x27
>> Trial 2
data: a background with size (27,27) and color black and layers
  _0: rectangle with size (1,27) with model Full with color grey at (7,0)
  + 230 delta pixels
diff: 
! size mismatch, 10x10 instead of 27x27
>> Trial 3
data: a background with size (27,27) and color black and layers
  _0: rectangle with size (1,27) with model Full with color grey at (19,0)
  + 230 delta pixels
diff: 
! size mismatch, 10x10 instead of 27x27

TEST 83302e8f.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.7 sec (59.7 sec/task)
bits-train-error = 24693.7 bits (24693.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-202] Checking task 834ec97d.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 45374.2 = 45376.5
DL output with Mo: L = 2.3 + 45374.2 = 45376.5
DL input+output M: L = 4.6 + 90748.4 = 90753.0

# learning a model for train pairs
2.000	
1.039	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.379	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.321	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.263	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.247	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.236	OUT SPE ^.size = ^.size
0.230	OUT SPE ^.layer_0.pos = projJ(^.layer_0.pos)
0.226	OUT SPE ^.layer_0.shape.color = yellow
0.224	OUT SPE ^.layer_0.shape.mask.size.j = 1
0.222	OUT SPE ^.layer_01.shape.mask.size.j = 1
0.220	OUT SPE ^.layer_0.shape.mask.model = Full
0.218	OUT SPE ^.layer_01.shape.mask.model = Full
0.216	IN  SPE ^.color = black
0.215	OUT SPE ^.color = black
0.194	
0.194	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,1) with model Full with color yellow at projJ(^.layer_0.pos)
  _01: rectangle with size (?,1) with model Full with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.3 + 932.1 = 964.4
DL output with Mo: L = 75.7 + 8709.2 = 8785.0
DL input+output M: L = 108.0 + 9641.4 = 9749.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,1) with model Full with color yellow at projJ(^.layer_0.pos)
  _01: rectangle with size (?,1) with model Full with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 0.0 = 32.2
DL output with Mo: L = 75.7 + 8709.2 = 8785.0
DL input+output M: L = 107.9 + 8709.2 = 8817.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: point with color red at (0,1)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color yellow at (0,1)
  _01: rectangle with size (1,1) with model Full with color red at (1,1)
diff: 
   (20.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: point with color red at (0,1)
diff: 
! 3 wrong pixels (generated / expected)

TRAIN 834ec97d.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (5,5) and color black and layers
  _0: point with color pink at (2,2)
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (3,1) with model Full with color yellow at (0,2)
  _01: rectangle with size (3,1) with model Full with color yellow at (0,0)
  + 4 delta pixels
diff: 
   (182.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color black and layers
  _0: point with color pink at (2,2)
diff: 
! 8 wrong pixels (generated / expected)

TRAIN 834ec97d.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: point with color brown at (4,2)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (5,1) with model Full with color yellow at (0,2)
  _01: rectangle with size (5,1) with model Full with color yellow at (0,0)
  + 16 delta pixels
diff: 
   (668.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color brown at (4,2)
diff: 
! 24 wrong pixels (generated / expected)

TRAIN 834ec97d.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: point with color green at (3,5)
diff: 
! 25 wrong pixels (generated / expected)

TEST 834ec97d.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 1.7 sec (1.7 sec/task)
bits-train-error = 8709.2 bits (8709.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-201] Checking task 8403a5d5.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.016	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.404	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.301	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.220	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.138	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.109	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.079	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.073	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.068	OUT SPE ^.layer_0.shape = scaleTo(^.layer_0.shape, projI(^.size) + (0, 1))
0.063	OUT SPE ^.layer_01.shape = scaleTo(^.layer_0.shape, projI(^.size) + (0, 1))
0.057	OUT SPE ^.layer_011.shape = scaleTo(^.layer_0.shape, projI(^.size) + (0, 1))
0.052	OUT SPE ^.size = ^.size
0.050	OUT SPE ^.layer_0.pos = projJ(^.layer_0.pos)
0.047	OUT SPE ^.layer_01.pos = projJ(^.layer_0.pos) + (0, 2)
0.045	OUT SPE ^.layer_011.pos.i = '0
0.044	OUT SPE ^.layer_0111.pos.i = '0
0.043	OUT SPE ^.layer_011.pos.j = center(^.layer_0) + 3
0.042	OUT SPE ^.layer_0111.shape.mask.size.j = 1
0.041	OUT SPE ^.layer_01111.shape.mask.size.j = 1
0.041	OUT SPE ^.layer_0111.shape.mask.model = Full
0.040	OUT SPE ^.layer_01111.shape.mask.model = Full
0.039	IN  SPE ^.color = black
0.039	OUT SPE ^.color = black
0.029	
0.029	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: scaleTo(^.layer_0.shape, projI(^.size) + (0, 1)) at projJ(^.layer_0.pos)
  _01: scaleTo(^.layer_0.shape, projI(^.size) + (0, 1)) at projJ(^.layer_0.pos) + (0, 2)
  _011: scaleTo(^.layer_0.shape, projI(^.size) + (0, 1)) at ('0,center(^.layer_0) + 3)
  _0111: rectangle with size (?,1) with model Full with color ? at ('0,?)
  _01111: rectangle with size (?,1) with model Full with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.3 + 1105.5 = 1137.8
DL output with Mo: L = 265.7 + 3220.4 = 3486.2
DL input+output M: L = 298.1 + 4325.9 = 4624.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: scaleTo(^.layer_0.shape, projI(^.size) + (0, 1)) at projJ(^.layer_0.pos)
  _01: scaleTo(^.layer_0.shape, projI(^.size) + (0, 1)) at projJ(^.layer_0.pos) + (0, 2)
  _011: scaleTo(^.layer_0.shape, projI(^.size) + (0, 1)) at ('0,center(^.layer_0) + 3)
  _0111: rectangle with size (?,1) with model Full with color ? at ('0,?)
  _01111: rectangle with size (?,1) with model Full with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 0.0 = 32.2
DL output with Mo: L = 265.7 + 3220.4 = 3486.2
DL input+output M: L = 297.9 + 3220.4 = 3518.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color red at (9,1)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
2 
2 
2 
2 
2 
2 
2 
2 
2 
2 
 at (0,1)
  _01: 
2 
2 
2 
2 
2 
2 
2 
2 
2 
2 
 at (0,3)
  _011: 
2 
2 
2 
2 
2 
2 
2 
2 
2 
2 
 at (0,5)
  _0111: rectangle with size (10,1) with model Full with color red at (0,7)
  _01111: rectangle with size (10,1) with model Full with color red at (0,9)
  + 4 delta pixels
diff: 
   (210.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color red at (9,1)
diff: 
! 26 wrong pixels (generated / expected)

TRAIN 8403a5d5.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color green at (9,5)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
3 
3 
3 
3 
3 
3 
3 
3 
3 
3 
 at (0,5)
  _01: 
3 
3 
3 
3 
3 
3 
3 
3 
3 
3 
 at (0,7)
  _011: 
3 
3 
3 
3 
3 
3 
3 
3 
3 
3 
 at (0,9)
  _0111: rectangle with size (1,1) with model Full with color grey at (0,6)
  _01111: rectangle with size (1,1) with model Full with color grey at (9,8)
diff: 
   (34.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color green at (9,5)
diff: 
! 4 wrong pixels (generated / expected)

TRAIN 8403a5d5.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (9,4)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
 at (0,4)
  _01: 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
 at (0,6)
  _011: 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
 at (0,8)
  _0111: rectangle with size (1,1) with model Full with color grey at (0,5)
  _01111: rectangle with size (1,1) with model Full with color grey at (0,9)
  + 1 delta pixels
diff: 
   (76.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (9,4)
diff: 
! 5 wrong pixels (generated / expected)

TRAIN 8403a5d5.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (9,2)
diff: 
! 16 wrong pixels (generated / expected)

TEST 8403a5d5.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 9.6 sec (9.6 sec/task)
bits-train-error = 3220.4 bits (3220.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-200] Checking task 846bdb03.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 274019.4 = 274021.7
DL output with Mo: L = 2.3 + 61840.9 = 61843.2
DL input+output M: L = 4.6 + 335860.3 = 335864.9

# learning a model for train pairs
2.000	
1.136	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.705	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.482	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.305	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.272	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.242	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.210	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.188	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.172	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.156	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.147	OUT SPE ^.layer_0111.shape.mask = scaleTo(^.layer_0111.shape.mask, ^.layer_0111.shape.mask.size + (2, 0))
0.137	OUT SPE ^.layer_011.shape.mask = scaleTo(^.layer_011.shape.mask, ^.layer_011.shape.mask.size + (2, 0))
0.129	OUT SPE ^.layer_0.shape.mask.size = ^.layer_0.shape.mask.size + (0, 1)
0.120	OUT SPE ^.layer_01.shape.mask.size = ^.layer_0.shape.mask.size + (0, 1)
0.113	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.106	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.099	OUT SPE ^.layer_011.pos = '(0, 0)
0.093	OUT SPE ^.layer_0.pos = '(1, 0)
0.089	OUT SPE ^.layer_0111.shape = ^.layer_011111.shape
0.085	OUT SPE ^.layer_011.shape = ^.layer_011111.shape
0.079	OUT SPE ^.layer_0111.pos = '(0, 0) + ^.layer_0111.pos - ^.layer_011.pos
0.074	OUT SPE ^.size.i = ^.layer_01111.shape.mask.size.i
0.069	OUT SPE ^.size = ^.layer_01111.shape.mask.size + ^.layer_0111.pos - ^.layer_011.pos
0.066	OUT SPE ^.layer_01.shape.color = ^.layer_0111.shape.color
0.062	OUT SPE ^.layer_0.shape.color = ^.layer_011.shape.color
0.059	OUT SPE ^.layer_01.pos.j = span(^.layer_0.pos.j, ^.layer_01.pos.j)
0.056	OUT SPE ^.layer_01.pos.i = 1
0.055	OUT SPE ^.color = black
0.054	IN  SPE ^.layer_01111.shape.color = yellow
0.053	IN  SPE ^.layer_011111.shape.color = yellow
0.053	IN  SPE ^.layer_011.shape.mask.model = Full
0.052	IN  SPE ^.layer_0111.shape.mask.model = Full
0.052	IN  SPE ^.layer_01111.shape.mask.model = Full
0.052	IN  SPE ^.layer_011111.shape.mask.model = Full
0.051	IN  SPE ^.color = black
0.022	
0.022	IN  GEN ^.layer_011111.shape.color = ?
0.022	IN  GEN ^.layer_011111.shape.mask.model = ?
0.022	IN  GEN ^.layer_01111.shape.mask.model = ?
0.022	IN  GEN ^.layer_0111.shape.mask.model = ?
0.022	IN  GEN ^.layer_011.shape.mask.model = ?
0.022	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_01111.shape.mask.size + ^.layer_0111.pos - ^.layer_011.pos and color black and layers
  _0: rectangle with size ^.layer_0.shape.mask.size + (0, 1) with model ? with color ^.layer_011.shape.color at '(1, 0)
  _01: rectangle with size ^.layer_0.shape.mask.size + (0, 1) with model ? with color ^.layer_0111.shape.color at (1,span(^.layer_0.pos.j, ^.layer_01.pos.j))
  _011: ^.layer_011111.shape at '(0, 0)
  _0111: ^.layer_011111.shape at '(0, 0) + ^.layer_0111.pos - ^.layer_011.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color yellow at (?,?)
  _011111: rectangle with size (?,?) with model Full with color yellow at (?,?)

DL input  with Mi: L = 189.7 + 8119.2 = 8308.9
DL output with Mo: L = 299.0 + 990.0 = 1289.0
DL input+output M: L = 488.7 + 9109.2 = 9597.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_01111.shape.mask.size + ^.layer_0111.pos - ^.layer_011.pos and color black and layers
  _0: rectangle with size ^.layer_0.shape.mask.size + (0, 1) with model ? with color ^.layer_011.shape.color at '(1, 0)
  _01: rectangle with size ^.layer_0.shape.mask.size + (0, 1) with model ? with color ^.layer_0111.shape.color at (1,span(^.layer_0.pos.j, ^.layer_01.pos.j))
  _011: ^.layer_011111.shape at '(0, 0)
  _0111: ^.layer_011111.shape at '(0, 0) + ^.layer_0111.pos - ^.layer_011.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color yellow at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 184.2 + 0.0 = 184.2
DL output with Mo: L = 299.0 + 990.0 = 1289.0
DL input+output M: L = 483.2 + 990.0 = 1473.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 0 . 
. 0 . 
. 0 0 
. . 0 
 with color red at (3,2)
  _01: rectangle with size (3,3) with mask 
0 . . 
0 0 0 
0 . . 
 with color blue at (3,5)
  _011: rectangle with size (4,1) with model Full with color red at (8,5)
  _0111: rectangle with size (4,1) with model Full with color blue at (8,12)
  _01111: rectangle with size (6,1) with model Full with color yellow at (7,5)
  _011111: rectangle with size (6,1) with model Full with color yellow at (7,12)
diff: 
   (0.0 bits)
data: a background with size (6,8) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 . 
0 . 0 . 
0 . 0 0 
0 . . 0 
 with color red at (1,0)
  _01: rectangle with size (4,4) with mask 
0 . . 0 
0 0 0 0 
0 . . 0 
. . . 0 
 with color blue at (1,4)
  _011: 
4 
4 
4 
4 
4 
4 
 at (0,0)
  _0111: 
4 
4 
4 
4 
4 
4 
 at (0,7)
diff: 
   (35.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 0 . 
. 0 . 
. 0 0 
. . 0 
 with color red at (3,2)
  _01: rectangle with size (3,3) with mask 
0 . . 
0 0 0 
0 . . 
 with color blue at (3,5)
  _011: rectangle with size (4,1) with model Full with color red at (8,5)
  _0111: rectangle with size (4,1) with model Full with color blue at (8,12)
  _01111: rectangle with size (6,1) with model Full with color yellow at (7,5)
  _011111: rectangle with size (6,1) with model Full with color yellow at (7,12)
diff: 
! 13 wrong pixels (generated / expected)

TRAIN 846bdb03.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: rectangle with size (5,3) with mask 
0 . 0 
0 0 0 
0 . 0 
0 0 0 
0 . 0 
 with color cyan at (1,7)
  _01: rectangle with size (4,3) with mask 
. 0 . 
0 0 0 
. 0 . 
. 0 0 
 with color green at (1,4)
  _011: rectangle with size (5,1) with model Full with color cyan at (7,1)
  _0111: rectangle with size (5,1) with model Full with color green at (7,8)
  _01111: rectangle with size (7,1) with model Full with color yellow at (6,1)
  _011111: rectangle with size (7,1) with model Full with color yellow at (6,8)
diff: 
   (0.0 bits)
data: a background with size (7,8) and color black and layers
  _0: rectangle with size (5,4) with mask 
0 0 . 0 
0 0 0 0 
0 0 . 0 
0 0 0 0 
0 0 . 0 
 with color cyan at (1,0)
  _01: rectangle with size (5,4) with mask 
. 0 . 0 
0 0 0 0 
. 0 . 0 
0 0 . 0 
. . . 0 
 with color green at (1,4)
  _011: 
4 
4 
4 
4 
4 
4 
4 
 at (0,0)
  _0111: 
4 
4 
4 
4 
4 
4 
4 
 at (0,7)
diff: 
   (36.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (5,3) with mask 
0 . 0 
0 0 0 
0 . 0 
0 0 0 
0 . 0 
 with color cyan at (1,7)
  _01: rectangle with size (4,3) with mask 
. 0 . 
0 0 0 
. 0 . 
. 0 0 
 with color green at (1,4)
  _011: rectangle with size (5,1) with model Full with color cyan at (7,1)
  _0111: rectangle with size (5,1) with model Full with color green at (7,8)
  _01111: rectangle with size (7,1) with model Full with color yellow at (6,1)
  _011111: rectangle with size (7,1) with model Full with color yellow at (6,8)
diff: 
! 11 wrong pixels (generated / expected)

TRAIN 846bdb03.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color blue at (9,3)
  _01: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color red at (9,5)
  _011: rectangle with size (2,1) with model Full with color red at (2,2)
  _0111: rectangle with size (2,1) with model Full with color blue at (2,7)
  _01111: rectangle with size (4,1) with model Full with color yellow at (1,2)
  _011111: rectangle with size (4,1) with model Full with color yellow at (1,7)
diff: 
   (0.0 bits)
data: a background with size (4,6) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 . 0 
0 0 0 
 with color red at (1,0)
  _01: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color blue at (1,3)
  _011: 
4 
4 
4 
4 
 at (0,0)
  _0111: 
4 
4 
4 
4 
 at (0,5)
diff: 
   (11.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color blue at (9,3)
  _01: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color red at (9,5)
  _011: rectangle with size (2,1) with model Full with color red at (2,2)
  _0111: rectangle with size (2,1) with model Full with color blue at (2,7)
  _01111: rectangle with size (4,1) with model Full with color yellow at (1,2)
  _011111: rectangle with size (4,1) with model Full with color yellow at (1,7)
diff: 
! 2 wrong pixels (generated / expected)

TRAIN 846bdb03.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 0 
0 0 
. 0 
 with color orange at (9,5)
  _01: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color green at (9,7)
  _011: rectangle with size (3,1) with model Full with color orange at (2,5)
  _0111: rectangle with size (3,1) with model Full with color green at (2,10)
  _01111: rectangle with size (5,1) with model Full with color yellow at (1,5)
  _011111: rectangle with size (5,1) with model Full with color yellow at (1,10)
diff: 
   (0.0 bits)
data: a background with size (5,6) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
0 0 0 
0 . 0 
 with color orange at (1,0)
  _01: rectangle with size (3,3) with mask 
. 0 0 
0 0 0 
. 0 0 
 with color green at (1,3)
  _011: 
4 
4 
4 
4 
4 
 at (0,0)
  _0111: 
4 
4 
4 
4 
4 
 at (0,5)
diff: 
   (15.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 0 
0 0 
. 0 
 with color orange at (9,5)
  _01: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color green at (9,7)
  _011: rectangle with size (3,1) with model Full with color orange at (2,5)
  _0111: rectangle with size (3,1) with model Full with color green at (2,10)
  _01111: rectangle with size (5,1) with model Full with color yellow at (1,5)
  _011111: rectangle with size (5,1) with model Full with color yellow at (1,10)
diff: 
! 3 wrong pixels (generated / expected)

TRAIN 846bdb03.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 . 0 
0 0 0 
0 . . 
0 . . 
 with color cyan at (9,1)
  _01: rectangle with size (4,3) with mask 
0 . . 
0 0 0 
. 0 . 
. 0 0 
 with color red at (9,4)
  _011: rectangle with size (4,1) with model Full with color red at (2,1)
  _0111: rectangle with size (4,1) with model Full with color cyan at (2,8)
  _01111: rectangle with size (6,1) with model Full with color yellow at (1,1)
  _011111: rectangle with size (6,1) with model Full with color yellow at (1,8)
diff: 
! 10 wrong pixels (generated / expected)

TEST 846bdb03.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 30.8 sec (30.8 sec/task)
bits-train-error = 990.0 bits (990.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-199] Checking task 855e0971.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 356424.9 = 356427.2
DL output with Mo: L = 2.3 + 356424.9 = 356427.2
DL input+output M: L = 4.6 + 712849.8 = 712854.4

# learning a model for train pairs
2.000	
1.546	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.130	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.764	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.418	OUT ADD ^.layer_0 = ^.layer_0
0.258	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.102	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.079	OUT ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.075	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.073	OUT SPE ^.size = ^.size
0.072	OUT SPE ^.layer_01.shape.mask.size.i = ^.layer_011.shape.mask.size.i
0.071	OUT SPE ^.layer_01.pos.i = ^.layer_011.pos.i
0.071	OUT SPE ^.layer_00.shape.color = black
0.070	OUT SPE ^.layer_01.shape.color = ^.layer_011.shape.color
0.070	OUT SPE ^.layer_00.shape.mask.model = Full
0.070	OUT SPE ^.layer_01.shape.mask.model = Full
0.051	
0.049	IN  DEL ^.layer_01

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _00: rectangle with size (?,?) with model Full with color black at (?,?)
  _0: ^.layer_0
  _01: rectangle with size (^.layer_011.shape.mask.size.i,?) with model Full with color ^.layer_011.shape.color at (^.layer_011.pos.i,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 6488.8 = 6586.9
DL output with Mo: L = 123.3 + 18064.5 = 18187.8
DL input+output M: L = 221.4 + 24553.3 = 24774.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _00: rectangle with size (?,?) with model Full with color black at (?,?)
  _0: ^.layer_0
  _01: rectangle with size (^.layer_011.shape.mask.size.i,?) with model Full with color ^.layer_011.shape.color at (^.layer_011.pos.i,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 31.7 = 101.9
DL output with Mo: L = 123.3 + 17253.7 = 17376.9
DL input+output M: L = 193.5 + 17285.3 = 17478.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (15,19) and color yellow and layers
  _0: rectangle with size (6,19) with model Full with color cyan at (9,0)
  _011: rectangle with size (2,19) with model Full with color grey at (0,0)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (15,19) and color yellow and layers
  _00: rectangle with size (7,1) with model Full with color black at (2,4)
  _0: 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
 at (9,0)
  _01: rectangle with size (2,19) with model Full with color grey at (0,0)
  + 13 delta pixels
diff: 
   (593.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,19) and color yellow and layers
  _0: rectangle with size (6,19) with model Full with color cyan at (9,0)
  _011: rectangle with size (2,19) with model Full with color grey at (0,0)
  + 3 delta pixels
diff: 
! 163 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,19) and color cyan and layers
  _0: rectangle with size (7,19) with model Full with color yellow at (2,0)
  _011: rectangle with size (2,19) with model Full with color grey at (0,0)
  + 3 delta pixels
diff: 
! 160 wrong pixels (generated / expected)

TRAIN 855e0971.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (14,13) and color blue and layers
  _0: rectangle with size (14,5) with model Full with color red at (0,0)
  _011: rectangle with size (1,1) with model Full with color black at (11,8)
  + 1 delta pixels
diff: 
   (3.2 bits)
data: a background with size (14,13) and color blue and layers
  _00: rectangle with size (1,5) with model Full with color black at (3,0)
  _0: 
2 2 2 2 2 
2 2 2 2 2 
2 2 2 2 2 
2 2 2 2 2 
2 2 2 2 2 
2 2 2 2 2 
2 2 2 2 2 
2 2 2 2 2 
2 2 2 2 2 
2 2 2 2 2 
2 2 2 2 2 
2 2 2 2 2 
2 2 2 2 2 
2 2 2 2 2 
 at (0,0)
  _01: rectangle with size (1,8) with model Full with color black at (11,5)
diff: 
   (47.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,13) and color black and layers
  _0: rectangle with size (14,8) with mask 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
 with color blue at (0,5)
  _011: rectangle with size (14,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 . 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
 with color red at (0,0)
diff: 
! 52 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,13) and color black and layers
  _0: rectangle with size (14,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 . 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
 with color red at (0,0)
  _011: rectangle with size (14,8) with mask 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
 with color blue at (0,5)
diff: 
! 112 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (14,13) and color blue and layers
  _0: rectangle with size (14,5) with model Full with color red at (0,0)
  _011: rectangle with size (1,1) with model Full with color black at (11,8)
  + 1 delta pixels
diff: 
! 113 wrong pixels (generated / expected)

TRAIN 855e0971.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (13,15) and color red and layers
  _0: rectangle with size (5,15) with model Full with color cyan at (0,0)
  _011: rectangle with size (3,15) with model Full with color green at (10,0)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (13,15) and color red and layers
  _00: rectangle with size (5,1) with model Full with color black at (0,3)
  _0: 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 
 at (0,0)
  _01: rectangle with size (3,15) with model Full with color green at (10,0)
  + 13 delta pixels
diff: 
   (583.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,15) and color red and layers
  _0: rectangle with size (5,15) with model Full with color cyan at (0,0)
  _011: rectangle with size (3,15) with model Full with color green at (10,0)
  + 4 delta pixels
diff: 
! 120 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,15) and color cyan and layers
  _0: rectangle with size (5,15) with model Full with color red at (5,0)
  _011: rectangle with size (3,15) with model Full with color green at (10,0)
  + 4 delta pixels
diff: 
! 106 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (13,15) and color red and layers
  _0: rectangle with size (3,15) with model Full with color green at (10,0)
  _011: rectangle with size (5,15) with model Full with color cyan at (0,0)
  + 4 delta pixels
diff: 
! 132 wrong pixels (generated / expected)

TRAIN 855e0971.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (14,15) and color yellow and layers
  _0: rectangle with size (14,5) with model Full with color grey at (0,4)
  _011: rectangle with size (14,4) with model Full with color red at (0,0)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (14,15) and color yellow and layers
  _00: rectangle with size (1,6) with model Full with color black at (2,9)
  _0: 
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
 at (0,4)
  _01: rectangle with size (14,4) with model Full with color red at (0,0)
  + 11 delta pixels
diff: 
   (500.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,15) and color yellow and layers
  _0: rectangle with size (14,5) with model Full with color grey at (0,4)
  _011: rectangle with size (14,4) with model Full with color red at (0,0)
  + 3 delta pixels
diff: 
! 109 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,15) and color yellow and layers
  _0: rectangle with size (14,4) with model Full with color red at (0,0)
  _011: rectangle with size (14,5) with model Full with color grey at (0,4)
  + 3 delta pixels
diff: 
! 141 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (14,15) and color grey and layers
  _0: rectangle with size (14,6) with model Full with color yellow at (0,9)
  _011: rectangle with size (14,4) with model Full with color red at (0,0)
  + 3 delta pixels
diff: 
! 109 wrong pixels (generated / expected)

TRAIN 855e0971.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,15) and color yellow and layers
  _0: rectangle with size (4,15) with model Full with color blue at (4,0)
  _011: rectangle with size (4,15) with model Full with color red at (13,0)
  + 63 delta pixels
diff: 
! 182 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,15) and color yellow and layers
  _0: rectangle with size (4,15) with model Full with color red at (13,0)
  _011: rectangle with size (4,15) with model Full with color blue at (4,0)
  + 63 delta pixels
diff: 
! 174 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (17,15) and color yellow and layers
  _0: rectangle with size (4,15) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 . 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color blue at (4,0)
  _011: rectangle with size (4,15) with model Full with color red at (13,0)
  + 63 delta pixels
diff: 
! 181 wrong pixels (generated / expected)

TEST 855e0971.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 11.4 sec (11.4 sec/task)
bits-train-error = 17253.7 bits (17253.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-198] Checking task 85c4e7cd.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 137320.7 = 137323.0
DL output with Mo: L = 2.3 + 137320.7 = 137323.0
DL input+output M: L = 4.6 + 274641.4 = 274646.0

# learning a model for train pairs
2.000	
1.634	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.267	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.002	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.738	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.563	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.388	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.293	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.198	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.161	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.124	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.113	OUT SPE ^.layer_0 = coloring(^.layer_0, ^.layer_011.shape.color)
0.103	OUT SPE ^.layer_01 = coloring(^.layer_011, ^.layer_0.shape.color)
0.097	OUT SPE ^.size = ^.size
0.092	OUT SPE ^.layer_011.shape.mask = ^.layer_01.shape.mask
0.087	OUT SPE ^.layer_0111.shape.mask = ^.layer_0111.shape.mask
0.084	OUT SPE ^.layer_0111.pos = ^.layer_0111.pos
0.081	OUT SPE ^.layer_011.pos = ^.layer_01.pos
0.080	IN  SPE ^.layer_0111.shape.mask.model = Full
0.019	
0.019	IN  GEN ^.layer_0111.shape.mask.model = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: coloring(^.layer_0, ^.layer_011.shape.color)
  _01: coloring(^.layer_011, ^.layer_0.shape.color)
  _011: ^.layer_01.shape.mask with color ? at ^.layer_01.pos
  _0111: ^.layer_0111.shape.mask with color ? at ^.layer_0111.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 126.3 + 8321.5 = 8447.8
DL output with Mo: L = 103.5 + 2392.3 = 2495.8
DL input+output M: L = 229.8 + 10713.7 = 10943.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: coloring(^.layer_0, ^.layer_011.shape.color)
  _01: coloring(^.layer_011, ^.layer_0.shape.color)
  _011: ^.layer_01.shape.mask with color ? at ^.layer_01.pos
  _0111: ^.layer_0111.shape.mask with color ? at ^.layer_0111.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 20.0 = 145.8
DL output with Mo: L = 103.5 + 2392.3 = 2495.8
DL input+output M: L = 229.3 + 2412.3 = 2641.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (12,12) and color yellow and layers
  _0: rectangle with size (10,10) with model Border with color red at (1,1)
  _01: rectangle with size (8,8) with model Border with color blue at (2,2)
  _011: rectangle with size (4,4) with model Full with color grey at (4,4)
  _0111: rectangle with size (6,6) with model Full with color green at (3,3)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (12,12) and color cyan and layers
  _0: 
5#5#5#5#5#5#5#5#5#5#
5#. . . . . . . . 5#
5#. . . . . . . . 5#
5#. . . . . . . . 5#
5#. . . . . . . . 5#
5#. . . . . . . . 5#
5#. . . . . . . . 5#
5#. . . . . . . . 5#
5#. . . . . . . . 5#
5#5#5#5#5#5#5#5#5#5#
 at (1,1)
  _01: 
2 2 2 2 
2 2 2 2 
2 2 2 2 
2 2 2 2 
 at (4,4)
  _011: 
0 0 0 0 0 0 0 0 
0 . . . . . . 0 
0 . . . . . . 0 
0 . . . . . . 0 
0 . . . . . . 0 
0 . . . . . . 0 
0 . . . . . . 0 
0 0 0 0 0 0 0 0 
 with color green at (2,2)
  _0111: 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
 with color blue at (3,3)
  + 4 delta pixels
diff: 
   (185.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color yellow and layers
  _0: rectangle with size (10,10) with model Border with color red at (1,1)
  _01: rectangle with size (8,8) with model Border with color blue at (2,2)
  _011: rectangle with size (4,4) with model Full with color grey at (4,4)
  _0111: rectangle with size (6,6) with model Full with color green at (3,3)
  + 4 delta pixels
diff: 
! 96 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color red and layers
  _0: rectangle with size (12,12) with model Border with color yellow at (0,0)
  _01: rectangle with size (8,8) with model Border with color blue at (2,2)
  _011: rectangle with size (4,4) with model Full with color grey at (4,4)
  _0111: rectangle with size (6,6) with model Full with color green at (3,3)
  + 4 delta pixels
diff: 
! 140 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color yellow and layers
  _0: rectangle with size (10,10) with model Border with color red at (1,1)
  _01: rectangle with size (8,8) with model Border with color blue at (2,2)
  _011: rectangle with size (6,6) with model Border with color green at (3,3)
  _0111: rectangle with size (4,4) with model Full with color grey at (4,4)
  + 4 delta pixels
diff: 
! 144 wrong pixels (generated / expected)

TRAIN 85c4e7cd.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (6,6) and color red and layers
  _0: rectangle with size (1,4) with model Full with color blue at (1,1)
  _01: rectangle with size (2,2) with model Full with color pink at (2,2)
  _011: rectangle with size (1,4) with model Full with color blue at (4,1)
  _0111: rectangle with size (4,4) with model Full with color blue at (1,1)
diff: 
   (0.0 bits)
data: a background with size (6,6) and color pink and layers
  _0: 
1 1 1 1 
 at (1,1)
  _01: 
1 1 1 1 
 at (4,1)
  _011: 
0 0 
0 0 
 with color red at (2,2)
  _0111: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color blue at (1,1)
diff: 
   (20.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color red and layers
  _0: rectangle with size (1,4) with model Full with color blue at (1,1)
  _01: rectangle with size (2,2) with model Full with color pink at (2,2)
  _011: rectangle with size (1,4) with model Full with color blue at (4,1)
  _0111: rectangle with size (4,4) with model Full with color blue at (1,1)
diff: 
! 28 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,6) and color red and layers
  _0: rectangle with size (4,1) with model Full with color blue at (1,1)
  _01: rectangle with size (4,1) with model Full with color blue at (1,4)
  _011: rectangle with size (2,2) with model Full with color pink at (2,2)
  _0111: rectangle with size (4,4) with model Full with color blue at (1,1)
diff: 
! 36 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (6,6) and color red and layers
  _0: rectangle with size (1,4) with model Full with color blue at (1,1)
  _01: rectangle with size (1,4) with model Full with color blue at (4,1)
  _011: rectangle with size (2,2) with model Full with color pink at (2,2)
  _0111: rectangle with size (4,4) with model Full with color blue at (1,1)
diff: 
! 36 wrong pixels (generated / expected)

TRAIN 85c4e7cd.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (8,8) and color black and layers
  _0: rectangle with size (6,6) with model Border with color blue at (1,1)
  _01: rectangle with size (8,8) with model Border with color cyan at (0,0)
  _011: rectangle with size (4,4) with model Border with color red at (2,2)
  _0111: rectangle with size (2,2) with model Full with color yellow at (3,3)
diff: 
   (2.0 bits)
data: a background with size (8,8) and color black and layers
  _0: 
2 2 2 2 2 2 
2 . . . . 2 
2 . . . . 2 
2 . . . . 2 
2 . . . . 2 
2 2 2 2 2 2 
 at (1,1)
  _01: 
1 1 1 1 
1 . . 1 
1 . . 1 
1 1 1 1 
 at (2,2)
  _011: 
0 0 0 0 0 0 0 0 
0 . . . . . . 0 
0 . . . . . . 0 
0 . . . . . . 0 
0 . . . . . . 0 
0 . . . . . . 0 
0 . . . . . . 0 
0 0 0 0 0 0 0 0 
 with color yellow at (0,0)
  _0111: 
0 0 
0 0 
 with color cyan at (3,3)
diff: 
   (13.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (8,8) with model Border with color cyan at (0,0)
  _01: rectangle with size (6,6) with model Border with color blue at (1,1)
  _011: rectangle with size (4,4) with model Border with color red at (2,2)
  _0111: rectangle with size (2,2) with model Full with color yellow at (3,3)
diff: 
! 64 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (6,6) with model Border with color blue at (1,1)
  _01: rectangle with size (8,8) with model Border with color cyan at (0,0)
  _011: rectangle with size (4,4) with model Border with color red at (2,2)
  _0111: rectangle with size (2,2) with model Full with color yellow at (3,3)
diff: 
! 32 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (8,8) with model Border with color cyan at (0,0)
  _01: rectangle with size (4,4) with model Border with color red at (2,2)
  _011: rectangle with size (6,6) with model Border with color blue at (1,1)
  _0111: rectangle with size (2,2) with model Full with color yellow at (3,3)
diff: 
! 64 wrong pixels (generated / expected)

TRAIN 85c4e7cd.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (10,10) and color orange and layers
  _0: rectangle with size (8,8) with model Border with color red at (1,1)
  _01: rectangle with size (6,6) with model Border with color yellow at (2,2)
  _011: rectangle with size (4,4) with model Border with color blue at (3,3)
  _0111: rectangle with size (2,2) with model Full with color green at (4,4)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color green and layers
  _0: 
1 1 1 1 1 1 1 1 
1 . . . . . . 1 
1 . . . . . . 1 
1 . . . . . . 1 
1 . . . . . . 1 
1 . . . . . . 1 
1 . . . . . . 1 
1 1 1 1 1 1 1 1 
 at (1,1)
  _01: 
2 2 2 2 
2 . . 2 
2 . . 2 
2 2 2 2 
 at (3,3)
  _011: 
0 0 0 0 0 0 
0 . . . . 0 
0 . . . . 0 
0 . . . . 0 
0 . . . . 0 
0 0 0 0 0 0 
 with color yellow at (2,2)
  _0111: 
0 0 
0 0 
 with color orange at (4,4)
diff: 
   (20.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color orange and layers
  _0: rectangle with size (8,8) with model Border with color red at (1,1)
  _01: rectangle with size (6,6) with model Border with color yellow at (2,2)
  _011: rectangle with size (4,4) with model Border with color blue at (3,3)
  _0111: rectangle with size (2,2) with model Full with color green at (4,4)
diff: 
! 60 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color orange and layers
  _0: rectangle with size (6,6) with model Border with color yellow at (2,2)
  _01: rectangle with size (8,8) with model Border with color red at (1,1)
  _011: rectangle with size (4,4) with model Border with color blue at (3,3)
  _0111: rectangle with size (2,2) with model Full with color green at (4,4)
diff: 
! 100 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color orange and layers
  _0: rectangle with size (8,8) with model Border with color red at (1,1)
  _01: rectangle with size (4,4) with model Border with color blue at (3,3)
  _011: rectangle with size (6,6) with model Border with color yellow at (2,2)
  _0111: rectangle with size (2,2) with model Full with color green at (4,4)
diff: 
! 100 wrong pixels (generated / expected)

TRAIN 85c4e7cd.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,14) and color cyan and layers
  _0: rectangle with size (12,12) with model Border with color red at (1,1)
  _01: rectangle with size (10,10) with model Border with color yellow at (2,2)
  _011: rectangle with size (6,6) with model Full with color orange at (4,4)
  _0111: rectangle with size (8,8) with model Full with color green at (3,3)
  + 16 delta pixels
diff: 
! 184 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,14) and color cyan and layers
  _0: rectangle with size (10,10) with model Border with color yellow at (2,2)
  _01: rectangle with size (12,12) with model Border with color red at (1,1)
  _011: rectangle with size (6,6) with model Full with color orange at (4,4)
  _0111: rectangle with size (8,8) with model Full with color green at (3,3)
  + 16 delta pixels
diff: 
! 140 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (14,14) and color cyan and layers
  _0: rectangle with size (12,12) with model Border with color red at (1,1)
  _01: rectangle with size (6,6) with model Full with color orange at (4,4)
  _011: rectangle with size (10,10) with model Border with color yellow at (2,2)
  _0111: rectangle with size (8,8) with model Full with color green at (3,3)
  + 16 delta pixels
diff: 
! 196 wrong pixels (generated / expected)

TEST 85c4e7cd.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 34.6 sec (34.6 sec/task)
bits-train-error = 2392.3 bits (2392.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-197] Checking task 868de0fa.json: 5 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 386996.0 = 386998.4
DL output with Mo: L = 2.3 + 386996.0 = 386998.4
DL input+output M: L = 4.6 + 773992.1 = 773996.7

# learning a model for train pairs
2.000	
1.260	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.707	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.565	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.448	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.353	OUT ADD ^.layer_01 = ^.layer_0
0.285	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.221	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.176	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.160	OUT ADD ^.layer_01111 = ^.layer_01
0.141	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.129	IN  ADD ^.layer_010 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.111	OUT ADD ^.layer_010 = ^.layer_010
0.094	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.077	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.075	OUT SPE ^.size = ^.size
0.073	OUT SPE ^.layer_0111.pos = ^.layer_010.pos + (1, 1)
0.071	OUT SPE ^.layer_011111.pos = min(^.layer_011.pos, ^.layer_0111.pos)
0.070	OUT SPE ^.layer_0111.shape.mask.size = max(^.layer_0111.shape.mask.size, ^.layer_010.shape.mask.size) - (2, 2)
0.042	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_010
  _01: ^.layer_0
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size max(^.layer_0111.shape.mask.size, ^.layer_010.shape.mask.size) - (2, 2) with model ? with color ? at ^.layer_010.pos + (1, 1)
  _01111: ^.layer_01
  _011111: rectangle with size (?,?) with model ? with color ? at min(^.layer_011.pos, ^.layer_0111.pos)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 153.4 + 10967.4 = 11120.8
DL output with Mo: L = 226.5 + 15809.6 = 16036.1
DL input+output M: L = 379.9 + 26776.9 = 27156.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_010
  _01: ^.layer_0
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size max(^.layer_0111.shape.mask.size, ^.layer_010.shape.mask.size) - (2, 2) with model ? with color ? at ^.layer_010.pos + (1, 1)
  _01111: ^.layer_01
  _011111: rectangle with size (?,?) with model ? with color ? at min(^.layer_011.pos, ^.layer_0111.pos)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 153.4 + 0.0 = 153.4
DL output with Mo: L = 226.5 + 15809.6 = 16036.1
DL input+output M: L = 379.9 + 15809.6 = 16189.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with model Border with color blue at (5,0)
  _010: rectangle with size (4,4) with model Border with color blue at (0,0)
  _01: rectangle with size (1,3) with model Full with color blue at (2,6)
  _011: rectangle with size (1,3) with model Full with color blue at (4,6)
  _0111: rectangle with size (3,1) with model Full with color blue at (2,6)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Full with color orange at (6,1)
  _010: 
1 1 1 1 
1 . . 1 
1 . . 1 
1 1 1 1 
 at (0,0)
  _01: 
1 1 1 1 1 
1 . . . 1 
1 . . . 1 
1 . . . 1 
1 1 1 1 1 
 at (5,0)
  _011: rectangle with size (1,1) with model Full with color orange at (3,7)
  _0111: rectangle with size (2,2) with model Full with color red at (1,1)
  _01111: 
1 1 1 
 at (2,6)
  _011111: rectangle with size (3,3) with model Full with color blue at (2,6)
  + 1 delta pixels
diff: 
   (133.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with model Border with color blue at (5,0)
  _010: rectangle with size (4,4) with model Border with color blue at (0,0)
  _01: rectangle with size (1,3) with model Full with color blue at (2,6)
  _011: rectangle with size (1,3) with model Full with color blue at (4,6)
  _0111: rectangle with size (3,1) with model Full with color blue at (2,6)
  + 1 delta pixels
diff: 
! 22 wrong pixels (generated / expected)

TRAIN 868de0fa.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,6) with model Border with color blue at (0,4)
  _010: rectangle with size (1,3) with model Full with color blue at (0,0)
  _01: rectangle with size (1,3) with model Full with color blue at (2,0)
  _011: rectangle with size (3,1) with model Full with color blue at (0,0)
  _0111: rectangle with size (3,1) with model Full with color blue at (0,2)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with model Full with color red at (1,5)
  _010: 
1 1 1 
 at (0,0)
  _01: 
1 1 1 1 1 1 
1 . . . . 1 
1 . . . . 1 
1 . . . . 1 
1 . . . . 1 
1 1 1 1 1 1 
 at (0,4)
  _011: rectangle with size (3,1) with model Full with color blue at (0,2)
  _0111: rectangle with size (1,1) with model Full with color orange at (1,1)
  _01111: 
1 1 1 
 at (2,0)
  _011111: rectangle with size (3,1) with model Full with color blue at (0,0)
diff: 
   (93.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,6) with model Border with color blue at (0,4)
  _010: rectangle with size (1,3) with model Full with color blue at (0,0)
  _01: rectangle with size (1,3) with model Full with color blue at (2,0)
  _011: rectangle with size (3,1) with model Full with color blue at (0,0)
  _0111: rectangle with size (3,1) with model Full with color blue at (0,2)
diff: 
! 21 wrong pixels (generated / expected)

TRAIN 868de0fa.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (8,8) with model Border with color blue at (12,12)
  _010: rectangle with size (7,7) with model Border with color blue at (9,2)
  _01: rectangle with size (6,6) with model Border with color blue at (3,12)
  _011: rectangle with size (5,5) with model Border with color blue at (0,0)
  _0111: rectangle with size (4,4) with model Border with color blue at (1,6)
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (6,6) with model Full with color red at (13,13)
  _010: 
1 1 1 1 1 1 1 
1 . . . . . 1 
1 . . . . . 1 
1 . . . . . 1 
1 . . . . . 1 
1 . . . . . 1 
1 1 1 1 1 1 1 
 at (9,2)
  _01: 
1 1 1 1 1 1 1 1 
1 . . . . . . 1 
1 . . . . . . 1 
1 . . . . . . 1 
1 . . . . . . 1 
1 . . . . . . 1 
1 . . . . . . 1 
1 1 1 1 1 1 1 1 
 at (12,12)
  _011: rectangle with size (4,4) with model Full with color red at (4,13)
  _0111: rectangle with size (5,5) with model Full with color orange at (10,3)
  _01111: 
1 1 1 1 1 1 
1 . . . . 1 
1 . . . . 1 
1 . . . . 1 
1 . . . . 1 
1 1 1 1 1 1 
 at (3,12)
  _011111: rectangle with size (5,5) with model Full with color blue at (0,0)
  + 25 delta pixels
diff: 
   (1157.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (8,8) with model Border with color blue at (12,12)
  _010: rectangle with size (7,7) with model Border with color blue at (9,2)
  _01: rectangle with size (6,6) with model Border with color blue at (3,12)
  _011: rectangle with size (5,5) with model Border with color blue at (0,0)
  _0111: rectangle with size (4,4) with model Border with color blue at (1,6)
diff: 
! 118 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (8,8) with model Border with color blue at (12,12)
  _010: rectangle with size (6,6) with model Border with color blue at (3,12)
  _01: rectangle with size (7,7) with model Border with color blue at (9,2)
  _011: rectangle with size (5,5) with model Border with color blue at (0,0)
  _0111: rectangle with size (4,4) with model Border with color blue at (1,6)
diff: 
! 118 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (7,7) with model Border with color blue at (9,2)
  _010: rectangle with size (8,8) with model Border with color blue at (12,12)
  _01: rectangle with size (6,6) with model Border with color blue at (3,12)
  _011: rectangle with size (5,5) with model Border with color blue at (0,0)
  _0111: rectangle with size (4,4) with model Border with color blue at (1,6)
diff: 
! 118 wrong pixels (generated / expected)

TRAIN 868de0fa.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _0: rectangle with size (9,9) with mask 
. . . . . 0 0 0 0 
. . . . . 0 . . 0 
. . . . . 0 . . 0 
. . . . . 0 0 0 0 
0 0 0 0 0 . . . . 
0 . . . 0 . . . . 
0 . . . 0 . . . . 
0 . . . 0 . . . . 
0 0 0 0 0 . . . . 
 with color blue at (2,0)
  _010: rectangle with size (1,3) with model Full with color blue at (1,1)
  _01: rectangle with size (1,3) with model Full with color blue at (3,1)
  _011: rectangle with size (3,1) with model Full with color blue at (1,1)
  _0111: rectangle with size (3,1) with model Full with color blue at (1,3)
diff: 
   (0.0 bits)
data: a background with size (11,11) and color black and layers
  _0: rectangle with size (3,3) with model Full with color orange at (7,1)
  _010: 
1 1 1 
 at (1,1)
  _01: 
. . . . . 1 1 1 1 
. . . . . 1 . . 1 
. . . . . 1 . . 1 
. . . . . 1 1 1 1 
1 1 1 1 1 . . . . 
1 . . . 1 . . . . 
1 . . . 1 . . . . 
1 . . . 1 . . . . 
1 1 1 1 1 . . . . 
 at (2,0)
  _011: rectangle with size (2,2) with model Full with color red at (3,6)
  _0111: rectangle with size (1,1) with model Full with color orange at (2,2)
  _01111: 
1 1 1 
 at (3,1)
  _011111: rectangle with size (3,3) with model Full with color blue at (1,1)
diff: 
   (96.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: rectangle with size (9,9) with mask 
. . . . . 0 0 0 0 
. . . . . 0 . . 0 
. . . . . 0 . . 0 
. . . . . 0 0 0 0 
0 0 0 0 0 . . . . 
0 . . . 0 . . . . 
0 . . . 0 . . . . 
0 . . . 0 . . . . 
0 0 0 0 0 . . . . 
 with color blue at (2,0)
  _010: rectangle with size (1,3) with model Full with color blue at (1,1)
  _01: rectangle with size (1,3) with model Full with color blue at (3,1)
  _011: rectangle with size (3,1) with model Full with color blue at (1,1)
  _0111: rectangle with size (3,1) with model Full with color blue at (1,3)
diff: 
! 20 wrong pixels (generated / expected)

TRAIN 868de0fa.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (7,7) with model Border with color blue at (1,1)
  _010: rectangle with size (1,6) with model Full with color blue at (9,6)
  _01: rectangle with size (1,6) with model Full with color blue at (14,6)
  _011: rectangle with size (6,1) with model Full with color blue at (9,6)
  _0111: rectangle with size (6,1) with model Full with color blue at (9,11)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (5,5) with model Full with color orange at (2,2)
  _010: 
1 1 1 1 1 1 
 at (9,6)
  _01: 
1 1 1 1 1 1 1 
1 . . . . . 1 
1 . . . . . 1 
1 . . . . . 1 
1 . . . . . 1 
1 . . . . . 1 
1 1 1 1 1 1 1 
 at (1,1)
  _011: rectangle with size (6,1) with model Full with color blue at (9,11)
  _0111: rectangle with size (4,4) with model Full with color red at (10,7)
  _01111: 
1 1 1 1 1 1 
 at (14,6)
  _011111: rectangle with size (6,1) with model Full with color blue at (9,6)
diff: 
   (100.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (7,7) with model Border with color blue at (1,1)
  _010: rectangle with size (1,6) with model Full with color blue at (9,6)
  _01: rectangle with size (1,6) with model Full with color blue at (14,6)
  _011: rectangle with size (6,1) with model Full with color blue at (9,6)
  _0111: rectangle with size (6,1) with model Full with color blue at (9,11)
diff: 
! 53 wrong pixels (generated / expected)

TRAIN 868de0fa.json/5: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (10,10) with model Border with color blue at (7,10)
  _010: rectangle with size (8,8) with model Border with color blue at (2,1)
  _01: rectangle with size (7,7) with model Border with color blue at (11,1)
  _011: rectangle with size (1,5) with model Full with color blue at (0,12)
  _0111: rectangle with size (1,5) with model Full with color blue at (4,12)
  + 6 delta pixels
diff: 
! 154 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (10,10) with model Border with color blue at (7,10)
  _010: rectangle with size (7,7) with model Border with color blue at (11,1)
  _01: rectangle with size (8,8) with model Border with color blue at (2,1)
  _011: rectangle with size (1,5) with model Full with color blue at (0,12)
  _0111: rectangle with size (1,5) with model Full with color blue at (4,12)
  + 6 delta pixels
diff: 
! 154 wrong pixels (generated / expected)

TEST 868de0fa.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.4 sec (59.4 sec/task)
bits-train-error = 15809.6 bits (15809.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-196] Checking task 8731374e.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 536890.4 = 536892.8
DL output with Mo: L = 2.3 + 71081.2 = 71083.5
DL input+output M: L = 4.6 + 607971.7 = 607976.3

# learning a model for train pairs
2.000	
1.426	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.052	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.815	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.804	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.795	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.787	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.781	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.775	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.769	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.762	IN  ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.756	IN  ADD ^.layer_01111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.752	OUT SPE ^.layer_0.pos = '(0, 0)
0.748	OUT SPE ^.color = ^.color
0.745	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_0.shape.mask.size.i + ^.layer_011111.shape.mask.size.i
0.741	OUT SPE ^.size.i = ^.layer_0.shape.mask.size.i + ^.layer_011111.shape.mask.size.i
0.738	OUT SPE ^.size.j = ^.layer_01.shape.mask.size.j + area(^.layer_0111111.shape)
0.735	OUT SPE ^.layer_0.shape.mask.size.j = ^.layer_01.shape.mask.size.j + area(^.layer_0111111.shape)
0.032	
0.032	IN  DEL ^.layer_01111111

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (^.layer_0.shape.mask.size.i + ^.layer_011111.shape.mask.size.i,^.layer_01.shape.mask.size.j + area(^.layer_0111111.shape)) and color ^.color and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i + ^.layer_011111.shape.mask.size.i,^.layer_01.shape.mask.size.j + area(^.layer_0111111.shape)) with model ? with color ? at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 235.7 + 377703.7 = 377939.4
DL output with Mo: L = 228.1 + 1987.1 = 2215.2
DL input+output M: L = 463.8 + 379690.8 = 380154.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (^.layer_0.shape.mask.size.i + ^.layer_011111.shape.mask.size.i,^.layer_01.shape.mask.size.j + area(^.layer_0111111.shape)) and color ^.color and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i + ^.layer_011111.shape.mask.size.i,^.layer_01.shape.mask.size.j + area(^.layer_0111111.shape)) with model ? with color ? at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 208.3 + 0.0 = 208.3
DL output with Mo: L = 228.1 + 1987.1 = 2215.2
DL input+output M: L = 436.5 + 1987.1 = 2423.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (17,23) and color blue and layers
  _0: rectangle with size (3,4) with mask 
0 . . 0 
0 0 0 . 
0 . . . 
 with color orange at (1,17)
  _01: rectangle with size (4,2) with mask 
0 . 
0 . 
. 0 
. 0 
 with color grey at (0,15)
  _011: rectangle with size (2,3) with mask 
0 0 0 
0 . . 
 with color pink at (1,12)
  _0111: rectangle with size (1,7) with model Full with color cyan at (4,15)
  _01111: rectangle with size (3,4) with mask 
. . 0 . 
. 0 . 0 
0 . . . 
 with color pink at (5,3)
  _011111: rectangle with size (4,2) with model Full with color red at (7,2)
  _0111111: rectangle with size (2,4) with mask 
0 . . 0 
. 0 0 . 
 with color yellow at (12,12)
  + 279 delta pixels
diff: 
   (0.0 bits)
data: a background with size (7,6) and color blue and layers
  _0: rectangle with size (7,6) with mask 
. 0 . . 0 . 
. 0 . . 0 . 
0 0 0 0 0 0 
. 0 . . 0 . 
0 0 0 0 0 0 
. 0 . . 0 . 
. 0 . . 0 . 
 with color red at (0,0)
diff: 
   (50.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,23) and color blue and layers
  _0: rectangle with size (3,4) with mask 
0 . . 0 
0 0 0 . 
0 . . . 
 with color orange at (1,17)
  _01: rectangle with size (4,2) with mask 
0 . 
0 . 
. 0 
. 0 
 with color grey at (0,15)
  _011: rectangle with size (2,3) with mask 
0 0 0 
0 . . 
 with color pink at (1,12)
  _0111: rectangle with size (1,7) with model Full with color cyan at (4,15)
  _01111: rectangle with size (3,4) with mask 
. . 0 . 
. 0 . 0 
0 . . . 
 with color pink at (5,3)
  _011111: rectangle with size (4,2) with model Full with color red at (7,2)
  _0111111: rectangle with size (2,4) with mask 
0 . . 0 
. 0 0 . 
 with color yellow at (12,12)
  + 279 delta pixels
diff: 
! 42 wrong pixels (generated / expected)

TRAIN 8731374e.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (27,23) and color yellow and layers
  _0: rectangle with size (6,3) with mask 
. 0 . 
0 . . 
0 . . 
. 0 . 
. 0 . 
. . 0 
 with color cyan at (1,15)
  _01: rectangle with size (4,5) with mask 
0 . 0 . . 
. 0 0 . . 
. . . 0 . 
. . . . 0 
 with color pink at (17,1)
  _011: rectangle with size (3,4) with mask 
0 0 0 . 
. . . 0 
. . . 0 
 with color pink at (21,9)
  _0111: rectangle with size (4,3) with mask 
. . 0 
. . 0 
. 0 . 
0 . . 
 with color cyan at (0,0)
  _01111: rectangle with size (3,3) with mask 
0 . 0 
. 0 . 
0 . . 
 with color red at (0,11)
  _011111: rectangle with size (4,2) with mask 
. 0 
0 . 
0 . 
. 0 
 with color pink at (6,13)
  _0111111: rectangle with size (2,4) with mask 
. . 0 0 
0 0 . . 
 with color brown at (13,19)
  + 440 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,9) and color yellow and layers
  _0: rectangle with size (10,9) with mask 
. . 0 . 0 . 0 . . 
. . 0 . 0 . 0 . . 
0 0 0 0 0 0 0 0 0 
. . 0 . 0 . 0 . . 
. . 0 . 0 . 0 . . 
0 0 0 0 0 0 0 0 0 
. . 0 . 0 . 0 . . 
0 0 0 0 0 0 0 0 0 
. . 0 . 0 . 0 . . 
. . 0 . 0 . 0 . . 
 with color blue at (0,0)
diff: 
   (98.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (27,23) and color yellow and layers
  _0: rectangle with size (6,3) with mask 
. 0 . 
0 . . 
0 . . 
. 0 . 
. 0 . 
. . 0 
 with color cyan at (1,15)
  _01: rectangle with size (4,5) with mask 
0 . 0 . . 
. 0 0 . . 
. . . 0 . 
. . . . 0 
 with color pink at (17,1)
  _011: rectangle with size (3,4) with mask 
0 0 0 . 
. . . 0 
. . . 0 
 with color pink at (21,9)
  _0111: rectangle with size (4,3) with mask 
. . 0 
. . 0 
. 0 . 
0 . . 
 with color cyan at (0,0)
  _01111: rectangle with size (3,3) with mask 
0 . 0 
. 0 . 
0 . . 
 with color red at (0,11)
  _011111: rectangle with size (4,2) with mask 
. 0 
0 . 
0 . 
. 0 
 with color pink at (6,13)
  _0111111: rectangle with size (2,4) with mask 
. . 0 0 
0 0 . . 
 with color brown at (13,19)
  + 440 delta pixels
diff: 
! 90 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (27,23) and color yellow and layers
  _0: rectangle with size (6,3) with mask 
. 0 . 
0 . . 
0 . . 
. 0 . 
. 0 . 
. . 0 
 with color cyan at (1,15)
  _01: rectangle with size (4,5) with mask 
0 . 0 . . 
. 0 0 . . 
. . . 0 . 
. . . . 0 
 with color pink at (17,1)
  _011: rectangle with size (3,4) with mask 
0 0 0 . 
. . . 0 
. . . 0 
 with color pink at (21,9)
  _0111: rectangle with size (4,3) with mask 
. . 0 
. . 0 
. 0 . 
0 . . 
 with color cyan at (0,0)
  _01111: rectangle with size (3,3) with mask 
0 . 0 
. 0 . 
0 . . 
 with color red at (0,11)
  _011111: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
0 . . 
 with color green at (7,1)
  _0111111: rectangle with size (4,2) with mask 
. 0 
0 . 
0 . 
. 0 
 with color pink at (6,13)
  + 440 delta pixels
diff: 
! size mismatch, 9x9 instead of 10x9

TRAIN 8731374e.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (16,17) and color cyan and layers
  _0: rectangle with size (4,2) with model Full with color green at (4,2)
  _01: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
0 . 0 
 with color yellow at (9,7)
  _011: rectangle with size (14,1) with model Full with color grey at (2,3)
  _0111: rectangle with size (3,4) with mask 
. . 0 . 
. 0 . 0 
0 . . . 
 with color black at (8,5)
  _01111: rectangle with size (1,9) with model Full with color red at (14,2)
  _011111: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color black at (0,0)
  _0111111: rectangle with size (3,3) with model Even Checkboard with color brown at (0,1)
  + 170 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,8) and color cyan and layers
  _0: rectangle with size (6,8) with mask 
. . . 0 . . . . 
. . . 0 . . . . 
. . . 0 . . . . 
0 0 0 0 0 0 0 0 
. . . 0 . . . . 
. . . 0 . . . . 
 with color red at (0,0)
diff: 
   (49.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,17) and color cyan and layers
  _0: rectangle with size (4,2) with model Full with color green at (4,2)
  _01: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
0 . 0 
 with color yellow at (9,7)
  _011: rectangle with size (14,1) with model Full with color grey at (2,3)
  _0111: rectangle with size (3,4) with mask 
. . 0 . 
. 0 . 0 
0 . . . 
 with color black at (8,5)
  _01111: rectangle with size (1,9) with model Full with color red at (14,2)
  _011111: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color black at (0,0)
  _0111111: rectangle with size (3,3) with model Even Checkboard with color brown at (0,1)
  + 170 delta pixels
diff: 
! 48 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (16,17) and color cyan and layers
  _0: rectangle with size (4,2) with mask 
0 . 
0 0 
0 . 
. 0 
 with color green at (4,2)
  _01: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
0 . 0 
 with color yellow at (9,7)
  _011: rectangle with size (3,4) with mask 
. . 0 . 
. 0 . 0 
0 . . . 
 with color black at (8,5)
  _0111: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color black at (0,0)
  _01111: rectangle with size (3,3) with model Full with color brown at (0,1)
  _011111: rectangle with size (2,3) with mask 
. . 0 
0 0 . 
 with color green at (0,8)
  _0111111: rectangle with size (3,2) with mask 
. 0 
. 0 
0 . 
 with color black at (2,13)
  + 170 delta pixels
diff: 
! size mismatch, 6x6 instead of 6x8
>> Trial 3
data: a background with size (16,17) and color cyan and layers
  _0: rectangle with size (4,2) with mask 
0 . 
0 0 
0 . 
. 0 
 with color green at (4,2)
  _01: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
0 . 0 
 with color yellow at (9,7)
  _011: rectangle with size (3,4) with mask 
. . 0 . 
. 0 . 0 
0 . . . 
 with color black at (8,5)
  _0111: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color black at (0,0)
  _01111: rectangle with size (3,3) with model Full with color brown at (0,1)
  _011111: rectangle with size (3,2) with mask 
. 0 
. 0 
0 . 
 with color black at (2,13)
  _0111111: rectangle with size (2,3) with mask 
. . 0 
0 0 . 
 with color green at (0,8)
  + 170 delta pixels
diff: 
! size mismatch, 7x6 instead of 6x8

TRAIN 8731374e.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,17) and color cyan and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
. 0 . 
0 0 0 
 with color brown at (12,7)
  _01: rectangle with size (4,2) with mask 
. 0 
0 . 
0 . 
0 . 
 with color yellow at (8,11)
  _011: rectangle with size (3,2) with model Full with color orange at (9,1)
  _0111: rectangle with size (4,2) with mask 
. 0 
. 0 
. 0 
0 . 
 with color blue at (15,0)
  _01111: rectangle with size (1,10) with model Full with color pink at (15,0)
  _011111: rectangle with size (4,2) with mask 
0 . 
0 . 
. 0 
0 . 
 with color black at (15,10)
  _0111111: rectangle with size (1,5) with model Full with color red at (0,0)
  + 191 delta pixels
diff: 
! size mismatch, 7x7 instead of 10x8
>> Trial 2
data: a background with size (19,17) and color cyan and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
. 0 . 
0 0 0 
 with color brown at (12,7)
  _01: rectangle with size (4,2) with mask 
. 0 
0 . 
0 . 
0 . 
 with color yellow at (8,11)
  _011: rectangle with size (3,2) with model Full with color orange at (9,1)
  _0111: rectangle with size (4,2) with mask 
. 0 
. 0 
. 0 
0 . 
 with color blue at (15,0)
  _01111: rectangle with size (1,10) with model Full with color pink at (15,0)
  _011111: rectangle with size (1,5) with model Full with color red at (0,0)
  _0111111: rectangle with size (4,2) with mask 
0 . 
0 . 
. 0 
0 . 
 with color black at (15,10)
  + 191 delta pixels
diff: 
! size mismatch, 4x6 instead of 10x8
>> Trial 3
data: a background with size (19,17) and color cyan and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
. 0 . 
0 0 0 
 with color brown at (12,7)
  _01: rectangle with size (4,2) with mask 
. 0 
0 . 
0 . 
0 . 
 with color yellow at (8,11)
  _011: rectangle with size (3,2) with model Full with color orange at (9,1)
  _0111: rectangle with size (4,2) with mask 
. 0 
. 0 
. 0 
0 . 
 with color blue at (15,0)
  _01111: rectangle with size (4,2) with mask 
0 . 
0 . 
. 0 
0 . 
 with color black at (15,10)
  _011111: rectangle with size (1,10) with model Full with color pink at (15,0)
  _0111111: rectangle with size (1,5) with model Full with color red at (0,0)
  + 191 delta pixels
diff: 
! size mismatch, 4x7 instead of 10x8

TEST 8731374e.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 25.3 sec (25.3 sec/task)
bits-train-error = 1987.1 bits (1987.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-195] Checking task 88a10436.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 85942.4 = 85944.7
DL output with Mo: L = 2.3 + 85942.4 = 85944.7
DL input+output M: L = 4.6 + 171884.8 = 171889.5

# learning a model for train pairs
2.000	
1.110	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.293	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.262	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.221	OUT ADD ^.layer_0 = ^.layer_0
0.184	OUT ADD ^.layer_01 = ^.layer_0.shape at (?,?)
0.167	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.139	OUT ADD ^.layer_011 = ^.layer_01
0.116	OUT ADD ^.layer_0111 = ^.layer_01.shape at (?,?)
0.106	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.093	OUT ADD ^.layer_01111 = ^.layer_011
0.073	OUT ADD ^.layer_011111 = ^.layer_011.shape at (?,?)
0.064	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.058	OUT SPE ^.size = ^.size
0.056	IN  SPE ^.layer_0111.shape.color = grey
0.053	OUT SPE ^.layer_0111.pos = ^.layer_0111.pos - (1, 1)
0.051	IN  SPE ^.layer_011.shape.color = blue
0.049	OUT SPE ^.layer_011111.pos.i = ^.layer_0111.pos.i
0.047	OUT SPE ^.layer_01.pos.i = ^.layer_0111.pos.i - ^.layer_011.pos.i - ^.layer_0.pos.i
0.046	IN  SPE ^.layer_011.shape.mask.model = Full
0.046	IN  SPE ^.color = black
0.045	OUT SPE ^.color = black
0.007	
0.007	IN  GEN ^.layer_0111.shape.color = ?
0.007	IN  GEN ^.layer_011.shape.mask.model = ?
0.007	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_0.shape at (^.layer_0111.pos.i - ^.layer_011.pos.i - ^.layer_0.pos.i,?)
  _011: ^.layer_01
  _0111: ^.layer_01.shape at ^.layer_0111.pos - (1, 1)
  _01111: ^.layer_011
  _011111: ^.layer_011.shape at (^.layer_0111.pos.i,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color blue at (?,?)
  _0111: point with color grey at (?,?)

DL input  with Mi: L = 123.3 + 3239.2 = 3362.4
DL output with Mo: L = 165.2 + 318.9 = 484.1
DL input+output M: L = 288.5 + 3558.0 = 3846.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_0.shape at (^.layer_0111.pos.i - ^.layer_011.pos.i - ^.layer_0.pos.i,?)
  _011: ^.layer_01
  _0111: ^.layer_01.shape at ^.layer_0111.pos - (1, 1)
  _01111: ^.layer_011
  _011111: ^.layer_011.shape at (^.layer_0111.pos.i,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color blue at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 119.3 + 20.0 = 139.3
DL output with Mo: L = 165.2 + 318.9 = 484.1
DL input+output M: L = 284.5 + 338.9 = 623.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: rectangle with size (1,1) with model Full with color green at (2,2)
  _01: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color red at (0,0)
  _011: rectangle with size (2,2) with model Full with color blue at (1,1)
  _0111: point with color grey at (5,5)
diff: 
   (2.0 bits)
data: a background with size (9,9) and color black and layers
  _0: 
3 
 at (2,2)
  _01: 
3 
 at (6,6)
  _011: 
. 2 
2 2 
 at (0,0)
  _0111: 
. 2 
2 2 
 at (4,4)
  _01111: 
1 1 
1 1 
 at (1,1)
  _011111: 
1 1 
1 1 
 at (5,5)
diff: 
   (11.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color red at (0,0)
  _01: rectangle with size (1,1) with model Full with color green at (2,2)
  _011: rectangle with size (2,2) with model Full with color blue at (1,1)
  _0111: point with color grey at (5,5)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (1,1) with model Full with color green at (2,2)
  _01: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color red at (0,0)
  _011: rectangle with size (2,2) with model Full with color blue at (1,1)
  _0111: point with color grey at (5,5)
diff: 
! 7 wrong pixels (generated / expected)

TRAIN 88a10436.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (8,7) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (2,4)
  _01: rectangle with size (1,1) with model Full with color pink at (0,4)
  _011: rectangle with size (1,2) with model Full with color blue at (1,4)
  _0111: point with color grey at (5,1)
diff: 
   (0.0 bits)
data: a background with size (8,7) and color black and layers
  _0: 
2 2 2 
 at (2,4)
  _01: 
2 2 2 
 at (6,0)
  _011: 
6 
 at (0,4)
  _0111: 
6 
 at (4,0)
  _01111: 
1 1 
 at (1,4)
  _011111: 
1 1 
 at (5,0)
diff: 
   (10.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,7) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (2,4)
  _01: rectangle with size (1,1) with model Full with color pink at (0,4)
  _011: rectangle with size (1,2) with model Full with color blue at (1,4)
  _0111: point with color grey at (5,1)
diff: 
correct output grid

TRAIN 88a10436.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (10,8) and color black and layers
  _0: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color green at (7,1)
  _01: rectangle with size (1,2) with model Full with color red at (6,1)
  _011: rectangle with size (2,1) with model Full with color blue at (7,3)
  _0111: point with color grey at (2,4)
diff: 
   (0.0 bits)
data: a background with size (10,8) and color black and layers
  _0: 
. 3 
3 3 
 at (7,1)
  _01: 
. 3 
3 3 
 at (2,3)
  _011: 
2 2 
 at (6,1)
  _0111: 
2 2 
 at (1,3)
  _01111: 
1 
1 
 at (7,3)
  _011111: 
1 
1 
 at (2,5)
diff: 
   (10.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,8) and color black and layers
  _0: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color green at (7,1)
  _01: rectangle with size (1,2) with model Full with color red at (6,1)
  _011: rectangle with size (2,1) with model Full with color blue at (7,3)
  _0111: point with color grey at (2,4)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,8) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (6,1)
  _01: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color green at (7,1)
  _011: rectangle with size (2,1) with model Full with color blue at (7,3)
  _0111: point with color grey at (2,4)
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,8) and color black and layers
  _0: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color green at (7,1)
  _01: rectangle with size (2,1) with model Full with color blue at (7,3)
  _011: rectangle with size (1,2) with model Full with color red at (6,1)
  _0111: point with color grey at (2,4)
diff:   ^.layer_011.shape.color
! 13 wrong pixels (generated / expected)

TRAIN 88a10436.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,11) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (2,3)
  _01: rectangle with size (1,2) with model Full with color green at (4,3)
  _011: rectangle with size (1,2) with model Full with color blue at (3,2)
  _0111: point with color grey at (8,6)
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,11) and color black and layers
  _0: rectangle with size (1,2) with model Full with color green at (4,3)
  _01: rectangle with size (1,2) with model Full with color red at (2,3)
  _011: rectangle with size (1,2) with model Full with color blue at (3,2)
  _0111: point with color grey at (8,6)
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,11) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (2,3)
  _01: rectangle with size (1,2) with model Full with color blue at (3,2)
  _011: rectangle with size (1,2) with model Full with color green at (4,3)
  _0111: point with color grey at (8,6)
diff:   ^.layer_011.shape.color
! 11 wrong pixels (generated / expected)

TEST 88a10436.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 8.1 sec (8.1 sec/task)
bits-train-error = 318.9 bits (318.9 bits/task)
acc-train-micro = 0.33 tasks (33.33%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.33
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-194] Checking task 88a62173.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 29114.4 = 29116.7
DL output with Mo: L = 2.3 + 4857.0 = 4859.4
DL input+output M: L = 4.6 + 33971.4 = 33976.0

# learning a model for train pairs
2.000	
1.412	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.851	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.607	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.459	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.395	OUT SPE ^.size = '(2, 2)
0.331	OUT SPE ^.layer_0.shape.mask.size = '(2, 2)
0.290	OUT SPE ^.layer_0.pos = '(0, 0)
0.257	OUT SPE ^.layer_0.shape.color = majorityColor(^)
0.233	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.218	OUT SPE ^.color = black
0.049	
0.047	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(2, 2) and color black and layers
  _0: rectangle with size '(2, 2) with model ? with color majorityColor(^) at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 4910.1 = 4980.3
DL output with Mo: L = 67.1 + 160.0 = 227.1
DL input+output M: L = 137.3 + 5070.1 = 5207.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(2, 2) and color black and layers
  _0: rectangle with size '(2, 2) with model ? with color majorityColor(^) at '(0, 0)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 67.1 + 160.0 = 227.1
DL input+output M: L = 69.4 + 160.0 = 229.4

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 2 0 0 2 
2 2 0 2 2 
0 0 0 0 0 
0 2 0 2 2 
2 2 0 2 0 

diff: 
   (0.0 bits)
data: a background with size (2,2) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color red at (0,0)
diff: 
   (4.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 2 0 0 2 
2 2 0 2 2 
0 0 0 0 0 
0 2 0 2 2 
2 2 0 2 0 

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 88a62173.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
1 0 0 1 0 
0 1 0 0 1 
0 0 0 0 0 
1 0 0 1 0 
1 1 0 0 1 

diff: 
   (0.0 bits)
data: a background with size (2,2) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color blue at (0,0)
diff: 
   (4.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 0 0 1 0 
0 1 0 0 1 
0 0 0 0 0 
1 0 0 1 0 
1 1 0 0 1 

diff: 
! 1 wrong pixels (generated / expected)

TRAIN 88a62173.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
8 8 0 0 8 
8 0 0 8 0 
0 0 0 0 0 
8 8 0 8 8 
8 0 0 8 0 

diff: 
   (0.0 bits)
data: a background with size (2,2) and color black and layers
  _0: rectangle with size (2,2) with model Odd Checkboard with color cyan at (0,0)
diff: 
   (6.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 8 0 0 8 
8 0 0 8 0 
0 0 0 0 0 
8 8 0 8 8 
8 0 0 8 0 

diff: 
! 2 wrong pixels (generated / expected)

TRAIN 88a62173.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#5#0 5#0 
0 5#0 0 5#
0 0 0 0 0 
5#5#0 5#5#
0 5#0 0 5#

diff: 
! 2 wrong pixels (generated / expected)

TEST 88a62173.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 5.5 sec (5.5 sec/task)
bits-train-error = 160.0 bits (160.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-193] Checking task 890034e9.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 552662.4 = 552664.8
DL output with Mo: L = 2.3 + 552662.4 = 552664.8
DL input+output M: L = 4.6 + 1105324.9 = 1105329.5

# learning a model for train pairs
2.000	
1.526	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.069	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.901	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.787	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.731	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.676	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.635	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.607	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.582	OUT ADD ^.layer_0111 = ^.layer_011
0.305	
0.305	IN  DEL ^.layer_01
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: ^.layer_011
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 152914.0 = 153012.1
DL output with Mo: L = 105.6 + 168283.0 = 168388.6
DL input+output M: L = 203.7 + 321197.0 = 321400.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: ^.layer_011
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 31.7 = 101.9
DL output with Mo: L = 105.6 + 168299.1 = 168404.7
DL input+output M: L = 175.9 + 168330.8 = 168506.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (21,21) and color black and layers
  _0: rectangle with size (21,21) with mask 
. . 0 0 . 0 0 0 0 . . . 0 . 0 0 0 0 0 0 0 
0 0 . . 0 0 0 . 0 . . . 0 0 0 0 . 0 0 0 0 
0 . . 0 . . . . . . 0 0 0 0 0 . 0 0 0 0 . 
. 0 0 0 0 0 . . . . 0 0 0 0 0 0 0 . 0 . 0 
0 0 0 0 0 . . . . . 0 . . 0 0 . 0 . 0 0 . 
0 . . . . 0 . . . . 0 . 0 0 0 0 0 . 0 0 0 
. . 0 0 . 0 . . . . 0 . 0 . . 0 0 . . . . 
. 0 . . . 0 0 . . 0 0 . 0 0 0 0 . 0 0 . . 
0 0 0 . . 0 0 0 . . . 0 0 0 0 0 . 0 . . 0 
. 0 . 0 0 0 0 . . 0 0 . 0 0 0 0 . . 0 . 0 
. . 0 0 0 0 0 . . 0 0 0 0 . 0 0 . 0 0 . 0 
0 0 0 . 0 . 0 0 . 0 . 0 0 0 . 0 0 0 0 . 0 
0 . . 0 0 . . 0 0 0 0 0 0 0 . 0 . . 0 0 0 
0 0 . 0 0 0 . 0 . . 0 0 . . 0 . 0 . 0 0 . 
0 0 0 0 0 0 . . . 0 . . 0 0 . 0 0 . 0 . 0 
. . . 0 0 0 0 . 0 0 . . 0 0 . 0 0 0 0 . 0 
. . . 0 . . . . 0 0 . . 0 0 0 0 . 0 . 0 . 
. . . 0 0 0 0 0 0 0 0 0 . 0 0 0 . . 0 0 . 
. . . . 0 . 0 0 . 0 0 0 0 0 0 . 0 . . 0 0 
. . . . . 0 . 0 . . . . 0 0 0 . . . . . . 
. . . . . . 0 . . 0 0 0 0 . 0 0 . . . . . 
 with color blue at (0,0)
  _011: rectangle with size (5,4) with model Border with color red at (2,6)
  + 53 delta pixels
diff: 
   (0.0 bits)
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (21,21) with mask 
. . 0 0 . 0 0 0 0 . . . 0 . 0 0 0 0 0 0 0 
0 0 . . 0 0 0 . 0 . . . 0 0 0 0 . 0 0 0 0 
0 . . 0 . . . . . . 0 0 0 0 0 . 0 0 0 0 . 
. 0 0 0 0 0 . . . . 0 0 0 0 0 0 0 . 0 . 0 
0 0 0 0 0 . . . . . 0 . . 0 0 . 0 . 0 0 . 
0 . . . . 0 . . . . 0 . 0 0 0 0 0 . 0 0 0 
. . 0 0 . 0 . . . . 0 . 0 . . 0 0 . . . . 
. 0 . . . 0 0 . . 0 0 . 0 0 0 0 . 0 0 . . 
0 0 0 . . 0 0 0 . . . 0 0 0 0 0 . 0 . . 0 
. 0 . 0 0 0 0 . . 0 0 . 0 0 0 0 . . 0 . 0 
. . 0 0 0 0 0 . . 0 0 0 0 . 0 0 . 0 0 . 0 
0 0 0 . 0 . 0 0 . 0 . 0 0 0 . 0 0 0 0 . 0 
0 . . 0 0 . . 0 0 0 0 0 0 0 . 0 . . 0 0 0 
0 0 . 0 0 0 . 0 . . . . . . 0 . 0 . 0 0 . 
0 0 0 0 0 0 . . . . . . . 0 . 0 0 . 0 . 0 
. . . 0 0 0 0 . 0 . . . . 0 . 0 0 0 0 . 0 
. . . 0 . . . . 0 . . . . 0 0 0 . 0 . 0 . 
. . . 0 0 0 0 0 0 . . . . 0 0 0 . . 0 0 . 
. . . . 0 . 0 0 . 0 0 0 0 0 0 . 0 . . 0 0 
. . . . . 0 . 0 . . . . 0 0 0 . . . . . . 
. . . . . . 0 . . 0 0 0 0 . 0 0 . . . . . 
 with color blue at (0,0)
  _01: rectangle with size (5,4) with model Border with color red at (13,9)
  _011: rectangle with size (5,2) with mask 
0 0 
0 . 
0 0 
0 0 
0 . 
 with color blue at (16,0)
  _0111: 
2 2 2 2 
2 . . 2 
2 . . 2 
2 . . 2 
2 2 2 2 
 at (2,6)
  + 45 delta pixels
diff: 
   (2481.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (21,21) with mask 
. . 0 0 . 0 0 0 0 . . . 0 . 0 0 0 0 0 0 0 
0 0 . . 0 0 0 . 0 . . . 0 0 0 0 . 0 0 0 0 
0 . . 0 . . . . . . 0 0 0 0 0 . 0 0 0 0 . 
. 0 0 0 0 0 . . . . 0 0 0 0 0 0 0 . 0 . 0 
0 0 0 0 0 . . . . . 0 . . 0 0 . 0 . 0 0 . 
0 . . . . 0 . . . . 0 . 0 0 0 0 0 . 0 0 0 
. . 0 0 . 0 . . . . 0 . 0 . . 0 0 . . . . 
. 0 . . . 0 0 . . 0 0 . 0 0 0 0 . 0 0 . . 
0 0 0 . . 0 0 0 . . . 0 0 0 0 0 . 0 . . 0 
. 0 . 0 0 0 0 . . 0 0 . 0 0 0 0 . . 0 . 0 
. . 0 0 0 0 0 . . 0 0 0 0 . 0 0 . 0 0 . 0 
0 0 0 . 0 . 0 0 . 0 . 0 0 0 . 0 0 0 0 . 0 
0 . . 0 0 . . 0 0 0 0 0 0 0 . 0 . . 0 0 0 
0 0 . 0 0 0 . 0 . . 0 0 . . 0 . 0 . 0 0 . 
0 0 0 0 0 0 . . . 0 . . 0 0 . 0 0 . 0 . 0 
. . . 0 0 0 0 . 0 0 . . 0 0 . 0 0 0 0 . 0 
. . . 0 . . . . 0 0 . . 0 0 0 0 . 0 . 0 . 
. . . 0 0 0 0 0 0 0 0 0 . 0 0 0 . . 0 0 . 
. . . . 0 . 0 0 . 0 0 0 0 0 0 . 0 . . 0 0 
. . . . . 0 . 0 . . . . 0 0 0 . . . . . . 
. . . . . . 0 . . 0 0 0 0 . 0 0 . . . . . 
 with color blue at (0,0)
  _011: rectangle with size (5,4) with model Border with color red at (2,6)
  + 53 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21
>> Trial 2
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (5,4) with model Border with color red at (2,6)
  _011: rectangle with size (21,21) with mask 
. . 0 0 . 0 0 0 0 . . . 0 . 0 0 0 0 0 0 0 
0 0 . . 0 0 0 . 0 . . . 0 0 0 0 . 0 0 0 0 
0 . . 0 . . . . . . 0 0 0 0 0 . 0 0 0 0 . 
. 0 0 0 0 0 . . . . 0 0 0 0 0 0 0 . 0 . 0 
0 0 0 0 0 . . . . . 0 . . 0 0 . 0 . 0 0 . 
0 . . . . 0 . . . . 0 . 0 0 0 0 0 . 0 0 0 
. . 0 0 . 0 . . . . 0 . 0 . . 0 0 . . . . 
. 0 . . . 0 0 . . 0 0 . 0 0 0 0 . 0 0 . . 
0 0 0 . . 0 0 0 . . . 0 0 0 0 0 . 0 . . 0 
. 0 . 0 0 0 0 . . 0 0 . 0 0 0 0 . . 0 . 0 
. . 0 0 0 0 0 . . 0 0 0 0 . 0 0 . 0 0 . 0 
0 0 0 . 0 . 0 0 . 0 . 0 0 0 . 0 0 0 0 . 0 
0 . . 0 0 . . 0 0 0 0 0 0 0 . 0 . . 0 0 0 
0 0 . 0 0 0 . 0 . . 0 0 . . 0 . 0 . 0 0 . 
0 0 0 0 0 0 . . . 0 . . 0 0 . 0 0 . 0 . 0 
. . . 0 0 0 0 . 0 0 . . 0 0 . 0 0 0 0 . 0 
. . . 0 . . . . 0 0 . . 0 0 0 0 . 0 . 0 . 
. . . 0 0 0 0 0 0 0 0 0 . 0 0 0 . . 0 0 . 
. . . . 0 . 0 0 . 0 0 0 0 0 0 . 0 . . 0 0 
. . . . . 0 . 0 . . . . 0 0 0 . . . . . . 
. . . . . . 0 . . 0 0 0 0 . 0 0 . . . . . 
 with color blue at (0,0)
  + 53 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21
>> Trial 3
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (21,21) with mask 
. . 0 0 . 0 0 0 0 . . . 0 . 0 0 0 0 0 0 0 
0 0 . . 0 0 0 . 0 . . . 0 0 0 0 . 0 0 0 0 
0 . . 0 . . . . . . 0 0 0 0 0 . 0 0 0 0 . 
. 0 0 0 0 0 . . . . 0 0 0 0 0 0 0 . 0 . 0 
0 0 0 0 0 . . . . . 0 . . 0 0 . 0 . 0 0 . 
0 . . . . 0 . . . . 0 . 0 0 0 0 0 . 0 0 0 
. . 0 0 . 0 . . . . 0 . 0 . . 0 0 . . . . 
. 0 . . . 0 0 . . 0 0 . 0 0 0 0 . 0 0 . . 
0 0 0 . . 0 0 0 . . . 0 0 0 0 0 . 0 . . 0 
. 0 . 0 0 0 0 . . 0 0 . 0 0 0 0 . . 0 . 0 
. . 0 0 0 0 0 . . 0 0 0 0 . 0 0 . 0 0 . 0 
0 0 0 . 0 . 0 0 . 0 . 0 0 0 . 0 0 0 0 . 0 
0 . . 0 0 . . 0 0 0 0 0 0 0 . 0 . . 0 0 0 
0 0 . 0 0 0 . 0 . . 0 0 . . 0 . 0 . 0 0 . 
0 0 0 0 0 0 . . . 0 . . 0 0 . 0 0 . 0 . 0 
. . . 0 0 0 0 . 0 0 . . 0 0 . 0 0 0 0 . 0 
. . . 0 . . . . 0 0 . . 0 0 0 0 . 0 . 0 . 
. . . 0 0 0 0 0 0 0 0 0 . 0 0 0 . . 0 0 . 
. . . . 0 . 0 0 . 0 0 0 0 0 0 . 0 . . 0 0 
. . . . . 0 . 0 . . . . 0 0 0 . . . . . . 
. . . . . . 0 . . 0 0 0 0 . 0 0 . . . . . 
 with color blue at (0,0)
  _011: rectangle with size (5,4) with model Full with color red at (2,6)
  + 59 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21

TRAIN 890034e9.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (21,21) and color green and layers
  _0: rectangle with size (21,16) with mask 
. . . 0 . . . . . . . . . . 0 0 
. . . 0 0 . . . . . . . . . 0 . 
. 0 . 0 0 . . 0 . . . . 0 0 . 0 
0 . . . 0 . 0 . 0 0 0 0 . . . . 
. 0 0 0 0 . 0 . . . . 0 . 0 0 0 
0 0 . 0 . 0 0 0 . . . . . . 0 . 
. 0 . . 0 . . 0 0 . . 0 0 0 . . 
. . . . . 0 . . . . 0 . 0 . . . 
. . . 0 0 . 0 0 0 0 . 0 . . . . 
. . . . . . . 0 0 0 . 0 0 . . . 
. . . . . 0 . . 0 . . 0 . . . . 
. . . . 0 0 0 0 . 0 . . 0 . . . 
. . . . . 0 . . . . 0 . 0 . . . 
. . . 0 . 0 . 0 0 . . . 0 . . . 
. . . 0 0 . 0 0 . . . . 0 . . . 
. . . 0 0 . . 0 0 . 0 0 . . . . 
. . . . . . . . 0 . . 0 . . . . 
. . . . . . . 0 0 0 . . . . . . 
. . . . . . . . . . 0 . 0 . . . 
. . . . . . . . . . . 0 0 . . . 
. . . . . . . . . . . . 0 0 . . 
 with color black at (0,5)
  _011: rectangle with size (16,8) with mask 
0 . . . . . . . 
0 . . . . . . . 
0 . . . . . . . 
. 0 . . . . . . 
0 0 . 0 0 0 0 . 
. 0 0 . . . . . 
. . 0 . . . . . 
0 0 0 . . . . . 
. 0 . . . . . . 
. 0 0 0 0 . 0 . 
0 0 . . 0 0 0 . 
. . 0 0 . 0 . . 
. . . . 0 0 0 0 
0 0 0 0 0 . 0 . 
. . . 0 . 0 . . 
. . . . . 0 . . 
 with color black at (5,0)
  + 149 delta pixels
diff: 
   (0.0 bits)
data: a background with size (21,21) and color green and layers
  _0: rectangle with size (9,16) with mask 
. . . 0 . . . . . . . . . . 0 0 
. . . 0 0 . . . . . . . . . 0 . 
. 0 . 0 0 . . 0 . . . . 0 0 . 0 
0 . . . 0 . 0 . 0 0 0 0 . . . . 
. 0 0 0 0 . 0 . . . . 0 . . . . 
0 0 . 0 . 0 0 0 . . . . . . . . 
. 0 . . 0 . . 0 0 . . . . . . . 
. . . . . 0 . . . . . . . . . . 
. . . 0 0 . . . . . . . . . . . 
 with color black at (0,5)
  _01: rectangle with size (11,11) with mask 
. . 0 . . . . . . . . 
. 0 0 0 0 . . . . . . 
. . 0 . . . . . . . . 
0 . 0 . 0 0 . . . . . 
0 0 . 0 0 . . . . . . 
0 0 . . 0 0 . . . . . 
. . . . . 0 . . . . . 
. . . . 0 0 0 . . . . 
. . . . . . . 0 . 0 . 
. . . . . . . . 0 0 . 
. . . . . . . . . 0 0 
 with color black at (10,8)
  _011: rectangle with size (13,6) with mask 
. . . 0 0 0 
. . . . 0 . 
. 0 0 0 . . 
. . 0 . . . 
. 0 . . . . 
. 0 0 . . . 
. 0 . . . . 
. . 0 . . . 
. . 0 . . . 
. . 0 . . . 
. . 0 . . . 
0 0 . . . . 
. 0 . . . . 
 with color black at (4,15)
  _0111: 
0 . . . . . . . 
0 . . . . . . . 
0 . . . . . . . 
. 0 . . . . . . 
0 0 . 0 0 0 0 . 
. 0 0 . . . . . 
. . 0 . . . . . 
0 0 0 . . . . . 
. 0 . . . . . . 
. 0 0 0 0 . 0 . 
0 0 . . 0 0 0 . 
. . 0 0 . 0 . . 
. . . . 0 0 0 0 
0 0 0 0 0 . 0 . 
. . . 0 . 0 . . 
. . . . . 0 . . 
 at (5,0)
  + 166 delta pixels
diff: 
   (7371.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (21,21) and color green and layers
  _0: rectangle with size (21,16) with mask 
. . . 0 . . . . . . . . . . 0 0 
. . . 0 0 . . . . . . . . . 0 . 
. 0 . 0 0 . . 0 . . . . 0 0 . 0 
0 . . . 0 . 0 . 0 0 0 0 . . . . 
. 0 0 0 0 . 0 . . . . 0 . 0 0 0 
0 0 . 0 . 0 0 0 . . . . . . 0 . 
. 0 . . 0 . . 0 0 . . 0 0 0 . . 
. . . . . 0 . . . . 0 . 0 . . . 
. . . 0 0 . 0 0 0 0 . 0 . . . . 
. . . . . . . 0 0 0 . 0 0 . . . 
. . . . . 0 . . 0 . . 0 . . . . 
. . . . 0 0 0 0 . 0 . . 0 . . . 
. . . . . 0 . . . . 0 . 0 . . . 
. . . 0 . 0 . 0 0 . . . 0 . . . 
. . . 0 0 . 0 0 . . . . 0 . . . 
. . . 0 0 . . 0 0 . 0 0 . . . . 
. . . . . . . . 0 . . 0 . . . . 
. . . . . . . 0 0 0 . . . . . . 
. . . . . . . . . . 0 . 0 . . . 
. . . . . . . . . . . 0 0 . . . 
. . . . . . . . . . . . 0 0 . . 
 with color black at (0,5)
  _011: rectangle with size (16,8) with mask 
0 . . . . . . . 
0 . . . . . . . 
0 . . . . . . . 
. 0 . . . . . . 
0 0 . 0 0 0 0 . 
. 0 0 . . . . . 
. . 0 . . . . . 
0 0 0 . . . . . 
. 0 . . . . . . 
. 0 0 0 0 . 0 . 
0 0 . . 0 0 0 . 
. . 0 0 . 0 . . 
. . . . 0 0 0 0 
0 0 0 0 0 . 0 . 
. . . 0 . 0 . . 
. . . . . 0 . . 
 with color black at (5,0)
  + 149 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21

TRAIN 890034e9.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (21,21) and color red and layers
  _0: rectangle with size (18,11) with mask 
. 0 . . . . . . . . . 
. 0 . . . . . . . . . 
0 . . . . . . . . . . 
. 0 0 0 . . . 0 . . . 
. . 0 . 0 . 0 0 . . . 
. . . . 0 . 0 0 0 . . 
. . . 0 0 0 . . . . 0 
. . . . 0 . . 0 0 . 0 
. . . . 0 . 0 . 0 0 . 
. . . . . 0 . . . . . 
. . . 0 0 . . . . . . 
. . 0 . 0 . . . . . . 
. 0 0 0 0 . 0 0 . . . 
0 0 0 0 0 0 . . . . . 
. 0 0 0 0 0 . 0 0 . . 
. . . . . 0 0 . . 0 0 
. . . . 0 . 0 0 0 . . 
. . . . . . . 0 0 . . 
 with color black at (3,10)
  _011: rectangle with size (5,6) with model Full with color yellow at (3,4)
  + 171 delta pixels
diff: 
   (3.2 bits)
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (10,14) with mask 
0 . . . 0 0 0 0 0 0 0 0 . . 
0 0 0 0 0 0 0 0 . 0 0 . . . 
0 0 0 0 . 0 0 0 0 . . . . . 
. . . . . . 0 . 0 0 0 . . . 
. . . . . 0 0 . 0 . . 0 0 . 
. . . . . 0 0 . 0 0 . . 0 . 
. . . . . . . 0 0 0 . 0 0 0 
. . . . . . 0 . 0 . . 0 0 0 
. . . . . . . . 0 . . . 0 0 
. . . . . . . . . 0 0 . 0 . 
 with color red at (0,7)
  _01: rectangle with size (13,14) with mask 
. . . . . . . . . . 0 . . . 
. . . . . . . . . . 0 0 . . 
. . . . . . 0 . 0 . . 0 . . 
. . . . . . 0 . 0 0 0 . 0 . 
. . . . 0 . . 0 0 . . . 0 . 
0 . . . 0 0 0 0 0 . . . . 0 
. 0 0 . 0 . 0 0 . . 0 0 0 0 
. . . 0 . 0 . 0 . . 0 0 0 . 
. . 0 0 0 . 0 . . 0 . . . . 
0 0 0 0 0 . 0 . . . . . . . 
0 0 0 0 . . . . . . . . . . 
0 . . 0 0 0 . . . . . . . . 
0 0 . . . . . . . . . . . . 
 with color red at (6,0)
  _011: rectangle with size (8,6) with mask 
0 . . . . 0 
. 0 0 0 0 0 
. 0 0 . 0 0 
. 0 . 0 0 . 
. . . 0 . . 
. 0 0 . 0 . 
. 0 . . 0 . 
. . 0 0 . . 
 with color red at (11,15)
  _0111: 
4 4 4 4 4 4 
4 4 4 4 4 4 
4 4 4 4 4 4 
4 4 4 4 4 4 
4 4 4 4 4 4 
 at (3,4)
  + 155 delta pixels
diff: 
   (6976.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (21,21) and color red and layers
  _0: rectangle with size (18,11) with mask 
. 0 . . . . . . . . . 
. 0 . . . . . . . . . 
0 . . . . . . . . . . 
. 0 0 0 . . . 0 . . . 
. . 0 . 0 . 0 0 . . . 
. . . . 0 . 0 0 0 . . 
. . . 0 0 0 . . . . 0 
. . . . 0 . . 0 0 . 0 
. . . . 0 . 0 . 0 0 . 
. . . . . 0 . . . . . 
. . . 0 0 . . . . . . 
. . 0 . 0 . . . . . . 
. 0 0 0 0 . 0 0 . . . 
0 0 0 0 0 0 . . . . . 
. 0 0 0 0 0 . 0 0 . . 
. . . . . 0 0 . . 0 0 
. . . . 0 . 0 0 0 . . 
. . . . . . . 0 0 . . 
 with color black at (3,10)
  _011: rectangle with size (9,13) with mask 
. 0 . 0 . . . . . . . . . 
0 . 0 . . . . . . . . . . 
. 0 . . . . . . . . . . . 
0 . . 0 . . . . . . . . . 
. 0 . 0 . . . . . 0 . . . 
. . 0 . . . . . . 0 0 0 0 
. . . 0 . 0 . . 0 . . . . 
. . . . 0 . 0 . 0 . . . . 
. . . . . . . 0 0 . . . . 
 with color black at (6,0)
  + 166 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21
>> Trial 2
data: a background with size (21,21) and color red and layers
  _0: rectangle with size (18,11) with mask 
. 0 . . . . . . . . . 
. 0 . . . . . . . . . 
0 . . . . . . . . . . 
. 0 0 0 . . . 0 . . . 
. . 0 . 0 . 0 0 . . . 
. . . . 0 . 0 0 0 . . 
. . . 0 0 0 . . . . 0 
. . . . 0 . . 0 0 . 0 
. . . . 0 . 0 . 0 0 . 
. . . . . 0 . . . . . 
. . . 0 0 . . . . . . 
. . 0 . 0 . . . . . . 
. 0 0 0 0 . 0 0 . . . 
0 0 0 0 0 0 . . . . . 
. 0 0 0 0 0 . 0 0 . . 
. . . . . 0 0 . . 0 0 
. . . . 0 . 0 0 0 . . 
. . . . . . . 0 0 . . 
 with color black at (3,10)
  _011: rectangle with size (5,6) with model Full with color yellow at (3,4)
  + 171 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21

TRAIN 890034e9.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (21,21) with mask 
. . 0 . 0 0 0 0 . . 0 . 0 . . 0 0 0 . 0 . 
0 0 0 . . 0 . 0 . 0 0 0 0 . 0 0 0 . . 0 0 
0 0 0 . . . 0 0 0 0 0 . 0 0 0 . 0 0 . 0 0 
. . 0 0 0 0 0 0 0 0 0 . 0 0 0 . . 0 0 0 0 
. . 0 . 0 0 . . 0 0 . 0 0 . . 0 . 0 0 0 . 
0 . . 0 0 . 0 0 0 0 0 . 0 . . 0 0 . . . . 
. 0 0 . . . 0 0 . 0 0 . 0 . . 0 0 . 0 0 0 
0 0 0 . . 0 . 0 . . 0 0 . . . 0 . 0 0 0 . 
0 . 0 . 0 . . . 0 0 0 . . . . 0 0 0 . 0 . 
. 0 . . 0 0 . 0 0 0 0 0 0 0 0 0 . 0 0 . 0 
. 0 0 0 . 0 . 0 0 0 0 . 0 0 0 0 . 0 0 0 0 
. 0 0 0 . . 0 . 0 . 0 0 0 0 0 . . 0 0 0 . 
. 0 . . 0 0 0 0 0 0 0 0 0 . . . 0 0 0 0 0 
0 . . . . 0 . . . 0 0 . 0 . . 0 . . 0 0 0 
. . . . . 0 . 0 . 0 . 0 0 0 0 0 0 0 0 0 . 
. . . . . 0 0 . . 0 0 0 . . 0 0 0 . 0 0 0 
. . . . . 0 . . . . 0 . 0 0 0 . 0 . 0 . 0 
. . . . . 0 0 . 0 . 0 . 0 . 0 0 0 0 0 0 0 
. . . . . 0 . . . 0 0 0 0 . 0 0 . . 0 0 0 
. . . . . 0 0 0 0 0 0 0 0 0 0 0 . . 0 0 . 
. . . . 0 . 0 . 0 . 0 0 0 0 0 0 . 0 0 0 0 
 with color blue at (0,0)
  _011: rectangle with size (7,4) with model Border with color green at (13,1)
  + 43 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21

TEST 890034e9.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 64.6 sec (64.6 sec/task)
bits-train-error = 168299.1 bits (168299.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-192] Checking task 8a004b2b.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 364131.4 = 364133.7
DL output with Mo: L = 2.3 + 118426.9 = 118429.2
DL input+output M: L = 4.6 + 482558.3 = 482563.0

# learning a model for train pairs
2.000	
1.090	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.462	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.264	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.214	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.166	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.147	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.130	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.116	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.107	OUT ADD ^.layer_010 = ^.layer_01.shape at (?,?)
0.100	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.092	OUT ADD ^.layer_0101 = ^.layer_011.shape at (?,?)
0.089	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.083	OUT ADD ^.layer_01111 = point with color ? at (?,?)
0.079	OUT SPE ^.layer_0111.pos.j = '0
0.076	OUT SPE ^.layer_011.shape.mask = 
0 

0.074	OUT SPE ^.layer_011.pos = '(0, 0)
0.072	IN  ADD ^.layer_00 = point with color ? at (?,?)
0.070	IN  ADD ^.layer_001 = point with color ? at (?,?)
0.068	OUT SPE ^.layer_011.shape.color = yellow
0.067	OUT SPE ^.layer_0111.shape.color = yellow
0.066	OUT SPE ^.layer_01111.shape.color = yellow
0.063	OUT SPE ^.layer_010.pos = '(0, 0) + ^.layer_01.pos - ^.layer_00.pos
0.061	OUT SPE ^.layer_01111.pos = '(0, 0) + ^.layer_001.pos - ^.layer_00.pos
0.059	OUT SPE ^.size.j = area(^.layer_00.shape) - ^.layer_00.pos.j - ^.layer_001.pos.j
0.058	OUT SPE ^.layer_0111.pos.i = middle(^.layer_00) + area(^.layer_0.shape)
0.057	OUT SPE ^.layer_01.shape.mask.model = Full
0.028	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,area(^.layer_00.shape) - ^.layer_00.pos.j - ^.layer_001.pos.j) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01.shape at '(0, 0) + ^.layer_01.pos - ^.layer_00.pos
  _0101: ^.layer_011.shape at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: 
0 
 with color yellow at '(0, 0)
  _0111: point with color yellow at (middle(^.layer_00) + area(^.layer_0.shape),'0)
  _01111: point with color yellow at '(0, 0) + ^.layer_001.pos - ^.layer_00.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: point with color ? at (?,?)
  _001: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 161.3 + 10597.2 = 10758.5
DL output with Mo: L = 386.0 + 2870.9 = 3256.8
DL input+output M: L = 547.2 + 13468.0 = 14015.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,area(^.layer_00.shape) - ^.layer_00.pos.j - ^.layer_001.pos.j) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01.shape at '(0, 0) + ^.layer_01.pos - ^.layer_00.pos
  _0101: ^.layer_011.shape at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: 
0 
 with color yellow at '(0, 0)
  _0111: point with color yellow at (middle(^.layer_00) + area(^.layer_0.shape),'0)
  _01111: point with color yellow at '(0, 0) + ^.layer_001.pos - ^.layer_00.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: point with color ? at (?,?)
  _001: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 161.3 + 63.4 = 224.7
DL output with Mo: L = 386.0 + 2870.9 = 3256.8
DL input+output M: L = 547.2 + 2934.3 = 3481.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (17,17) and color black and layers
  _00: point with color yellow at (0,2)
  _001: point with color yellow at (0,15)
  _0: rectangle with size (2,5) with mask 
0 0 . 0 0 
. 0 0 0 . 
 with color blue at (13,2)
  _01: rectangle with size (2,2) with model Full with color green at (2,3)
  _011: rectangle with size (2,2) with model Full with color red at (2,11)
  _0111: rectangle with size (2,2) with model Full with color blue at (6,7)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (9,14) and color black and layers
  _0: rectangle with size (4,10) with mask 
0 0 0 0 . . 0 0 0 0 
0 0 0 0 . . 0 0 0 0 
. . 0 0 0 0 0 0 . . 
. . 0 0 0 0 0 0 . . 
 with color blue at (4,1)
  _010: 
3 3 
3 3 
 at (2,1)
  _0101: 
2 2 
2 2 
 at (2,9)
  _01: rectangle with size (1,1) with model Full with color yellow at (8,13)
  _011: 
0 
 with color yellow at (0,0)
  _0111: point with color yellow at (8,0)
  _01111: point with color yellow at (0,13)
diff: 
   (120.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,17) and color black and layers
  _00: point with color yellow at (0,2)
  _001: point with color yellow at (0,15)
  _0: rectangle with size (2,5) with mask 
0 0 . 0 0 
. 0 0 0 . 
 with color blue at (13,2)
  _01: rectangle with size (2,2) with model Full with color green at (2,3)
  _011: rectangle with size (2,2) with model Full with color red at (2,11)
  _0111: rectangle with size (2,2) with model Full with color blue at (6,7)
  + 4 delta pixels
diff: 
! size mismatch, 10x14 instead of 9x14

TRAIN 8a004b2b.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (17,18) and color black and layers
  _00: point with color yellow at (1,2)
  _001: point with color yellow at (1,8)
  _0: rectangle with size (2,2) with model Full with color red at (2,3)
  _01: rectangle with size (2,2) with model Full with color cyan at (4,5)
  _011: rectangle with size (1,1) with model Full with color yellow at (7,2)
  _0111: rectangle with size (2,2) with model Odd Checkboard with color green at (13,10)
  + 3 delta pixels
diff: 
   (3.2 bits)
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (2,2) with model Full with color red at (1,1)
  _010: 
8 8 
8 8 
 at (3,3)
  _0101: 
4 
 at (6,6)
  _01: rectangle with size (4,4) with model Full with color green at (1,1)
  _011: 
0 
 with color yellow at (0,0)
  _0111: point with color yellow at (6,0)
  _01111: point with color yellow at (0,6)
diff: 
   (81.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,18) and color black and layers
  _00: point with color yellow at (1,2)
  _001: point with color yellow at (1,8)
  _0: rectangle with size (2,2) with model Full with color red at (2,3)
  _01: rectangle with size (2,2) with model Full with color cyan at (4,5)
  _011: rectangle with size (2,2) with model Odd Checkboard with color green at (13,10)
  _0111: rectangle with size (1,1) with model Full with color yellow at (7,2)
  + 3 delta pixels
diff: 
! size mismatch, 10x7 instead of 7x7

TRAIN 8a004b2b.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (16,18) and color black and layers
  _00: point with color yellow at (0,3)
  _001: point with color yellow at (0,13)
  _0: rectangle with size (3,3) with model Full with color blue at (3,10)
  _01: rectangle with size (3,3) with model Full with color red at (3,4)
  _011: rectangle with size (3,3) with model Full with color green at (6,7)
  _0111: rectangle with size (2,2) with model Full with color blue at (13,7)
  + 4 delta pixels
diff: 
   (3.2 bits)
data: a background with size (11,11) and color black and layers
  _0: rectangle with size (1,1) with model Full with color yellow at (10,10)
  _010: 
2 2 2 
2 2 2 
2 2 2 
 at (3,1)
  _0101: 
3 3 3 
3 3 3 
3 3 3 
 at (6,4)
  _01: rectangle with size (6,6) with model Full with color blue at (3,4)
  _011: 
0 
 with color yellow at (0,0)
  _0111: point with color yellow at (10,0)
  _01111: point with color yellow at (0,10)
diff: 
   (85.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,18) and color black and layers
  _00: point with color yellow at (0,3)
  _001: point with color yellow at (0,13)
  _0: rectangle with size (3,3) with model Full with color red at (3,4)
  _01: rectangle with size (3,3) with model Full with color blue at (3,10)
  _011: rectangle with size (3,3) with model Full with color green at (6,7)
  _0111: rectangle with size (2,2) with model Full with color blue at (13,7)
  + 4 delta pixels
diff: 
! size mismatch, 10x11 instead of 11x11
>> Trial 2
data: a background with size (16,18) and color black and layers
  _00: point with color yellow at (0,3)
  _001: point with color yellow at (0,13)
  _0: rectangle with size (3,3) with model Full with color red at (3,4)
  _01: rectangle with size (3,3) with model Full with color green at (6,7)
  _011: rectangle with size (3,3) with model Full with color blue at (3,10)
  _0111: rectangle with size (2,2) with model Full with color blue at (13,7)
  + 4 delta pixels
diff: 
! size mismatch, 10x11 instead of 11x11
>> Trial 3
data: a background with size (16,18) and color black and layers
  _00: point with color yellow at (0,3)
  _001: point with color yellow at (0,13)
  _0: rectangle with size (3,3) with model Full with color blue at (3,10)
  _01: rectangle with size (3,3) with model Full with color red at (3,4)
  _011: rectangle with size (3,3) with model Full with color green at (6,7)
  _0111: rectangle with size (2,2) with model Full with color blue at (13,7)
  + 4 delta pixels
diff: 
! size mismatch, 10x11 instead of 11x11

TRAIN 8a004b2b.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,18) and color black and layers
  _00: point with color yellow at (0,0)
  _001: point with color yellow at (0,17)
  _0: rectangle with size (4,4) with model Full with color cyan at (2,4)
  _01: rectangle with size (4,4) with model Full with color green at (2,12)
  _011: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color blue at (16,8)
  _0111: rectangle with size (1,1) with model Full with color yellow at (13,0)
  + 3 delta pixels
diff: 
! size mismatch, 10x18 instead of 14x18
>> Trial 2
data: a background with size (19,18) and color black and layers
  _00: point with color yellow at (0,0)
  _001: point with color yellow at (0,17)
  _0: rectangle with size (4,4) with model Full with color cyan at (2,4)
  _01: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color blue at (16,8)
  _011: rectangle with size (4,4) with model Full with color green at (2,12)
  _0111: rectangle with size (1,1) with model Full with color yellow at (13,0)
  + 3 delta pixels
diff: 
! size mismatch, 10x18 instead of 14x18

TEST 8a004b2b.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.2 sec (59.2 sec/task)
bits-train-error = 2870.9 bits (2870.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-191] Checking task 8be77c9e.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 10534.8 = 10537.1
DL output with Mo: L = 2.3 + 20923.3 = 20925.6
DL input+output M: L = 4.6 + 31458.1 = 31462.7

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = unfoldSym( [ id ] [ flipHeight ], ^)
0.406	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.132	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.117	IN  SPE ^.layer_0.shape.color = blue
0.110	IN  SPE ^.color = black
0.005	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
unfoldSym( [ id ] [ flipHeight ], ^)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color blue at (?,?)

DL input  with Mi: L = 45.4 + 1103.0 = 1148.4
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 56.7 + 1103.0 = 1159.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
unfoldSym( [ id ] [ flipHeight ], ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 13.6 + 0.0 = 13.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
1 1 0 
1 1 1 
0 0 0 

diff: 
   (0.0 bits)
data: 
1 1 0 
1 1 1 
0 0 0 
0 0 0 
1 1 1 
1 1 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 0 
1 1 1 
0 0 0 

diff: 
correct output grid

TRAIN 8be77c9e.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 0 0 
1 0 1 
1 1 0 

diff: 
   (0.0 bits)
data: 
0 0 0 
1 0 1 
1 1 0 
1 1 0 
1 0 1 
0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 
1 0 1 
1 1 0 

diff: 
correct output grid

TRAIN 8be77c9e.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 0 0 
0 0 1 
0 0 1 

diff: 
   (0.0 bits)
data: 
0 0 0 
0 0 1 
0 0 1 
0 0 1 
0 0 1 
0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 
0 0 1 
0 0 1 

diff: 
correct output grid

TRAIN 8be77c9e.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 
0 0 1 
1 0 0 

diff: 
correct output grid

TEST 8be77c9e.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.0 sec (1.0 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-190] Checking task 8d5021e8.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 7119.2 = 7121.6
DL output with Mo: L = 2.3 + 42126.8 = 42129.1
DL input+output M: L = 4.6 + 49246.0 = 49250.7

# learning a model for train pairs
2.000	
1.346	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.729	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.551	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.404	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.389	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.353	IN  SPE ^.layer_0.shape.mask = 
0 

0.341	OUT SPE ^.size = tiling(^.size, 3, 2)
0.329	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.325	OUT SPE ^.layer_0.shape.color = majorityColor(^)
0.321	OUT SPE ^.layer_01.shape.color = majorityColor(^)
0.318	OUT SPE ^.layer_0.pos.i = '0
0.314	OUT SPE ^.layer_01.pos = projI(^.layer_01.pos) * '2
0.312	OUT SPE ^.color = black
0.311	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.292	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.288	OUT SPE ^.layer_011.shape.color = majorityColor(^)
0.285	OUT SPE ^.layer_0111.shape.color = majorityColor(^)
0.282	OUT SPE ^.layer_011.pos.j = '0
0.279	OUT SPE ^.layer_011.shape.mask.size.i = 1
0.277	OUT SPE ^.layer_0.pos.j = middle(^.layer_0) + ^.layer_01.pos.j - ^.layer_0.pos.j
0.275	OUT SPE ^.layer_0.shape.mask.model = Full
0.273	OUT SPE ^.layer_011.shape.mask.model = Full
0.271	OUT SPE ^.layer_0111.shape.mask.model = Full
0.269	OUT SPE ^.layer_0111.pos.j = min(^.layer_0.pos.i, ^.layer_01.pos.i) * '3
0.091	

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size tiling(^.size, 3, 2) and color black and layers
  _0: rectangle with size (?,?) with model Full with color majorityColor(^) at ('0,middle(^.layer_0) + ^.layer_01.pos.j - ^.layer_0.pos.j)
  _01: rectangle with size (?,?) with model ? with color majorityColor(^) at projI(^.layer_01.pos) * '2
  _011: rectangle with size (1,?) with model Full with color majorityColor(^) at (?,'0)
  _0111: rectangle with size (?,?) with model Full with color majorityColor(^) at (?,min(^.layer_0.pos.i, ^.layer_01.pos.i) * '3)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 
 with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 52.6 + 1287.7 = 1340.3
DL output with Mo: L = 288.3 + 3131.9 = 3420.1
DL input+output M: L = 340.9 + 4419.6 = 4760.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size tiling(^.size, 3, 2) and color black and layers
  _0: rectangle with size (?,?) with model Full with color majorityColor(^) at ('0,middle(^.layer_0) + ^.layer_01.pos.j - ^.layer_0.pos.j)
  _01: rectangle with size (?,?) with model ? with color majorityColor(^) at projI(^.layer_01.pos) * '2
  _011: rectangle with size (1,?) with model Full with color majorityColor(^) at (?,'0)
  _0111: rectangle with size (?,?) with model Full with color majorityColor(^) at (?,min(^.layer_0.pos.i, ^.layer_01.pos.i) * '3)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 
 with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 52.6 + 20.0 = 72.6
DL output with Mo: L = 288.3 + 3131.9 = 3420.1
DL input+output M: L = 340.9 + 3151.9 = 3492.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,2) and color black and layers
  _0: 
0 
 with color cyan at (2,1)
  _01: point with color cyan at (0,1)
diff: 
   (2.0 bits)
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (9,1) with model Full with color cyan at (0,3)
  _01: rectangle with size (1,1) with model Full with color cyan at (0,0)
  _011: rectangle with size (1,1) with model Full with color cyan at (8,0)
  _0111: rectangle with size (5,1) with model Full with color cyan at (2,0)
  + 4 delta pixels
diff: 
   (204.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,2) and color black and layers
  _0: 
0 
 with color cyan at (0,1)
  _01: point with color cyan at (2,1)
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,2) and color black and layers
  _0: 
0 
 with color cyan at (2,1)
  _01: point with color cyan at (0,1)
diff: 
! 14 wrong pixels (generated / expected)

TRAIN 8d5021e8.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,2) and color red and layers
  _0: 
0 
 with color black at (0,1)
  _01: point with color black at (2,1)
diff: 
   (0.0 bits)
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (9,2) with model Full with color red at (0,1)
  _01: rectangle with size (1,4) with model Full with color red at (4,0)
  _011: rectangle with size (1,4) with model Full with color red at (1,0)
  _0111: rectangle with size (1,4) with model Full with color red at (7,0)
diff: 
   (57.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,2) and color red and layers
  _0: 
0 
 with color black at (0,1)
  _01: point with color black at (2,1)
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,2) and color red and layers
  _0: 
0 
 with color black at (2,1)
  _01: point with color black at (0,1)
diff: 
! 22 wrong pixels (generated / expected)

TRAIN 8d5021e8.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,2) and color black and layers
  _0: 
0 
 with color grey at (1,1)
  _01: point with color grey at (2,0)
diff: 
   (0.0 bits)
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (1,2) with model Full with color grey at (0,1)
  _01: rectangle with size (4,4) with model x-cross with color grey at (4,0)
  _011: rectangle with size (1,1) with model Full with color grey at (1,0)
  _0111: rectangle with size (1,1) with model Full with color grey at (1,3)
diff: 
   (50.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,2) and color black and layers
  _0: 
0 
 with color grey at (1,1)
  _01: point with color grey at (2,0)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,2) and color black and layers
  _0: 
0 
 with color grey at (2,0)
  _01: point with color grey at (1,1)
diff: 
! 16 wrong pixels (generated / expected)

TRAIN 8d5021e8.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,2) and color black and layers
  _0: 
0 
0 
0 
 with color green at (0,0)
  _01: point with color green at (0,1)
  + 1 delta pixels
diff:   ^.layer_0.shape.mask
! 28 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,2) and color black and layers
  _0: 
0 
0 
0 
 with color green at (0,0)
  _01: point with color green at (2,1)
  + 1 delta pixels
diff:   ^.layer_0.shape.mask
! 26 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,2) and color black and layers
  _0: 
0 0 
 with color green at (0,0)
  _01: point with color green at (1,0)
  + 2 delta pixels
diff:   ^.layer_0.shape.mask
! 22 wrong pixels (generated / expected)

TEST 8d5021e8.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 9.3 sec (9.3 sec/task)
bits-train-error = 3131.9 bits (3131.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-189] Checking task 8d510a79.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79850.6 = 79852.9
DL output with Mo: L = 2.3 + 79850.6 = 79852.9
DL input+output M: L = 4.6 + 159701.1 = 159705.8

# learning a model for train pairs
2.000	
1.191	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.501	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.410	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.311	OUT ADD ^.layer_0 = ^.layer_0
0.279	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.248	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.221	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.208	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.195	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.183	OUT ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.175	OUT ADD ^.layer_01111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.169	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.164	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.158	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.153	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.147	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.141	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.136	IN  ADD ^.layer_01111111 = point with color ? at (?,?)
0.131	OUT SPE ^.size = ^.size
0.126	IN  SPE ^.layer_0.shape.mask = 
0 0 0 0 0 0 0 0 0 0 

0.124	OUT SPE ^.layer_01111.shape.mask = 
0 
0 

0.121	OUT SPE ^.layer_011111.shape.mask = 
0 
0 

0.118	OUT SPE ^.layer_0111111.shape.mask = 
0 
0 

0.115	OUT SPE ^.layer_0111111.pos = ^.layer_01111111.pos
0.060	
0.060	IN  GEN ^.layer_0.shape.mask = rectangle with size (?,?) with model ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: 
0 
0 
 with color ? at (?,?)
  _011111: 
0 
0 
 with color ? at (?,?)
  _0111111: 
0 
0 
 with color ? at ^.layer_01111111.pos
  _01111111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 0 0 0 0 0 0 0 0 0 
 with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)

DL input  with Mi: L = 167.4 + 4400.2 = 4567.6
DL output with Mo: L = 199.9 + 4429.1 = 4629.1
DL input+output M: L = 367.4 + 8829.3 = 9196.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: 
0 
0 
 with color ? at (?,?)
  _011111: 
0 
0 
 with color ? at (?,?)
  _0111111: 
0 
0 
 with color ? at ^.layer_01111111.pos
  _01111111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)

DL input  with Mi: L = 167.1 + 20.0 = 187.1
DL output with Mo: L = 199.9 + 4429.1 = 4629.1
DL input+output M: L = 367.0 + 4449.1 = 4816.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color grey at (5,0)
  _01: point with color blue at (0,2)
  _011: point with color blue at (1,6)
  _0111: point with color red at (2,1)
  _01111: point with color red at (2,9)
  _011111: point with color blue at (8,1)
  _0111111: point with color red at (8,5)
  _01111111: point with color blue at (8,8)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
5#5#5#5#5#5#5#5#5#5#
 at (5,0)
  _01: rectangle with size (3,1) with model Full with color red at (2,1)
  _011: rectangle with size (3,1) with model Full with color red at (2,9)
  _0111: rectangle with size (3,1) with model Full with color red at (6,5)
  _01111: 
0 
0 
 with color blue at (0,6)
  _011111: 
0 
0 
 with color blue at (8,1)
  _0111111: 
0 
0 
 with color blue at (8,8)
  _01111111: rectangle with size (1,1) with model Full with color blue at (0,2)
diff: 
   (157.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color grey at (5,0)
  _01: point with color blue at (0,2)
  _011: point with color blue at (1,6)
  _0111: point with color red at (2,1)
  _01111: point with color red at (2,9)
  _011111: point with color blue at (8,1)
  _0111111: point with color red at (8,5)
  _01111111: point with color blue at (8,8)
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color grey at (5,0)
  _01: point with color blue at (0,2)
  _011: point with color blue at (1,6)
  _0111: point with color red at (2,1)
  _01111: point with color red at (2,9)
  _011111: point with color blue at (8,1)
  _0111111: point with color blue at (8,8)
  _01111111: point with color red at (8,5)
diff: 
! 21 wrong pixels (generated / expected)

TRAIN 8d510a79.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color grey at (3,0)
  _01: point with color red at (0,1)
  _011: point with color blue at (0,3)
  _0111: point with color red at (1,5)
  _01111: point with color blue at (1,7)
  _011111: point with color red at (5,1)
  _0111111: point with color red at (5,9)
  _01111111: point with color blue at (8,2)
  + 3 delta pixels
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
5#5#5#5#5#5#5#5#5#5#
 at (3,0)
  _01: rectangle with size (6,1) with model Full with color red at (0,1)
  _011: rectangle with size (5,1) with model Full with color red at (4,6)
  _0111: rectangle with size (4,1) with model Full with color blue at (6,4)
  _01111: 
0 
0 
 with color blue at (0,7)
  _011111: 
0 
0 
 with color red at (1,5)
  _0111111: 
0 
0 
 with color blue at (8,2)
  _01111111: rectangle with size (2,1) with model Full with color red at (4,9)
  + 3 delta pixels
diff: 
   (285.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color grey at (3,0)
  _01: point with color red at (0,1)
  _011: point with color blue at (0,3)
  _0111: point with color red at (1,5)
  _01111: point with color blue at (1,7)
  _011111: point with color red at (5,1)
  _0111111: point with color red at (5,9)
  _01111111: point with color blue at (6,4)
  + 3 delta pixels
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color grey at (3,0)
  _01: point with color red at (0,1)
  _011: point with color blue at (0,3)
  _0111: point with color red at (1,5)
  _01111: point with color blue at (1,7)
  _011111: point with color red at (5,1)
  _0111111: point with color red at (5,9)
  _01111111: point with color blue at (8,2)
  + 3 delta pixels
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color grey at (3,0)
  _01: point with color red at (0,1)
  _011: point with color blue at (0,3)
  _0111: point with color red at (1,5)
  _01111: point with color blue at (1,7)
  _011111: point with color red at (5,1)
  _0111111: point with color blue at (6,4)
  _01111111: point with color red at (5,9)
  + 3 delta pixels
diff: 
! 28 wrong pixels (generated / expected)

TRAIN 8d510a79.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color grey at (4,0)
  _01: point with color red at (1,1)
  _011: point with color blue at (1,3)
  _0111: point with color red at (1,8)
  _01111: point with color blue at (2,6)
  _011111: point with color blue at (7,2)
  _0111111: point with color red at (7,5)
  _01111111: point with color red at (8,0)
  + 1 delta pixels
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color grey at (4,0)
  _01: point with color red at (1,1)
  _011: point with color blue at (1,3)
  _0111: point with color red at (1,8)
  _01111: point with color blue at (2,6)
  _011111: point with color blue at (7,2)
  _0111111: point with color red at (7,5)
  _01111111: point with color blue at (9,8)
  + 1 delta pixels
diff: 
! 25 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color grey at (4,0)
  _01: point with color red at (1,1)
  _011: point with color blue at (1,3)
  _0111: point with color red at (1,8)
  _01111: point with color blue at (2,6)
  _011111: point with color blue at (7,2)
  _0111111: point with color red at (8,0)
  _01111111: point with color red at (7,5)
  + 1 delta pixels
diff: 
! 26 wrong pixels (generated / expected)

TEST 8d510a79.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 67.6 sec (67.6 sec/task)
bits-train-error = 4429.1 bits (4429.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-188] Checking task 8e1813be.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 217287.6 = 217289.9
DL output with Mo: L = 2.3 + 23753.5 = 23755.9
DL input+output M: L = 4.6 + 241041.1 = 241045.8

# learning a model for train pairs
2.000	
1.381	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.180	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.011	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.841	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.714	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.600	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.532	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.470	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.424	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.401	OUT SPE ^.layer_011.shape = scaleTo(^.layer_011.shape, min(^.layer_0.shape.mask.size, ^.layer_01.shape.mask.size))
0.385	OUT SPE ^.layer_01.shape.mask = scaleTo(^.layer_01.shape.mask, min(^.layer_0.shape.mask.size, ^.layer_01.shape.mask.size))
0.373	OUT SPE ^.layer_0.shape.mask.size = min(^.layer_0.shape.mask.size, ^.layer_01.shape.mask.size)
0.362	OUT SPE ^.layer_0.pos = '(0, 0)
0.356	OUT SPE ^.layer_01.pos.j = ^.layer_01.pos.j
0.351	OUT SPE ^.layer_011.pos.j = ^.layer_0111.pos.j
0.347	OUT SPE ^.layer_01.pos.i = min(^.layer_0.pos.i, ^.layer_0111.pos.i)
0.344	OUT SPE ^.layer_0.shape.mask.model = Full
0.343	IN  SPE ^.layer_0.shape.mask.model = Full
0.343	IN  SPE ^.layer_01.shape.mask.model = Full
0.343	IN  SPE ^.layer_011.shape.mask.model = Full
0.342	IN  SPE ^.layer_0111.shape.mask.model = Full
0.342	IN  SPE ^.color = black
0.253	
0.253	IN  GEN ^.layer_0111.shape.mask.model = ?
0.253	IN  GEN ^.layer_011.shape.mask.model = ?
0.253	IN  GEN ^.layer_01.shape.mask.model = ?
0.253	IN  GEN ^.layer_0.shape.mask.model = ?
0.253	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size min(^.layer_0.shape.mask.size, ^.layer_01.shape.mask.size) with model Full with color ? at '(0, 0)
  _01: scaleTo(^.layer_01.shape.mask, min(^.layer_0.shape.mask.size, ^.layer_01.shape.mask.size)) with color ? at (min(^.layer_0.pos.i, ^.layer_0111.pos.i),^.layer_01.pos.j)
  _011: scaleTo(^.layer_011.shape, min(^.layer_0.shape.mask.size, ^.layer_01.shape.mask.size)) at (?,^.layer_0111.pos.j)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 128.0 + 19362.7 = 19490.6
DL output with Mo: L = 230.2 + 5758.9 = 5989.1
DL input+output M: L = 358.2 + 25121.5 = 25479.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size min(^.layer_0.shape.mask.size, ^.layer_01.shape.mask.size) with model Full with color ? at '(0, 0)
  _01: scaleTo(^.layer_01.shape.mask, min(^.layer_0.shape.mask.size, ^.layer_01.shape.mask.size)) with color ? at (min(^.layer_0.pos.i, ^.layer_0111.pos.i),^.layer_01.pos.j)
  _011: scaleTo(^.layer_011.shape, min(^.layer_0.shape.mask.size, ^.layer_01.shape.mask.size)) at (?,^.layer_0111.pos.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 95.1 = 220.9
DL output with Mo: L = 230.2 + 5758.9 = 5989.1
DL input+output M: L = 356.0 + 5854.0 = 6210.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (18,15) and color black and layers
  _0: rectangle with size (6,6) with model Full with color grey at (10,1)
  _01: rectangle with size (1,15) with model Full with color red at (2,0)
  _011: rectangle with size (1,15) with model Full with color green at (8,0)
  _0111: rectangle with size (1,15) with model Full with color blue at (5,0)
  + 29 delta pixels
diff: 
   (3.2 bits)
data: a background with size (6,6) and color blue and layers
  _0: rectangle with size (1,6) with model Full with color red at (0,0)
  _01: 
0 0 0 0 0 0 
 with color pink at (5,0)
  _011: 
3 3 3 3 3 3 
 at (2,0)
  + 12 delta pixels
diff: 
   (506.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,15) and color black and layers
  _0: rectangle with size (6,6) with model Full with color grey at (10,1)
  _01: rectangle with size (1,15) with model Full with color red at (2,0)
  _011: rectangle with size (1,15) with model Full with color blue at (5,0)
  _0111: rectangle with size (1,15) with model Full with color green at (8,0)
  + 29 delta pixels
diff: 
! size mismatch, 10x10 instead of 6x6
>> Trial 2
data: a background with size (18,15) and color black and layers
  _0: rectangle with size (6,6) with model Full with color grey at (10,1)
  _01: rectangle with size (1,15) with model Full with color red at (2,0)
  _011: rectangle with size (1,15) with model Full with color blue at (5,0)
  _0111: rectangle with size (1,15) with model Full with color pink at (17,0)
  + 29 delta pixels
diff: 
! size mismatch, 10x10 instead of 6x6
>> Trial 3
data: a background with size (18,15) and color black and layers
  _0: rectangle with size (6,6) with model Full with color grey at (10,1)
  _01: rectangle with size (1,15) with model Full with color red at (2,0)
  _011: rectangle with size (1,15) with model Full with color green at (8,0)
  _0111: rectangle with size (1,15) with model Full with color blue at (5,0)
  + 29 delta pixels
diff: 
! size mismatch, 10x10 instead of 6x6

TRAIN 8e1813be.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (12,10) and color black and layers
  _0: rectangle with size (12,1) with model Full with color red at (0,5)
  _01: rectangle with size (3,3) with model Full with color grey at (1,1)
  _011: rectangle with size (12,1) with model Full with color yellow at (0,8)
  _0111: rectangle with size (7,1) with model Full with color blue at (5,2)
diff: 
   (3.2 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,1) with model Full with color blue at (0,0)
  _01: 
0 
0 
0 
 with color red at (0,1)
  _011: 
4 
4 
4 
 at (0,2)
diff: 
   (30.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,10) and color black and layers
  _0: rectangle with size (12,1) with model Full with color red at (0,5)
  _01: rectangle with size (12,1) with model Full with color yellow at (0,8)
  _011: rectangle with size (3,3) with model Full with color grey at (1,1)
  _0111: rectangle with size (7,1) with model Full with color blue at (5,2)
diff: 
! size mismatch, 10x10 instead of 3x3
>> Trial 2
data: a background with size (12,10) and color black and layers
  _0: rectangle with size (12,1) with model Full with color red at (0,5)
  _01: rectangle with size (12,1) with model Full with color yellow at (0,8)
  _011: rectangle with size (7,1) with model Full with color blue at (5,2)
  _0111: rectangle with size (3,3) with model Full with color grey at (1,1)
diff: 
! size mismatch, 10x10 instead of 3x3
>> Trial 3
data: a background with size (12,10) and color black and layers
  _0: rectangle with size (12,1) with model Full with color red at (0,5)
  _01: rectangle with size (3,3) with model Full with color grey at (1,1)
  _011: rectangle with size (12,1) with model Full with color yellow at (0,8)
  _0111: rectangle with size (7,1) with model Full with color blue at (5,2)
diff: 
! size mismatch, 10x10 instead of 3x3

TRAIN 8e1813be.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (4,4) with model Full with color grey at (1,6)
  _01: rectangle with size (1,12) with model Full with color blue at (10,0)
  _011: rectangle with size (1,12) with model Full with color yellow at (7,0)
  _0111: rectangle with size (1,5) with model Full with color red at (1,0)
  + 7 delta pixels
diff: 
   (3.2 bits)
data: a background with size (4,4) and color blue and layers
  _0: rectangle with size (1,4) with model Full with color red at (0,0)
  _01: 
0 0 0 0 
 with color cyan at (1,0)
  _011: 
4 4 4 4 
 at (2,0)
diff: 
   (39.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (4,4) with model Full with color grey at (1,6)
  _01: rectangle with size (1,12) with model Full with color yellow at (7,0)
  _011: rectangle with size (1,12) with model Full with color blue at (10,0)
  _0111: rectangle with size (1,5) with model Full with color red at (1,0)
  + 7 delta pixels
diff: 
! size mismatch, 10x10 instead of 4x4

TRAIN 8e1813be.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,19) and color black and layers
  _0: rectangle with size (7,7) with model Full with color grey at (1,8)
  _01: rectangle with size (1,19) with model Full with color yellow at (9,0)
  _011: rectangle with size (1,19) with model Full with color pink at (12,0)
  _0111: rectangle with size (1,19) with model Full with color blue at (15,0)
  + 49 delta pixels
diff: 
! size mismatch, 10x10 instead of 7x7

TEST 8e1813be.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 13.1 sec (13.1 sec/task)
bits-train-error = 5758.9 bits (5758.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-187] Checking task 8e5a5113.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 38563.4 = 38565.7
DL output with Mo: L = 2.3 + 38563.4 = 38565.7
DL input+output M: L = 4.6 + 77126.8 = 77131.4

# learning a model for train pairs
2.000	
1.464	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.022	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.898	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.832	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.743	OUT ADD ^.layer_0 = ^.layer_01
0.662	OUT ADD ^.layer_01 = ^.layer_01.shape at (?,?)
0.595	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.529	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.446	OUT ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.379	IN  ADD ^.layer_010 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.314	OUT ADD ^.layer_010 = ^.layer_0
0.295	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.271	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.250	OUT ADD ^.layer_01111 = ^.layer_0111
0.238	OUT ADD ^.layer_01110 = ^.layer_0111.shape at (?,?)
0.225	OUT SPE ^.size = ^.size
0.213	OUT SPE ^.layer_0111.shape = ^.layer_0111.shape
0.203	IN  SPE ^.layer_01.shape.mask = 
0 
0 
0 

0.190	IN  SPE ^.layer_011.shape.mask = 
0 
0 
0 

0.181	OUT SPE ^.layer_00.shape.mask.size = ^.layer_0.shape.mask.size
0.174	OUT SPE ^.layer_01 = ^.layer_011
0.167	OUT SPE ^.layer_0111.pos = ^.layer_0111.pos + translationSym(rotate180, ^.layer_0111, ^)
0.160	OUT SPE ^.color = ^.layer_010.shape.color
0.156	IN  SPE ^.layer_01.shape.color = grey
0.151	IN  SPE ^.layer_011.shape.color = grey
0.057	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.layer_010.shape.color and layers
  _00: rectangle with size ^.layer_0.shape.mask.size with model ? with color ? at (?,?)
  _0: ^.layer_01
  _010: ^.layer_0
  _01: ^.layer_011
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01110: ^.layer_0111.shape at (?,?)
  _0111: ^.layer_0111.shape at ^.layer_0111.pos + translationSym(rotate180, ^.layer_0111, ^)
  _01111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: 
0 
0 
0 
 with color grey at (?,?)
  _011: 
0 
0 
0 
 with color grey at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 142.3 + 3715.0 = 3857.2
DL output with Mo: L = 188.2 + 1764.6 = 1952.8
DL input+output M: L = 330.5 + 5479.5 = 5810.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.layer_010.shape.color and layers
  _00: rectangle with size ^.layer_0.shape.mask.size with model ? with color ? at (?,?)
  _0: ^.layer_01
  _010: ^.layer_0
  _01: ^.layer_011
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01110: ^.layer_0111.shape at (?,?)
  _0111: ^.layer_0111.shape at ^.layer_0111.pos + translationSym(rotate180, ^.layer_0111, ^)
  _01111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: 
0 
0 
0 
 with color grey at (?,?)
  _011: 
0 
0 
0 
 with color grey at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 142.3 + 95.1 = 237.4
DL output with Mo: L = 188.2 + 1764.6 = 1952.8
DL input+output M: L = 330.5 + 1859.7 = 2190.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,11) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color yellow at (1,0)
  _010: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
. . 0 
 with color blue at (0,0)
  _01: 
0 
0 
0 
 with color grey at (0,3)
  _011: 
0 
0 
0 
 with color grey at (0,7)
  _0111: point with color red at (0,2)
diff: 
   (3.2 bits)
data: a background with size (3,11) and color blue and layers
  _00: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color yellow at (0,4)
  _0: 
5#
5#
5#
 at (0,3)
  _010: 
4 . 
4 4 
 at (1,0)
  _01: 
5#
5#
5#
 at (0,7)
  _011: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color yellow at (0,9)
  _01110: 
2 
 at (2,6)
  _0111: 
2 
 at (2,8)
  _01111: 
2 
 at (0,2)
diff: 
   (60.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
. . 0 
 with color blue at (0,0)
  _010: rectangle with size (2,2) with model Full with color yellow at (1,0)
  _01: 
0 
0 
0 
 with color grey at (0,3)
  _011: 
0 
0 
0 
 with color grey at (0,7)
  _0111: point with color red at (0,2)
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color yellow at (1,0)
  _010: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
. . 0 
 with color blue at (0,0)
  _01: 
0 
0 
0 
 with color grey at (0,3)
  _011: 
0 
0 
0 
 with color grey at (0,7)
  _0111: point with color red at (0,2)
diff: 
! 11 wrong pixels (generated / expected)

TRAIN 8e5a5113.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,1) with model Full with color pink at (0,0)
  _010: rectangle with size (3,2) with mask 
0 0 
0 0 
0 . 
 with color green at (0,1)
  _01: 
0 
0 
0 
 with color grey at (0,3)
  _011: 
0 
0 
0 
 with color grey at (0,7)
  _0111: point with color red at (2,2)
diff: 
   (3.2 bits)
data: a background with size (3,11) and color green and layers
  _00: rectangle with size (3,1) with model Full with color pink at (0,10)
  _0: 
5#
5#
5#
 at (0,3)
  _010: 
6 
6 
6 
 at (0,0)
  _01: 
5#
5#
5#
 at (0,7)
  _011: rectangle with size (1,3) with model Full with color pink at (0,4)
  _01110: 
2 
 at (2,4)
  _0111: 
2 
 at (0,8)
  _01111: 
2 
 at (2,2)
diff: 
   (55.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 0 
0 0 
0 . 
 with color green at (0,1)
  _010: rectangle with size (3,1) with model Full with color pink at (0,0)
  _01: 
0 
0 
0 
 with color grey at (0,3)
  _011: 
0 
0 
0 
 with color grey at (0,7)
  _0111: point with color red at (2,2)
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,1) with model Full with color pink at (0,0)
  _010: rectangle with size (3,2) with mask 
0 0 
0 0 
0 . 
 with color green at (0,1)
  _01: 
0 
0 
0 
 with color grey at (0,3)
  _011: 
0 
0 
0 
 with color grey at (0,7)
  _0111: point with color red at (2,2)
diff: 
! 12 wrong pixels (generated / expected)

TRAIN 8e5a5113.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,11) and color black and layers
  _0: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color orange at (0,0)
  _010: rectangle with size (3,3) with mask 
. . 0 
. . 0 
0 0 0 
 with color cyan at (0,0)
  _01: 
0 
0 
0 
 with color grey at (0,3)
  _011: 
0 
0 
0 
 with color grey at (0,7)
  _0111: point with color red at (0,0)
diff: 
   (3.2 bits)
data: a background with size (3,11) and color cyan and layers
  _00: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color orange at (0,5)
  _0: 
5#
5#
5#
 at (0,3)
  _010: 
. 7#
7#7#
 at (0,0)
  _01: 
5#
5#
5#
 at (0,7)
  _011: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color orange at (1,9)
  _01110: 
2 
 at (0,6)
  _0111: 
2 
 at (2,10)
  _01111: 
2 
 at (0,0)
diff: 
   (60.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
. . 0 
0 0 0 
 with color cyan at (0,0)
  _010: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color orange at (0,0)
  _01: 
0 
0 
0 
 with color grey at (0,3)
  _011: 
0 
0 
0 
 with color grey at (0,7)
  _0111: point with color red at (0,0)
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color orange at (0,0)
  _010: rectangle with size (3,3) with mask 
. . 0 
. . 0 
0 0 0 
 with color cyan at (0,0)
  _01: 
0 
0 
0 
 with color grey at (0,3)
  _011: 
0 
0 
0 
 with color grey at (0,7)
  _0111: point with color red at (0,0)
diff: 
! 11 wrong pixels (generated / expected)

TRAIN 8e5a5113.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. 0 0 
 with color brown at (0,0)
  _010: rectangle with size (1,2) with model Full with color green at (0,0)
  _01: 
0 
0 
0 
 with color grey at (0,3)
  _011: 
0 
0 
0 
 with color grey at (0,7)
  _0111: point with color red at (2,0)
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (1,2) with model Full with color green at (0,0)
  _010: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. 0 0 
 with color brown at (0,0)
  _01: 
0 
0 
0 
 with color grey at (0,3)
  _011: 
0 
0 
0 
 with color grey at (0,7)
  _0111: point with color red at (2,0)
diff: 
! 9 wrong pixels (generated / expected)

TEST 8e5a5113.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.5 sec (59.5 sec/task)
bits-train-error = 1764.6 bits (1764.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-186] Checking task 8eb1be9a.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 165562.8 = 165565.2
DL output with Mo: L = 2.3 + 165562.8 = 165565.2
DL input+output M: L = 4.6 + 331125.7 = 331130.3

# learning a model for train pairs
2.000	
1.124	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.539	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.391	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.280	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.277	OUT SPE ^.size = ^.size
0.276	OUT SPE ^.layer_0.pos = ^.layer_0.pos - (3, 0)
0.275	OUT SPE ^.layer_0.shape.mask.size.j = ^.layer_0.shape.mask.size.j
0.274	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.274	IN  SPE ^.color = black
0.273	OUT SPE ^.color = black
0.261	
0.261	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,^.layer_0.shape.mask.size.j) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos - (3, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.1 + 2099.2 = 2141.3
DL output with Mo: L = 50.0 + 43085.5 = 43135.4
DL input+output M: L = 92.1 + 45184.7 = 45276.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,^.layer_0.shape.mask.size.j) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos - (3, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 50.0 + 43085.5 = 43135.4
DL input+output M: L = 92.0 + 43085.5 = 43177.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (15,19) and color black and layers
  _0: rectangle with size (3,19) with mask 
. . 0 . . . . . 0 . . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . 
 with color cyan at (4,0)
diff: 
   (0.0 bits)
data: a background with size (15,19) and color black and layers
  _0: rectangle with size (3,19) with mask 
. . 0 . . . . . 0 . . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . 
 with color cyan at (1,0)
  + 100 delta pixels
diff: 
   (4182.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,19) and color black and layers
  _0: rectangle with size (3,19) with mask 
. . 0 . . . . . 0 . . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . 
 with color cyan at (4,0)
diff: 
! 119 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,19) and color black and layers
  _0: rectangle with size (1,19) with model Full with color cyan at (5,0)
  + 6 delta pixels
diff: 
! 119 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,19) and color black and layers
  _0: rectangle with size (2,1) with model Full with color cyan at (4,2)
  + 23 delta pixels
diff: 
! 123 wrong pixels (generated / expected)

TRAIN 8eb1be9a.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,12) and color black and layers
  _0: rectangle with size (3,12) with mask 
0 . 0 . 0 . 0 . 0 . 0 . 
0 0 0 0 0 0 0 0 0 0 0 0 
0 . 0 . 0 . 0 . 0 . 0 . 
 with color red at (3,0)
diff: 
   (0.0 bits)
data: a background with size (10,12) and color black and layers
  _0: rectangle with size (10,12) with mask 
0 . 0 . 0 . 0 . 0 . 0 . 
0 0 0 0 0 0 0 0 0 0 0 0 
0 . 0 . 0 . 0 . 0 . 0 . 
0 . 0 . 0 . 0 . 0 . 0 . 
0 0 0 0 0 0 0 0 0 0 0 0 
0 . 0 . 0 . 0 . 0 . 0 . 
0 . 0 . 0 . 0 . 0 . 0 . 
0 0 0 0 0 0 0 0 0 0 0 0 
0 . 0 . 0 . 0 . 0 . 0 . 
0 . 0 . 0 . 0 . 0 . 0 . 
 with color red at (0,0)
diff: 
   (125.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,12) and color black and layers
  _0: rectangle with size (3,12) with mask 
0 . 0 . 0 . 0 . 0 . 0 . 
0 0 0 0 0 0 0 0 0 0 0 0 
0 . 0 . 0 . 0 . 0 . 0 . 
 with color red at (3,0)
diff: 
! 66 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,12) and color black and layers
  _0: rectangle with size (1,12) with model Full with color red at (4,0)
  + 12 delta pixels
diff: 
! 66 wrong pixels (generated / expected)

TRAIN 8eb1be9a.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,13) and color black and layers
  _0: rectangle with size (3,13) with mask 
. 0 . . 0 . . 0 . . 0 . . 
0 . 0 0 . 0 0 . 0 0 . 0 0 
0 . 0 0 . 0 0 . 0 0 . 0 0 
 with color blue at (3,0)
diff: 
! 101 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,13) and color black and layers
  _0: rectangle with size (2,13) with model Full with color blue at (4,0)
  + 12 delta pixels
diff: 
! 91 wrong pixels (generated / expected)

TEST 8eb1be9a.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 6.3 sec (6.3 sec/task)
bits-train-error = 43085.5 bits (43085.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-185] Checking task 8efcae92.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 499711.3 = 499713.6
DL output with Mo: L = 2.3 + 77616.3 = 77618.6
DL input+output M: L = 4.6 + 577327.6 = 577332.2

# learning a model for train pairs
2.000	
1.138	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.561	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.252	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.230	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.207	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.188	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.175	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.166	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.163	OUT SPE ^.color = blue
0.161	OUT SPE ^.layer_0.shape.color = red
0.158	OUT SPE ^.size.j = ^.layer_01.shape.mask.size.j
0.156	OUT SPE ^.layer_01.shape.color = red
0.154	OUT SPE ^.layer_0.pos.i = 1
0.152	OUT SPE ^.layer_01.pos.j = span(^.layer_01.pos.i, ^.layer_0111.pos.i) + 1
0.151	IN  SPE ^.layer_0.shape.color = blue
0.149	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.147	OUT SPE ^.size.i = min(^.layer_011.shape.mask.size.j, ^.layer_01111.shape.mask.size.j) + 3
0.146	OUT SPE ^.layer_01.pos.i = max(^.layer_01.pos.j, ^.layer_01111.pos.j) - ^.layer_01111.shape.mask.size.i
0.146	IN  SPE ^.layer_01.shape.color = blue
0.145	IN  SPE ^.layer_011.shape.color = blue
0.145	IN  SPE ^.layer_01111.shape.color = red
0.145	IN  SPE ^.layer_0111.shape.mask.model = Full
0.144	IN  SPE ^.layer_01111.shape.mask.model = Full
0.144	IN  SPE ^.color = black
0.089	
0.089	IN  GEN ^.layer_01111.shape.color = ?
0.089	IN  GEN ^.layer_011.shape.color = ?
0.089	IN  GEN ^.layer_01.shape.color = ?
0.089	IN  GEN ^.layer_0.shape.color = ?
0.089	IN  GEN ^.layer_01111.shape.mask.model = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (min(^.layer_011.shape.mask.size.j, ^.layer_01111.shape.mask.size.j) + 3,^.layer_01.shape.mask.size.j) and color blue and layers
  _0: rectangle with size (?,?) with model ? with color red at (1,?)
  _01: point with color red at (max(^.layer_01.pos.j, ^.layer_01111.pos.j) - ^.layer_01111.shape.mask.size.i,span(^.layer_01.pos.i, ^.layer_0111.pos.i) + 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color blue at (?,?)
  _01: rectangle with size (?,?) with model ? with color blue at (?,?)
  _011: rectangle with size (?,?) with model ? with color blue at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color red at (?,?)

DL input  with Mi: L = 167.8 + 27462.9 = 27630.7
DL output with Mo: L = 266.4 + 6644.3 = 6910.7
DL input+output M: L = 434.2 + 34107.2 = 34541.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (min(^.layer_011.shape.mask.size.j, ^.layer_01111.shape.mask.size.j) + 3,^.layer_01.shape.mask.size.j) and color blue and layers
  _0: rectangle with size (?,?) with model ? with color red at (1,?)
  _01: point with color red at (max(^.layer_01.pos.j, ^.layer_01111.pos.j) - ^.layer_01111.shape.mask.size.i,span(^.layer_01.pos.i, ^.layer_0111.pos.i) + 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 154.0 + 51.7 = 205.7
DL output with Mo: L = 266.4 + 6644.3 = 6910.7
DL input+output M: L = 420.5 + 6696.0 = 7116.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (8,8) with model Full with color blue at (1,10)
  _01: rectangle with size (5,6) with mask 
0 0 0 0 0 0 
0 . 0 . 0 0 
0 0 . 0 . 0 
0 . 0 0 0 0 
0 0 0 . 0 0 
 with color blue at (13,6)
  _011: rectangle with size (6,5) with mask 
0 0 0 0 0 
0 0 0 . 0 
0 0 . 0 0 
0 0 0 0 0 
0 . 0 0 0 
0 0 0 0 0 
 with color blue at (3,2)
  _0111: rectangle with size (3,4) with model Full with color red at (14,7)
  _01111: rectangle with size (2,2) with model Full with color red at (4,4)
  + 6 delta pixels
diff: 
   (3.2 bits)
data: a background with size (5,6) and color blue and layers
  _0: rectangle with size (3,4) with mask 
0 . 0 . 
. 0 . 0 
0 . . . 
 with color red at (1,1)
  _01: point with color red at (4,3)
diff: 
   (32.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (8,8) with model Full with color blue at (1,10)
  _01: rectangle with size (6,5) with mask 
0 0 0 0 0 
0 0 0 . 0 
0 0 . 0 0 
0 0 0 0 0 
0 . 0 0 0 
0 0 0 0 0 
 with color blue at (3,2)
  _011: rectangle with size (5,6) with mask 
0 0 0 0 0 0 
0 . 0 . 0 0 
0 0 . 0 . 0 
0 . 0 0 0 0 
0 0 0 . 0 0 
 with color blue at (13,6)
  _0111: rectangle with size (3,4) with model Full with color red at (14,7)
  _01111: rectangle with size (2,2) with model Full with color red at (4,4)
  + 6 delta pixels
diff: 
! size mismatch, 5x5 instead of 5x6
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (8,8) with model Full with color blue at (1,10)
  _01: rectangle with size (6,5) with mask 
0 0 0 0 0 
0 0 0 . 0 
0 0 . 0 0 
0 0 0 0 0 
0 . 0 0 0 
0 0 0 0 0 
 with color blue at (3,2)
  _011: rectangle with size (5,6) with mask 
0 0 0 0 0 0 
0 . 0 . 0 0 
0 0 . 0 . 0 
0 . 0 0 0 0 
0 0 0 . 0 0 
 with color blue at (13,6)
  _0111: rectangle with size (2,2) with model Full with color red at (4,4)
  _01111: rectangle with size (3,4) with model Full with color red at (14,7)
  + 6 delta pixels
diff: 
! size mismatch, 7x5 instead of 5x6
>> Trial 3
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (8,8) with model Full with color blue at (1,10)
  _01: rectangle with size (5,6) with mask 
0 0 0 0 0 0 
0 . 0 . 0 0 
0 0 . 0 . 0 
0 . 0 0 0 0 
0 0 0 . 0 0 
 with color blue at (13,6)
  _011: rectangle with size (6,5) with mask 
0 0 0 0 0 
0 0 0 . 0 
0 0 . 0 0 
0 0 0 0 0 
0 . 0 0 0 
0 0 0 0 0 
 with color blue at (3,2)
  _0111: rectangle with size (3,4) with model Full with color red at (14,7)
  _01111: rectangle with size (2,2) with model Full with color red at (4,4)
  + 6 delta pixels
diff: 
! 7 wrong pixels (generated / expected)

TRAIN 8efcae92.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (9,9) with model Full with color blue at (2,2)
  _01: rectangle with size (7,9) with mask 
0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 0 
0 . 0 0 0 0 0 . 0 
0 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 . 0 0 
0 0 . 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color blue at (13,0)
  _011: rectangle with size (9,6) with model Full with color blue at (3,14)
  _0111: rectangle with size (4,6) with model Full with color blue at (15,11)
  _01111: rectangle with size (1,7) with model Full with color red at (15,1)
  + 23 delta pixels
diff: 
   (2.0 bits)
data: a background with size (9,9) and color blue and layers
  _0: rectangle with size (1,1) with model Full with color red at (1,1)
  _01: point with color red at (0,4)
  + 9 delta pixels
diff: 
   (374.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (9,9) with model Full with color blue at (2,2)
  _01: rectangle with size (7,9) with model Full with color blue at (13,0)
  _011: rectangle with size (9,6) with mask 
0 0 0 0 0 . 
0 0 . 0 0 0 
0 0 0 0 0 0 
0 0 0 . 0 0 
0 0 0 0 0 0 
0 . 0 0 0 0 
0 0 0 0 . 0 
0 . 0 0 0 0 
0 0 0 0 0 0 
 with color blue at (3,14)
  _0111: rectangle with size (4,6) with model Full with color blue at (15,11)
  _01111: rectangle with size (3,1) with model Full with color red at (8,15)
  + 23 delta pixels
diff: 
! size mismatch, 4x9 instead of 9x9
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (9,9) with model Full with color blue at (2,2)
  _01: rectangle with size (7,9) with mask 
0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 0 
0 . 0 0 0 0 0 . 0 
0 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 . 0 0 
0 0 . 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color blue at (13,0)
  _011: rectangle with size (9,6) with model Full with color blue at (3,14)
  _0111: rectangle with size (4,6) with model Full with color blue at (15,11)
  _01111: rectangle with size (1,7) with model Full with color red at (15,1)
  + 23 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (9,9) with model Full with color blue at (2,2)
  _01: rectangle with size (7,9) with mask 
0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 0 
0 . 0 0 0 0 0 . 0 
0 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 . 0 0 
0 0 . 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color blue at (13,0)
  _011: rectangle with size (4,6) with mask 
0 0 0 0 0 0 
0 0 0 . 0 0 
0 . 0 0 0 0 
0 0 0 0 0 0 
 with color blue at (15,11)
  _0111: rectangle with size (9,6) with model Full with color blue at (3,14)
  _01111: rectangle with size (1,7) with model Full with color red at (15,1)
  + 23 delta pixels
diff: 
! 13 wrong pixels (generated / expected)

TRAIN 8efcae92.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (12,9) with model Full with color blue at (2,9)
  _01: rectangle with size (5,17) with model Full with color blue at (15,2)
  _011: rectangle with size (6,6) with mask 
. 0 0 0 0 0 
0 0 0 . 0 0 
0 0 . 0 0 0 
0 0 0 0 0 0 
0 . 0 0 . 0 
0 0 0 0 0 0 
 with color blue at (0,1)
  _0111: rectangle with size (4,4) with model Full with color blue at (10,3)
  _01111: rectangle with size (2,2) with model Full with color red at (1,3)
  + 21 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,17) and color blue and layers
  _0: rectangle with size (1,1) with model Full with color red at (1,13)
  _01: point with color red at (1,7)
  + 6 delta pixels
diff: 
   (257.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (12,9) with model Full with color blue at (2,9)
  _01: rectangle with size (5,17) with model Full with color blue at (15,2)
  _011: rectangle with size (6,6) with mask 
. 0 0 0 0 0 
0 0 0 . 0 0 
0 0 . 0 0 0 
0 0 0 0 0 0 
0 . 0 0 . 0 
0 0 0 0 0 0 
 with color blue at (0,1)
  _0111: rectangle with size (4,4) with model Full with color blue at (10,3)
  _01111: rectangle with size (2,2) with model Full with color red at (1,3)
  + 21 delta pixels
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (12,9) with mask 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 . 
0 0 . 0 0 0 0 0 0 
0 0 0 0 0 . 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 . 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color blue at (2,9)
  _01: rectangle with size (5,17) with model Full with color blue at (15,2)
  _011: rectangle with size (6,6) with model Full with color blue at (0,1)
  _0111: rectangle with size (4,4) with model Full with color blue at (10,3)
  _01111: rectangle with size (4,1) with model Full with color red at (7,12)
  + 21 delta pixels
diff: 
! size mismatch, 4x17 instead of 5x17

TRAIN 8efcae92.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (18,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 . 0 0 0 
0 0 0 . 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 . 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 . 0 0 0 
0 0 0 0 0 
0 0 0 . 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 . 0 0 0 
0 0 0 0 0 
 with color blue at (1,1)
  _01: rectangle with size (9,10) with model Full with color blue at (6,8)
  _011: rectangle with size (3,9) with model Full with color blue at (17,11)
  _0111: rectangle with size (3,8) with model Full with color blue at (1,9)
  _01111: rectangle with size (15,1) with model Full with color red at (3,2)
  + 19 delta pixels
diff: 
! size mismatch, 4x10 instead of 9x10

TEST 8efcae92.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 28.4 sec (28.4 sec/task)
bits-train-error = 6644.3 bits (6644.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-184] Checking task 8f2ea7aa.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 96473.4 = 96475.7
DL output with Mo: L = 2.3 + 96473.4 = 96475.7
DL input+output M: L = 4.6 + 192946.8 = 192951.5

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = compose(majorityColor(strip(^)), strip(^), strip(^))
0.062	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.024	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.023	IN  SPE ^.color = black
0.001	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
compose(majorityColor(strip(^)), strip(^), strip(^))
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.1 + 2162.3 = 2204.4
DL output with Mo: L = 33.8 + 0.0 = 33.8
DL input+output M: L = 75.9 + 2162.3 = 2238.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
compose(majorityColor(strip(^)), strip(^), strip(^))
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 33.8 + 0.0 = 33.8
DL input+output M: L = 36.1 + 0.0 = 36.1

# train input/output grids

## instance 1

> Input and output best reading:

data: 
8 8 0 0 0 0 0 0 0 
0 0 8 0 0 0 0 0 0 
8 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
8 8 0 8 8 0 0 0 0 
0 0 8 0 0 8 0 0 0 
8 0 0 8 0 0 0 0 0 
0 0 0 0 0 0 8 8 0 
0 0 0 0 0 0 0 0 8 
0 0 0 0 0 0 8 0 0 
8 8 0 0 0 0 0 0 0 
0 0 8 0 0 0 0 0 0 
8 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 8 0 0 0 0 0 0 0 
0 0 8 0 0 0 0 0 0 
8 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 8f2ea7aa.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 7#0 0 0 
0 0 0 0 7#7#0 0 0 
0 0 0 7#0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
0 0 0 0 0 0 0 0 7#
0 0 0 0 0 0 0 7#7#
0 0 0 0 0 0 7#0 0 
0 0 0 0 0 7#0 0 7#
0 0 0 0 7#7#0 7#7#
0 0 0 7#0 0 7#0 0 
0 0 7#0 0 0 0 0 0 
0 7#7#0 0 0 0 0 0 
7#0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 7#0 0 0 
0 0 0 0 7#7#0 0 0 
0 0 0 7#0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 8f2ea7aa.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 6 0 0 0 0 
0 0 0 6 0 6 0 0 0 
0 0 0 6 6 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
0 0 0 0 6 0 0 0 0 
0 0 0 6 0 6 0 0 0 
0 0 0 6 6 0 0 0 0 
0 6 0 0 0 0 0 6 0 
6 0 6 0 0 0 6 0 6 
6 6 0 0 0 0 6 6 0 
0 6 0 0 6 0 0 0 0 
6 0 6 6 0 6 0 0 0 
6 6 0 6 6 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 6 0 0 0 0 
0 0 0 6 0 6 0 0 0 
0 0 0 6 6 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 8f2ea7aa.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
2 0 0 0 0 0 0 0 0 
2 2 0 0 0 0 0 0 0 
0 2 2 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TEST 8f2ea7aa.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 0.7 sec (0.7 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-183] Checking task 90c28cc7.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 552662.4 = 552664.8
DL output with Mo: L = 2.3 + 7503.7 = 7506.0
DL input+output M: L = 4.6 + 560166.1 = 560170.8

# learning a model for train pairs
2.000	
1.552	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.321	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.166	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
1.054	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.950	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.853	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.762	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.669	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.581	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.527	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.499	OUT SPE ^.layer_011.pos = projI(^.layer_011.pos)
0.470	OUT SPE ^.layer_01.pos = '(0, 0)
0.442	OUT SPE ^.layer_0.pos = '(0, 1)
0.415	OUT SPE ^.layer_0111.pos = projI(^.layer_011.pos) + (0, 1)
0.394	OUT SPE ^.layer_01.shape.color = ^.layer_011.shape.color
0.381	OUT SPE ^.layer_0.shape.mask.size.i = 1
0.370	OUT SPE ^.layer_0.shape.mask.model = Full
0.370	IN  SPE ^.layer_0.shape.mask.model = Full
0.370	IN  SPE ^.layer_01.shape.mask.model = Full
0.370	IN  SPE ^.layer_011.shape.mask.model = Full
0.369	IN  SPE ^.layer_0111.shape.mask.model = Full
0.369	IN  SPE ^.color = black
0.277	
0.277	IN  GEN ^.layer_0111.shape.mask.model = ?
0.277	IN  GEN ^.layer_011.shape.mask.model = ?
0.277	IN  GEN ^.layer_01.shape.mask.model = ?
0.277	IN  GEN ^.layer_0.shape.mask.model = ?
0.277	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (1,?) with model Full with color ? at '(0, 1)
  _01: point with color ^.layer_011.shape.color at '(0, 0)
  _011: point with color ? at projI(^.layer_011.pos)
  _0111: point with color ? at projI(^.layer_011.pos) + (0, 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 128.0 + 51281.3 = 51409.3
DL output with Mo: L = 136.7 + 1937.3 = 2074.0
DL input+output M: L = 264.7 + 53218.6 = 53483.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (1,?) with model Full with color ? at '(0, 1)
  _01: point with color ^.layer_011.shape.color at '(0, 0)
  _011: point with color ? at projI(^.layer_011.pos)
  _0111: point with color ? at projI(^.layer_011.pos) + (0, 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 63.4 = 189.2
DL output with Mo: L = 136.7 + 1937.3 = 2074.0
DL input+output M: L = 262.5 + 2000.7 = 2263.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (21,21) and color black and layers
  _0: rectangle with size (6,12) with model Full with color orange at (1,9)
  _01: rectangle with size (5,12) with model Full with color grey at (11,9)
  _011: rectangle with size (6,8) with model Full with color cyan at (1,1)
  _0111: rectangle with size (5,8) with model Full with color red at (11,1)
  + 80 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color grey and layers
  _0: rectangle with size (1,2) with model Full with color orange at (0,1)
  _01: point with color cyan at (0,0)
  _011: point with color green at (1,0)
  _0111: point with color yellow at (1,1)
  + 2 delta pixels
diff: 
   (119.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (6,12) with model Full with color orange at (1,9)
  _01: rectangle with size (5,12) with model Full with color grey at (11,9)
  _011: rectangle with size (6,8) with model Full with color cyan at (1,1)
  _0111: rectangle with size (5,8) with model Full with color red at (11,1)
  + 80 delta pixels
diff: 
! size mismatch, 10x10 instead of 3x3
>> Trial 2
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (6,12) with model Full with color orange at (1,9)
  _01: rectangle with size (5,12) with model Full with color grey at (11,9)
  _011: rectangle with size (5,8) with model Full with color red at (11,1)
  _0111: rectangle with size (6,8) with model Full with color cyan at (1,1)
  + 80 delta pixels
diff: 
! size mismatch, 10x10 instead of 3x3
>> Trial 3
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (6,12) with model Full with color orange at (1,9)
  _01: rectangle with size (6,8) with model Full with color cyan at (1,1)
  _011: rectangle with size (5,12) with model Full with color grey at (11,9)
  _0111: rectangle with size (5,8) with model Full with color red at (11,1)
  + 80 delta pixels
diff: 
! size mismatch, 10x10 instead of 3x3

TRAIN 90c28cc7.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (21,21) and color black and layers
  _0: rectangle with size (8,8) with model Full with color cyan at (1,8)
  _01: rectangle with size (7,8) with model Full with color yellow at (9,8)
  _011: rectangle with size (8,7) with model Full with color red at (1,1)
  _0111: rectangle with size (7,7) with model Full with color blue at (9,1)
diff: 
   (3.2 bits)
data: a background with size (2,2) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (0,1)
  _01: point with color red at (0,0)
  _011: point with color blue at (1,0)
  _0111: point with color yellow at (1,1)
diff: 
   (33.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (8,8) with model Full with color cyan at (1,8)
  _01: rectangle with size (8,7) with model Full with color red at (1,1)
  _011: rectangle with size (7,8) with model Full with color yellow at (9,8)
  _0111: rectangle with size (7,7) with model Full with color blue at (9,1)
diff: 
! size mismatch, 10x10 instead of 2x2
>> Trial 2
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (8,8) with model Full with color cyan at (1,8)
  _01: rectangle with size (8,7) with model Full with color red at (1,1)
  _011: rectangle with size (7,7) with model Full with color blue at (9,1)
  _0111: rectangle with size (7,8) with model Full with color yellow at (9,8)
diff: 
! size mismatch, 10x10 instead of 2x2
>> Trial 3
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (8,8) with model Full with color cyan at (1,8)
  _01: rectangle with size (7,8) with model Full with color yellow at (9,8)
  _011: rectangle with size (8,7) with model Full with color red at (1,1)
  _0111: rectangle with size (7,7) with model Full with color blue at (9,1)
diff: 
! size mismatch, 10x10 instead of 2x2

TRAIN 90c28cc7.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (21,21) and color black and layers
  _0: rectangle with size (6,12) with model Full with color green at (7,2)
  _01: rectangle with size (6,6) with model Full with color yellow at (13,2)
  _011: rectangle with size (5,6) with model Full with color cyan at (2,2)
  _0111: rectangle with size (6,6) with model Full with color blue at (13,8)
  + 30 delta pixels
diff: 
   (3.2 bits)
data: a background with size (3,2) and color green and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,1)
  _01: point with color cyan at (0,0)
  _011: point with color yellow at (2,0)
  _0111: point with color blue at (2,1)
diff: 
   (41.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (6,12) with model Full with color green at (7,2)
  _01: rectangle with size (6,6) with model Full with color yellow at (13,2)
  _011: rectangle with size (6,6) with model Full with color blue at (13,8)
  _0111: rectangle with size (5,6) with model Full with color cyan at (2,2)
  + 30 delta pixels
diff: 
! size mismatch, 10x10 instead of 3x2
>> Trial 2
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (6,12) with model Full with color green at (7,2)
  _01: rectangle with size (6,6) with model Full with color yellow at (13,2)
  _011: rectangle with size (5,6) with model Full with color cyan at (2,2)
  _0111: rectangle with size (6,6) with model Full with color blue at (13,8)
  + 30 delta pixels
diff: 
! size mismatch, 10x10 instead of 3x2

TRAIN 90c28cc7.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (8,8) with model Full with color green at (7,6)
  _01: rectangle with size (18,8) with model Full with color yellow at (1,6)
  _011: rectangle with size (8,18) with model Full with color cyan at (7,1)
  _0111: rectangle with size (18,5) with model Full with color red at (1,1)
  + 50 delta pixels
diff: 
! size mismatch, 10x10 instead of 3x3
>> Trial 2
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (8,8) with model Full with color green at (7,6)
  _01: rectangle with size (8,18) with model Full with color cyan at (7,1)
  _011: rectangle with size (18,8) with model Full with color yellow at (1,6)
  _0111: rectangle with size (18,5) with model Full with color red at (1,1)
  + 50 delta pixels
diff: 
! size mismatch, 10x10 instead of 3x3
>> Trial 3
data: a background with size (21,21) and color black and layers
  _0: rectangle with size (8,8) with model Full with color green at (7,6)
  _01: rectangle with size (8,18) with model Full with color cyan at (7,1)
  _011: rectangle with size (18,5) with model Full with color red at (1,1)
  _0111: rectangle with size (18,8) with model Full with color yellow at (1,6)
  + 50 delta pixels
diff: 
! size mismatch, 10x10 instead of 3x3

TEST 90c28cc7.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 23.4 sec (23.4 sec/task)
bits-train-error = 1937.3 bits (1937.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-182] Checking task 90f3ed37.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 181760.8 = 181763.1
DL output with Mo: L = 2.3 + 181760.8 = 181763.1
DL input+output M: L = 4.6 + 363521.5 = 363526.2

# learning a model for train pairs
2.000	
1.125	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.351	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.292	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.226	OUT ADD ^.layer_0 = ^.layer_0
0.183	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.149	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.121	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.099	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.076	OUT ADD ^.layer_010 = ^.layer_01
0.061	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.058	OUT SPE ^.size = ^.size
0.057	OUT SPE ^.layer_011.pos.i = ^.layer_011.pos.i
0.055	OUT SPE ^.layer_01.shape.mask.size.j = ^.layer_01.shape.mask.size.j + 2
0.054	IN  SPE ^.layer_0.shape.color = cyan
0.053	IN  SPE ^.layer_01.shape.color = cyan
0.053	IN  SPE ^.layer_011.shape.color = cyan
0.052	OUT SPE ^.layer_01.shape.color = blue
0.051	OUT SPE ^.layer_0111.shape.color = blue
0.050	OUT SPE ^.layer_011.shape.mask.size.i = ^.layer_011.shape.mask.size.i
0.049	OUT SPE ^.layer_01.shape.mask.size.i = ^.layer_01.shape.mask.size.j - 3
0.049	OUT SPE ^.layer_0111.shape.mask.size.i = area(^.layer_01.shape) - 3
0.048	IN  SPE ^.color = black
0.048	OUT SPE ^.color = black
0.024	
0.024	IN  GEN ^.layer_011.shape.color = ?
0.024	IN  GEN ^.layer_01.shape.color = ?
0.024	IN  GEN ^.layer_0.shape.color = ?
0.024	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _010: ^.layer_01
  _01: rectangle with size (^.layer_01.shape.mask.size.j - 3,^.layer_01.shape.mask.size.j + 2) with model ? with color blue at (?,?)
  _011: rectangle with size (^.layer_011.shape.mask.size.i,?) with model ? with color ? at (^.layer_011.pos.i,?)
  _0111: rectangle with size (area(^.layer_01.shape) - 3,?) with model ? with color blue at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color cyan at (?,?)
  _01: rectangle with size (?,?) with model ? with color cyan at (?,?)
  _011: rectangle with size (?,?) with model ? with color cyan at (?,?)

DL input  with Mi: L = 108.2 + 4449.2 = 4557.4
DL output with Mo: L = 167.8 + 4007.0 = 4174.8
DL input+output M: L = 276.0 + 8456.2 = 8732.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _010: ^.layer_01
  _01: rectangle with size (^.layer_01.shape.mask.size.j - 3,^.layer_01.shape.mask.size.j + 2) with model ? with color blue at (?,?)
  _011: rectangle with size (^.layer_011.shape.mask.size.i,?) with model ? with color ? at (^.layer_011.pos.i,?)
  _0111: rectangle with size (area(^.layer_01.shape) - 3,?) with model ? with color blue at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 0.0 = 98.1
DL output with Mo: L = 167.8 + 4007.0 = 4174.8
DL input+output M: L = 265.9 + 4007.0 = 4272.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (15,10) and color black and layers
  _0: rectangle with size (3,10) with mask 
0 0 . . . . . . . . 
. . 0 . . . . . . . 
. . . 0 0 0 0 0 0 0 
 with color cyan at (1,0)
  _01: rectangle with size (2,4) with mask 
0 0 0 . 
. . . 0 
 with color cyan at (6,0)
  _011: rectangle with size (2,3) with mask 
0 0 . 
. . 0 
 with color cyan at (10,0)
diff: 
   (0.0 bits)
data: a background with size (15,10) and color black and layers
  _0: 
8 8 . . . . . . . . 
. . 8 . . . . . . . 
. . . 8 8 8 8 8 8 8 
 at (1,0)
  _010: 
8 8 8 . 
. . . 8 
 at (6,0)
  _01: rectangle with size (1,6) with model Full with color blue at (8,4)
  _011: rectangle with size (2,3) with mask 
0 0 . 
. . 0 
 with color cyan at (10,0)
  _0111: rectangle with size (1,7) with model Full with color blue at (12,3)
diff: 
   (63.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,10) and color black and layers
  _0: rectangle with size (3,10) with mask 
0 0 . . . . . . . . 
. . 0 . . . . . . . 
. . . 0 0 0 0 0 0 0 
 with color cyan at (1,0)
  _01: rectangle with size (2,4) with mask 
0 0 0 . 
. . . 0 
 with color cyan at (6,0)
  _011: rectangle with size (2,3) with mask 
0 0 . 
. . 0 
 with color cyan at (10,0)
diff: 
! 24 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,10) and color black and layers
  _0: rectangle with size (2,4) with mask 
0 0 0 . 
. . . 0 
 with color cyan at (6,0)
  _01: rectangle with size (3,10) with mask 
0 0 . . . . . . . . 
. . 0 . . . . . . . 
. . . 0 0 0 0 0 0 0 
 with color cyan at (1,0)
  _011: rectangle with size (2,3) with mask 
0 0 . 
. . 0 
 with color cyan at (10,0)
diff: 
! 75 wrong pixels (generated / expected)

TRAIN 90f3ed37.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (15,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color cyan at (2,0)
  _01: rectangle with size (1,4) with model Full with color cyan at (11,0)
  _011: rectangle with size (1,3) with model Full with color cyan at (6,0)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (15,10) and color black and layers
  _0: 
8 8 8 8 8 8 8 8 8 8 
 at (2,0)
  _010: 
8 8 8 8 
 at (11,0)
  _01: rectangle with size (1,6) with model Full with color blue at (11,4)
  _011: rectangle with size (1,7) with model Full with color blue at (6,3)
  _0111: rectangle with size (1,8) with model Full with color blue at (13,2)
  + 5 delta pixels
diff: 
   (267.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,10) and color black and layers
  _0: rectangle with size (1,10) with model Full with color cyan at (2,0)
  _01: rectangle with size (1,4) with model Full with color cyan at (11,0)
  _011: rectangle with size (1,3) with model Full with color cyan at (6,0)
  + 2 delta pixels
diff: 
! 32 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,10) and color black and layers
  _0: rectangle with size (1,4) with model Full with color cyan at (11,0)
  _01: rectangle with size (1,10) with model Full with color cyan at (2,0)
  _011: rectangle with size (1,3) with model Full with color cyan at (6,0)
  + 2 delta pixels
diff: 
! 69 wrong pixels (generated / expected)

TRAIN 90f3ed37.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (15,10) and color black and layers
  _0: rectangle with size (2,10) with model Even Checkboard with color cyan at (1,0)
  _01: rectangle with size (2,5) with model Even Checkboard with color cyan at (10,0)
  _011: rectangle with size (2,3) with model Even Checkboard with color cyan at (6,0)
diff: 
   (0.0 bits)
data: a background with size (15,10) and color black and layers
  _0: 
8 . 8 . 8 . 8 . 8 . 
. 8 . 8 . 8 . 8 . 8 
 at (1,0)
  _010: 
8 . 8 . 8 
. 8 . 8 . 
 at (10,0)
  _01: rectangle with size (2,7) with model Odd Checkboard with color blue at (6,3)
  _011: rectangle with size (2,3) with model Even Checkboard with color cyan at (6,0)
  _0111: rectangle with size (2,5) with model Odd Checkboard with color blue at (10,5)
diff: 
   (69.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,10) and color black and layers
  _0: rectangle with size (2,10) with model Even Checkboard with color cyan at (1,0)
  _01: rectangle with size (2,5) with model Even Checkboard with color cyan at (10,0)
  _011: rectangle with size (2,3) with model Even Checkboard with color cyan at (6,0)
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,10) and color black and layers
  _0: rectangle with size (2,5) with model Even Checkboard with color cyan at (10,0)
  _01: rectangle with size (2,10) with model Even Checkboard with color cyan at (1,0)
  _011: rectangle with size (2,3) with model Even Checkboard with color cyan at (6,0)
diff: 
! 68 wrong pixels (generated / expected)

TRAIN 90f3ed37.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,10) and color black and layers
  _0: rectangle with size (1,8) with model Full with color cyan at (1,2)
  _01: rectangle with size (1,8) with model Full with color cyan at (3,2)
  _011: rectangle with size (3,5) with mask 
. . . 0 0 
0 0 0 . . 
. . . 0 0 
 with color cyan at (8,0)
  + 2 delta pixels
diff: 
! 55 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,10) and color black and layers
  _0: rectangle with size (1,8) with model Full with color cyan at (1,2)
  _01: rectangle with size (3,5) with mask 
. . . 0 0 
0 0 0 . . 
. . . 0 0 
 with color cyan at (8,0)
  _011: rectangle with size (1,8) with model Full with color cyan at (3,2)
  + 2 delta pixels
diff: 
! 31 wrong pixels (generated / expected)

TEST 90f3ed37.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 20.0 sec (20.0 sec/task)
bits-train-error = 4007.0 bits (4007.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-181] Checking task 913fb3ed.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 191283.0 = 191285.3
DL output with Mo: L = 2.3 + 191283.0 = 191285.3
DL input+output M: L = 4.6 + 382565.9 = 382570.6

# learning a model for train pairs
2.000	
1.020	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.157	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.097	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.065	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.057	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.052	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.044	OUT ADD ^.layer_00 = ^.layer_0
0.040	OUT SPE ^.size = ^.size
0.037	OUT SPE ^.layer_0.pos = ^.layer_0.pos - (1, 1)
0.036	OUT SPE ^.layer_0.shape.mask.size.j = 3
0.033	OUT SPE ^.layer_011.shape.mask = 
0 0 0 
0 0 0 
0 0 0 

0.032	OUT SPE ^.layer_0.shape.mask.model = Full
0.032	OUT SPE ^.layer_01.shape.mask.model = Full
0.031	IN  SPE ^.color = black
0.030	OUT SPE ^.color = black
0.016	
0.016	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,3) with model Full with color ? at ^.layer_0.pos - (1, 1)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: 
0 0 0 
0 0 0 
0 0 0 
 with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.3 + 2703.4 = 2735.7
DL output with Mo: L = 116.0 + 2978.7 = 3094.7
DL input+output M: L = 148.3 + 5682.1 = 5830.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,3) with model Full with color ? at ^.layer_0.pos - (1, 1)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: 
0 0 0 
0 0 0 
0 0 0 
 with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 0.0 = 32.2
DL output with Mo: L = 116.0 + 2978.7 = 3094.7
DL input+output M: L = 148.2 + 2978.7 = 3126.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: point with color cyan at (4,5)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _00: 
8 
 at (4,5)
  _0: rectangle with size (3,3) with model Full with color yellow at (3,4)
  _01: rectangle with size (3,3) with model Full with color pink at (4,0)
  _011: 
0 0 0 
0 0 0 
0 0 0 
 with color blue at (5,7)
  + 2 delta pixels
diff: 
   (143.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: point with color cyan at (4,5)
  + 2 delta pixels
diff: 
! 35 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: point with color green at (5,1)
  + 2 delta pixels
diff: 
! 35 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color black and layers
  _0: point with color red at (6,8)
  + 2 delta pixels
diff: 
! 35 wrong pixels (generated / expected)

TRAIN 913fb3ed.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _0: point with color green at (1,3)
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _00: 
3 
 at (1,3)
  _0: rectangle with size (1,3) with model Full with color pink at (0,2)
  _01: rectangle with size (1,3) with model Full with color pink at (2,2)
  _011: 
0 0 0 
0 0 0 
0 0 0 
 with color pink at (0,2)
diff: 
   (49.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: point with color green at (1,3)
diff: 
! 14 wrong pixels (generated / expected)

TRAIN 913fb3ed.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (16,16) and color black and layers
  _0: point with color green at (3,12)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (16,16) and color black and layers
  _00: 
3 
 at (3,12)
  _0: rectangle with size (3,3) with model Full with color pink at (2,11)
  _01: rectangle with size (1,1) with model Full with color red at (10,3)
  _011: 
0 0 0 
0 0 0 
0 0 0 
 with color blue at (9,2)
diff: 
   (55.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color black and layers
  _0: point with color green at (3,12)
  + 1 delta pixels
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (16,16) and color black and layers
  _0: point with color red at (10,3)
  + 1 delta pixels
diff: 
! 26 wrong pixels (generated / expected)

TRAIN 913fb3ed.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _0: point with color cyan at (2,2)
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _00: 
8 
 at (2,2)
  _0: rectangle with size (1,3) with model Full with color yellow at (1,1)
  _01: rectangle with size (1,3) with model Full with color yellow at (3,1)
  _011: 
0 0 0 
0 0 0 
0 0 0 
 with color yellow at (1,1)
diff: 
   (49.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: point with color cyan at (2,2)
diff: 
! 13 wrong pixels (generated / expected)

TRAIN 913fb3ed.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color black and layers
  _0: point with color green at (1,1)
  + 2 delta pixels
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (16,16) and color black and layers
  _0: point with color red at (10,13)
  + 2 delta pixels
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (16,16) and color black and layers
  _0: point with color cyan at (14,2)
  + 2 delta pixels
diff: 
! 26 wrong pixels (generated / expected)

TEST 913fb3ed.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 11.9 sec (11.9 sec/task)
bits-train-error = 2978.7 bits (2978.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-180] Checking task 91413438.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 14046.4 = 14048.7
DL output with Mo: L = 2.3 + 316274.4 = 316276.7
DL input+output M: L = 4.6 + 330320.8 = 330325.4

# learning a model for train pairs
2.000	
1.113	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.538	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.262	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.162	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.155	IN  SPE ^.color = black
0.154	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.153	OUT SPE ^.layer_0.shape.mask = tiling to size (?,?)
of grid ?
0.152	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.152	OUT SPE ^.color = black
0.013	
0.013	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color black and layers
  _0: tiling to size (?,?)
of grid ? with color ^.layer_0.shape.color at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.1 + 1950.8 = 1992.9
DL output with Mo: L = 41.1 + 3017.4 = 3058.5
DL input+output M: L = 83.2 + 4968.2 = 5051.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color black and layers
  _0: tiling to size (?,?)
of grid ? with color ^.layer_0.shape.color at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 41.1 + 3017.4 = 3058.5
DL input+output M: L = 83.1 + 3017.4 = 3100.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
. . 0 
 with color pink at (0,0)
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _0: tiling to size (6,12)
of grid 
0 0 . 0 0 . 0 0 . 0 0 . 
. 0 0 . 0 0 . 0 0 . 0 0 
. . 0 . . 0 . . 0 . . 0 
0 0 . . . . . . . . . . 
. 0 0 . . . . . . . . . 
. . 0 . . . . . . . . . 
 with color pink at (0,0)
diff: 
   (127.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
. . 0 
 with color pink at (0,0)
diff: 
! size mismatch, 10x10 instead of 12x12
>> Trial 2
data: a background with size (3,3) and color pink and layers
  _0: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color black at (1,0)
  + 1 delta pixels
diff: 
! size mismatch, 10x10 instead of 12x12

TRAIN 91413438.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
. 0 0 
0 . . 
 with color yellow at (0,0)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: tiling to size (3,12)
of grid 
. 0 . 
. 0 0 
0 . . 
 with color yellow at (0,0)
diff: 
   (60.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
. 0 0 
0 . . 
 with color yellow at (0,0)
diff: 
! size mismatch, 10x10 instead of 15x15
>> Trial 2
data: a background with size (3,3) and color yellow and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
0 . . 
. 0 0 
 with color black at (0,0)
  + 1 delta pixels
diff: 
! size mismatch, 10x10 instead of 15x15
>> Trial 3
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,1) with model Full with color yellow at (0,1)
  + 2 delta pixels
diff: 
! size mismatch, 10x10 instead of 15x15

TRAIN 91413438.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 . 0 
. 0 0 
 with color green at (0,0)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: tiling to size (6,9)
of grid 
0 . 0 
0 . 0 
. 0 0 
 with color green at (0,0)
diff: 
   (58.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 . 0 
. 0 0 
 with color green at (0,0)
diff: 
! size mismatch, 10x10 instead of 9x9
>> Trial 2
data: a background with size (3,3) and color green and layers
  _0: rectangle with size (3,2) with mask 
. 0 
. 0 
0 . 
 with color black at (0,0)
diff: 
! size mismatch, 10x10 instead of 9x9

TRAIN 91413438.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,3) with model Even Checkboard with color red at (0,0)
diff: 
   (0.0 bits)
data: a background with size (18,18) and color black and layers
  _0: tiling to size (2,9)
of grid 
0 . 0 
. 0 . 
 with color red at (0,0)
diff: 
   (55.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,3) with model Even Checkboard with color red at (0,0)
diff: 
! size mismatch, 10x10 instead of 18x18
>> Trial 2
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,2)
  + 2 delta pixels
diff: 
! size mismatch, 10x10 instead of 18x18

TRAIN 91413438.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,2) with model Odd Checkboard with color cyan at (0,1)
diff: 
! size mismatch, 10x10 instead of 21x21
>> Trial 2
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (0,2)
  + 1 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21
>> Trial 3
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (1,1)
  + 1 delta pixels
diff: 
! size mismatch, 10x10 instead of 21x21

TEST 91413438.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 2.9 sec (2.9 sec/task)
bits-train-error = 3017.4 bits (3017.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-179] Checking task 91714a58.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 315315.2 = 315317.5
DL output with Mo: L = 2.3 + 315315.2 = 315317.5
DL input+output M: L = 4.6 + 630630.4 = 630635.0

# learning a model for train pairs
2.000	
1.048	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.405	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.360	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.317	OUT ADD ^.layer_0 = ^.layer_0
0.315	OUT SPE ^.size = ^.size
0.314	IN  SPE ^.layer_0.shape.mask.model = Full
0.304	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.303	IN  SPE ^.color = black
0.303	OUT SPE ^.color = black
0.000	
0.000	IN  DEL ^.layer_01
0.000	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.9 + 95491.1 = 95562.0
DL output with Mo: L = 15.6 + 0.0 = 15.6
DL input+output M: L = 86.4 + 95491.1 = 95577.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 42.5 + 0.0 = 42.5
DL output with Mo: L = 15.6 + 0.0 = 15.6
DL input+output M: L = 58.1 + 0.0 = 58.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (16,16) and color black and layers
  _0: rectangle with size (4,3) with model Full with color red at (3,3)
  + 90 delta pixels
diff: 
   (0.0 bits)
data: a background with size (16,16) and color black and layers
  _0: 
2 2 2 
2 2 2 
2 2 2 
2 2 2 
 at (3,3)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (4,3) with model Full with color red at (3,3)
  + 90 delta pixels
diff: 
correct output grid

TRAIN 91714a58.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (16,16) and color black and layers
  _0: rectangle with size (2,7) with model Full with color pink at (11,2)
  + 84 delta pixels
diff: 
   (0.0 bits)
data: a background with size (16,16) and color black and layers
  _0: 
6 6 6 6 6 6 6 
6 6 6 6 6 6 6 
 at (11,2)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (2,7) with model Full with color pink at (11,2)
  + 84 delta pixels
diff: 
correct output grid

TRAIN 91714a58.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (16,16) and color black and layers
  _0: rectangle with size (3,3) with model Full with color orange at (2,8)
  + 63 delta pixels
diff: 
   (0.0 bits)
data: a background with size (16,16) and color black and layers
  _0: 
7#7#7#
7#7#7#
7#7#7#
 at (2,8)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (3,3) with model Full with color orange at (2,8)
  + 63 delta pixels
diff: 
correct output grid

TRAIN 91714a58.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (2,6) with model Full with color grey at (10,5)
  + 81 delta pixels
diff: 
correct output grid

TEST 91714a58.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 2.1 sec (2.1 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-178] Checking task 9172f3a0.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 7023.2 = 7025.5
DL output with Mo: L = 2.3 + 64315.6 = 64317.9
DL input+output M: L = 4.6 + 71338.8 = 71343.5

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = ^ * '3
0.574	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.393	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.315	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.248	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.232	IN  SPE ^.layer_01.shape.color = green
0.224	IN  SPE ^.layer_01.shape.mask.model = Full
0.217	IN  SPE ^.color = black
0.013	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
^ * '3
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color green at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 92.3 + 1432.7 = 1524.9
DL output with Mo: L = 19.7 + 0.0 = 19.7
DL input+output M: L = 112.0 + 1432.7 = 1544.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
^ * '3
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 19.7 + 0.0 = 19.7
DL input+output M: L = 22.0 + 0.0 = 22.0

# train input/output grids

## instance 1

> Input and output best reading:

data: 
3 3 0 
7#4 0 
0 0 4 

diff: 
   (0.0 bits)
data: 
3 3 3 3 3 3 0 0 0 
3 3 3 3 3 3 0 0 0 
3 3 3 3 3 3 0 0 0 
7#7#7#4 4 4 0 0 0 
7#7#7#4 4 4 0 0 0 
7#7#7#4 4 4 0 0 0 
0 0 0 0 0 0 4 4 4 
0 0 0 0 0 0 4 4 4 
0 0 0 0 0 0 4 4 4 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 3 0 
7#4 0 
0 0 4 

diff: 
correct output grid

TRAIN 9172f3a0.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
3 0 2 
0 2 2 
0 0 3 

diff: 
   (0.0 bits)
data: 
3 3 3 0 0 0 2 2 2 
3 3 3 0 0 0 2 2 2 
3 3 3 0 0 0 2 2 2 
0 0 0 2 2 2 2 2 2 
0 0 0 2 2 2 2 2 2 
0 0 0 2 2 2 2 2 2 
0 0 0 0 0 0 3 3 3 
0 0 0 0 0 0 3 3 3 
0 0 0 0 0 0 3 3 3 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 0 2 
0 2 2 
0 0 3 

diff: 
correct output grid

TRAIN 9172f3a0.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 1 0 
0 0 6 
6 1 0 

diff: 
correct output grid

TEST 9172f3a0.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.2 sec (1.2 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-177] Checking task 928ad970.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 228161.7 = 228164.1
DL output with Mo: L = 2.3 + 228161.7 = 228164.1
DL input+output M: L = 4.6 + 456323.5 = 456328.1

# learning a model for train pairs
2.000	
1.079	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.335	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.163	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.115	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.066	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.059	OUT ADD ^.layer_00 = ^.layer_0
0.056	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.053	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.050	OUT ADD ^.layer_01111 = point with color ? at (?,?)
0.047	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.043	OUT SPE ^.layer_01 = ^.layer_01
0.040	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.037	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.034	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.031	OUT SPE ^.size = ^.size
0.029	OUT SPE ^.layer_01111 = ^.layer_01111
0.027	OUT SPE ^.layer_0111 = ^.layer_0111
0.024	OUT SPE ^.layer_011 = ^.layer_011
0.023	OUT SPE ^.layer_0.pos = projI(^.layer_01.pos) + (1, 2)
0.021	OUT SPE ^.layer_0.shape.mask.size.i = ^.size.j - ^.layer_0.shape.mask.size.i
0.021	OUT SPE ^.layer_0.shape.mask.size.j = area(^) - ^.layer_011.pos.i - ^.layer_01.pos.i
0.020	OUT SPE ^.layer_0.shape.mask.model = ^.layer_0.shape.mask.model
0.019	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.018	IN  SPE ^.layer_0.shape.mask.model = Border
0.018	IN  SPE ^.layer_01.shape.color = grey
0.017	IN  SPE ^.layer_011.shape.color = grey
0.016	IN  SPE ^.layer_0111.shape.color = grey
0.016	IN  SPE ^.layer_01111.shape.color = grey
0.015	IN  SPE ^.color = black
0.015	OUT SPE ^.color = black
0.002	
0.001	IN  GEN ^.layer_0.shape.mask.model = ?
0.001	IN  GEN ^.layer_01111.shape.color = ?
0.001	IN  GEN ^.layer_0111.shape.color = ?
0.001	IN  GEN ^.layer_011.shape.color = ?
0.001	IN  GEN ^.layer_01.shape.color = ?
0.001	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (^.size.j - ^.layer_0.shape.mask.size.i,area(^) - ^.layer_011.pos.i - ^.layer_01.pos.i) with model ^.layer_0.shape.mask.model with color ^.layer_0.shape.color at projI(^.layer_01.pos) + (1, 2)
  _01: ^.layer_01
  _011: ^.layer_011
  _0111: ^.layer_0111
  _01111: ^.layer_01111
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Border with color ? at (?,?)
  _01: point with color grey at (?,?)
  _011: point with color grey at (?,?)
  _0111: point with color grey at (?,?)
  _01111: point with color grey at (?,?)

DL input  with Mi: L = 130.9 + 3093.4 = 3224.2
DL output with Mo: L = 179.9 + 0.0 = 179.9
DL input+output M: L = 310.8 + 3093.4 = 3404.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (^.size.j - ^.layer_0.shape.mask.size.i,area(^) - ^.layer_011.pos.i - ^.layer_01.pos.i) with model ^.layer_0.shape.mask.model with color ^.layer_0.shape.color at projI(^.layer_01.pos) + (1, 2)
  _01: ^.layer_01
  _011: ^.layer_011
  _0111: ^.layer_0111
  _01111: ^.layer_01111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 114.2 + 31.7 = 145.9
DL output with Mo: L = 179.9 + 0.0 = 179.9
DL input+output M: L = 294.1 + 31.7 = 325.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (12,13) and color black and layers
  _0: rectangle with size (4,3) with model Border with color blue at (4,5)
  _01: point with color grey at (1,4)
  _011: point with color grey at (6,1)
  _0111: point with color grey at (6,11)
  _01111: point with color grey at (11,4)
diff: 
   (0.0 bits)
data: a background with size (12,13) and color black and layers
  _00: 
1 1 1 
1 . 1 
1 . 1 
1 1 1 
 at (4,5)
  _0: rectangle with size (9,9) with model Border with color blue at (2,2)
  _01: 
5#
 at (1,4)
  _011: 
5#
 at (6,1)
  _0111: 
5#
 at (6,11)
  _01111: 
5#
 at (11,4)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,13) and color black and layers
  _0: rectangle with size (4,3) with model Border with color blue at (4,5)
  _01: point with color grey at (1,4)
  _011: point with color grey at (6,1)
  _0111: point with color grey at (6,11)
  _01111: point with color grey at (11,4)
diff: 
correct output grid

TRAIN 928ad970.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (15,13) and color black and layers
  _0: rectangle with size (3,3) with model Border with color green at (5,4)
  _01: point with color grey at (1,5)
  _011: point with color grey at (5,1)
  _0111: point with color grey at (8,10)
  _01111: point with color grey at (12,5)
diff: 
   (0.0 bits)
data: a background with size (15,13) and color black and layers
  _00: 
3 3 3 
3 . 3 
3 3 3 
 at (5,4)
  _0: rectangle with size (10,8) with model Border with color green at (2,2)
  _01: 
5#
 at (1,5)
  _011: 
5#
 at (5,1)
  _0111: 
5#
 at (8,10)
  _01111: 
5#
 at (12,5)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,13) and color black and layers
  _0: rectangle with size (3,3) with model Border with color green at (5,4)
  _01: point with color grey at (1,5)
  _011: point with color grey at (5,1)
  _0111: point with color grey at (8,10)
  _01111: point with color grey at (12,5)
diff: 
correct output grid

TRAIN 928ad970.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (15,14) and color black and layers
  _0: rectangle with size (4,4) with model Border with color yellow at (5,4)
  _01: point with color grey at (2,6)
  _011: point with color grey at (8,1)
  _0111: point with color grey at (6,12)
  _01111: point with color grey at (13,7)
diff: 
   (3.2 bits)
data: a background with size (15,14) and color black and layers
  _00: 
4 4 4 4 
4 . . 4 
4 . . 4 
4 4 4 4 
 at (5,4)
  _0: rectangle with size (10,10) with model Border with color yellow at (3,2)
  _01: 
5#
 at (2,6)
  _011: 
5#
 at (8,1)
  _0111: 
5#
 at (6,12)
  _01111: 
5#
 at (13,7)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,14) and color black and layers
  _0: rectangle with size (4,4) with model Border with color yellow at (5,4)
  _01: point with color grey at (2,6)
  _011: point with color grey at (6,12)
  _0111: point with color grey at (8,1)
  _01111: point with color grey at (13,7)
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,14) and color black and layers
  _0: rectangle with size (4,4) with model Border with color yellow at (5,4)
  _01: point with color grey at (2,6)
  _011: point with color grey at (8,1)
  _0111: point with color grey at (6,12)
  _01111: point with color grey at (13,7)
diff: 
correct output grid

TRAIN 928ad970.json/3: 1 2nd (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (3,4) with model Border with color cyan at (5,5)
  _01: point with color grey at (1,7)
  _011: point with color grey at (6,2)
  _0111: point with color grey at (9,12)
  _01111: point with color grey at (13,5)
diff: 
! 56 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (3,4) with model Border with color cyan at (5,5)
  _01: point with color grey at (1,7)
  _011: point with color grey at (9,12)
  _0111: point with color grey at (6,2)
  _01111: point with color grey at (13,5)
diff: 
! 54 wrong pixels (generated / expected)

TEST 928ad970.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 23.6 sec (23.6 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 0.83
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-176] Checking task 93b581b8.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 42126.8 = 42129.1
DL output with Mo: L = 2.3 + 42126.8 = 42129.1
DL input+output M: L = 4.6 + 84253.6 = 84258.3

# learning a model for train pairs
2.000	
1.126	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.625	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.537	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.467	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.397	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.335	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.319	OUT ADD ^.layer_01111 = point with color ? at (?,?)
0.302	OUT ADD ^.layer_011111 = point with color ? at (?,?)
0.286	OUT ADD ^.layer_0111111 = point with color ? at (?,?)
0.269	OUT ADD ^.layer_01111111 = point with color ? at (?,?)
0.253	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.236	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.220	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.203	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.191	OUT SPE ^.size = ^.size
0.179	OUT SPE ^.layer_0111111 = ^.layer_0111
0.168	OUT SPE ^.layer_011111 = ^.layer_01
0.157	OUT SPE ^.layer_01111 = ^.layer_0
0.146	OUT SPE ^.layer_01111111 = ^.layer_011
0.134	OUT SPE ^.layer_011.shape = scaleTo(^.layer_01.shape, span(^.layer_01.pos, ^.layer_011.pos))
0.124	OUT SPE ^.layer_0.shape.mask = 
0 0 
0 0 

0.117	OUT SPE ^.layer_011.pos = projI(^.layer_011.pos) + (1, 0)
0.111	OUT SPE ^.layer_01.pos = projJ(^.layer_01.pos) + (0, 1)
0.107	OUT SPE ^.layer_01.shape.mask.size.j = 2
0.100	OUT SPE ^.layer_0111.shape.mask = scaleTo(^.layer_0111.shape.mask, span(^.layer_011.pos, ^.layer_0111.pos) - translationSym(rotate90, ^.layer_011, ^))
0.096	OUT SPE ^.layer_01.shape.mask = scaleTo(^.layer_01.shape.mask, span(^.layer_01.pos, ^.layer_011.pos) - translationSym(flipDiag2, ^.layer_01, ^.layer_011))
0.093	OUT SPE ^.layer_0111.pos.j = ^.layer_0111.pos.j + ^.layer_0111.pos.j - ^.layer_011.pos.j
0.090	OUT SPE ^.layer_0111.pos.i = ^.layer_0111.pos.j + ^.layer_0111.pos.j - ^.layer_011.pos.j
0.089	IN  SPE ^.color = black
0.087	OUT SPE ^.color = black
0.031	
0.031	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 0 
0 0 
 with color ? at (?,?)
  _01: scaleTo(^.layer_01.shape.mask, span(^.layer_01.pos, ^.layer_011.pos) - translationSym(flipDiag2, ^.layer_01, ^.layer_011)) with color ? at projJ(^.layer_01.pos) + (0, 1)
  _011: scaleTo(^.layer_01.shape, span(^.layer_01.pos, ^.layer_011.pos)) at projI(^.layer_011.pos) + (1, 0)
  _0111: scaleTo(^.layer_0111.shape.mask, span(^.layer_011.pos, ^.layer_0111.pos) - translationSym(rotate90, ^.layer_011, ^)) with color ? at (^.layer_0111.pos.j + ^.layer_0111.pos.j - ^.layer_011.pos.j,^.layer_0111.pos.j + ^.layer_0111.pos.j - ^.layer_011.pos.j)
  _01111: ^.layer_0
  _011111: ^.layer_01
  _0111111: ^.layer_0111
  _01111111: ^.layer_011
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 86.7 + 2382.7 = 2469.4
DL output with Mo: L = 390.2 + 801.1 = 1191.2
DL input+output M: L = 476.9 + 3183.8 = 3660.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 0 
0 0 
 with color ? at (?,?)
  _01: scaleTo(^.layer_01.shape.mask, span(^.layer_01.pos, ^.layer_011.pos) - translationSym(flipDiag2, ^.layer_01, ^.layer_011)) with color ? at projJ(^.layer_01.pos) + (0, 1)
  _011: scaleTo(^.layer_01.shape, span(^.layer_01.pos, ^.layer_011.pos)) at projI(^.layer_011.pos) + (1, 0)
  _0111: scaleTo(^.layer_0111.shape.mask, span(^.layer_011.pos, ^.layer_0111.pos) - translationSym(rotate90, ^.layer_011, ^)) with color ? at (^.layer_0111.pos.j + ^.layer_0111.pos.j - ^.layer_011.pos.j,^.layer_0111.pos.j + ^.layer_0111.pos.j - ^.layer_011.pos.j)
  _01111: ^.layer_0
  _011111: ^.layer_01
  _0111111: ^.layer_0111
  _01111111: ^.layer_011
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 86.6 + 20.0 = 106.6
DL output with Mo: L = 390.2 + 801.1 = 1191.2
DL input+output M: L = 476.8 + 821.1 = 1297.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _0: point with color brown at (2,2)
  _01: point with color green at (2,3)
  _011: point with color orange at (3,2)
  _0111: point with color cyan at (3,3)
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _0: 
0 0 
0 0 
 with color cyan at (0,0)
  _01: 
0 0 
0 0 
 with color orange at (0,4)
  _011: 
3 3 
3 3 
 at (4,0)
  _0111: 
0 0 
0 0 
 with color brown at (4,4)
  _01111: 
9#
 at (2,2)
  _011111: 
3 
 at (2,3)
  _0111111: 
8 
 at (3,3)
  _01111111: 
7#
 at (3,2)
diff: 
   (26.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: point with color brown at (2,2)
  _01: point with color green at (2,3)
  _011: point with color orange at (3,2)
  _0111: point with color cyan at (3,3)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,6) and color black and layers
  _0: point with color brown at (2,2)
  _01: point with color green at (2,3)
  _011: point with color cyan at (3,3)
  _0111: point with color orange at (3,2)
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (6,6) and color black and layers
  _0: point with color brown at (2,2)
  _01: point with color orange at (3,2)
  _011: point with color green at (2,3)
  _0111: point with color cyan at (3,3)
diff: 
! 21 wrong pixels (generated / expected)

TRAIN 93b581b8.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _0: point with color yellow at (1,1)
  _01: point with color pink at (1,2)
  _011: point with color blue at (2,2)
  _0111: point with color red at (2,1)
diff: 
   (2.0 bits)
data: a background with size (6,6) and color black and layers
  _0: 
0 0 
0 0 
 with color yellow at (3,3)
  _01: 
0 0 
 with color red at (0,3)
  _011: 
6 
6 
 at (3,0)
  _0111: 
0 
 with color blue at (0,0)
  _01111: 
4 
 at (1,1)
  _011111: 
6 
 at (1,2)
  _0111111: 
2 
 at (2,1)
  _01111111: 
1 
 at (2,2)
diff: 
   (26.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: point with color yellow at (1,1)
  _01: point with color pink at (1,2)
  _011: point with color blue at (2,2)
  _0111: point with color red at (2,1)
diff: 
! 10 wrong pixels (generated / expected)

TRAIN 93b581b8.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _0: point with color green at (2,2)
  _01: point with color pink at (2,3)
  _011: point with color grey at (3,2)
  _0111: point with color red at (3,3)
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (0,0)
  _01: 
0 0 
0 0 
 with color grey at (0,4)
  _011: 
6 6 
6 6 
 at (4,0)
  _0111: 
0 0 
0 0 
 with color green at (4,4)
  _01111: 
3 
 at (2,2)
  _011111: 
6 
 at (2,3)
  _0111111: 
2 
 at (3,3)
  _01111111: 
5#
 at (3,2)
diff: 
   (26.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: point with color green at (2,2)
  _01: point with color pink at (2,3)
  _011: point with color grey at (3,2)
  _0111: point with color red at (3,3)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,6) and color black and layers
  _0: point with color green at (2,2)
  _01: point with color pink at (2,3)
  _011: point with color red at (3,3)
  _0111: point with color grey at (3,2)
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (6,6) and color black and layers
  _0: point with color green at (2,2)
  _01: point with color grey at (3,2)
  _011: point with color pink at (2,3)
  _0111: point with color red at (3,3)
diff: 
! 21 wrong pixels (generated / expected)

TRAIN 93b581b8.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: point with color green at (3,2)
  _01: point with color blue at (3,3)
  _011: point with color red at (4,2)
  _0111: point with color grey at (4,3)
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,6) and color black and layers
  _0: point with color green at (3,2)
  _01: point with color blue at (3,3)
  _011: point with color grey at (4,3)
  _0111: point with color red at (4,2)
diff: 
! 19 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (6,6) and color black and layers
  _0: point with color green at (3,2)
  _01: point with color red at (4,2)
  _011: point with color blue at (3,3)
  _0111: point with color grey at (4,3)
diff: 
! 23 wrong pixels (generated / expected)

TEST 93b581b8.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 20.6 sec (20.6 sec/task)
bits-train-error = 801.1 bits (801.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-175] Checking task 941d9a10.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.445	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.963	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.558	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.187	OUT ADD ^.layer_0 = ^.layer_0
0.119	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.086	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.070	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.065	OUT SPE ^.size = ^.size
0.062	OUT SPE ^.layer_011.pos = '(0, 0)
0.061	IN  SPE ^.layer_0.shape.color = grey
0.059	OUT SPE ^.layer_011.shape.color = blue
0.058	OUT SPE ^.layer_01.shape.color = red
0.056	OUT SPE ^.layer_0111.shape.color = green
0.055	OUT SPE ^.layer_01.pos.i = right(^.layer_0) / '2
0.055	OUT SPE ^.layer_01.shape.mask.model = Full
0.054	OUT SPE ^.layer_011.shape.mask.model = Full
0.053	OUT SPE ^.layer_0111.shape.mask.model = Full
0.052	IN  SPE ^.color = black
0.052	OUT SPE ^.color = black
0.014	
0.014	IN  GEN ^.layer_0.shape.color = ?
0.014	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model Full with color red at (right(^.layer_0) / '2,?)
  _011: rectangle with size (?,?) with model Full with color blue at '(0, 0)
  _0111: rectangle with size (?,?) with model Full with color green at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)

DL input  with Mi: L = 45.4 + 4584.4 = 4629.9
DL output with Mo: L = 138.8 + 1444.4 = 1583.2
DL input+output M: L = 184.3 + 6028.8 = 6213.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model Full with color red at (right(^.layer_0) / '2,?)
  _011: rectangle with size (?,?) with model Full with color blue at '(0, 0)
  _0111: rectangle with size (?,?) with model Full with color green at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 138.8 + 1444.4 = 1583.2
DL input+output M: L = 180.8 + 1444.4 = 1625.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
. . 0 . . . . 0 . . 
. . 0 . . . . 0 . . 
. . 0 . . . . 0 . . 
0 0 0 0 0 0 0 0 0 0 
. . 0 . . . . 0 . . 
. . 0 . . . . 0 . . 
. . 0 . . . . 0 . . 
0 0 0 0 0 0 0 0 0 0 
. . 0 . . . . 0 . . 
. . 0 . . . . 0 . . 
 with color grey at (0,0)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
. . 5#. . . . 5#. . 
. . 5#. . . . 5#. . 
. . 5#. . . . 5#. . 
5#5#5#5#5#5#5#5#5#5#
. . 5#. . . . 5#. . 
. . 5#. . . . 5#. . 
. . 5#. . . . 5#. . 
5#5#5#5#5#5#5#5#5#5#
. . 5#. . . . 5#. . 
. . 5#. . . . 5#. . 
 at (0,0)
  _01: rectangle with size (3,4) with model Full with color red at (4,3)
  _011: rectangle with size (3,2) with model Full with color blue at (0,0)
  _0111: rectangle with size (2,2) with model Full with color green at (8,8)
diff: 
   (53.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
. . 0 . . . . 0 . . 
. . 0 . . . . 0 . . 
. . 0 . . . . 0 . . 
0 0 0 0 0 0 0 0 0 0 
. . 0 . . . . 0 . . 
. . 0 . . . . 0 . . 
. . 0 . . . . 0 . . 
0 0 0 0 0 0 0 0 0 0 
. . 0 . . . . 0 . . 
. . 0 . . . . 0 . . 
 with color grey at (0,0)
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color grey at (0,2)
  + 26 delta pixels
diff: 
! 46 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color grey at (0,7)
  + 26 delta pixels
diff: 
! 46 wrong pixels (generated / expected)

TRAIN 941d9a10.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
. . . 0 . . . . 0 . 
0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . . 0 . 
0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . . 0 . 
. . . 0 . . . . 0 . 
0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . . 0 . 
0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . . 0 . 
 with color grey at (0,0)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
. . . 5#. . . . 5#. 
5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . . 5#. 
5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . . 5#. 
. . . 5#. . . . 5#. 
5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . . 5#. 
5#5#5#5#5#5#5#5#5#5#
. . . 5#. . . . 5#. 
 at (0,0)
  _01: rectangle with size (2,4) with model Full with color red at (4,4)
  _011: rectangle with size (1,3) with model Full with color blue at (0,0)
  _0111: rectangle with size (1,1) with model Full with color green at (9,9)
diff: 
   (46.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
. . . 0 . . . . 0 . 
0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . . 0 . 
0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . . 0 . 
. . . 0 . . . . 0 . 
0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . . 0 . 
0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . . 0 . 
 with color grey at (0,0)
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color grey and layers
  _0: rectangle with size (2,10) with model Full with color black at (4,0)
  + 36 delta pixels
diff: 
! 62 wrong pixels (generated / expected)

TRAIN 941d9a10.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
. 0 . . 0 . 0 . 0 . 
. 0 . . 0 . 0 . 0 . 
. 0 . . 0 . 0 . 0 . 
0 0 0 0 0 0 0 0 0 0 
. 0 . . 0 . 0 . 0 . 
. 0 . . 0 . 0 . 0 . 
0 0 0 0 0 0 0 0 0 0 
. 0 . . 0 . 0 . 0 . 
. 0 . . 0 . 0 . 0 . 
. 0 . . 0 . 0 . 0 . 
 with color grey at (0,0)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
. 5#. . 5#. 5#. 5#. 
. 5#. . 5#. 5#. 5#. 
. 5#. . 5#. 5#. 5#. 
5#5#5#5#5#5#5#5#5#5#
. 5#. . 5#. 5#. 5#. 
. 5#. . 5#. 5#. 5#. 
5#5#5#5#5#5#5#5#5#5#
. 5#. . 5#. 5#. 5#. 
. 5#. . 5#. 5#. 5#. 
. 5#. . 5#. 5#. 5#. 
 at (0,0)
  _01: rectangle with size (2,1) with model Full with color red at (4,5)
  _011: rectangle with size (3,1) with model Full with color blue at (0,0)
  _0111: rectangle with size (3,1) with model Full with color green at (7,9)
diff: 
   (45.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
. 0 . . 0 . 0 . 0 . 
. 0 . . 0 . 0 . 0 . 
. 0 . . 0 . 0 . 0 . 
0 0 0 0 0 0 0 0 0 0 
. 0 . . 0 . 0 . 0 . 
. 0 . . 0 . 0 . 0 . 
0 0 0 0 0 0 0 0 0 0 
. 0 . . 0 . 0 . 0 . 
. 0 . . 0 . 0 . 0 . 
. 0 . . 0 . 0 . 0 . 
 with color grey at (0,0)
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color grey and layers
  _0: rectangle with size (10,2) with model Full with color black at (0,2)
  + 36 delta pixels
diff: 
! 59 wrong pixels (generated / expected)

TRAIN 941d9a10.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
. 0 . 0 . . 0 . 0 . 
0 0 0 0 0 0 0 0 0 0 
. 0 . 0 . . 0 . 0 . 
. 0 . 0 . . 0 . 0 . 
0 0 0 0 0 0 0 0 0 0 
. 0 . 0 . . 0 . 0 . 
0 0 0 0 0 0 0 0 0 0 
. 0 . 0 . . 0 . 0 . 
0 0 0 0 0 0 0 0 0 0 
. 0 . 0 . . 0 . 0 . 
 with color grey at (0,0)
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color grey and layers
  _0: rectangle with size (2,2) with model Full with color black at (2,4)
  + 32 delta pixels
diff: 
! 69 wrong pixels (generated / expected)

TEST 941d9a10.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 7.4 sec (7.4 sec/task)
bits-train-error = 1444.4 bits (1444.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-174] Checking task 94f9d214.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 49837.1 = 49839.4
DL output with Mo: L = 2.3 + 24798.7 = 24801.0
DL input+output M: L = 4.6 + 74635.8 = 74640.5

# learning a model for train pairs
2.000	
1.197	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.730	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.467	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.326	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.222	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.199	OUT SPE ^.size = tiling('(2, 2), 2, 2)
0.190	OUT SPE ^.layer_0.shape.color = red
0.186	OUT SPE ^.color = black
0.059	
0.058	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size tiling('(2, 2), 2, 2) and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 6314.9 = 6385.1
DL output with Mo: L = 64.8 + 1367.3 = 1432.1
DL input+output M: L = 135.0 + 7682.1 = 7817.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size tiling('(2, 2), 2, 2) and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 64.8 + 1367.3 = 1432.1
DL input+output M: L = 67.1 + 1367.3 = 1434.4

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 
0 3 3 0 
0 0 0 0 
3 0 0 3 
0 0 0 1 
1 0 1 1 
1 1 1 1 
0 1 0 1 

diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (0,0)
  + 1 delta pixels
diff: 
   (60.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 
0 3 3 0 
0 0 0 0 
3 0 0 3 
0 0 0 1 
1 0 1 1 
1 1 1 1 
0 1 0 1 

diff: 
! 4 wrong pixels (generated / expected)

TRAIN 94f9d214.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
3 3 3 3 
0 3 3 0 
0 0 3 3 
3 0 0 0 
0 0 0 1 
0 0 0 1 
0 1 0 0 
1 0 0 1 

diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
0 . . 
. 0 0 
 with color red at (1,0)
diff: 
   (32.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 3 3 3 
0 3 3 0 
0 0 3 3 
3 0 0 0 
0 0 0 1 
0 0 0 1 
0 1 0 0 
1 0 0 1 

diff: 
! 6 wrong pixels (generated / expected)

TRAIN 94f9d214.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
0 3 3 0 
0 3 0 3 
0 0 3 0 
3 3 3 3 
1 1 1 1 
1 1 0 0 
1 1 0 0 
0 1 1 0 

diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (2,2) with model Even Checkboard with color red at (1,2)
diff: 
   (25.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 3 3 0 
0 3 0 3 
0 0 3 0 
3 3 3 3 
1 1 1 1 
1 1 0 0 
1 1 0 0 
0 1 1 0 

diff: 
! 6 wrong pixels (generated / expected)

TRAIN 94f9d214.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: 
3 3 3 3 
3 0 0 0 
3 0 3 3 
3 3 0 3 
1 1 1 0 
0 1 1 1 
1 0 1 1 
0 1 1 1 

diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (2,1)
diff: 
   (18.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 3 3 3 
3 0 0 0 
3 0 3 3 
3 3 0 3 
1 1 1 0 
0 1 1 1 
1 0 1 1 
0 1 1 1 

diff: 
! 5 wrong pixels (generated / expected)

TRAIN 94f9d214.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 3 0 3 
3 3 3 0 
0 0 0 3 
3 3 3 0 
0 0 1 1 
0 0 1 1 
0 1 0 0 
1 1 0 0 

diff: 
! 6 wrong pixels (generated / expected)

TEST 94f9d214.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.4 sec (3.4 sec/task)
bits-train-error = 1367.3 bits (1367.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-173] Checking task 952a094c.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.219	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.438	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.276	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.103	OUT ADD ^.layer_0 = ^.layer_0
0.097	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.090	OUT ADD ^.layer_01 = ^.layer_01.shape at (?,?)
0.084	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.077	OUT ADD ^.layer_011 = ^.layer_011.shape at (?,?)
0.071	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.064	OUT ADD ^.layer_0111 = ^.layer_0111.shape at (?,?)
0.058	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.051	OUT ADD ^.layer_01111 = ^.layer_01111.shape at (?,?)
0.046	OUT SPE ^.size = ^.size
0.043	OUT SPE ^.layer_01111.pos = ^.layer_0.pos - (1, 1)
0.040	OUT SPE ^.layer_01.pos = ^.layer_01111.pos + (2, 2)
0.039	IN  SPE ^.layer_0.shape.mask.model = Border
0.038	OUT SPE ^.layer_011.pos.j = ^.layer_0.pos.j - 1
0.036	OUT SPE ^.layer_0111.pos.i = ^.layer_0.pos.i - 1
0.035	OUT SPE ^.layer_0111.pos.j = center(^.layer_011) + 1
0.034	OUT SPE ^.layer_011.pos.i = bottom(^.layer_0) + 1
0.033	IN  SPE ^.color = black
0.033	OUT SPE ^.color = black
0.002	
0.002	IN  GEN ^.layer_0.shape.mask.model = ?
0.002	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_01.shape at ^.layer_01111.pos + (2, 2)
  _011: ^.layer_011.shape at (bottom(^.layer_0) + 1,^.layer_0.pos.j - 1)
  _0111: ^.layer_0111.shape at (^.layer_0.pos.i - 1,center(^.layer_011) + 1)
  _01111: ^.layer_01111.shape at ^.layer_0.pos - (1, 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Border with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 117.6 + 3622.8 = 3740.4
DL output with Mo: L = 181.7 + 0.0 = 181.7
DL input+output M: L = 299.3 + 3622.8 = 3922.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_01.shape at ^.layer_01111.pos + (2, 2)
  _011: ^.layer_011.shape at (bottom(^.layer_0) + 1,^.layer_0.pos.j - 1)
  _0111: ^.layer_0111.shape at (^.layer_0.pos.i - 1,center(^.layer_011) + 1)
  _01111: ^.layer_01111.shape at ^.layer_0.pos - (1, 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 114.2 + 0.0 = 114.2
DL output with Mo: L = 181.7 + 0.0 = 181.7
DL input+output M: L = 295.8 + 0.0 = 295.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,4) with model Border with color cyan at (2,3)
  _01: point with color yellow at (3,4)
  _011: point with color green at (3,5)
  _0111: point with color red at (5,4)
  _01111: point with color pink at (5,5)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
8 8 8 8 
8 . . 8 
8 . . 8 
8 . . 8 
8 8 8 8 
 at (2,3)
  _01: 
4 
 at (7,7)
  _011: 
3 
 at (7,2)
  _0111: 
2 
 at (1,7)
  _01111: 
6 
 at (1,2)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,4) with model Border with color cyan at (2,3)
  _01: point with color yellow at (3,4)
  _011: point with color green at (3,5)
  _0111: point with color red at (5,4)
  _01111: point with color pink at (5,5)
diff: 
correct output grid

TRAIN 952a094c.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,6) with model Border with color orange at (2,2)
  _01: point with color red at (3,3)
  _011: point with color cyan at (3,6)
  _0111: point with color brown at (6,3)
  _01111: point with color green at (6,6)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
7#7#7#7#7#7#
7#. . . . 7#
7#. . . . 7#
7#. . . . 7#
7#. . . . 7#
7#7#7#7#7#7#
 at (2,2)
  _01: 
2 
 at (8,8)
  _011: 
8 
 at (8,1)
  _0111: 
9#
 at (1,8)
  _01111: 
3 
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,6) with model Border with color orange at (2,2)
  _01: point with color red at (3,3)
  _011: point with color cyan at (3,6)
  _0111: point with color brown at (6,3)
  _01111: point with color green at (6,6)
diff: 
correct output grid

TRAIN 952a094c.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,6) with model Border with color blue at (1,1)
  _01: point with color red at (2,2)
  _011: point with color grey at (2,5)
  _0111: point with color pink at (4,2)
  _01111: point with color green at (4,5)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
1 1 1 1 1 1 
1 . . . . 1 
1 . . . . 1 
1 . . . . 1 
1 1 1 1 1 1 
 at (1,1)
  _01: 
2 
 at (6,7)
  _011: 
5#
 at (6,0)
  _0111: 
6 
 at (0,7)
  _01111: 
3 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,6) with model Border with color blue at (1,1)
  _01: point with color red at (2,2)
  _011: point with color grey at (2,5)
  _0111: point with color pink at (4,2)
  _01111: point with color green at (4,5)
diff: 
correct output grid

TRAIN 952a094c.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,6) with model Border with color green at (3,2)
  _01: point with color pink at (4,3)
  _011: point with color yellow at (4,6)
  _0111: point with color cyan at (6,3)
  _01111: point with color red at (6,6)
diff: 
correct output grid

TEST 952a094c.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 9.0 sec (9.0 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-172] Checking task 9565186b.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 14046.4 = 14048.7
DL output with Mo: L = 2.3 + 14046.4 = 14048.7
DL input+output M: L = 4.6 + 28092.8 = 28097.5

# learning a model for train pairs
2.000	
1.409	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.922	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.656	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.494	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.431	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.394	OUT SPE ^.size = ^.size
0.373	OUT SPE ^.layer_0.pos = projJ(^.layer_0.pos) + (1, 0)
0.357	IN  ADD ^.layer_00 = point with color ? at (?,?)
0.345	OUT SPE ^.layer_0.shape.mask.size.j = area(^.layer_0.shape.mask) - ^.layer_0.pos.j - ^.layer_01.pos.j
0.335	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_0.shape.mask.size.i + ^.layer_0.pos.i - ^.layer_00.pos.i
0.327	IN  SPE ^.layer_0.shape.mask.model = Full
0.319	IN  SPE ^.layer_01.shape.mask.model = Full
0.069	
0.069	IN  GEN ^.layer_01.shape.mask.model = ?
0.069	IN  GEN ^.layer_0.shape.mask.model = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i + ^.layer_0.pos.i - ^.layer_00.pos.i,area(^.layer_0.shape.mask) - ^.layer_0.pos.j - ^.layer_01.pos.j) with model ? with color ? at projJ(^.layer_0.pos) + (1, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 89.3 + 3521.5 = 3610.8
DL output with Mo: L = 151.7 + 725.0 = 876.6
DL input+output M: L = 241.0 + 4246.5 = 4487.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i + ^.layer_0.pos.i - ^.layer_00.pos.i,area(^.layer_0.shape.mask) - ^.layer_0.pos.j - ^.layer_01.pos.j) with model ? with color ? at projJ(^.layer_0.pos) + (1, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 88.3 + 0.0 = 88.3
DL output with Mo: L = 151.7 + 725.0 = 876.6
DL input+output M: L = 240.0 + 725.0 = 964.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color red and layers
  _00: point with color cyan at (1,2)
  _0: rectangle with size (1,2) with model Full with color cyan at (2,1)
  _01: rectangle with size (1,1) with model Full with color blue at (1,1)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color red and layers
  _0: rectangle with size (2,2) with model Full with color grey at (1,1)
diff: 
   (17.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color red and layers
  _00: point with color cyan at (1,2)
  _0: rectangle with size (1,2) with model Full with color cyan at (2,1)
  _01: rectangle with size (1,1) with model Full with color blue at (1,1)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color red and layers
  _00: point with color cyan at (1,2)
  _0: rectangle with size (1,1) with model Full with color blue at (1,1)
  _01: rectangle with size (1,2) with model Full with color cyan at (2,1)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,3) and color red and layers
  _00: point with color cyan at (2,1)
  _0: rectangle with size (2,1) with model Full with color cyan at (1,2)
  _01: rectangle with size (1,1) with model Full with color blue at (1,1)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 9565186b.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,3) and color blue and layers
  _00: point with color green at (1,2)
  _0: rectangle with size (2,1) with model Full with color cyan at (1,0)
  _01: rectangle with size (1,2) with model Full with color red at (2,1)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color blue and layers
  _0: rectangle with size (2,3) with mask 
0 . 0 
0 0 0 
 with color grey at (1,0)
diff: 
   (20.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color blue and layers
  _00: point with color green at (1,2)
  _0: rectangle with size (2,1) with model Full with color cyan at (1,0)
  _01: rectangle with size (1,2) with model Full with color red at (2,1)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color blue and layers
  _00: point with color green at (1,2)
  _0: rectangle with size (1,2) with model Full with color red at (2,1)
  _01: rectangle with size (2,1) with model Full with color cyan at (1,0)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,3) and color red and layers
  _00: point with color green at (1,2)
  _0: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color blue at (0,0)
  _01: rectangle with size (2,1) with model Full with color cyan at (1,0)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 9565186b.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _00: point with color red at (1,2)
  _0: rectangle with size (1,2) with model Full with color cyan at (1,0)
  _01: rectangle with size (3,3) with model Full with color red at (0,0)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color red and layers
  _0: rectangle with size (1,2) with model Full with color grey at (1,0)
diff: 
   (17.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _00: point with color red at (1,2)
  _0: rectangle with size (1,2) with model Full with color cyan at (1,0)
  _01: rectangle with size (3,3) with model Full with color red at (0,0)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color cyan and layers
  _00: point with color red at (1,2)
  _0: rectangle with size (1,3) with model Full with color red at (2,0)
  _01: rectangle with size (1,3) with model Full with color red at (0,0)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 9565186b.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (3,3) and color yellow and layers
  _00: point with color cyan at (0,2)
  _0: rectangle with size (1,2) with model Full with color green at (0,0)
  _01: rectangle with size (1,2) with model Full with color blue at (2,1)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color grey and layers
  _0: rectangle with size (1,3) with model Full with color yellow at (1,0)
diff: 
   (17.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color yellow and layers
  _00: point with color cyan at (0,2)
  _0: rectangle with size (1,2) with model Full with color green at (0,0)
  _01: rectangle with size (1,2) with model Full with color blue at (2,1)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color yellow and layers
  _00: point with color cyan at (0,2)
  _0: rectangle with size (1,2) with model Full with color blue at (2,1)
  _01: rectangle with size (1,2) with model Full with color green at (0,0)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 9565186b.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color green and layers
  _00: point with color blue at (0,0)
  _0: rectangle with size (3,1) with model Full with color red at (0,2)
  _01: rectangle with size (1,1) with model Full with color blue at (2,0)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color green and layers
  _00: point with color blue at (0,0)
  _0: rectangle with size (1,1) with model Full with color blue at (2,0)
  _01: rectangle with size (3,1) with model Full with color red at (0,2)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,3) and color green and layers
  _00: point with color blue at (2,0)
  _0: rectangle with size (3,1) with model Full with color red at (0,2)
  _01: rectangle with size (1,1) with model Full with color blue at (0,0)
diff: 
! 9 wrong pixels (generated / expected)

TEST 9565186b.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 4.6 sec (4.6 sec/task)
bits-train-error = 725.0 bits (725.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-171] Checking task 95990924.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 171857.0 = 171859.4
DL output with Mo: L = 2.3 + 171857.0 = 171859.4
DL input+output M: L = 4.6 + 343714.1 = 343718.7

# learning a model for train pairs
2.000	
1.071	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.207	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.184	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.156	OUT ADD ^.layer_0 = ^.layer_0
0.141	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.132	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.122	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.118	OUT ADD ^.layer_01111 = point with color ? at (?,?)
0.115	OUT SPE ^.size = ^.size
0.112	IN  SPE ^.layer_0.shape.mask = 
0 0 
0 0 

0.112	IN  SPE ^.layer_0.shape.color = grey
0.111	OUT SPE ^.layer_01111.pos.j = ^.layer_0.pos.j - 1
0.110	OUT SPE ^.layer_01111.shape.color = green
0.109	OUT SPE ^.layer_01111.pos.i = bottom(^.layer_0) + 1
0.108	OUT SPE ^.layer_011.pos.j = ^.layer_0.pos.i * '2
0.107	OUT SPE ^.layer_0111.pos.i = bottom(^.layer_0) + 1
0.106	OUT SPE ^.layer_01.shape.mask.model = Full
0.106	OUT SPE ^.layer_011.shape.mask.model = Full
0.105	OUT SPE ^.layer_0111.shape.mask.model = Full
0.105	IN  SPE ^.color = black
0.105	OUT SPE ^.color = black
0.061	
0.061	IN  GEN ^.layer_0.shape.color = ?
0.061	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,^.layer_0.pos.i * '2)
  _0111: rectangle with size (?,?) with model Full with color ? at (bottom(^.layer_0) + 1,?)
  _01111: point with color green at (bottom(^.layer_0) + 1,^.layer_0.pos.j - 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
0 0 
0 0 
 with color grey at (?,?)

DL input  with Mi: L = 42.5 + 7556.0 = 7598.5
DL output with Mo: L = 204.6 + 10176.8 = 10381.4
DL input+output M: L = 247.1 + 17732.8 = 17979.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,^.layer_0.pos.i * '2)
  _0111: rectangle with size (?,?) with model Full with color ? at (bottom(^.layer_0) + 1,?)
  _01111: point with color green at (bottom(^.layer_0) + 1,^.layer_0.pos.j - 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 0 
0 0 
 with color ? at (?,?)

DL input  with Mi: L = 39.1 + 0.0 = 39.1
DL output with Mo: L = 204.6 + 10176.8 = 10381.4
DL input+output M: L = 243.6 + 10176.8 = 10420.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color grey at (3,4)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
5#5#
5#5#
 at (3,4)
  _01: rectangle with size (1,1) with model Full with color blue at (2,3)
  _011: rectangle with size (1,1) with model Full with color red at (2,6)
  _0111: rectangle with size (1,1) with model Full with color yellow at (5,6)
  _01111: point with color green at (5,3)
diff: 
   (59.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color grey at (3,4)
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: 
0 
 with color grey at (3,4)
  + 3 delta pixels
diff:   ^.layer_0.shape.mask
! 20 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: 
0 
 with color grey at (3,5)
  + 3 delta pixels
diff:   ^.layer_0.shape.mask
! 19 wrong pixels (generated / expected)

TRAIN 95990924.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color grey at (2,2)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
5#5#
5#5#
 at (2,2)
  _01: rectangle with size (2,2) with model Full with color grey at (6,6)
  _011: rectangle with size (1,1) with model Full with color red at (1,4)
  _0111: rectangle with size (1,1) with model Full with color yellow at (4,4)
  _01111: point with color green at (4,1)
  + 5 delta pixels
diff: 
   (266.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color grey at (2,2)
  + 4 delta pixels
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color grey at (6,6)
  + 4 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: 
0 
 with color grey at (2,2)
  + 7 delta pixels
diff:   ^.layer_0.shape.mask
! 24 wrong pixels (generated / expected)

TRAIN 95990924.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: 
0 0 
0 0 
 with color grey at (2,3)
  + 12 delta pixels
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: 
5#5#
5#5#
 at (2,3)
  _01: rectangle with size (2,2) with model Full with color grey at (11,9)
  _011: rectangle with size (2,2) with model Full with color grey at (8,4)
  _0111: rectangle with size (2,2) with model Full with color grey at (4,8)
  _01111: point with color green at (4,2)
  + 15 delta pixels
diff: 
   (692.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: 
0 0 
0 0 
 with color grey at (2,3)
  + 12 delta pixels
diff: 
! 38 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: 
0 0 
0 0 
 with color grey at (4,8)
  + 12 delta pixels
diff: 
! 39 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,15) and color black and layers
  _0: 
0 0 
0 0 
 with color grey at (8,4)
  + 12 delta pixels
diff: 
! 35 wrong pixels (generated / expected)

TRAIN 95990924.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: 
0 0 
0 0 
 with color grey at (1,1)
  + 20 delta pixels
diff: 
! 51 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: 
0 0 
0 0 
 with color grey at (1,11)
  + 20 delta pixels
diff: 
! 50 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,15) and color black and layers
  _0: 
0 0 
0 0 
 with color grey at (4,5)
  + 20 delta pixels
diff: 
! 53 wrong pixels (generated / expected)

TEST 95990924.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 38.5 sec (38.5 sec/task)
bits-train-error = 10176.8 bits (10176.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-170] Checking task 963e52fc.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 40947.1 = 40949.4
DL output with Mo: L = 2.3 + 83083.8 = 83086.1
DL input+output M: L = 4.6 + 124030.8 = 124035.5

# learning a model for train pairs
2.000	
1.340	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.685	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.345	OUT SPE ^ = fillResizeAlike(black, projJ(^.size) + ^.size, ^)
0.181	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.113	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.104	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.100	IN  SPE ^.layer_0.shape.color = red
0.098	IN  SPE ^.layer_01.shape.mask.model = Full
0.096	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.094	IN  SPE ^.layer_011.shape.mask.model = Full
0.092	IN  SPE ^.layer_0111.shape.mask.model = Full
0.090	IN  SPE ^.color = black
0.004	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
fillResizeAlike(black, projJ(^.size) + ^.size, ^)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 130.8 + 3534.2 = 3665.0
DL output with Mo: L = 36.7 + 0.0 = 36.7
DL input+output M: L = 167.5 + 3534.2 = 3701.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
fillResizeAlike(black, projJ(^.size) + ^.size, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 36.7 + 0.0 = 36.7
DL input+output M: L = 39.0 + 0.0 = 39.0

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 0 0 
2 8 2 8 2 8 
2 8 2 8 2 8 
0 0 0 0 0 0 
0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
0 0 0 0 0 0 0 0 0 0 0 0 
2 8 2 8 2 8 2 8 2 8 2 8 
2 8 2 8 2 8 2 8 2 8 2 8 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 
2 8 2 8 2 8 
2 8 2 8 2 8 
0 0 0 0 0 0 
0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 963e52fc.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
2 3 3 2 3 3 2 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
2 3 3 2 3 3 2 3 3 2 3 3 2 3 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
2 3 3 2 3 3 2 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 963e52fc.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
1 2 2 1 2 2 1 2 
2 1 2 2 1 2 2 1 
0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
1 2 2 1 2 2 1 2 2 1 2 2 1 2 2 1 
2 1 2 2 1 2 2 1 2 2 1 2 2 1 2 2 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
1 2 2 1 2 2 1 2 
2 1 2 2 1 2 2 1 
0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN 963e52fc.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 
3 1 1 3 1 1 3 1 1 
3 1 1 3 1 1 3 1 1 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TEST 963e52fc.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.8 sec (1.8 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-169] Checking task 97999447.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 101940.4 = 101942.7
DL output with Mo: L = 2.3 + 101940.4 = 101942.7
DL input+output M: L = 4.6 + 203880.7 = 203885.3

# learning a model for train pairs
2.000	
1.031	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.206	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.169	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.139	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.120	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.113	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.106	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.098	OUT ADD ^.layer_010 = ^.layer_0
0.092	OUT SPE ^.size = ^.size
0.091	OUT SPE ^.layer_011.shape.color = grey
0.089	OUT SPE ^.layer_0.shape.color = grey
0.088	OUT SPE ^.layer_01.shape.mask.size.i = 1
0.087	OUT SPE ^.layer_011.pos.i = ^.layer_0.pos.i
0.086	OUT SPE ^.layer_011.shape.mask.size.i = 1
0.085	OUT SPE ^.layer_0111.shape.mask.size.i = 1
0.084	OUT SPE ^.layer_01.shape.mask.model = Full
0.083	OUT SPE ^.layer_011.shape.mask.model = Full
0.060	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)
  _010: ^.layer_0
  _01: rectangle with size (1,?) with model Full with color ? at (?,?)
  _011: rectangle with size (1,?) with model Full with color grey at (^.layer_0.pos.i,?)
  _0111: rectangle with size (1,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 2391.7 = 2423.9
DL output with Mo: L = 151.8 + 5906.8 = 6058.6
DL input+output M: L = 184.0 + 8298.6 = 8482.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)
  _010: ^.layer_0
  _01: rectangle with size (1,?) with model Full with color ? at (?,?)
  _011: rectangle with size (1,?) with model Full with color grey at (^.layer_0.pos.i,?)
  _0111: rectangle with size (1,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 0.0 = 32.2
DL output with Mo: L = 151.8 + 5906.8 = 6058.6
DL input+output M: L = 184.0 + 5906.8 = 6090.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,8) and color black and layers
  _0: point with color red at (2,2)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,8) and color black and layers
  _0: rectangle with size (1,3) with model Full with color grey at (5,4)
  _010: 
2 
 at (2,2)
  _01: rectangle with size (1,1) with model Full with color red at (2,4)
  _011: rectangle with size (1,5) with model Full with color grey at (2,3)
  _0111: rectangle with size (1,5) with model Full with color pink at (5,3)
  + 2 delta pixels
diff: 
   (168.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,8) and color black and layers
  _0: point with color red at (2,2)
  + 1 delta pixels
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,8) and color black and layers
  _0: point with color pink at (5,3)
  + 1 delta pixels
diff: 
! 16 wrong pixels (generated / expected)

TRAIN 97999447.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,12) and color black and layers
  _0: point with color red at (1,2)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,12) and color black and layers
  _0: rectangle with size (2,6) with model Even Checkboard with color grey at (4,6)
  _010: 
2 
 at (1,2)
  _01: rectangle with size (1,11) with model Full with color green at (4,1)
  _011: rectangle with size (1,9) with model Full with color grey at (1,3)
  _0111: rectangle with size (1,5) with model Full with color pink at (5,6)
  + 6 delta pixels
diff: 
   (349.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,12) and color black and layers
  _0: point with color red at (1,2)
  + 2 delta pixels
diff: 
! 30 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,12) and color black and layers
  _0: point with color green at (4,1)
  + 2 delta pixels
diff: 
! 31 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,12) and color black and layers
  _0: point with color pink at (5,6)
  + 2 delta pixels
diff: 
! 32 wrong pixels (generated / expected)

TRAIN 97999447.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (7,8) and color black and layers
  _0: point with color cyan at (3,3)
diff: 
   (0.0 bits)
data: a background with size (7,8) and color black and layers
  _0: rectangle with size (1,1) with model Full with color grey at (3,4)
  _010: 
8 
 at (3,3)
  _01: rectangle with size (1,1) with model Full with color cyan at (3,5)
  _011: rectangle with size (1,1) with model Full with color grey at (3,6)
  _0111: rectangle with size (1,1) with model Full with color cyan at (3,7)
diff: 
   (72.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,8) and color black and layers
  _0: point with color cyan at (3,3)
diff: 
! 10 wrong pixels (generated / expected)

TRAIN 97999447.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,8) and color black and layers
  _0: point with color green at (1,3)
  + 3 delta pixels
diff: 
! 23 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,8) and color black and layers
  _0: point with color yellow at (2,2)
  + 3 delta pixels
diff: 
! 25 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,8) and color black and layers
  _0: point with color cyan at (4,4)
  + 3 delta pixels
diff: 
! 25 wrong pixels (generated / expected)

TEST 97999447.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 58.0 sec (58.0 sec/task)
bits-train-error = 5906.8 bits (5906.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-168] Checking task 97a05b5b.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 350308.8 = 350311.2
DL output with Mo: L = 2.3 + 119252.6 = 119254.9
DL input+output M: L = 4.6 + 469561.4 = 469566.0

# learning a model for train pairs
2.000	
1.129	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.525	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.225	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.200	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.182	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.165	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.153	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.143	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.134	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.128	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.122	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.116	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.111	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.109	OUT SPE ^.layer_01.shape.mask = applySym(flipDiag1, ^.layer_011111.shape.mask)
0.063	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: applySym(flipDiag1, ^.layer_011111.shape.mask) with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 180.9 + 16140.6 = 16321.5
DL output with Mo: L = 153.5 + 7238.9 = 7392.4
DL input+output M: L = 334.4 + 23379.6 = 23714.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: applySym(flipDiag1, ^.layer_011111.shape.mask) with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 180.9 + 0.0 = 180.9
DL output with Mo: L = 153.5 + 7238.9 = 7392.4
DL input+output M: L = 334.4 + 7238.9 = 7573.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (24,19) and color black and layers
  _0: rectangle with size (17,9) with mask 
0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 0 . 0 
0 . . 0 0 0 0 . 0 
0 0 0 0 0 0 0 . 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 
0 0 0 . . . 0 0 0 
0 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 . . 0 0 0 . 0 0 
0 0 . 0 0 0 . 0 0 
0 . . 0 0 . . . 0 
0 0 0 0 0 0 0 0 0 
 with color red at (1,2)
  _01: rectangle with size (3,3) with model Full with color green at (7,14)
  _011: rectangle with size (3,3) with model Full with color yellow at (20,3)
  _0111: rectangle with size (3,3) with model +-cross with color red at (2,13)
  _01111: rectangle with size (2,3) with mask 
0 . 0 
0 0 0 
 with color red at (18,14)
  _011111: rectangle with size (3,3) with model Full with color red at (20,8)
  + 18 delta pixels
diff: 
   (0.0 bits)
data: a background with size (17,9) and color red and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
. . 0 
0 0 0 
 with color yellow at (1,1)
  _01: 
0 0 0 
0 0 0 
0 0 0 
 with color green at (1,6)
  _011: rectangle with size (3,2) with mask 
0 . 
0 0 
0 . 
 with color cyan at (13,0)
  _0111: rectangle with size (2,3) with model Full with color grey at (13,5)
  + 9 delta pixels
diff: 
   (503.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (24,19) and color black and layers
  _0: rectangle with size (17,9) with mask 
0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 0 . 0 
0 . . 0 0 0 0 . 0 
0 0 0 0 0 0 0 . 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 
0 0 0 . . . 0 0 0 
0 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 . . 0 0 0 . 0 0 
0 0 . 0 0 0 . 0 0 
0 . . 0 0 . . . 0 
0 0 0 0 0 0 0 0 0 
 with color red at (1,2)
  _01: rectangle with size (3,3) with model Full with color green at (7,14)
  _011: rectangle with size (3,3) with model Full with color yellow at (20,3)
  _0111: rectangle with size (3,3) with model +-cross with color red at (2,13)
  _01111: rectangle with size (2,3) with mask 
0 . 0 
0 0 0 
 with color red at (18,14)
  _011111: rectangle with size (3,3) with model Full with color red at (20,8)
  + 18 delta pixels
diff: 
! 153 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (24,19) and color black and layers
  _0: rectangle with size (17,9) with mask 
0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 0 . 0 
0 . . 0 0 0 0 . 0 
0 0 0 0 0 0 0 . 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 
0 0 0 . . . 0 0 0 
0 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 . . 0 0 0 . 0 0 
0 0 . 0 0 0 . 0 0 
0 . . 0 0 . . . 0 
0 0 0 0 0 0 0 0 0 
 with color red at (1,2)
  _01: rectangle with size (3,3) with model Full with color green at (7,14)
  _011: rectangle with size (3,3) with model Full with color yellow at (20,3)
  _0111: rectangle with size (3,3) with model Full with color red at (2,13)
  _01111: rectangle with size (2,3) with mask 
0 . 0 
0 0 0 
 with color red at (18,14)
  _011111: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. . 0 
 with color red at (20,8)
  + 18 delta pixels
diff: 
! 153 wrong pixels (generated / expected)

TRAIN 97a05b5b.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (20,10) and color black and layers
  _0: rectangle with size (8,8) with mask 
0 0 0 0 0 0 0 0 
0 0 . 0 0 0 0 0 
0 . . . 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 . . 0 0 
0 0 0 0 . 0 . 0 
0 0 0 0 0 . . 0 
0 0 0 0 0 0 0 0 
 with color red at (1,1)
  _01: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 0 
 with color red at (13,5)
  _011: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color red at (11,1)
  _0111: rectangle with size (3,1) with model Full with color yellow at (11,3)
  _01111: rectangle with size (3,3) with model Full with color green at (13,5)
  _011111: rectangle with size (3,1) with model Full with color yellow at (11,1)
diff: 
   (0.0 bits)
data: a background with size (8,8) and color red and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
. 0 . 
0 . . 
 with color green at (4,4)
  _01: 
0 0 0 
 with color yellow at (3,1)
  _011: rectangle with size (1,1) with model Full with color yellow at (1,1)
  _0111: rectangle with size (1,1) with model Full with color yellow at (1,3)
diff: 
   (116.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,10) and color black and layers
  _0: rectangle with size (8,8) with mask 
0 0 0 0 0 0 0 0 
0 0 . 0 0 0 0 0 
0 . . . 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 . . 0 0 
0 0 0 0 . 0 . 0 
0 0 0 0 0 . . 0 
0 0 0 0 0 0 0 0 
 with color red at (1,1)
  _01: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 0 
 with color red at (13,5)
  _011: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color red at (11,1)
  _0111: rectangle with size (3,1) with model Full with color yellow at (11,3)
  _01111: rectangle with size (3,3) with model Full with color green at (13,5)
  _011111: rectangle with size (3,1) with model Full with color yellow at (11,1)
diff: 
! 64 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,10) and color black and layers
  _0: rectangle with size (8,8) with mask 
0 0 0 0 0 0 0 0 
0 0 . 0 0 0 0 0 
0 . . . 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 . . 0 0 
0 0 0 0 . 0 . 0 
0 0 0 0 0 . . 0 
0 0 0 0 0 0 0 0 
 with color red at (1,1)
  _01: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 0 
 with color red at (13,5)
  _011: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color red at (11,1)
  _0111: rectangle with size (3,1) with model Full with color yellow at (11,3)
  _01111: rectangle with size (3,1) with model Full with color yellow at (11,1)
  _011111: rectangle with size (3,3) with model Full with color green at (13,5)
diff: 
! 64 wrong pixels (generated / expected)

TRAIN 97a05b5b.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (16,12) and color black and layers
  _0: rectangle with size (9,9) with mask 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 0 
0 0 . . . 0 0 0 0 
0 0 0 . 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color red at (6,1)
  _01: rectangle with size (3,1) with model Full with color red at (1,6)
  _011: rectangle with size (1,3) with model Full with color cyan at (1,5)
  _0111: rectangle with size (1,3) with model Full with color red at (2,5)
  _01111: rectangle with size (1,1) with model Full with color cyan at (3,5)
  _011111: rectangle with size (1,1) with model Full with color cyan at (3,7)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color red and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (2,2)
  _01: 
0 
 with color cyan at (2,4)
  _011: rectangle with size (1,1) with model Full with color cyan at (4,2)
  _0111: rectangle with size (1,1) with model Full with color cyan at (4,4)
diff: 
   (103.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,12) and color black and layers
  _0: rectangle with size (9,9) with mask 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 0 
0 0 . . . 0 0 0 0 
0 0 0 . 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color red at (6,1)
  _01: rectangle with size (3,1) with model Full with color red at (1,6)
  _011: rectangle with size (1,3) with model Full with color cyan at (1,5)
  _0111: rectangle with size (1,3) with model Full with color red at (2,5)
  _01111: rectangle with size (1,1) with model Full with color cyan at (3,5)
  _011111: rectangle with size (1,1) with model Full with color cyan at (3,7)
diff: 
! 81 wrong pixels (generated / expected)

TRAIN 97a05b5b.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,15) and color black and layers
  _0: rectangle with size (8,12) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 . 0 0 0 . 0 
0 . . 0 0 . . 0 0 0 0 0 
0 0 . . 0 0 . 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 . . . 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color red at (1,2)
  _01: rectangle with size (3,3) with model Full with color blue at (11,1)
  _011: rectangle with size (3,3) with model Full with color yellow at (16,3)
  _0111: rectangle with size (3,2) with mask 
0 0 
. 0 
0 0 
 with color green at (11,9)
  _01111: rectangle with size (3,3) with model Full with color red at (15,11)
  _011111: rectangle with size (3,2) with model Full with color red at (11,8)
  + 8 delta pixels
diff: 
! 96 wrong pixels (generated / expected)

TEST 97a05b5b.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.8 sec (59.8 sec/task)
bits-train-error = 7238.9 bits (7238.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-167] Checking task 98cf29f8.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 310703.0 = 310705.3
DL output with Mo: L = 2.3 + 310703.0 = 310705.3
DL input+output M: L = 4.6 + 621406.0 = 621410.6

# learning a model for train pairs
2.000	
1.200	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.414	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.259	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.107	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.061	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.020	OUT ADD ^.layer_01 = ^.layer_0
0.018	OUT SPE ^.size = ^.size
0.017	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.015	OUT SPE ^.layer_0.shape = ^.layer_01.shape
0.014	OUT SPE ^.layer_0.pos = ^.layer_01.pos - translationOnto(^.layer_0, ^.layer_01)
0.013	IN  SPE ^.layer_01.shape.mask.model = Full
0.013	IN  SPE ^.layer_0.shape.mask.model = Full
0.013	IN  SPE ^.layer_011.shape.mask.model = Full
0.013	IN  SPE ^.color = black
0.012	OUT SPE ^.color = black
0.001	
0.001	IN  DEL ^.layer_011
0.001	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_01.shape at ^.layer_01.pos - translationOnto(^.layer_0, ^.layer_01)
  _01: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 99.8 + 3637.2 = 3737.0
DL output with Mo: L = 77.8 + 0.0 = 77.8
DL input+output M: L = 177.6 + 3637.2 = 3814.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_01.shape at ^.layer_01.pos - translationOnto(^.layer_0, ^.layer_01)
  _01: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 71.2 + 20.0 = 91.2
DL output with Mo: L = 77.8 + 0.0 = 77.8
DL input+output M: L = 149.1 + 20.0 = 169.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (17,14) and color black and layers
  _0: rectangle with size (3,7) with model Full with color yellow at (1,1)
  _01: rectangle with size (3,4) with model Full with color grey at (8,2)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (17,14) and color black and layers
  _0: 
5#5#5#5#
5#5#5#5#
5#5#5#5#
 at (4,2)
  _01: 
4 4 4 4 4 4 4 
4 4 4 4 4 4 4 
4 4 4 4 4 4 4 
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,14) and color black and layers
  _0: rectangle with size (3,7) with model Full with color yellow at (1,1)
  _01: rectangle with size (3,4) with model Full with color grey at (8,2)
  + 4 delta pixels
diff: 
correct output grid

TRAIN 98cf29f8.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (13,18) and color black and layers
  _0: rectangle with size (7,7) with model Full with color red at (3,7)
  _01: rectangle with size (3,3) with model Full with color yellow at (5,1)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (13,18) and color black and layers
  _0: 
4 4 4 
4 4 4 
4 4 4 
 at (5,4)
  _01: 
2 2 2 2 2 2 2 
2 2 2 2 2 2 2 
2 2 2 2 2 2 2 
2 2 2 2 2 2 2 
2 2 2 2 2 2 2 
2 2 2 2 2 2 2 
2 2 2 2 2 2 2 
 at (3,7)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,18) and color black and layers
  _0: rectangle with size (7,7) with model Full with color red at (3,7)
  _01: rectangle with size (3,3) with model Full with color yellow at (5,1)
  + 3 delta pixels
diff: 
correct output grid

TRAIN 98cf29f8.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (15,19) and color black and layers
  _0: rectangle with size (2,5) with model Full with color red at (1,6)
  _01: rectangle with size (6,8) with model Full with color green at (7,3)
  + 4 delta pixels
diff: 
   (2.0 bits)
data: a background with size (15,19) and color black and layers
  _0: 
3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 
 at (3,3)
  _01: 
2 2 2 2 2 
2 2 2 2 2 
 at (1,6)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,19) and color black and layers
  _0: rectangle with size (6,8) with model Full with color green at (7,3)
  _01: rectangle with size (2,5) with model Full with color red at (1,6)
  + 4 delta pixels
diff: 
! 74 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,19) and color black and layers
  _0: rectangle with size (2,5) with model Full with color red at (1,6)
  _01: rectangle with size (6,8) with model Full with color green at (7,3)
  + 4 delta pixels
diff: 
correct output grid

TRAIN 98cf29f8.json/3: 1 2nd (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,17) and color black and layers
  _0: rectangle with size (8,5) with model Full with color green at (3,1)
  _01: rectangle with size (3,4) with model Full with color orange at (4,11)
  + 5 delta pixels
diff: 
correct output grid

TEST 98cf29f8.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 3.4 sec (3.4 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 0.83
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-166] Checking task 995c5fa3.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 88136.1 = 88138.4
DL output with Mo: L = 2.3 + 14046.4 = 14048.7
DL input+output M: L = 4.6 + 102182.5 = 102187.1

# learning a model for train pairs
2.000	
1.279	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.897	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.659	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.493	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.420	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.363	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.276	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.239	OUT SPE ^.layer_0.shape.mask = 
0 0 0 

0.203	OUT SPE ^.size = '(3, 3)
0.169	OUT SPE ^.layer_01.shape.mask = 
0 0 0 

0.147	OUT SPE ^.layer_0.pos = '(0, 0)
0.136	OUT SPE ^.layer_01.pos.j = '0
0.127	OUT SPE ^.layer_01.pos.i = right(^.layer_0) - 2
0.066	

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color ? and layers
  _0: 
0 0 0 
 with color ? at '(0, 0)
  _01: 
0 0 0 
 with color ? at (right(^.layer_0) - 2,'0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 5401.6 = 5499.7
DL output with Mo: L = 98.3 + 809.0 = 907.3
DL input+output M: L = 196.4 + 6210.6 = 6407.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color ? and layers
  _0: 
0 0 0 
 with color ? at '(0, 0)
  _01: 
0 0 0 
 with color ? at (right(^.layer_0) - 2,'0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 40.0 = 138.1
DL output with Mo: L = 98.3 + 809.0 = 907.3
DL input+output M: L = 196.4 + 849.0 = 1045.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with model Full with color grey at (0,0)
  _01: rectangle with size (4,4) with model Border with color grey at (0,5)
  _011: rectangle with size (4,4) with mask 
0 0 0 0 
. 0 0 . 
. 0 0 . 
0 0 0 0 
 with color grey at (0,10)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color green and layers
  _0: 
0 0 0 
 with color red at (0,0)
  _01: 
0 0 0 
 with color cyan at (1,0)
diff: 
   (20.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with model Full with color grey at (0,0)
  _01: rectangle with size (4,4) with model Border with color grey at (0,5)
  _011: rectangle with size (4,4) with mask 
0 0 0 0 
. 0 0 . 
. 0 0 . 
0 0 0 0 
 with color grey at (0,10)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with model Border with color grey at (0,5)
  _01: rectangle with size (4,4) with model Full with color grey at (0,0)
  _011: rectangle with size (4,4) with mask 
0 0 0 0 
. 0 0 . 
. 0 0 . 
0 0 0 0 
 with color grey at (0,10)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 995c5fa3.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 0 
. 0 0 . 
. 0 0 . 
0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (4,4) with model Full with color grey at (0,10)
  _011: rectangle with size (4,4) with mask 
0 0 0 0 
0 0 0 0 
0 . . 0 
0 . . 0 
 with color grey at (0,5)
diff: 
   (2.0 bits)
data: a background with size (3,3) and color red and layers
  _0: 
0 0 0 
 with color green at (0,0)
  _01: 
0 0 0 
 with color yellow at (1,0)
diff: 
   (20.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with model Full with color grey at (0,10)
  _01: rectangle with size (4,4) with mask 
0 0 0 0 
. 0 0 . 
. 0 0 . 
0 0 0 0 
 with color grey at (0,0)
  _011: rectangle with size (4,4) with mask 
0 0 0 0 
0 0 0 0 
0 . . 0 
0 . . 0 
 with color grey at (0,5)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 0 
. 0 0 . 
. 0 0 . 
0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (4,4) with model Full with color grey at (0,10)
  _011: rectangle with size (4,4) with mask 
0 0 0 0 
0 0 0 0 
0 . . 0 
0 . . 0 
 with color grey at (0,5)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 995c5fa3.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with model Border with color grey at (0,0)
  _01: rectangle with size (4,4) with model Full with color grey at (0,5)
  _011: rectangle with size (4,4) with mask 
0 0 0 0 
0 0 0 0 
0 . . 0 
0 . . 0 
 with color grey at (0,10)
diff: 
   (2.0 bits)
data: a background with size (3,3) and color yellow and layers
  _0: 
0 0 0 
 with color cyan at (0,0)
  _01: 
0 0 0 
 with color red at (1,0)
diff: 
   (20.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with model Full with color grey at (0,5)
  _01: rectangle with size (4,4) with model Border with color grey at (0,0)
  _011: rectangle with size (4,4) with mask 
0 0 0 0 
0 0 0 0 
0 . . 0 
0 . . 0 
 with color grey at (0,10)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with model Border with color grey at (0,0)
  _01: rectangle with size (4,4) with model Full with color grey at (0,5)
  _011: rectangle with size (4,4) with mask 
0 0 0 0 
0 0 0 0 
0 . . 0 
0 . . 0 
 with color grey at (0,10)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 995c5fa3.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (4,14) and color grey and layers
  _0: rectangle with size (4,1) with model Full with color black at (0,4)
  _01: rectangle with size (4,1) with model Full with color black at (0,9)
  _011: rectangle with size (2,2) with model Full with color black at (2,6)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color yellow and layers
  _0: 
0 0 0 
 with color red at (0,0)
  _01: 
0 0 0 
 with color red at (2,0)
diff: 
   (20.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,14) and color grey and layers
  _0: rectangle with size (4,1) with model Full with color black at (0,4)
  _01: rectangle with size (4,1) with model Full with color black at (0,9)
  _011: rectangle with size (2,2) with model Full with color black at (2,6)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,14) and color grey and layers
  _0: rectangle with size (4,1) with model Full with color black at (0,9)
  _01: rectangle with size (4,1) with model Full with color black at (0,4)
  _011: rectangle with size (2,2) with model Full with color black at (2,6)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 995c5fa3.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 0 
0 0 0 0 
0 . . 0 
0 . . 0 
 with color grey at (0,0)
  _01: rectangle with size (4,4) with mask 
0 0 0 0 
. 0 0 . 
. 0 0 . 
0 0 0 0 
 with color grey at (0,5)
  _011: rectangle with size (4,4) with model Border with color grey at (0,10)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 0 
. 0 0 . 
. 0 0 . 
0 0 0 0 
 with color grey at (0,5)
  _01: rectangle with size (4,4) with mask 
0 0 0 0 
0 0 0 0 
0 . . 0 
0 . . 0 
 with color grey at (0,0)
  _011: rectangle with size (4,4) with model Border with color grey at (0,10)
diff: 
! 9 wrong pixels (generated / expected)

TEST 995c5fa3.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 7.8 sec (7.8 sec/task)
bits-train-error = 809.0 bits (809.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-165] Checking task 99b1bc43.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 56169.1 = 56171.4
DL output with Mo: L = 2.3 + 24798.7 = 24801.0
DL input+output M: L = 4.6 + 80967.8 = 80972.4

# learning a model for train pairs
2.000	
1.442	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.033	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.761	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.533	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.414	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.329	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.306	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.295	OUT SPE ^.layer_0.shape.mask.size.j = ^.layer_0.shape.mask.size.j
0.285	OUT SPE ^.layer_0.pos = '(0, 0)
0.275	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.261	IN  SPE ^.layer_011.shape.mask = 
0 0 0 0 

0.254	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.250	IN  SPE ^.layer_011.shape.color = yellow
0.249	IN  SPE ^.color = black
0.127	
0.127	IN  DEL ^.layer_011
0.126	IN  DEL ^.layer_0111
0.126	IN  DEL ^.layer_01
0.125	IN  DEL ^.layer_01111
0.125	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color ? and layers
  _0: rectangle with size (?,^.layer_0.shape.mask.size.j) with model ? with color ? at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: 
0 0 0 0 
 with color yellow at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 144.1 + 6825.0 = 6969.1
DL output with Mo: L = 53.1 + 3036.4 = 3089.5
DL input+output M: L = 197.2 + 9861.3 = 10058.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color ? and layers
  _0: rectangle with size (?,^.layer_0.shape.mask.size.j) with model ? with color ? at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 53.1 + 3036.4 = 3089.5
DL input+output M: L = 95.1 + 3036.4 = 3131.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . . 0 
0 . . 0 
0 0 0 . 
 with color red at (5,0)
  + 11 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color green and layers
  _0: rectangle with size (3,4) with mask 
0 0 0 0 
0 0 0 0 
0 0 . . 
 with color black at (0,0)
diff: 
   (31.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . . 0 
0 . . 0 
0 0 0 . 
 with color red at (5,0)
  + 11 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (1,4) with model Full with color yellow at (4,0)
  + 14 delta pixels
diff: 
! size mismatch, 1x4 instead of 4x4
>> Trial 3
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,2) with mask 
. 0 
. 0 
0 . 
. 0 
 with color blue at (0,2)
  + 14 delta pixels
diff: 
! size mismatch, 4x2 instead of 4x4

TRAIN 99b1bc43.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 0 0 
0 . 0 . 
0 0 0 0 
0 0 0 0 
 with color red at (5,0)
  + 13 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (1,4) with model Full with color green at (0,0)
  + 4 delta pixels
diff: 
   (166.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 0 0 
0 . 0 . 
0 0 0 0 
0 0 0 0 
 with color red at (5,0)
  + 13 delta pixels
diff: 
! 11 wrong pixels (generated / expected)

TRAIN 99b1bc43.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 . . 
0 . 0 0 
0 0 0 . 
0 0 0 . 
 with color blue at (0,0)
  + 10 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 . . 
0 0 0 . 
. . 0 0 
. . 0 . 
 with color green at (0,0)
  + 1 delta pixels
diff: 
   (72.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 . . 
0 . 0 0 
0 0 0 . 
0 0 0 . 
 with color blue at (0,0)
  + 10 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (2,3) with model Full with color blue at (2,0)
  + 14 delta pixels
diff: 
! size mismatch, 2x3 instead of 4x4

TRAIN 99b1bc43.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 0 0 
. 0 0 0 
0 . 0 0 
0 0 0 0 
 with color red at (5,0)
  + 12 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 . . 
. 0 0 . 
. 0 0 0 
0 0 . . 
 with color green at (0,0)
diff: 
   (33.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 0 0 
. 0 0 0 
0 . 0 0 
0 0 0 0 
 with color red at (5,0)
  + 12 delta pixels
diff: 
! 13 wrong pixels (generated / expected)

TRAIN 99b1bc43.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . 0 0 
. 0 0 0 
. . 0 . 
. . 0 0 
 with color blue at (0,0)
  + 13 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,2) with model Full with color blue at (0,2)
  + 17 delta pixels
diff: 
! size mismatch, 4x2 instead of 4x4

TEST 99b1bc43.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 7.3 sec (7.3 sec/task)
bits-train-error = 3036.4 bits (3036.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-164] Checking task 99fa7670.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 45242.1 = 45244.4
DL output with Mo: L = 2.3 + 45242.1 = 45244.4
DL input+output M: L = 4.6 + 90484.2 = 90488.9

# learning a model for train pairs
2.000	
1.086	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.435	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.285	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.202	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.182	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.167	OUT SPE ^.size = ^.size
0.159	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.154	OUT SPE ^.layer_0.shape.mask.size.j = ^.size.j - 1
0.149	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.144	OUT SPE ^.layer_01.shape.color = majorityColor(^)
0.140	OUT SPE ^.layer_01.shape.mask.size.i = 2
0.135	OUT SPE ^.layer_0.shape.mask.size.i = ^.size.j / '2
0.133	IN  SPE ^.color = black
0.131	OUT SPE ^.color = black
0.069	
0.069	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (^.size.j / '2,^.size.j - 1) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: rectangle with size (2,?) with model ? with color majorityColor(^) at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.3 + 2868.7 = 2901.0
DL output with Mo: L = 120.3 + 2911.0 = 3031.3
DL input+output M: L = 152.6 + 5779.7 = 5932.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (^.size.j / '2,^.size.j - 1) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: rectangle with size (2,?) with model ? with color majorityColor(^) at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 40.0 = 72.2
DL output with Mo: L = 120.3 + 2911.0 = 3031.3
DL input+output M: L = 152.5 + 2951.0 = 3103.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _0: point with color green at (3,1)
  + 1 delta pixels
diff: 
   (2.0 bits)
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (3,5) with mask 
0 0 0 0 0 
. . . . 0 
. . . . 0 
 with color green at (3,1)
  _01: rectangle with size (2,4) with mask 
0 0 0 0 
. . . 0 
 with color red at (1,2)
diff: 
   (43.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: point with color red at (1,2)
  + 1 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,6) and color black and layers
  _0: point with color green at (3,1)
  + 1 delta pixels
diff: 
! 17 wrong pixels (generated / expected)

TRAIN 99fa7670.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: point with color pink at (1,1)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,2) with model Full with color pink at (1,1)
  _01: rectangle with size (2,1) with model Full with color pink at (1,2)
diff: 
   (16.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: point with color pink at (1,1)
diff: 
! 4 wrong pixels (generated / expected)

TRAIN 99fa7670.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _0: point with color cyan at (1,1)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (3,5) with mask 
0 0 0 0 0 
. . . . 0 
. . . . 0 
 with color cyan at (1,1)
  _01: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color grey at (4,3)
diff: 
   (40.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: point with color cyan at (1,1)
  + 1 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,6) and color black and layers
  _0: point with color grey at (4,3)
  + 1 delta pixels
diff: 
! 12 wrong pixels (generated / expected)

TRAIN 99fa7670.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (7,5) and color black and layers
  _0: point with color orange at (3,1)
  + 2 delta pixels
diff: 
   (2.0 bits)
data: a background with size (7,5) and color black and layers
  _0: rectangle with size (2,4) with mask 
0 0 0 0 
. . . 0 
 with color orange at (3,1)
  _01: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color pink at (5,2)
  + 4 delta pixels
diff: 
   (189.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,5) and color black and layers
  _0: point with color cyan at (1,2)
  + 2 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,5) and color black and layers
  _0: point with color orange at (3,1)
  + 2 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (7,5) and color black and layers
  _0: point with color pink at (5,2)
  + 2 delta pixels
diff: 
! 15 wrong pixels (generated / expected)

TRAIN 99fa7670.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,8) and color black and layers
  _0: point with color cyan at (0,3)
  + 2 delta pixels
diff: 
! 24 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,8) and color black and layers
  _0: point with color orange at (2,2)
  + 2 delta pixels
diff: 
! 28 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (7,8) and color black and layers
  _0: point with color red at (4,5)
  + 2 delta pixels
diff: 
! 21 wrong pixels (generated / expected)

TEST 99fa7670.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.0 sec (3.0 sec/task)
bits-train-error = 2911.0 bits (2911.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-163] Checking task 9aec4887.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 281928.8 = 281931.1
DL output with Mo: L = 2.3 + 37789.3 = 37791.7
DL input+output M: L = 4.6 + 319718.1 = 319722.8

# learning a model for train pairs
2.000	
1.105	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.830	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.699	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.588	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.476	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.368	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.288	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.256	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.243	OUT SPE ^.size = ^.layer_0.shape.mask.size + (2, 2)
0.231	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.214	OUT ADD ^.layer_010 = ^.layer_01.shape at (?,?)
0.201	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.192	OUT SPE ^.layer_01.shape.mask.size = projI(^.layer_0.shape.mask.size) + (0, 2)
0.186	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_0.shape.mask.size.i
0.177	OUT SPE ^.layer_011.shape.mask.size = projJ(^.layer_0.shape.mask.size) + (2, 0)
0.173	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.160	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.152	OUT SPE ^.layer_010.pos = '(0, 1)
0.131	
0.131	IN  DEL ^.layer_01111
0.131	IN  DEL ^.layer_0111
0.131	IN  DEL ^.layer_011
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size + (2, 2) and color ? and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i,?) with model ? with color ? at (?,?)
  _010: ^.layer_01.shape at '(0, 1)
  _01: rectangle with size projI(^.layer_0.shape.mask.size) + (0, 2) with model ? with color ? at (?,?)
  _011: rectangle with size projJ(^.layer_0.shape.mask.size) + (2, 0) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 153.4 + 5922.8 = 6076.1
DL output with Mo: L = 252.4 + 4687.4 = 4939.8
DL input+output M: L = 405.8 + 10610.2 = 11015.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size + (2, 2) and color ? and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i,?) with model ? with color ? at (?,?)
  _010: ^.layer_01.shape at '(0, 1)
  _01: rectangle with size projI(^.layer_0.shape.mask.size) + (0, 2) with model ? with color ? at (?,?)
  _011: rectangle with size projJ(^.layer_0.shape.mask.size) + (2, 0) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 252.4 + 4687.4 = 4939.8
DL input+output M: L = 322.6 + 4687.4 = 5010.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (15,16) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . . 0 
. 0 . 0 
0 0 0 0 
. 0 . 0 
 with color cyan at (1,1)
  _01: rectangle with size (1,4) with model Full with color yellow at (7,7)
  + 12 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (4,2) with mask 
. 0 
0 0 
0 0 
. 0 
 with color blue at (1,4)
  _010: 
4 4 4 4 
 at (0,1)
  _01: rectangle with size (4,2) with mask 
0 . 
0 . 
0 0 
0 . 
 with color red at (1,0)
  _011: rectangle with size (2,4) with mask 
. 0 . . 
0 0 0 0 
 with color green at (4,1)
  _0111: rectangle with size (4,4) with mask 
0 . . . 
. 0 . . 
. 0 0 . 
. . . 0 
 with color cyan at (1,1)
  _01111: rectangle with size (1,1) with model Full with color cyan at (1,4)
diff: 
   (153.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,16) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . . 0 
. 0 . 0 
0 0 0 0 
. 0 . 0 
 with color cyan at (1,1)
  _01: rectangle with size (1,4) with model Full with color yellow at (7,7)
  + 12 delta pixels
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,16) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . . 0 
. 0 . 0 
0 0 0 0 
. 0 . 0 
 with color cyan at (1,1)
  _01: rectangle with size (4,1) with model Full with color red at (8,6)
  + 12 delta pixels
diff: 
! 30 wrong pixels (generated / expected)

TRAIN 9aec4887.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (14,16) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
. 0 0 
 with color cyan at (2,8)
  _01: rectangle with size (1,3) with model Full with color green at (6,2)
  + 9 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 . 
0 0 
0 . 
 with color pink at (1,0)
  _010: 
3 3 3 
 at (0,1)
  _01: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color yellow at (1,3)
  _011: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color red at (3,1)
  _0111: rectangle with size (2,2) with model Full with color cyan at (2,2)
  _01111: rectangle with size (2,1) with model Full with color green at (0,2)
diff: 
   (128.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,16) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
. 0 0 
 with color cyan at (2,8)
  _01: rectangle with size (1,3) with model Full with color green at (6,2)
  + 9 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,16) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
. 0 0 
 with color cyan at (2,8)
  _01: rectangle with size (3,1) with model Full with color pink at (7,1)
  + 9 delta pixels
diff: 
! 20 wrong pixels (generated / expected)

TRAIN 9aec4887.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 . 0 
. 0 0 . 
. 0 . 0 
0 0 . 0 
 with color cyan at (9,6)
  _01: rectangle with size (1,4) with model Full with color orange at (1,3)
  + 12 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . . 0 
. 0 0 . 
. 0 . . 
0 . . . 
 with color cyan at (1,1)
  _010: 
7#7#7#7#
 at (0,1)
  _01: rectangle with size (4,2) with mask 
. 0 
. 0 
0 0 
. 0 
 with color pink at (1,4)
  _011: rectangle with size (2,4) with mask 
. 0 . . 
0 0 0 0 
 with color blue at (4,1)
  _0111: rectangle with size (4,1) with model Full with color yellow at (1,0)
  _01111: rectangle with size (1,1) with model Full with color cyan at (4,4)
  + 1 delta pixels
diff: 
   (186.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 . 0 
. 0 0 . 
. 0 . 0 
0 0 . 0 
 with color cyan at (9,6)
  _01: rectangle with size (1,4) with model Full with color orange at (1,3)
  + 12 delta pixels
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 . 0 
. 0 0 . 
. 0 . 0 
0 0 . 0 
 with color cyan at (9,6)
  _01: rectangle with size (4,1) with model Full with color yellow at (2,2)
  + 12 delta pixels
diff: 
! 30 wrong pixels (generated / expected)

TRAIN 9aec4887.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 . 0 0 
0 . 0 0 . 
. 0 0 0 0 
. . 0 . . 
0 0 . 0 0 
 with color cyan at (9,2)
  _01: rectangle with size (1,5) with model Full with color blue at (0,6)
  + 15 delta pixels
diff: 
! 36 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 . 0 0 
0 . 0 0 . 
. 0 0 0 0 
. . 0 . . 
0 0 . 0 0 
 with color cyan at (9,2)
  _01: rectangle with size (5,1) with model Full with color red at (1,5)
  + 15 delta pixels
diff: 
! 40 wrong pixels (generated / expected)

TEST 9aec4887.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.6 sec (59.6 sec/task)
bits-train-error = 4687.4 bits (4687.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-162] Checking task 9af7a82c.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 17487.7 = 17490.1
DL output with Mo: L = 2.3 + 29852.6 = 29854.9
DL input+output M: L = 4.6 + 47340.3 = 47345.0

# learning a model for train pairs
2.000	
1.543	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.137	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.901	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.671	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.532	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.439	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.384	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.367	OUT SPE ^.layer_01.shape.mask = scaleTo(^.layer_01.shape.mask, projI(^.size) + (0, 1))
0.353	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.342	OUT SPE ^.layer_0.pos = '(0, 0)
0.330	OUT SPE ^.layer_01.pos = '(0, 1)
0.318	OUT SPE ^.layer_011.pos = '(0, 2)
0.311	OUT SPE ^.layer_0.shape.color = majorityColor(^)
0.303	OUT SPE ^.layer_011.shape.color = ^.layer_01.shape.color
0.297	IN  SPE ^.layer_01.shape.mask.model = Full
0.291	OUT SPE ^.layer_011.shape.mask.size.i = area(^.layer_01.shape)
0.286	OUT SPE ^.layer_01.shape.color = ^.layer_0.shape.color
0.278	OUT SPE ^.size.j = area(^.layer_011.shape) * colorCount(^)
0.273	OUT SPE ^.layer_0.shape.mask.size.j = 1
0.269	OUT SPE ^.layer_011.shape.mask.size.j = 1
0.265	OUT SPE ^.layer_0.shape.mask.model = Full
0.261	OUT SPE ^.layer_011.shape.mask.model = Full
0.258	OUT SPE ^.color = black
0.062	
0.062	IN  GEN ^.layer_01.shape.mask.model = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,area(^.layer_011.shape) * colorCount(^)) and color black and layers
  _0: rectangle with size (?,1) with model Full with color majorityColor(^) at '(0, 0)
  _01: scaleTo(^.layer_01.shape.mask, projI(^.size) + (0, 1)) with color ^.layer_0.shape.color at '(0, 1)
  _011: rectangle with size (area(^.layer_01.shape),1) with model Full with color ^.layer_01.shape.color at '(0, 2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 88.8 + 3457.1 = 3545.9
DL output with Mo: L = 210.6 + 1444.9 = 1655.5
DL input+output M: L = 299.4 + 4902.0 = 5201.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,area(^.layer_011.shape) * colorCount(^)) and color black and layers
  _0: rectangle with size (?,1) with model Full with color majorityColor(^) at '(0, 0)
  _01: scaleTo(^.layer_01.shape.mask, projI(^.size) + (0, 1)) with color ^.layer_0.shape.color at '(0, 1)
  _011: rectangle with size (area(^.layer_01.shape),1) with model Full with color ^.layer_01.shape.color at '(0, 2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 88.3 + 20.0 = 108.3
DL output with Mo: L = 210.6 + 1444.9 = 1655.5
DL input+output M: L = 298.9 + 1464.9 = 1763.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color blue and layers
  _0: rectangle with size (1,2) with model Full with color red at (0,0)
  _01: rectangle with size (1,1) with model Full with color green at (1,1)
  _011: point with color red at (1,0)
diff: 
   (0.0 bits)
data: a background with size (5,3) and color black and layers
  _0: rectangle with size (5,1) with model Full with color blue at (0,0)
  _01: 
0 
0 
0 
 with color red at (0,1)
  _011: rectangle with size (1,1) with model Full with color green at (0,2)
diff: 
   (15.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color blue and layers
  _0: rectangle with size (1,2) with model Full with color red at (0,0)
  _01: rectangle with size (1,1) with model Full with color green at (1,1)
  _011: point with color red at (1,0)
diff: 
! size mismatch, 10x3 instead of 5x3
>> Trial 2
data: a background with size (3,3) and color blue and layers
  _0: rectangle with size (1,1) with model Full with color green at (1,1)
  _01: rectangle with size (1,2) with model Full with color red at (0,0)
  _011: point with color red at (1,0)
diff: 
! size mismatch, 10x3 instead of 5x3

TRAIN 9af7a82c.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,4) and color yellow and layers
  _0: rectangle with size (1,3) with model Full with color red at (1,0)
  _01: rectangle with size (1,2) with model Full with color blue at (0,1)
  _011: point with color green at (0,0)
diff: 
   (0.0 bits)
data: a background with size (6,4) and color black and layers
  _0: rectangle with size (6,1) with model Full with color yellow at (0,0)
  _01: 
0 
0 
0 
 with color red at (0,1)
  _011: rectangle with size (2,1) with model Full with color blue at (0,2)
  + 1 delta pixels
diff: 
   (56.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,4) and color yellow and layers
  _0: rectangle with size (1,3) with model Full with color red at (1,0)
  _01: rectangle with size (1,2) with model Full with color blue at (0,1)
  _011: point with color green at (0,0)
diff: 
! size mismatch, 10x4 instead of 6x4
>> Trial 2
data: a background with size (3,4) and color yellow and layers
  _0: rectangle with size (1,2) with model Full with color blue at (0,1)
  _01: rectangle with size (1,3) with model Full with color red at (1,0)
  _011: point with color green at (0,0)
diff: 
! size mismatch, 10x4 instead of 6x4
>> Trial 3
data: a background with size (3,4) and color red and layers
  _0: rectangle with size (3,4) with mask 
. . . 0 
. . . 0 
0 0 0 0 
 with color yellow at (0,0)
  _01: rectangle with size (1,2) with model Full with color blue at (0,1)
  _011: point with color green at (0,0)
diff: 
! size mismatch, 10x4 instead of 6x4

TRAIN 9af7a82c.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (4,3) and color green and layers
  _0: rectangle with size (2,3) with mask 
0 0 . 
. 0 0 
 with color cyan at (0,0)
  _01: rectangle with size (2,1) with model Full with color yellow at (2,2)
  _011: point with color red at (0,2)
diff: 
   (2.0 bits)
data: a background with size (5,4) and color black and layers
  _0: rectangle with size (5,1) with model Full with color green at (0,0)
  _01: 
0 
0 
0 
0 
 with color cyan at (0,1)
  _011: rectangle with size (2,1) with model Full with color yellow at (0,2)
  + 1 delta pixels
diff: 
   (55.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,3) and color cyan and layers
  _0: rectangle with size (3,2) with mask 
0 . 
0 0 
0 0 
 with color green at (1,0)
  _01: rectangle with size (2,1) with model Full with color yellow at (2,2)
  _011: point with color red at (0,2)
diff: 
! size mismatch, 10x4 instead of 5x4
>> Trial 2
data: a background with size (4,3) and color green and layers
  _0: rectangle with size (2,3) with mask 
0 0 . 
. 0 0 
 with color cyan at (0,0)
  _01: rectangle with size (2,1) with model Full with color yellow at (2,2)
  _011: point with color red at (0,2)
diff: 
! size mismatch, 10x4 instead of 5x4

TRAIN 9af7a82c.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (4,3) and color blue and layers
  _0: rectangle with size (3,1) with model Full with color red at (1,0)
  _01: rectangle with size (2,1) with model Full with color cyan at (2,1)
  _011: point with color red at (1,1)
diff: 
   (0.0 bits)
data: a background with size (6,3) and color black and layers
  _0: rectangle with size (6,1) with model Full with color blue at (0,0)
  _01: 
0 
0 
0 
0 
 with color red at (0,1)
  _011: rectangle with size (2,1) with model Full with color cyan at (0,2)
diff: 
   (17.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,3) and color blue and layers
  _0: rectangle with size (3,1) with model Full with color red at (1,0)
  _01: rectangle with size (2,1) with model Full with color cyan at (2,1)
  _011: point with color red at (1,1)
diff: 
! size mismatch, 10x3 instead of 6x3
>> Trial 2
data: a background with size (4,3) and color blue and layers
  _0: rectangle with size (2,1) with model Full with color cyan at (2,1)
  _01: rectangle with size (3,1) with model Full with color red at (1,0)
  _011: point with color red at (1,1)
diff: 
! size mismatch, 10x3 instead of 6x3

TRAIN 9af7a82c.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,4) and color blue and layers
  _0: rectangle with size (2,3) with mask 
0 0 . 
. 0 0 
 with color cyan at (0,0)
  _01: rectangle with size (2,2) with model Full with color red at (0,2)
  _011: point with color green at (2,1)
  + 2 delta pixels
diff: 
! size mismatch, 10x5 instead of 6x5

TEST 9af7a82c.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 11.3 sec (11.3 sec/task)
bits-train-error = 1444.9 bits (1444.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-161] Checking task 9d9215db.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 449510.2 = 449512.5
DL output with Mo: L = 2.3 + 449510.2 = 449512.5
DL input+output M: L = 4.6 + 899020.4 = 899025.0

# learning a model for train pairs
2.000	
1.014	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.112	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.111	OUT SPE ^.size = ^.size
0.109	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.106	OUT ADD ^.layer_0 = ^.layer_0
0.105	OUT ADD ^.layer_01 = ^.layer_0.shape at (?,?)
0.103	OUT ADD ^.layer_00 = ^.layer_0.shape at (?,?)
0.101	OUT ADD ^.layer_011 = ^.layer_0.shape at (?,?)
0.099	OUT ADD ^.layer_010 = ^.layer_0.shape at (?,?)
0.097	OUT ADD ^.layer_001 = ^.layer_0.shape at (?,?)
0.095	OUT ADD ^.layer_000 = ^.layer_0.shape at (?,?)
0.094	OUT ADD ^.layer_0111 = ^.layer_0.shape at (?,?)
0.092	IN  ADD ^.layer_00 = point with color ? at (?,?)
0.090	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.089	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.088	OUT SPE ^.layer_011 = ^.layer_011
0.087	OUT SPE ^.layer_0111 = ^.layer_01
0.087	OUT SPE ^.layer_00.pos.i = ^.layer_0.pos.i
0.086	OUT SPE ^.layer_000.pos.i = ^.layer_0.pos.i
0.086	OUT SPE ^.layer_001.pos.i = ^.layer_0.pos.i
0.078	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _000: ^.layer_0.shape at (^.layer_0.pos.i,?)
  _00: ^.layer_0.shape at (^.layer_0.pos.i,?)
  _001: ^.layer_0.shape at (^.layer_0.pos.i,?)
  _0: ^.layer_0
  _010: ^.layer_0.shape at (?,?)
  _01: ^.layer_0.shape at (?,?)
  _011: ^.layer_011
  _0111: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: point with color ? at (?,?)
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 86.6 + 3468.8 = 3555.4
DL output with Mo: L = 160.4 + 34838.3 = 34998.7
DL input+output M: L = 246.9 + 38307.2 = 38554.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _000: ^.layer_0.shape at (^.layer_0.pos.i,?)
  _00: ^.layer_0.shape at (^.layer_0.pos.i,?)
  _001: ^.layer_0.shape at (^.layer_0.pos.i,?)
  _0: ^.layer_0
  _010: ^.layer_0.shape at (?,?)
  _01: ^.layer_0.shape at (?,?)
  _011: ^.layer_011
  _0111: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: point with color ? at (?,?)
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 86.6 + 0.0 = 86.6
DL output with Mo: L = 160.4 + 34838.3 = 34998.7
DL input+output M: L = 246.9 + 34838.3 = 35085.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (19,19) and color black and layers
  _00: point with color cyan at (1,1)
  _0: point with color blue at (1,3)
  _01: point with color blue at (3,1)
  _011: point with color red at (3,3)
diff: 
   (0.0 bits)
data: a background with size (19,19) and color black and layers
  _000: 
1 
 at (1,5)
  _00: 
1 
 at (1,7)
  _001: 
1 
 at (1,9)
  _0: 
1 
 at (1,3)
  _010: 
1 
 at (1,11)
  _01: 
1 
 at (1,13)
  _011: 
2 
 at (3,3)
  _0111: 
1 
 at (3,1)
  + 28 delta pixels
diff: 
   (1216.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,19) and color black and layers
  _00: point with color cyan at (1,1)
  _0: point with color blue at (1,3)
  _01: point with color blue at (3,1)
  _011: point with color red at (3,3)
diff: 
! 35 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (19,19) and color black and layers
  _00: point with color cyan at (1,1)
  _0: point with color blue at (3,1)
  _01: point with color blue at (1,3)
  _011: point with color red at (3,3)
diff: 
! 35 wrong pixels (generated / expected)

TRAIN 9d9215db.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (19,19) and color black and layers
  _00: point with color green at (1,17)
  _0: point with color blue at (3,13)
  _01: point with color yellow at (3,15)
  _011: point with color blue at (5,15)
diff: 
   (0.0 bits)
data: a background with size (19,19) and color black and layers
  _000: 
1 
 at (3,5)
  _00: 
1 
 at (3,7)
  _001: 
1 
 at (3,9)
  _0: 
1 
 at (3,13)
  _010: 
1 
 at (3,11)
  _01: 
1 
 at (5,3)
  _011: 
1 
 at (5,15)
  _0111: 
4 
 at (3,15)
  + 20 delta pixels
diff: 
   (884.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,19) and color black and layers
  _00: point with color green at (1,17)
  _0: point with color blue at (3,13)
  _01: point with color yellow at (3,15)
  _011: point with color blue at (5,15)
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (19,19) and color black and layers
  _00: point with color green at (1,17)
  _0: point with color yellow at (3,15)
  _01: point with color blue at (3,13)
  _011: point with color blue at (5,15)
diff: 
! 27 wrong pixels (generated / expected)

TRAIN 9d9215db.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (19,19) and color black and layers
  _00: point with color yellow at (1,1)
  _0: point with color green at (1,3)
  _01: point with color green at (3,1)
  _011: point with color blue at (3,3)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (19,19) and color black and layers
  _000: 
3 
 at (1,5)
  _00: 
3 
 at (1,7)
  _001: 
3 
 at (1,9)
  _0: 
3 
 at (1,3)
  _010: 
3 
 at (1,11)
  _01: 
3 
 at (1,13)
  _011: 
1 
 at (3,3)
  _0111: 
3 
 at (3,1)
  + 32 delta pixels
diff: 
   (1382.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,19) and color black and layers
  _00: point with color yellow at (1,1)
  _0: point with color green at (1,3)
  _01: point with color green at (3,1)
  _011: point with color blue at (3,3)
  + 1 delta pixels
diff: 
! 39 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (19,19) and color black and layers
  _00: point with color yellow at (1,1)
  _0: point with color green at (1,3)
  _01: point with color green at (3,1)
  _011: point with color cyan at (5,5)
  + 1 delta pixels
diff: 
! 39 wrong pixels (generated / expected)

TRAIN 9d9215db.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,19) and color black and layers
  _00: point with color cyan at (11,5)
  _0: point with color yellow at (13,5)
  _01: point with color cyan at (13,7)
  _011: point with color green at (15,1)
  + 3 delta pixels
diff: 
! 51 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (19,19) and color black and layers
  _00: point with color cyan at (11,5)
  _0: point with color yellow at (13,5)
  _01: point with color cyan at (13,7)
  _011: point with color red at (15,3)
  + 3 delta pixels
diff: 
! 51 wrong pixels (generated / expected)

TEST 9d9215db.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.7 sec (59.7 sec/task)
bits-train-error = 34838.3 bits (34838.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-160] Checking task 9dfd6313.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 19416.1 = 19418.4
DL output with Mo: L = 2.3 + 19416.1 = 19418.4
DL input+output M: L = 4.6 + 38832.1 = 38836.8

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = applySym(flipDiag1, ^)
0.437	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.275	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.217	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.209	IN  SPE ^.layer_0.shape.color = grey
0.201	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.196	IN  SPE ^.layer_01.shape.mask.model = Full
0.192	IN  SPE ^.layer_011.shape.mask.model = Full
0.188	IN  SPE ^.color = black
0.006	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
applySym(flipDiag1, ^)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 102.6 + 3541.1 = 3643.7
DL output with Mo: L = 12.3 + 0.0 = 12.3
DL input+output M: L = 114.9 + 3541.1 = 3656.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
applySym(flipDiag1, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 12.3 + 0.0 = 12.3
DL input+output M: L = 14.6 + 0.0 = 14.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
5#0 0 
3 5#0 
0 0 5#

diff: 
   (0.0 bits)
data: 
5#3 0 
0 5#0 
0 0 5#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#0 0 
3 5#0 
0 0 5#

diff: 
correct output grid

TRAIN 9dfd6313.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
5#0 0 0 
0 5#0 0 
6 0 5#0 
6 0 4 5#

diff: 
   (0.0 bits)
data: 
5#0 6 6 
0 5#0 0 
0 0 5#4 
0 0 0 5#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#0 0 0 
0 5#0 0 
6 0 5#0 
6 0 4 5#

diff: 
correct output grid

TRAIN 9dfd6313.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
5#0 0 0 0 
0 5#0 0 0 
8 8 5#0 0 
0 2 0 5#0 
0 2 0 1 5#

diff: 
   (0.0 bits)
data: 
5#0 8 0 0 
0 5#8 2 2 
0 0 5#0 0 
0 0 0 5#1 
0 0 0 0 5#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#0 0 0 0 
0 5#0 0 0 
8 8 5#0 0 
0 2 0 5#0 
0 2 0 1 5#

diff: 
correct output grid

TRAIN 9dfd6313.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#0 0 0 0 0 
0 5#0 0 0 0 
3 3 5#0 0 0 
0 0 0 5#0 0 
2 0 8 8 5#0 
2 0 6 0 0 5#

diff: 
correct output grid

TEST 9dfd6313.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.3 sec (1.3 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-159] Checking task 9ecd008a.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 315315.2 = 315317.5
DL output with Mo: L = 2.3 + 10534.8 = 10537.1
DL input+output M: L = 4.6 + 325850.0 = 325854.6

# learning a model for train pairs
2.000	
1.487	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.215	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.085	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.961	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.894	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.855	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.819	OUT SPE ^.size = '(3, 3)
0.786	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.748	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.718	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.699	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.685	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.668	IN  ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.648	IN  ADD ^.layer_01111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.639	OUT SPE ^.layer_01.pos.j = ^.layer_01.pos.j / '2
0.631	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_01111.shape.mask.size.i - 3
0.623	OUT SPE ^.layer_0.shape.mask.model = Full
0.615	OUT SPE ^.layer_01.pos.i = ^.layer_011111.pos.i - ^.layer_01.shape.mask.size.i
0.608	OUT SPE ^.layer_011.pos.i = ^.layer_011111.pos.i - ^.layer_01.shape.mask.size.i
0.604	OUT SPE ^.layer_0.pos.j = ^.layer_01111111.pos.j + ^.layer_01111111.pos.j - ^.layer_011.pos.j
0.601	OUT SPE ^.layer_0.shape.mask.size.j = ^.layer_011.shape.mask.size.j - min(^.layer_0111.shape.mask.size.i, ^.layer_0111111.shape.mask.size.i)
0.601	IN  SPE ^.layer_0111111.shape.mask.model = Full
0.169	

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color ? and layers
  _0: rectangle with size (^.layer_01111.shape.mask.size.i - 3,^.layer_011.shape.mask.size.j - min(^.layer_0111.shape.mask.size.i, ^.layer_0111111.shape.mask.size.i)) with model Full with color ? at (?,^.layer_01111111.pos.j + ^.layer_01111111.pos.j - ^.layer_011.pos.j)
  _01: point with color ? at (^.layer_011111.pos.i - ^.layer_01.shape.mask.size.i,^.layer_01.pos.j / '2)
  _011: point with color ? at (^.layer_011111.pos.i - ^.layer_01.shape.mask.size.i,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 236.2 + 136099.4 = 136335.7
DL output with Mo: L = 386.2 + 1390.5 = 1776.7
DL input+output M: L = 622.4 + 137490.0 = 138112.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color ? and layers
  _0: rectangle with size (^.layer_01111.shape.mask.size.i - 3,^.layer_011.shape.mask.size.j - min(^.layer_0111.shape.mask.size.i, ^.layer_0111111.shape.mask.size.i)) with model Full with color ? at (?,^.layer_01111111.pos.j + ^.layer_01111111.pos.j - ^.layer_011.pos.j)
  _01: point with color ? at (^.layer_011111.pos.i - ^.layer_01.shape.mask.size.i,^.layer_01.pos.j / '2)
  _011: point with color ? at (^.layer_011111.pos.i - ^.layer_01.shape.mask.size.i,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 236.2 + 0.0 = 236.2
DL output with Mo: L = 386.2 + 1390.5 = 1776.7
DL input+output M: L = 622.4 + 1390.5 = 2013.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (16,16) and color blue and layers
  _0: rectangle with size (16,16) with mask 
. . . . . . . 0 0 . . . . . . . 
. . . . . . 0 0 0 0 . . . . . . 
. . . . . 0 . . . . 0 . . . . . 
. . . . 0 0 . . . . 0 0 . . . . 
. . . 0 . . . . . . . . 0 . . . 
. . 0 0 . . . . . . . . 0 0 . . 
. 0 . . . . . . . . . . . . 0 . 
0 0 . . . . . . . . . . . . 0 0 
0 0 . . . . . . . . . . . . 0 0 
. 0 . . . . . . . . . . . . 0 . 
. . 0 0 . . . . . . . . 0 0 . . 
. . . 0 . . . . . . . . 0 . . . 
. . . . 0 0 . . . . 0 0 . . . . 
. . . . . 0 . . . . 0 . . . . . 
. . . . . . 0 0 0 0 . . . . . . 
. . . . . . . 0 0 . . . . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (4,12) with model Full with color yellow at (10,2)
  _011: rectangle with size (3,3) with model Full with color black at (5,4)
  _0111: rectangle with size (2,12) with model Full with color yellow at (2,2)
  _01111: rectangle with size (4,16) with model Full with color grey at (0,0)
  _011111: rectangle with size (4,4) with mask 
. 0 0 . 
. . . 0 
0 . . 0 
. 0 0 . 
 with color green at (6,6)
  _0111111: rectangle with size (4,16) with model Full with color grey at (12,0)
  _01111111: rectangle with size (4,2) with mask 
0 . 
. 0 
. 0 
0 . 
 with color red at (6,2)
  + 111 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color blue and layers
  _0: rectangle with size (1,1) with model Full with color yellow at (0,0)
  _01: point with color brown at (2,1)
  _011: point with color green at (2,2)
  + 1 delta pixels
diff: 
   (71.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color blue and layers
  _0: rectangle with size (16,16) with mask 
. . . . . . . 0 0 . . . . . . . 
. . . . . . 0 0 0 0 . . . . . . 
. . . . . 0 . . . . 0 . . . . . 
. . . . 0 0 . . . . 0 0 . . . . 
. . . 0 . . . . . . . . 0 . . . 
. . 0 0 . . . . . . . . 0 0 . . 
. 0 . . . . . . . . . . . . 0 . 
0 0 . . . . . . . . . . . . 0 0 
0 0 . . . . . . . . . . . . 0 0 
. 0 . . . . . . . . . . . . 0 . 
. . 0 0 . . . . . . . . 0 0 . . 
. . . 0 . . . . . . . . 0 . . . 
. . . . 0 0 . . . . 0 0 . . . . 
. . . . . 0 . . . . 0 . . . . . 
. . . . . . 0 0 0 0 . . . . . . 
. . . . . . . 0 0 . . . . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (4,12) with model Full with color yellow at (10,2)
  _011: rectangle with size (3,3) with model Full with color black at (5,4)
  _0111: rectangle with size (2,12) with model Full with color yellow at (2,2)
  _01111: rectangle with size (4,16) with model Full with color grey at (0,0)
  _011111: rectangle with size (4,4) with mask 
. 0 0 . 
. . . 0 
0 . . 0 
. 0 0 . 
 with color green at (6,6)
  _0111111: rectangle with size (4,16) with model Full with color grey at (12,0)
  _01111111: rectangle with size (4,2) with mask 
0 . 
. 0 
. 0 
0 . 
 with color red at (6,2)
  + 111 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 9ecd008a.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (16,16) and color blue and layers
  _0: rectangle with size (16,16) with mask 
. . . . . . 0 0 0 0 . . . . . . 
. . . . . . 0 . . 0 . . . . . . 
. . . . 0 0 . . . . 0 0 . . . . 
. . . . 0 . . . . . . 0 . . . . 
. . 0 0 . . . . . . . . 0 0 . . 
. . 0 . . . . . . . . . . 0 . . 
0 0 . . . . . . . . . . . . 0 0 
0 . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . 0 
0 0 . . . . . . . . . . . . 0 0 
. . 0 . . . . . . . . . . 0 . . 
. . 0 0 . . . . . . . . 0 0 . . 
. . . . 0 . . . . . . 0 . . . . 
. . . . 0 0 . . . . 0 0 . . . . 
. . . . . . 0 . . 0 . . . . . . 
. . . . . . 0 0 0 0 . . . . . . 
 with color pink at (0,0)
  _01: rectangle with size (3,3) with model Full with color black at (8,4)
  _011: rectangle with size (4,4) with mask 
0 0 0 . 
0 0 . 0 
0 . . . 
. 0 . . 
 with color green at (0,0)
  _0111: rectangle with size (2,8) with model Full with color orange at (0,4)
  _01111: rectangle with size (4,4) with mask 
. 0 0 0 
0 . 0 0 
. . . 0 
. . 0 . 
 with color green at (0,12)
  _011111: rectangle with size (8,2) with model Full with color orange at (4,0)
  _0111111: rectangle with size (8,2) with model Full with color orange at (4,14)
  _01111111: rectangle with size (4,4) with mask 
. 0 . . 
0 . . . 
0 0 . 0 
0 0 0 . 
 with color green at (12,0)
  + 98 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color blue and layers
  _0: rectangle with size (1,2) with model Full with color green at (2,0)
  _01: point with color pink at (1,2)
  _011: point with color grey at (1,0)
diff: 
   (33.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color blue and layers
  _0: rectangle with size (16,16) with mask 
. . . . . . 0 0 0 0 . . . . . . 
. . . . . . 0 . . 0 . . . . . . 
. . . . 0 0 . . . . 0 0 . . . . 
. . . . 0 . . . . . . 0 . . . . 
. . 0 0 . . . . . . . . 0 0 . . 
. . 0 . . . . . . . . . . 0 . . 
0 0 . . . . . . . . . . . . 0 0 
0 . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . 0 
0 0 . . . . . . . . . . . . 0 0 
. . 0 . . . . . . . . . . 0 . . 
. . 0 0 . . . . . . . . 0 0 . . 
. . . . 0 . . . . . . 0 . . . . 
. . . . 0 0 . . . . 0 0 . . . . 
. . . . . . 0 . . 0 . . . . . . 
. . . . . . 0 0 0 0 . . . . . . 
 with color pink at (0,0)
  _01: rectangle with size (3,3) with model Full with color black at (8,4)
  _011: rectangle with size (4,4) with mask 
0 0 0 . 
0 0 . 0 
0 . . . 
. 0 . . 
 with color green at (0,0)
  _0111: rectangle with size (2,8) with model Full with color orange at (0,4)
  _01111: rectangle with size (4,4) with mask 
. 0 0 0 
0 . 0 0 
. . . 0 
. . 0 . 
 with color green at (0,12)
  _011111: rectangle with size (8,2) with model Full with color orange at (4,0)
  _0111111: rectangle with size (8,2) with model Full with color orange at (4,14)
  _01111111: rectangle with size (4,4) with mask 
. 0 . . 
0 . . . 
0 0 . 0 
0 0 0 . 
 with color green at (12,0)
  + 98 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (16,16) and color blue and layers
  _0: rectangle with size (16,16) with mask 
. . . . . . 0 0 0 0 . . . . . . 
. . . . . . 0 . . 0 . . . . . . 
. . . . 0 0 . . . . 0 0 . . . . 
. . . . 0 . . . . . . 0 . . . . 
. . 0 0 . . . . . . . . 0 0 . . 
. . 0 . . . . . . . . . . 0 . . 
0 0 . . . . . . . . . . . . 0 0 
0 . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . 0 
0 0 . . . . . . . . . . . . 0 0 
. . 0 . . . . . . . . . . 0 . . 
. . 0 0 . . . . . . . . 0 0 . . 
. . . . 0 . . . . . . 0 . . . . 
. . . . 0 0 . . . . 0 0 . . . . 
. . . . . . 0 . . 0 . . . . . . 
. . . . . . 0 0 0 0 . . . . . . 
 with color pink at (0,0)
  _01: rectangle with size (3,3) with model Full with color black at (8,4)
  _011: rectangle with size (4,4) with mask 
0 0 0 . 
0 0 . 0 
0 . . . 
. 0 . . 
 with color green at (0,0)
  _0111: rectangle with size (2,8) with model Full with color orange at (0,4)
  _01111: rectangle with size (4,4) with mask 
. 0 0 0 
0 . 0 0 
. . . 0 
. . 0 . 
 with color green at (0,12)
  _011111: rectangle with size (8,2) with model Full with color orange at (4,0)
  _0111111: rectangle with size (8,2) with model Full with color orange at (4,14)
  _01111111: rectangle with size (4,4) with mask 
. . 0 . 
. . . 0 
0 . 0 0 
. 0 0 0 
 with color green at (12,12)
  + 98 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (16,16) and color blue and layers
  _0: rectangle with size (16,16) with mask 
. . . . . . 0 0 0 0 . . . . . . 
. . . . . . 0 . . 0 . . . . . . 
. . . . 0 0 . . . . 0 0 . . . . 
. . . . 0 . . . . . . 0 . . . . 
. . 0 0 . . . . . . . . 0 0 . . 
. . 0 . . . . . . . . . . 0 . . 
0 0 . . . . . . . . . . . . 0 0 
0 . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . 0 
0 0 . . . . . . . . . . . . 0 0 
. . 0 . . . . . . . . . . 0 . . 
. . 0 0 . . . . . . . . 0 0 . . 
. . . . 0 . . . . . . 0 . . . . 
. . . . 0 0 . . . . 0 0 . . . . 
. . . . . . 0 . . 0 . . . . . . 
. . . . . . 0 0 0 0 . . . . . . 
 with color pink at (0,0)
  _01: rectangle with size (3,3) with model Full with color black at (8,4)
  _011: rectangle with size (4,4) with mask 
0 0 0 . 
0 0 . 0 
0 . . . 
. 0 . . 
 with color green at (0,0)
  _0111: rectangle with size (2,8) with model Full with color orange at (0,4)
  _01111: rectangle with size (8,2) with model Full with color orange at (4,0)
  _011111: rectangle with size (4,4) with mask 
. 0 0 0 
0 . 0 0 
. . . 0 
. . 0 . 
 with color green at (0,12)
  _0111111: rectangle with size (8,2) with model Full with color orange at (4,14)
  _01111111: rectangle with size (4,4) with mask 
. 0 . . 
0 . . . 
0 0 . 0 
0 0 0 . 
 with color green at (12,0)
  + 98 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 9ecd008a.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (16,16) and color grey and layers
  _0: rectangle with size (8,7) with mask 
. . . 0 0 . . 
. . 0 . . 0 . 
. 0 . . . . 0 
0 . . . . . . 
0 . . . . . . 
. 0 . . . . . 
. . 0 . . 0 . 
. . . 0 0 . . 
 with color blue at (4,4)
  _01: rectangle with size (5,5) with mask 
. 0 . 0 0 
0 . 0 . . 
. 0 0 0 . 
0 . 0 . . 
0 . . . . 
 with color green at (0,0)
  _011: rectangle with size (5,5) with mask 
0 0 . 0 . 
. . 0 . 0 
. 0 0 0 . 
. . 0 . 0 
. . . . 0 
 with color green at (0,11)
  _0111: rectangle with size (5,5) with mask 
0 . . . . 
0 . 0 . . 
. 0 0 0 . 
0 . 0 . . 
. 0 . 0 0 
 with color green at (11,0)
  _01111: rectangle with size (5,5) with mask 
. . . . 0 
. . 0 . 0 
. 0 0 0 . 
. . 0 . 0 
0 0 . 0 . 
 with color green at (11,11)
  _011111: rectangle with size (3,3) with model Full with color black at (7,10)
  _0111111: rectangle with size (4,12) with model Full with color pink at (6,2)
  _01111111: rectangle with size (12,4) with model Full with color pink at (2,6)
  + 85 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color pink and layers
  _0: rectangle with size (2,1) with model Full with color blue at (0,1)
  _01: point with color blue at (2,0)
  _011: point with color red at (2,1)
diff: 
   (33.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color grey and layers
  _0: rectangle with size (8,7) with mask 
. . . 0 0 . . 
. . 0 . . 0 . 
. 0 . . . . 0 
0 . . . . . . 
0 . . . . . . 
. 0 . . . . . 
. . 0 . . 0 . 
. . . 0 0 . . 
 with color blue at (4,4)
  _01: rectangle with size (5,5) with mask 
. 0 . 0 0 
0 . 0 . . 
. 0 0 0 . 
0 . 0 . . 
0 . . . . 
 with color green at (0,0)
  _011: rectangle with size (5,5) with mask 
0 0 . 0 . 
. . 0 . 0 
. 0 0 0 . 
. . 0 . 0 
. . . . 0 
 with color green at (0,11)
  _0111: rectangle with size (5,5) with mask 
0 . . . . 
0 . 0 . . 
. 0 0 0 . 
0 . 0 . . 
. 0 . 0 0 
 with color green at (11,0)
  _01111: rectangle with size (5,5) with mask 
. . . . 0 
. . 0 . 0 
. 0 0 0 . 
. . 0 . 0 
0 0 . 0 . 
 with color green at (11,11)
  _011111: rectangle with size (3,3) with model Full with color black at (7,10)
  _0111111: rectangle with size (4,12) with model Full with color pink at (6,2)
  _01111111: rectangle with size (12,4) with model Full with color pink at (2,6)
  + 85 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 9ecd008a.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color grey and layers
  _0: rectangle with size (16,16) with mask 
. . . . . . . 0 0 . . . . . . . 
. . . . . . 0 . . 0 . . . . . . 
. . . . . 0 . . . . 0 . . . . . 
. . . . 0 . . . . . . 0 . . . . 
. . . 0 0 . . . . . . 0 0 . . . 
. . . . . . . . . . . . . 0 . . 
. . . . . . . . . . . . . . 0 . 
0 . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . 0 
. 0 . . . . . . . . . . . . 0 . 
. . 0 . . . . . . . . . . 0 . . 
. . . 0 0 . . . . . . 0 0 . . . 
. . . . 0 . . . . . . 0 . . . . 
. . . . . 0 . . . . 0 . . . . . 
. . . . . . 0 . . 0 . . . . . . 
. . . . . . . 0 0 . . . . . . . 
 with color blue at (0,0)
  _01: rectangle with size (8,8) with mask 
. . . 0 0 . . . 
. . 0 . . 0 . . 
. 0 . . . . 0 . 
0 . . . . . . 0 
0 . . . . . . 0 
. 0 . . . . 0 . 
. . 0 . . 0 . . 
. . . 0 0 . . . 
 with color red at (4,4)
  _011: rectangle with size (3,3) with model Full with color black at (5,1)
  _0111: rectangle with size (4,4) with mask 
. . 0 0 
. . 0 0 
0 0 . . 
0 0 . . 
 with color brown at (0,0)
  _01111: rectangle with size (4,4) with mask 
0 0 . . 
0 0 . . 
. . 0 0 
. . 0 0 
 with color brown at (0,12)
  _011111: rectangle with size (4,4) with model x-cross with color brown at (6,6)
  _0111111: rectangle with size (2,8) with model Full with color pink at (0,4)
  _01111111: rectangle with size (4,4) with mask 
0 0 . . 
0 0 . . 
. . 0 0 
. . 0 0 
 with color brown at (12,0)
  + 92 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TEST 9ecd008a.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 38.4 sec (38.4 sec/task)
bits-train-error = 1390.5 bits (1390.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-158] Checking task 9edfc990.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 265616.4 = 265618.7
DL output with Mo: L = 2.3 + 265616.4 = 265618.7
DL input+output M: L = 4.6 + 531232.8 = 531237.4

# learning a model for train pairs
2.000	
1.530	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.088	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.057	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
1.043	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
1.029	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
1.014	OUT ADD ^.layer_00 = ^.layer_0
1.001	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.986	OUT ADD ^.layer_010 = ^.layer_01
0.976	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.962	OUT ADD ^.layer_0101 = ^.layer_011
0.954	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.944	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.936	IN  ADD ^.layer_0110 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.451	
0.450	IN  DEL ^.layer_0110
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _0101: ^.layer_011
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 128855.2 = 128980.9
DL output with Mo: L = 155.9 + 119367.3 = 119523.2
DL input+output M: L = 281.7 + 248222.5 = 248504.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _0101: ^.layer_011
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 0.0 = 98.1
DL output with Mo: L = 155.9 + 119399.0 = 119554.9
DL input+output M: L = 254.0 + 119399.0 = 119653.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with model Odd Checkboard with color orange at (5,7)
  _01: rectangle with size (3,2) with mask 
0 . 
. 0 
. 0 
 with color grey at (7,5)
  _011: rectangle with size (1,2) with model Full with color brown at (8,0)
  + 65 delta pixels
diff: 
   (0.0 bits)
data: a background with size (13,13) and color blue and layers
  _00: 
. 7#. 
7#. 7#
. 7#. 
 at (5,7)
  _0: rectangle with size (2,2) with model Odd Checkboard with color brown at (0,11)
  _010: 
5#. 
. 5#
. 5#
 at (7,5)
  _0101: 
9#9#
 at (8,0)
  _01: rectangle with size (3,1) with model Full with color black at (0,11)
  _011: rectangle with size (1,3) with model Full with color cyan at (2,10)
  _0111: rectangle with size (1,2) with model Full with color black at (5,11)
  + 57 delta pixels
diff: 
   (2463.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with model Odd Checkboard with color orange at (5,7)
  _01: rectangle with size (3,2) with mask 
0 . 
. 0 
. 0 
 with color grey at (7,5)
  _011: rectangle with size (1,2) with model Full with color brown at (8,0)
  + 65 delta pixels
diff: 
! size mismatch, 10x10 instead of 13x13
>> Trial 2
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with model Odd Checkboard with color orange at (5,7)
  _01: rectangle with size (3,2) with mask 
0 . 
. 0 
. 0 
 with color grey at (7,5)
  _011: rectangle with size (1,2) with model Full with color brown at (10,6)
  + 65 delta pixels
diff: 
! size mismatch, 10x10 instead of 13x13

TRAIN 9edfc990.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . . 
 with color orange at (4,0)
  _01: rectangle with size (3,3) with mask 
0 . 0 
. 0 . 
0 . . 
 with color yellow at (4,7)
  _011: rectangle with size (1,3) with model Full with color grey at (0,6)
  + 102 delta pixels
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _00: 
7#7#7#
7#. . 
 at (4,0)
  _0: rectangle with size (15,15) with mask 
. . . . . . . . . . . 0 0 0 0 
. . . . . 0 0 0 . . 0 0 0 . 0 
. . . 0 0 0 . . 0 0 0 . 0 . 0 
. . . 0 . 0 0 0 . 0 . . 0 . . 
. . . . 0 0 . . . . 0 0 . . . 
. . . . 0 . 0 0 . 0 . 0 0 . . 
. . . . . . 0 . 0 0 . 0 . . . 
. . 0 0 . 0 0 0 0 0 . 0 0 0 0 
. . 0 0 . 0 0 . 0 . . 0 0 0 0 
0 0 0 0 0 . 0 0 0 . 0 . 0 . . 
0 0 . 0 . . 0 . 0 0 0 . 0 0 . 
. . 0 0 . . 0 0 . 0 0 . . 0 0 
0 0 0 0 . . . 0 . . . 0 0 0 . 
0 . 0 . . . . . 0 0 0 0 . . 0 
0 . . . . . . 0 0 0 . 0 0 0 0 
 with color blue at (0,0)
  _010: 
4 . 4 
. 4 . 
4 . . 
 at (4,7)
  _0101: 
5#5#5#
 at (0,6)
  _01: rectangle with size (6,2) with model Full with color yellow at (1,2)
  _011: rectangle with size (1,14) with model Full with color cyan at (2,0)
  _0111: rectangle with size (1,9) with model Full with color cyan at (14,2)
  + 79 delta pixels
diff: 
   (3625.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . . 
 with color orange at (4,0)
  _01: rectangle with size (3,3) with mask 
0 . 0 
. 0 . 
0 . . 
 with color yellow at (4,7)
  _011: rectangle with size (1,3) with model Full with color grey at (0,6)
  + 102 delta pixels
diff: 
! size mismatch, 10x10 instead of 15x15

TRAIN 9edfc990.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (16,16) and color black and layers
  _0: rectangle with size (4,3) with mask 
. . 0 
. 0 . 
. 0 . 
0 . . 
 with color brown at (7,7)
  _01: rectangle with size (3,3) with mask 
0 0 . 
. . 0 
. 0 . 
 with color pink at (8,5)
  _011: rectangle with size (3,3) with mask 
. 0 . 
. 0 . 
0 . 0 
 with color red at (10,11)
  + 144 delta pixels
diff: 
   (0.0 bits)
data: a background with size (16,16) and color blue and layers
  _00: 
. . 9#
. 9#. 
. 9#. 
9#. . 
 at (7,7)
  _0: rectangle with size (4,7) with mask 
. 0 . . . . . 
0 . 0 0 . . . 
. . 0 0 0 . 0 
. . . . . 0 . 
 with color black at (7,0)
  _010: 
6 6 . 
. . 6 
. 6 . 
 at (8,5)
  _0101: 
. 2 . 
. 2 . 
2 . 2 
 at (10,11)
  _01: rectangle with size (3,3) with model Full with color black at (11,10)
  _011: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color black at (0,5)
  _0111: rectangle with size (1,8) with model Full with color green at (1,2)
  + 138 delta pixels
diff: 
   (5851.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (4,3) with mask 
. . 0 
. 0 . 
. 0 . 
0 . . 
 with color brown at (7,7)
  _01: rectangle with size (3,3) with mask 
0 0 . 
. . 0 
. 0 . 
 with color pink at (8,5)
  _011: rectangle with size (3,3) with mask 
. 0 . 
. 0 . 
0 . 0 
 with color red at (10,11)
  + 144 delta pixels
diff: 
! size mismatch, 10x10 instead of 16x16

TRAIN 9edfc990.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 0 
. 0 
. 0 
 with color red at (3,7)
  _01: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color brown at (4,12)
  _011: rectangle with size (3,3) with mask 
0 . . 
. 0 . 
. 0 0 
 with color yellow at (7,13)
  + 112 delta pixels
diff: 
! size mismatch, 10x10 instead of 16x16

TEST 9edfc990.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.4 sec (59.4 sec/task)
bits-train-error = 119399.0 bits (119399.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-157] Checking task 9f236235.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 348242.0 = 348244.3
DL output with Mo: L = 2.3 + 15911.0 = 15913.3
DL input+output M: L = 4.6 + 364153.0 = 364157.6

# learning a model for train pairs
2.000	
1.387	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.936	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.666	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.473	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.379	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.334	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.289	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.253	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.228	OUT SPE ^.size = ^.layer_011.shape.mask.size
0.218	OUT SPE ^.layer_0.shape.color = ^.layer_01.shape.color
0.210	OUT SPE ^.layer_0.pos.i = ^.layer_0.pos.i
0.206	OUT SPE ^.color = black
0.205	IN  SPE ^.layer_01.shape.mask.model = Full
0.205	IN  SPE ^.layer_011.shape.mask.model = Full
0.205	IN  SPE ^.layer_0111.shape.mask.model = Full
0.205	IN  SPE ^.layer_01111.shape.mask.model = Full
0.204	IN  SPE ^.color = black
0.147	
0.147	IN  DEL ^.layer_01111
0.147	IN  DEL ^.layer_0111
0.147	IN  GEN ^.layer_011.shape.mask.model = ?
0.147	IN  GEN ^.layer_01.shape.mask.model = ?
0.147	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_011.shape.mask.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at (^.layer_0.pos.i,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 155.6 + 20037.5 = 20193.0
DL output with Mo: L = 70.9 + 2258.0 = 2328.9
DL input+output M: L = 226.4 + 22295.5 = 22521.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_011.shape.mask.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at (^.layer_0.pos.i,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 0.0 = 98.1
DL output with Mo: L = 70.9 + 2258.0 = 2328.9
DL input+output M: L = 169.0 + 2258.0 = 2427.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (19,19) and color black and layers
  _0: rectangle with size (19,19) with mask 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
 with color red at (0,0)
  _01: rectangle with size (4,14) with model Full with color green at (15,0)
  _011: rectangle with size (4,4) with model Full with color green at (0,0)
  + 32 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (4,3) with mask 
. . 0 
. 0 . 
0 . . 
0 0 0 
 with color green at (0,1)
diff: 
   (32.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,19) and color black and layers
  _0: rectangle with size (19,19) with mask 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
 with color red at (0,0)
  _01: rectangle with size (4,14) with model Full with color green at (15,0)
  _011: rectangle with size (4,4) with model Full with color green at (0,0)
  + 32 delta pixels
diff: 
! 10 wrong pixels (generated / expected)

TRAIN 9f236235.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (19,19) and color black and layers
  _0: rectangle with size (19,19) with mask 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (4,4) with model Full with color red at (0,5)
  _011: rectangle with size (4,4) with model Full with color red at (5,0)
  + 48 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (2,2) with model Even Checkboard with color red at (0,2)
  + 3 delta pixels
diff: 
   (136.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,19) and color black and layers
  _0: rectangle with size (19,19) with mask 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
. . . . 0 . . . . 0 . . . . 0 . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (4,4) with model Full with color red at (0,5)
  _011: rectangle with size (4,4) with model Full with color red at (5,0)
  + 48 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN 9f236235.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color red at (0,0)
  _01: rectangle with size (7,3) with model Full with color cyan at (0,4)
  _011: rectangle with size (3,3) with model Full with color cyan at (4,0)
  + 9 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color cyan at (0,1)
  + 1 delta pixels
diff: 
   (57.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: rectangle with size (11,11) with mask 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
. . . 0 . . . 0 . . . 
 with color red at (0,0)
  _01: rectangle with size (7,3) with model Full with color cyan at (0,4)
  _011: rectangle with size (3,3) with model Full with color cyan at (4,0)
  + 9 delta pixels
diff: 
! 4 wrong pixels (generated / expected)

TRAIN 9f236235.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (23,23) with mask 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (23,5) with model Full with color green at (0,6)
  _011: rectangle with size (5,23) with model Full with color blue at (0,0)
  + 50 delta pixels
diff: 
! size mismatch, 5x23 instead of 4x4
>> Trial 2
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (23,5) with model Full with color green at (0,6)
  _01: rectangle with size (23,23) with mask 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
 with color cyan at (0,0)
  _011: rectangle with size (5,23) with model Full with color blue at (0,0)
  + 65 delta pixels
diff: 
! size mismatch, 5x23 instead of 4x4
>> Trial 3
data: a background with size (23,23) and color black and layers
  _0: rectangle with size (23,23) with mask 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (5,23) with model Full with color blue at (0,0)
  _011: rectangle with size (17,5) with model Full with color green at (6,6)
  + 75 delta pixels
diff: 
! size mismatch, 17x5 instead of 4x4

TEST 9f236235.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 26.1 sec (26.1 sec/task)
bits-train-error = 2258.0 bits (2258.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-156] Checking task a1570a43.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 115711.2 = 115713.5
DL output with Mo: L = 2.3 + 115711.2 = 115713.5
DL input+output M: L = 4.6 + 231422.4 = 231427.0

# learning a model for train pairs
2.000	
1.223	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.446	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.307	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.151	OUT ADD ^.layer_0 = ^.layer_0.shape at (?,?)
0.143	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.129	OUT ADD ^.layer_01 = ^.layer_01
0.120	OUT ADD ^.layer_011 = ^.layer_01.shape at (?,?)
0.110	OUT ADD ^.layer_010 = ^.layer_01.shape at (?,?)
0.099	OUT ADD ^.layer_0111 = ^.layer_01.shape at (?,?)
0.091	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.083	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.075	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.068	OUT SPE ^.size = ^.size
0.064	OUT SPE ^.layer_0111 = ^.layer_0111
0.061	OUT SPE ^.layer_011 = ^.layer_01111
0.057	OUT SPE ^.layer_010 = ^.layer_011
0.053	OUT SPE ^.layer_0.pos = ^.layer_01.pos + (1, 1)
0.051	IN  SPE ^.layer_0.shape.color = red
0.050	IN  SPE ^.layer_01.shape.color = green
0.048	IN  SPE ^.layer_011.shape.color = green
0.046	IN  SPE ^.layer_0111.shape.color = green
0.044	IN  SPE ^.layer_01111.shape.color = green
0.043	IN  SPE ^.color = black
0.042	OUT SPE ^.color = black
0.002	
0.002	IN  GEN ^.layer_01111.shape.color = ?
0.002	IN  GEN ^.layer_011.shape.color = ?
0.002	IN  GEN ^.layer_0111.shape.color = ?
0.002	IN  GEN ^.layer_01.shape.color = ?
0.002	IN  GEN ^.layer_0.shape.color = ?
0.002	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0.shape at ^.layer_01.pos + (1, 1)
  _010: ^.layer_011
  _01: ^.layer_01
  _011: ^.layer_01111
  _0111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at (?,?)
  _01: point with color green at (?,?)
  _011: point with color green at (?,?)
  _0111: point with color green at (?,?)
  _01111: point with color green at (?,?)

DL input  with Mi: L = 130.8 + 4655.6 = 4786.5
DL output with Mo: L = 81.3 + 0.0 = 81.3
DL input+output M: L = 212.2 + 4655.6 = 4867.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0.shape at ^.layer_01.pos + (1, 1)
  _010: ^.layer_011
  _01: ^.layer_01
  _011: ^.layer_01111
  _0111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 114.2 + 0.0 = 114.2
DL output with Mo: L = 81.3 + 0.0 = 81.3
DL input+output M: L = 195.5 + 0.0 = 195.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (7,7) and color black and layers
  _0: rectangle with size (5,5) with mask 
. . 0 . . 
. 0 0 . . 
0 0 0 0 0 
. 0 . . . 
. 0 0 . . 
 with color red at (0,0)
  _01: point with color green at (0,0)
  _011: point with color green at (0,6)
  _0111: point with color green at (6,0)
  _01111: point with color green at (6,6)
diff: 
   (0.0 bits)
data: a background with size (7,7) and color black and layers
  _0: 
. . 2 . . 
. 2 2 . . 
2 2 2 2 2 
. 2 . . . 
. 2 2 . . 
 at (1,1)
  _010: 
3 
 at (0,6)
  _01: 
3 
 at (0,0)
  _011: 
3 
 at (6,6)
  _0111: 
3 
 at (6,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (5,5) with mask 
. . 0 . . 
. 0 0 . . 
0 0 0 0 0 
. 0 . . . 
. 0 0 . . 
 with color red at (0,0)
  _01: point with color green at (0,0)
  _011: point with color green at (0,6)
  _0111: point with color green at (6,0)
  _01111: point with color green at (6,6)
diff: 
correct output grid

TRAIN a1570a43.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: rectangle with size (5,5) with mask 
. . 0 0 0 
0 0 0 . . 
0 . 0 . . 
0 0 0 0 . 
. . . 0 . 
 with color red at (2,0)
  _01: point with color green at (1,1)
  _011: point with color green at (1,7)
  _0111: point with color green at (7,1)
  _01111: point with color green at (7,7)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: 
. . 2 2 2 
2 2 2 . . 
2 . 2 . . 
2 2 2 2 . 
. . . 2 . 
 at (2,2)
  _010: 
3 
 at (1,7)
  _01: 
3 
 at (1,1)
  _011: 
3 
 at (7,7)
  _0111: 
3 
 at (7,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (5,5) with mask 
. . 0 0 0 
0 0 0 . . 
0 . 0 . . 
0 0 0 0 . 
. . . 0 . 
 with color red at (2,0)
  _01: point with color green at (1,1)
  _011: point with color green at (1,7)
  _0111: point with color green at (7,1)
  _01111: point with color green at (7,7)
diff: 
correct output grid

TRAIN a1570a43.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (9,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
. 0 0 . . 
0 0 0 0 . 
. . 0 0 0 
. . 0 . . 
. 0 0 . . 
 with color red at (0,2)
  _01: point with color green at (1,1)
  _011: point with color green at (1,7)
  _0111: point with color green at (7,1)
  _01111: point with color green at (7,7)
diff: 
   (0.0 bits)
data: a background with size (9,10) and color black and layers
  _0: 
. 2 2 . . 
2 2 2 2 . 
. . 2 2 2 
. . 2 . . 
. 2 2 . . 
 at (2,2)
  _010: 
3 
 at (1,7)
  _01: 
3 
 at (1,1)
  _011: 
3 
 at (7,7)
  _0111: 
3 
 at (7,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
. 0 0 . . 
0 0 0 0 . 
. . 0 0 0 
. . 0 . . 
. 0 0 . . 
 with color red at (0,2)
  _01: point with color green at (1,1)
  _011: point with color green at (1,7)
  _0111: point with color green at (7,1)
  _01111: point with color green at (7,7)
diff: 
correct output grid

TRAIN a1570a43.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: a background with size (9,8) and color black and layers
  _0: rectangle with size (5,5) with mask 
. . . 0 . 
. 0 0 0 . 
. 0 . . . 
0 0 0 0 0 
. 0 . . . 
 with color red at (1,0)
  _01: point with color green at (0,0)
  _011: point with color green at (0,6)
  _0111: point with color green at (6,0)
  _01111: point with color green at (6,6)
diff: 
   (0.0 bits)
data: a background with size (9,8) and color black and layers
  _0: 
. . . 2 . 
. 2 2 2 . 
. 2 . . . 
2 2 2 2 2 
. 2 . . . 
 at (1,1)
  _010: 
3 
 at (0,6)
  _01: 
3 
 at (0,0)
  _011: 
3 
 at (6,6)
  _0111: 
3 
 at (6,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,8) and color black and layers
  _0: rectangle with size (5,5) with mask 
. . . 0 . 
. 0 0 0 . 
. 0 . . . 
0 0 0 0 0 
. 0 . . . 
 with color red at (1,0)
  _01: point with color green at (0,0)
  _011: point with color green at (0,6)
  _0111: point with color green at (6,0)
  _01111: point with color green at (6,6)
diff: 
correct output grid

TRAIN a1570a43.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,8) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 . . . . 
0 0 . . . 
0 0 0 . . 
0 0 0 0 0 
0 . . . . 
 with color red at (2,0)
  _01: point with color green at (1,0)
  _011: point with color green at (1,6)
  _0111: point with color green at (7,0)
  _01111: point with color green at (7,6)
diff: 
correct output grid

TEST a1570a43.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 13.4 sec (13.4 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-155] Checking task a2fd1cf0.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 224844.1 = 224846.4
DL output with Mo: L = 2.3 + 224844.1 = 224846.4
DL input+output M: L = 4.6 + 449688.2 = 449692.8

# learning a model for train pairs
2.000	
1.014	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.114	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.041	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.038	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.035	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.032	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.029	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.026	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.023	OUT SPE ^.size = ^.size
0.020	OUT SPE ^.layer_011 = ^.layer_01
0.018	OUT SPE ^.layer_0111 = ^.layer_0
0.017	IN  SPE ^.layer_0.shape.color = red
0.016	OUT SPE ^.layer_0.pos.i = ^.layer_0.pos.i
0.016	IN  SPE ^.layer_01.shape.color = green
0.015	OUT SPE ^.layer_0.shape.color = cyan
0.014	OUT SPE ^.layer_01.shape.color = cyan
0.014	OUT SPE ^.layer_0.shape.mask.model = Full
0.013	OUT SPE ^.layer_01.shape.mask.model = Full
0.013	IN  SPE ^.color = black
0.013	OUT SPE ^.color = black
0.006	
0.006	IN  GEN ^.layer_01.shape.color = ?
0.006	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model Full with color cyan at (^.layer_0.pos.i,?)
  _01: rectangle with size (?,?) with model Full with color cyan at (?,?)
  _011: ^.layer_01
  _0111: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color red at (?,?)
  _01: point with color green at (?,?)

DL input  with Mi: L = 57.4 + 1379.1 = 1436.4
DL output with Mo: L = 92.9 + 1311.1 = 1404.1
DL input+output M: L = 150.3 + 2690.2 = 2840.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model Full with color cyan at (^.layer_0.pos.i,?)
  _01: rectangle with size (?,?) with model Full with color cyan at (?,?)
  _011: ^.layer_01
  _0111: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color red at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 53.9 + 0.0 = 53.9
DL output with Mo: L = 92.9 + 1311.1 = 1404.1
DL input+output M: L = 146.9 + 1311.1 = 1458.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: point with color red at (1,4)
  _01: point with color green at (13,10)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (12,1) with model Full with color cyan at (1,10)
  _01: rectangle with size (1,6) with model Full with color cyan at (1,5)
  _011: 
3 
 at (13,10)
  _0111: 
2 
 at (1,4)
diff: 
   (44.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: point with color red at (1,4)
  _01: point with color green at (13,10)
diff: 
! 23 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: point with color green at (13,10)
  _01: point with color red at (1,4)
diff:   ^.layer_0.shape.color
! 25 wrong pixels (generated / expected)

TRAIN a2fd1cf0.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,16) and color black and layers
  _0: point with color red at (7,1)
  _01: point with color green at (1,11)
diff: 
   (0.0 bits)
data: a background with size (10,16) and color black and layers
  _0: rectangle with size (1,10) with model Full with color cyan at (7,2)
  _01: rectangle with size (6,1) with model Full with color cyan at (2,11)
  _011: 
3 
 at (1,11)
  _0111: 
2 
 at (7,1)
diff: 
   (43.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,16) and color black and layers
  _0: point with color red at (7,1)
  _01: point with color green at (1,11)
diff: 
! 23 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,16) and color black and layers
  _0: point with color green at (1,11)
  _01: point with color red at (7,1)
diff:   ^.layer_0.shape.color
! 21 wrong pixels (generated / expected)

TRAIN a2fd1cf0.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (12,14) and color black and layers
  _0: point with color red at (1,11)
  _01: point with color green at (10,4)
diff: 
   (0.0 bits)
data: a background with size (12,14) and color black and layers
  _0: rectangle with size (9,1) with model Full with color cyan at (1,4)
  _01: rectangle with size (1,7) with model Full with color cyan at (1,4)
  _011: 
3 
 at (10,4)
  _0111: 
2 
 at (1,11)
diff: 
   (43.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,14) and color black and layers
  _0: point with color red at (1,11)
  _01: point with color green at (10,4)
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,14) and color black and layers
  _0: point with color green at (10,4)
  _01: point with color red at (1,11)
diff:   ^.layer_0.shape.color
! 23 wrong pixels (generated / expected)

TRAIN a2fd1cf0.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,14) and color black and layers
  _0: point with color red at (2,1)
  _01: point with color green at (10,10)
diff: 
! 24 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,14) and color black and layers
  _0: point with color green at (10,10)
  _01: point with color red at (2,1)
diff:   ^.layer_0.shape.color
! 24 wrong pixels (generated / expected)

TEST a2fd1cf0.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 5.1 sec (5.1 sec/task)
bits-train-error = 1311.1 bits (1311.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-154] Checking task a3325580.json: 6 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 239551.7 = 239554.0
DL output with Mo: L = 2.3 + 21911.1 = 21913.4
DL input+output M: L = 4.6 + 261462.8 = 261467.4

# learning a model for train pairs
2.000	
1.141	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.679	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.407	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.370	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.335	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.310	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.290	OUT SPE ^.layer_0.pos = '(0, 0)
0.270	OUT SPE ^.layer_0.shape.mask.size.i = area(^.layer_0.shape.mask)
0.250	OUT SPE ^.size.i = area(^.layer_0.shape)
0.235	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.226	OUT SPE ^.layer_0.shape.mask.size.j = 1
0.218	OUT SPE ^.layer_0.shape.mask.model = Full
0.217	IN  SPE ^.color = black
0.174	
0.174	IN  DEL ^.layer_011
0.174	IN  DEL ^.layer_01
0.174	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (area(^.layer_0.shape),?) and color ? and layers
  _0: rectangle with size (area(^.layer_0.shape.mask),1) with model Full with color ^.layer_0.shape.color at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.2 + 10467.2 = 10565.5
DL output with Mo: L = 70.9 + 3722.9 = 3793.8
DL input+output M: L = 169.2 + 14190.1 = 14359.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (area(^.layer_0.shape),?) and color ? and layers
  _0: rectangle with size (area(^.layer_0.shape.mask),1) with model Full with color ^.layer_0.shape.color at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 60.0 = 102.0
DL output with Mo: L = 70.9 + 3722.9 = 3793.8
DL input+output M: L = 112.9 + 3782.9 = 3895.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,2) with mask 
0 . 
0 . 
0 0 
0 . 
 with color yellow at (2,2)
  + 14 delta pixels
diff: 
   (2.0 bits)
data: a background with size (5,3) and color pink and layers
  _0: rectangle with size (5,1) with model Full with color yellow at (0,0)
  + 5 delta pixels
diff: 
   (204.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 0 
. 0 
0 0 
 with color pink at (3,5)
  + 14 delta pixels
diff: 
! size mismatch, 5x10 instead of 5x3
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,2) with mask 
0 . 
0 . 
0 0 
0 . 
 with color yellow at (2,2)
  + 14 delta pixels
diff: 
! size mismatch, 5x10 instead of 5x3
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. . 0 
. . 0 
 with color cyan at (1,7)
  + 14 delta pixels
diff: 
! size mismatch, 5x10 instead of 5x3

TRAIN a3325580.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,3) with mask 
. 0 . 
. 0 0 
0 0 . 
. 0 . 
. 0 0 
. 0 . 
 with color brown at (3,0)
  + 15 delta pixels
diff: 
   (2.0 bits)
data: a background with size (9,2) and color yellow and layers
  _0: rectangle with size (9,1) with model Full with color brown at (0,0)
diff: 
   (14.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,3) with mask 
0 0 0 
0 . 0 
. . 0 
. 0 0 
. . 0 
 with color yellow at (0,7)
  + 15 delta pixels
diff: 
! size mismatch, 9x10 instead of 9x2
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,3) with mask 
. 0 . 
. 0 0 
0 0 . 
. 0 . 
. 0 0 
. 0 . 
 with color brown at (3,0)
  + 15 delta pixels
diff: 
! size mismatch, 9x10 instead of 9x2
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,1) with model Full with color brown at (3,1)
  + 18 delta pixels
diff: 
! size mismatch, 6x10 instead of 9x2

TRAIN a3325580.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
. 0 . 
 with color red at (1,5)
  + 11 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,1) and color black and layers
  _0: rectangle with size (5,1) with model Full with color red at (0,0)
diff: 
   (5.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
. 0 . 
 with color red at (1,5)
  + 11 delta pixels
diff: 
! size mismatch, 5x10 instead of 5x1
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,1) with model Full with color blue at (0,9)
  + 12 delta pixels
diff: 
! size mismatch, 4x10 instead of 5x1
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color orange at (1,0)
  + 12 delta pixels
diff: 
! size mismatch, 4x10 instead of 5x1

TRAIN a3325580.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,1) with model Full with color cyan at (3,2)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,1) and color black and layers
  _0: rectangle with size (3,1) with model Full with color cyan at (0,0)
diff: 
   (5.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,1) with model Full with color cyan at (3,2)
  + 4 delta pixels
diff: 
! size mismatch, 3x10 instead of 3x1
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,1) with model Full with color pink at (4,6)
  + 5 delta pixels
diff: 
! size mismatch, 2x10 instead of 3x1
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,2) with model Full with color yellow at (8,4)
  + 5 delta pixels
diff: 
! size mismatch, 2x10 instead of 3x1

TRAIN a3325580.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color red at (4,1)
  + 3 delta pixels
diff: 
   (2.0 bits)
data: a background with size (3,2) and color green and layers
  _0: rectangle with size (3,1) with model Full with color red at (0,0)
diff: 
   (14.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color green at (2,5)
  + 3 delta pixels
diff: 
! size mismatch, 3x10 instead of 3x2
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color red at (4,1)
  + 3 delta pixels
diff: 
! size mismatch, 3x10 instead of 3x2
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,2) with model Full with color green at (2,5)
  + 4 delta pixels
diff: 
! size mismatch, 2x10 instead of 3x2

TRAIN a3325580.json/5: 0 - (FAILURE)

## instance 6

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,1) with model Full with color blue at (2,1)
  + 6 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color yellow and layers
  _0: rectangle with size (3,1) with model Full with color blue at (0,0)
  + 3 delta pixels
diff: 
   (127.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,1) with model Full with color blue at (2,1)
  + 6 delta pixels
diff: 
! size mismatch, 3x10 instead of 3x3
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,3) with model Full with color cyan at (3,7)
  + 6 delta pixels
diff: 
! size mismatch, 3x10 instead of 3x3
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color yellow at (5,3)
  + 6 delta pixels
diff: 
! size mismatch, 3x10 instead of 3x3

TRAIN a3325580.json/6: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color blue at (0,7)
  + 13 delta pixels
diff: 
! size mismatch, 4x10 instead of 4x3
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color grey at (1,1)
  + 13 delta pixels
diff: 
! size mismatch, 4x10 instead of 4x3
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 0 
0 . 
0 . 
 with color red at (7,3)
  + 13 delta pixels
diff: 
! size mismatch, 4x10 instead of 4x3

TEST a3325580.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 5.3 sec (5.3 sec/task)
bits-train-error = 3722.9 bits (3722.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-153] Checking task a3df8b1e.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 35052.8 = 35055.1
DL output with Mo: L = 2.3 + 35052.8 = 35055.1
DL input+output M: L = 4.6 + 70105.7 = 70110.3

# learning a model for train pairs
2.000	
1.050	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.396	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.115	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.095	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.081	OUT SPE ^.size = ^.size
0.067	OUT SPE ^.layer_0.shape.mask.size = ^.size
0.059	OUT SPE ^.layer_0.pos = '(0, 0)
0.054	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.049	IN  SPE ^.layer_0.shape.color = blue
0.047	IN  SPE ^.color = black
0.045	OUT SPE ^.color = black
0.023	
0.023	IN  GEN ^.layer_0.shape.color = ?
0.023	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size ^.size with model ? with color ^.layer_0.shape.color at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color blue at (?,?)

DL input  with Mi: L = 35.6 + 775.2 = 810.8
DL output with Mo: L = 45.4 + 724.3 = 769.7
DL input+output M: L = 81.0 + 1499.5 = 1580.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size ^.size with model ? with color ^.layer_0.shape.color at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 0.0 = 32.2
DL output with Mo: L = 45.4 + 724.3 = 769.7
DL input+output M: L = 77.6 + 724.3 = 801.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,2) and color black and layers
  _0: point with color blue at (9,0)
diff: 
   (0.0 bits)
data: a background with size (10,2) and color black and layers
  _0: rectangle with size (10,2) with model Odd Checkboard with color blue at (0,0)
diff: 
   (6.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,2) and color black and layers
  _0: point with color blue at (9,0)
diff: 
! 10 wrong pixels (generated / expected)

TRAIN a3df8b1e.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,3) and color black and layers
  _0: point with color blue at (9,0)
diff: 
   (0.0 bits)
data: a background with size (10,3) and color black and layers
  _0: rectangle with size (10,3) with mask 
. 0 . 
0 . . 
. 0 . 
. . 0 
. 0 . 
0 . . 
. 0 . 
. . 0 
. 0 . 
0 . . 
 with color blue at (0,0)
diff: 
   (30.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,3) and color black and layers
  _0: point with color blue at (9,0)
diff: 
! 20 wrong pixels (generated / expected)

TRAIN a3df8b1e.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,4) and color black and layers
  _0: point with color blue at (9,0)
diff: 
   (0.0 bits)
data: a background with size (10,4) and color black and layers
  _0: rectangle with size (10,4) with mask 
. . . 0 
. . 0 . 
. 0 . . 
0 . . . 
. 0 . . 
. . 0 . 
. . . 0 
. . 0 . 
. 0 . . 
0 . . . 
 with color blue at (0,0)
diff: 
   (35.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,4) and color black and layers
  _0: point with color blue at (9,0)
diff: 
! 30 wrong pixels (generated / expected)

TRAIN a3df8b1e.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,5) and color black and layers
  _0: point with color blue at (9,0)
diff: 
! 40 wrong pixels (generated / expected)

TEST a3df8b1e.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 1.2 sec (1.2 sec/task)
bits-train-error = 724.3 bits (724.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-152] Checking task a416b8f3.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 14370.0 = 14372.3
DL output with Mo: L = 2.3 + 28746.8 = 28749.2
DL input+output M: L = 4.6 + 43116.8 = 43121.5

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = tiling(^, 1, 2)
0.608	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.464	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.364	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.316	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.293	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.287	IN  SPE ^.layer_01.shape.mask.model = Full
0.281	IN  SPE ^.layer_011.shape.mask.model = Full
0.275	IN  SPE ^.layer_0111.shape.mask.model = Full
0.009	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
tiling(^, 1, 2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 127.3 + 3823.1 = 3950.5
DL output with Mo: L = 13.3 + 0.0 = 13.3
DL input+output M: L = 140.6 + 3823.1 = 3963.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
tiling(^, 1, 2)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 13.3 + 0.0 = 13.3
DL input+output M: L = 15.6 + 0.0 = 15.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 5#0 
5#5#2 
0 0 0 

diff: 
   (0.0 bits)
data: 
0 5#0 0 5#0 
5#5#2 5#5#2 
0 0 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 5#0 
5#5#2 
0 0 0 

diff: 
correct output grid

TRAIN a416b8f3.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
3 0 0 
2 3 0 
2 1 8 
0 1 0 

diff: 
   (0.0 bits)
data: 
3 0 0 3 0 0 
2 3 0 2 3 0 
2 1 8 2 1 8 
0 1 0 0 1 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 0 0 
2 3 0 
2 1 8 
0 1 0 

diff: 
correct output grid

TRAIN a416b8f3.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
5#2 3 0 
2 5#3 0 
5#2 8 8 
0 0 6 0 

diff: 
   (0.0 bits)
data: 
5#2 3 0 5#2 3 0 
2 5#3 0 2 5#3 0 
5#2 8 8 5#2 8 8 
0 0 6 0 0 0 6 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#2 3 0 
2 5#3 0 
5#2 8 8 
0 0 6 0 

diff: 
correct output grid

TRAIN a416b8f3.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 0 0 0 
4 5#0 0 
0 5#6 0 
6 6 1 0 
0 0 0 1 

diff: 
correct output grid

TEST a416b8f3.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.3 sec (1.3 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-151] Checking task a48eeaf7.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79850.6 = 79852.9
DL output with Mo: L = 2.3 + 79850.6 = 79852.9
DL input+output M: L = 4.6 + 159701.1 = 159705.8

# learning a model for train pairs
2.000	
1.082	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.163	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.131	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.091	OUT ADD ^.layer_0 = ^.layer_0
0.084	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.078	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.072	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.067	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.061	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.055	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.050	OUT SPE ^.size = ^.size
0.047	IN  SPE ^.layer_0.shape.mask = 
0 0 
0 0 

0.044	OUT SPE ^.layer_0111.pos = ^.layer_0111.pos - (2, 2)
0.042	OUT SPE ^.layer_0111.shape = ^.layer_0111.shape
0.041	OUT SPE ^.layer_011.shape = ^.layer_011.shape
0.040	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.037	OUT SPE ^.layer_011.pos = ^.layer_01.pos - translationOnto(^.layer_0, ^.layer_01)
0.035	OUT SPE ^.layer_01.pos = ^.layer_011.pos - translationOnto(^.layer_0, ^.layer_011)
0.033	IN  SPE ^.layer_0.shape.color = red
0.032	IN  SPE ^.layer_01.shape.color = grey
0.031	IN  SPE ^.layer_011.shape.color = grey
0.029	IN  SPE ^.layer_0111.shape.color = grey
0.029	IN  SPE ^.color = black
0.028	OUT SPE ^.color = black
0.028	OUT SPE ^.layer_01.shape.mask.size.i = area(^.layer_0.shape) - ^.layer_0.pos.i - ^.layer_01.pos.i
0.027	OUT SPE ^.layer_01.shape.mask.size.j = area(^.layer_0.shape) - ^.layer_0.pos.i - ^.layer_01.pos.i
0.006	
0.006	IN  GEN ^.layer_0111.shape.color = ?
0.006	IN  GEN ^.layer_011.shape.color = ?
0.006	IN  GEN ^.layer_01.shape.color = ?
0.006	IN  GEN ^.layer_0.shape.color = ?
0.006	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (area(^.layer_0.shape) - ^.layer_0.pos.i - ^.layer_01.pos.i,area(^.layer_0.shape) - ^.layer_0.pos.i - ^.layer_01.pos.i) with model ? with color ^.layer_01.shape.color at ^.layer_011.pos - translationOnto(^.layer_0, ^.layer_011)
  _011: ^.layer_011.shape at ^.layer_01.pos - translationOnto(^.layer_0, ^.layer_01)
  _0111: ^.layer_0111.shape at ^.layer_0111.pos - (2, 2)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (?,?)
  _01: point with color grey at (?,?)
  _011: point with color grey at (?,?)
  _0111: point with color grey at (?,?)

DL input  with Mi: L = 106.8 + 1716.9 = 1823.7
DL output with Mo: L = 261.3 + 94.8 = 356.1
DL input+output M: L = 368.2 + 1811.7 = 2179.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (area(^.layer_0.shape) - ^.layer_0.pos.i - ^.layer_01.pos.i,area(^.layer_0.shape) - ^.layer_0.pos.i - ^.layer_01.pos.i) with model ? with color ^.layer_01.shape.color at ^.layer_011.pos - translationOnto(^.layer_0, ^.layer_011)
  _011: ^.layer_011.shape at ^.layer_01.pos - translationOnto(^.layer_0, ^.layer_01)
  _0111: ^.layer_0111.shape at ^.layer_0111.pos - (2, 2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 0 
0 0 
 with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 93.5 + 0.0 = 93.5
DL output with Mo: L = 261.3 + 94.8 = 356.1
DL input+output M: L = 354.8 + 94.8 = 449.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (3,3)
  _01: point with color grey at (0,3)
  _011: point with color grey at (3,8)
  _0111: point with color grey at (7,7)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
2 2 
2 2 
 at (3,3)
  _01: rectangle with size (1,1) with model Full with color grey at (3,5)
  _011: 
5#
 at (2,3)
  _0111: 
5#
 at (5,5)
diff: 
   (2.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (3,3)
  _01: point with color grey at (0,3)
  _011: point with color grey at (3,8)
  _0111: point with color grey at (7,7)
diff: 
correct output grid

TRAIN a48eeaf7.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (2,5)
  _01: point with color grey at (0,8)
  _011: point with color grey at (3,1)
  _0111: point with color grey at (6,9)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
2 2 
2 2 
 at (2,5)
  _01: rectangle with size (2,2) with model Even Checkboard with color grey at (3,4)
  _011: 
5#
 at (1,7)
  _0111: 
5#
 at (4,7)
diff: 
   (6.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (2,5)
  _01: point with color grey at (0,8)
  _011: point with color grey at (3,1)
  _0111: point with color grey at (6,9)
  + 1 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (2,5)
  _01: point with color grey at (0,8)
  _011: point with color grey at (3,1)
  _0111: point with color grey at (8,5)
  + 1 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color red at (2,5)
  _01: point with color grey at (0,8)
  _011: point with color grey at (6,9)
  _0111: point with color grey at (3,1)
  + 1 delta pixels
diff: 
! 5 wrong pixels (generated / expected)

TRAIN a48eeaf7.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
Invalid_argument("Model2.mask_rectangle: negative or null mask size")

TEST a48eeaf7.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 9.6 sec (9.6 sec/task)
bits-train-error = 94.8 bits (94.8 bits/task)
acc-train-micro = 0.50 tasks (50.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.50
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-150] Checking task a5313dff.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 108612.9 = 108615.2
DL output with Mo: L = 2.3 + 108612.9 = 108615.2
DL input+output M: L = 4.6 + 217225.8 = 217230.5

# learning a model for train pairs
2.000	
1.329	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.797	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.522	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.223	OUT ADD ^.layer_0 = ^.layer_0
0.115	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.093	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.087	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.081	OUT SPE ^.size = ^.size
0.078	OUT ADD ^.layer_010 = ^.layer_01
0.075	OUT SPE ^.layer_01.pos = ^.layer_01.pos - (1, 1)
0.074	OUT SPE ^.layer_01.shape.mask.size.j = 3
0.072	IN  SPE ^.layer_0.shape.color = red
0.070	IN  SPE ^.layer_01.shape.color = red
0.069	OUT SPE ^.layer_01.shape.color = blue
0.068	OUT SPE ^.layer_011.shape.mask.size.i = ^.size.i - ^.layer_0.shape.mask.size.j
0.067	OUT SPE ^.layer_01.shape.mask.model = Full
0.066	OUT SPE ^.layer_011.shape.mask.model = Full
0.066	IN  SPE ^.color = black
0.065	OUT SPE ^.color = black
0.021	
0.021	IN  GEN ^.layer_01.shape.color = ?
0.021	IN  GEN ^.layer_0.shape.color = ?
0.021	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _010: ^.layer_01
  _01: rectangle with size (?,3) with model Full with color blue at ^.layer_01.pos - (1, 1)
  _011: rectangle with size (^.size.i - ^.layer_0.shape.mask.size.j,?) with model Full with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at (?,?)
  _01: point with color red at (?,?)

DL input  with Mi: L = 67.2 + 4768.2 = 4835.4
DL output with Mo: L = 131.7 + 2080.2 = 2211.9
DL input+output M: L = 198.9 + 6848.4 = 7047.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _010: ^.layer_01
  _01: rectangle with size (?,3) with model Full with color blue at ^.layer_01.pos - (1, 1)
  _011: rectangle with size (^.size.i - ^.layer_0.shape.mask.size.j,?) with model Full with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 60.4 + 20.0 = 80.4
DL output with Mo: L = 131.7 + 2080.2 = 2211.9
DL input+output M: L = 192.2 + 2100.2 = 2292.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (8,8) and color black and layers
  _0: rectangle with size (5,5) with model Border with color red at (1,1)
  _01: point with color red at (3,3)
diff: 
   (0.0 bits)
data: a background with size (8,8) and color black and layers
  _0: 
2 2 2 2 2 
2 . . . 2 
2 . . . 2 
2 . . . 2 
2 2 2 2 2 
 at (1,1)
  _010: 
2 
 at (3,3)
  _01: rectangle with size (1,3) with model Full with color blue at (2,2)
  _011: rectangle with size (3,3) with model Full with color blue at (2,2)
  + 1 delta pixels
diff: 
   (67.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (5,5) with model Border with color red at (1,1)
  _01: point with color red at (3,3)
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (1,5) with model Full with color red at (1,1)
  _01: point with color red at (3,3)
  + 11 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (5,1) with model Full with color red at (1,1)
  _01: point with color red at (3,3)
  + 11 delta pixels
diff: 
! 23 wrong pixels (generated / expected)

TRAIN a5313dff.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (8,8) and color black and layers
  _0: rectangle with size (8,7) with mask 
. . . 0 . . . 
. . . 0 . . . 
. . . 0 . . . 
0 0 0 0 0 0 0 
. . 0 . . . 0 
. . 0 . . . 0 
. . 0 . . . 0 
. . 0 0 0 0 0 
 with color red at (0,0)
  _01: point with color red at (5,4)
  + 1 delta pixels
diff: 
   (2.0 bits)
data: a background with size (8,8) and color black and layers
  _0: 
. . . 2 . . . 
. . . 2 . . . 
. . . 2 . . . 
2 2 2 2 2 2 2 
. . 2 . . . 2 
. . 2 . . . 2 
. . 2 . . . 2 
. . 2 2 2 2 2 
 at (0,0)
  _010: 
2 
 at (5,4)
  _01: rectangle with size (3,3) with model Full with color blue at (4,3)
  _011: rectangle with size (1,1) with model Full with color red at (1,1)
diff: 
   (26.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (8,7) with mask 
. . . 0 . . . 
. . . 0 . . . 
. . . 0 . . . 
0 0 0 0 0 0 0 
. . 0 . . . 0 
. . 0 . . . 0 
. . 0 . . . 0 
. . 0 0 0 0 0 
 with color red at (0,0)
  _01: point with color red at (1,1)
  + 1 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (8,7) with mask 
. . . 0 . . . 
. . . 0 . . . 
. . . 0 . . . 
0 0 0 0 0 0 0 
. . 0 . . . 0 
. . 0 . . . 0 
. . 0 . . . 0 
. . 0 0 0 0 0 
 with color red at (0,0)
  _01: point with color red at (5,4)
  + 1 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (1,7) with model Full with color red at (3,0)
  _01: point with color red at (1,1)
  + 15 delta pixels
diff: 
! 28 wrong pixels (generated / expected)

TRAIN a5313dff.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (12,9) with mask 
0 0 0 0 0 . . . . 
0 . . . 0 . . . . 
0 . . . 0 0 0 0 . 
0 . . . 0 . . 0 . 
0 0 0 0 0 . . 0 . 
0 . . . 0 . . 0 . 
0 . . . 0 0 0 0 . 
0 . . . 0 . . . . 
0 0 0 0 0 . . . . 
. . . . 0 0 0 0 0 
. . . . 0 . . . 0 
. . . . 0 . . . 0 
 with color red at (0,3)
  _01: point with color red at (2,5)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _0: 
2 2 2 2 2 . . . . 
2 . . . 2 . . . . 
2 . . . 2 2 2 2 . 
2 . . . 2 . . 2 . 
2 2 2 2 2 . . 2 . 
2 . . . 2 . . 2 . 
2 . . . 2 2 2 2 . 
2 . . . 2 . . . . 
2 2 2 2 2 . . . . 
. . . . 2 2 2 2 2 
. . . . 2 . . . 2 
. . . . 2 . . . 2 
 at (0,3)
  _010: 
2 
 at (2,5)
  _01: rectangle with size (7,3) with model Full with color blue at (1,4)
  _011: rectangle with size (3,2) with model Full with color blue at (3,8)
  + 2 delta pixels
diff: 
   (115.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (12,9) with mask 
0 0 0 0 0 . . . . 
0 . . . 0 . . . . 
0 . . . 0 0 0 0 . 
0 . . . 0 . . 0 . 
0 0 0 0 0 . . 0 . 
0 . . . 0 . . 0 . 
0 . . . 0 0 0 0 . 
0 . . . 0 . . . . 
0 0 0 0 0 . . . . 
. . . . 0 0 0 0 0 
. . . . 0 . . . 0 
. . . . 0 . . . 0 
 with color red at (0,3)
  _01: point with color red at (2,5)
  + 2 delta pixels
diff: 
! 25 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (12,9) with mask 
0 0 0 0 0 . . . . 
0 . . . 0 . . . . 
0 . . . 0 0 0 0 . 
0 . . . 0 . . 0 . 
0 0 0 0 0 . . 0 . 
0 . . . 0 . . 0 . 
0 . . . 0 0 0 0 . 
0 . . . 0 . . . . 
0 0 0 0 0 . . . . 
. . . . 0 0 0 0 0 
. . . . 0 . . . 0 
. . . . 0 . . . 0 
 with color red at (0,3)
  _01: point with color red at (6,5)
  + 2 delta pixels
diff: 
! 25 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (12,9) with mask 
0 0 0 0 0 . . . . 
0 . . . 0 . . . . 
0 . . . 0 0 0 0 . 
0 . . . 0 . . 0 . 
0 0 0 0 0 . . 0 . 
0 . . . 0 . . 0 . 
0 . . . 0 0 0 0 . 
0 . . . 0 . . . . 
0 0 0 0 0 . . . . 
. . . . 0 0 0 0 0 
. . . . 0 . . . 0 
. . . . 0 . . . 0 
 with color red at (0,3)
  _01: point with color red at (11,9)
  + 2 delta pixels
diff: 
! 35 wrong pixels (generated / expected)

TRAIN a5313dff.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (1,7) with model Full with color red at (3,0)
  _01: point with color red at (5,2)
  + 25 delta pixels
diff: 
! 38 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (6,1) with model Full with color red at (3,4)
  _01: point with color red at (5,2)
  + 26 delta pixels
diff: 
! 41 wrong pixels (generated / expected)

TEST a5313dff.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 10.9 sec (10.9 sec/task)
bits-train-error = 2080.2 bits (2080.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-149] Checking task a5f85a15.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 42813.7 = 42816.0
DL output with Mo: L = 2.3 + 42813.7 = 42816.0
DL input+output M: L = 4.6 + 85627.3 = 85631.9

# learning a model for train pairs
2.000	
1.196	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.391	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.308	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.274	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.259	OUT ADD ^.layer_0 = point with color ? at (?,?)
0.243	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.227	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.215	OUT SPE ^.size = ^.size
0.208	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.202	OUT SPE ^.layer_01.pos = ^.layer_01.pos
0.196	OUT SPE ^.layer_011.pos = ^.layer_01.pos + (1, 1)
0.192	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.190	IN  SPE ^.color = black
0.188	OUT SPE ^.color = black
0.113	
0.113	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: point with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: point with color ? at ^.layer_01.pos
  _011: point with color ? at ^.layer_01.pos + (1, 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.3 + 3224.1 = 3294.4
DL output with Mo: L = 75.0 + 4687.6 = 4762.5
DL input+output M: L = 145.3 + 7911.7 = 8057.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: point with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: point with color ? at ^.layer_01.pos
  _011: point with color ? at ^.layer_01.pos + (1, 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 75.0 + 4687.6 = 4762.5
DL input+output M: L = 145.2 + 4687.6 = 4832.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,0)
  _01: rectangle with size (1,1) with model Full with color red at (1,1)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: point with color red at (0,0)
  _01: point with color yellow at (1,1)
  _011: point with color red at (2,2)
diff: 
   (11.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,0)
  _01: rectangle with size (1,1) with model Full with color red at (1,1)
  + 1 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,0)
  _01: rectangle with size (1,1) with model Full with color red at (2,2)
  + 1 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (1,1)
  _01: rectangle with size (1,1) with model Full with color red at (0,0)
  + 1 delta pixels
diff: 
! 3 wrong pixels (generated / expected)

TRAIN a5f85a15.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (8,8) and color black and layers
  _0: rectangle with size (6,6) with mask 
0 . . . . . 
. 0 . . . . 
. . 0 . . . 
. . . 0 . . 
. . . . 0 . 
. . . . . 0 
 with color brown at (0,2)
  _01: rectangle with size (4,4) with mask 
0 . . . 
. 0 . . 
. . 0 . 
. . . 0 
 with color brown at (4,0)
diff: 
   (0.0 bits)
data: a background with size (8,8) and color black and layers
  _0: point with color brown at (0,2)
  _01: point with color brown at (4,0)
  _011: point with color yellow at (5,1)
  + 7 delta pixels
diff: 
   (289.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (6,6) with mask 
0 . . . . . 
. 0 . . . . 
. . 0 . . . 
. . . 0 . . 
. . . . 0 . 
. . . . . 0 
 with color brown at (0,2)
  _01: rectangle with size (4,4) with mask 
0 . . . 
. 0 . . 
. . 0 . 
. . . 0 
 with color brown at (4,0)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . . . 
. 0 . . 
. . 0 . 
. . . 0 
 with color brown at (4,0)
  _01: rectangle with size (6,6) with mask 
0 . . . . . 
. 0 . . . . 
. . 0 . . . 
. . . 0 . . 
. . . . 0 . 
. . . . . 0 
 with color brown at (0,2)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN a5f85a15.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . . . 
. 0 . . 
. . 0 . 
. . . 0 
 with color green at (0,2)
  _01: rectangle with size (3,3) with mask 
0 . . 
. 0 . 
. . 0 
 with color green at (3,0)
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _0: point with color green at (0,2)
  _01: point with color green at (3,0)
  _011: point with color yellow at (4,1)
  + 4 delta pixels
diff: 
   (168.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . . . 
. 0 . . 
. . 0 . 
. . . 0 
 with color green at (0,2)
  _01: rectangle with size (3,3) with mask 
0 . . 
. 0 . 
. . 0 
 with color green at (3,0)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
. 0 . 
. . 0 
 with color green at (3,0)
  _01: rectangle with size (4,4) with mask 
0 . . . 
. 0 . . 
. . 0 . 
. . . 0 
 with color green at (0,2)
diff: 
! 6 wrong pixels (generated / expected)

TRAIN a5f85a15.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (11,11) with mask 
0 . . . . . . . . . . 
. 0 . . . . . . . . . 
. . 0 . . . . . . . . 
. . . 0 . . . . . . . 
. . . . 0 . . . . . . 
. . . . . 0 . . . . . 
. . . . . . 0 . . . . 
. . . . . . . 0 . . . 
. . . . . . . . 0 . . 
. . . . . . . . . 0 . 
. . . . . . . . . . 0 
 with color pink at (1,0)
  _01: rectangle with size (8,8) with mask 
0 . . . . . . . 
. 0 . . . . . . 
. . 0 . . . . . 
. . . 0 . . . . 
. . . . 0 . . . 
. . . . . 0 . . 
. . . . . . 0 . 
. . . . . . . 0 
 with color pink at (0,4)
  + 4 delta pixels
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (8,8) with mask 
0 . . . . . . . 
. 0 . . . . . . 
. . 0 . . . . . 
. . . 0 . . . . 
. . . . 0 . . . 
. . . . . 0 . . 
. . . . . . 0 . 
. . . . . . . 0 
 with color pink at (0,4)
  _01: rectangle with size (11,11) with mask 
0 . . . . . . . . . . 
. 0 . . . . . . . . . 
. . 0 . . . . . . . . 
. . . 0 . . . . . . . 
. . . . 0 . . . . . . 
. . . . . 0 . . . . . 
. . . . . . 0 . . . . 
. . . . . . . 0 . . . 
. . . . . . . . 0 . . 
. . . . . . . . . 0 . 
. . . . . . . . . . 0 
 with color pink at (1,0)
  + 4 delta pixels
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (11,11) with mask 
0 . . . . . . . . . . 
. 0 . . . . . . . . . 
. . 0 . . . . . . . . 
. . . 0 . . . . . . . 
. . . . 0 . . . . . . 
. . . . . 0 . . . . . 
. . . . . . 0 . . . . 
. . . . . . . 0 . . . 
. . . . . . . . 0 . . 
. . . . . . . . . 0 . 
. . . . . . . . . . 0 
 with color pink at (1,0)
  _01: rectangle with size (4,4) with mask 
0 . . . 
. 0 . . 
. . 0 . 
. . . 0 
 with color pink at (8,0)
  + 8 delta pixels
diff: 
! 22 wrong pixels (generated / expected)

TEST a5f85a15.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 20.8 sec (20.8 sec/task)
bits-train-error = 4687.6 bits (4687.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-148] Checking task a61ba2ce.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 137009.7 = 137012.0
DL output with Mo: L = 2.3 + 12399.3 = 12401.7
DL input+output M: L = 4.6 + 149409.0 = 149413.7

# learning a model for train pairs
2.000	
1.075	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.829	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.700	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.570	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.439	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.304	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.279	OUT SPE ^.layer_0.shape.mask = 
0 0 
0 . 

0.254	OUT SPE ^.layer_01.shape.mask = 
0 0 
. 0 

0.230	OUT SPE ^.layer_011.shape.mask = 
0 . 
0 0 

0.205	OUT SPE ^.layer_0111.shape.mask = 
. 0 
0 0 

0.183	OUT SPE ^.size = tiling('(2, 2), 2, 2)
0.169	OUT SPE ^.layer_0.pos = '(0, 0)
0.156	OUT SPE ^.layer_01.pos = '(0, 2)
0.142	OUT SPE ^.layer_011.pos = '(2, 0)
0.129	OUT SPE ^.layer_0111.pos = '(2, 2)
0.116	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.103	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.090	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.077	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.067	OUT SPE ^.layer_0111.shape = ^.layer_0111.shape
0.057	OUT SPE ^.layer_011.shape = ^.layer_011.shape
0.053	OUT SPE ^.color = black
0.051	IN  SPE ^.layer_011.shape.mask = 
0 . 
0 0 

0.041	OUT SPE ^.layer_01.shape = ^.layer_01.shape
0.030	OUT SPE ^.layer_0.shape = ^.layer_0.shape
0.028	IN  SPE ^.layer_0.shape.mask = 
0 0 
0 . 

0.026	IN  SPE ^.layer_01.shape.mask = 
0 0 
. 0 

0.023	IN  SPE ^.layer_0111.shape.mask = 
. 0 
0 0 

0.023	IN  SPE ^.color = black
0.010	
0.010	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size tiling('(2, 2), 2, 2) and color black and layers
  _0: ^.layer_0.shape at '(0, 0)
  _01: ^.layer_01.shape at '(0, 2)
  _011: ^.layer_011.shape at '(2, 0)
  _0111: ^.layer_0111.shape at '(2, 2)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
0 0 
0 . 
 with color ? at (?,?)
  _01: 
0 0 
. 0 
 with color ? at (?,?)
  _011: 
0 . 
0 0 
 with color ? at (?,?)
  _0111: 
. 0 
0 0 
 with color ? at (?,?)

DL input  with Mi: L = 125.4 + 1842.9 = 1968.3
DL output with Mo: L = 108.0 + 0.0 = 108.0
DL input+output M: L = 233.4 + 1842.9 = 2076.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size tiling('(2, 2), 2, 2) and color black and layers
  _0: ^.layer_0.shape at '(0, 0)
  _01: ^.layer_01.shape at '(0, 2)
  _011: ^.layer_011.shape at '(2, 0)
  _0111: ^.layer_0111.shape at '(2, 2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 0 
0 . 
 with color ? at (?,?)
  _01: 
0 0 
. 0 
 with color ? at (?,?)
  _011: 
0 . 
0 0 
 with color ? at (?,?)
  _0111: 
. 0 
0 0 
 with color ? at (?,?)

DL input  with Mi: L = 125.3 + 0.0 = 125.3
DL output with Mo: L = 108.0 + 0.0 = 108.0
DL input+output M: L = 233.3 + 0.0 = 233.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: 
0 0 
0 . 
 with color cyan at (1,6)
  _01: 
0 0 
. 0 
 with color red at (3,1)
  _011: 
0 . 
0 0 
 with color green at (9,3)
  _0111: 
. 0 
0 0 
 with color blue at (7,7)
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: 
8 8 
8 . 
 at (0,0)
  _01: 
2 2 
. 2 
 at (0,2)
  _011: 
3 . 
3 3 
 at (2,0)
  _0111: 
. 1 
1 1 
 at (2,2)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: 
0 0 
0 . 
 with color cyan at (1,6)
  _01: 
0 0 
. 0 
 with color red at (3,1)
  _011: 
0 . 
0 0 
 with color green at (9,3)
  _0111: 
. 0 
0 0 
 with color blue at (7,7)
diff: 
correct output grid

TRAIN a61ba2ce.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: 
0 0 
0 . 
 with color blue at (3,2)
  _01: 
0 0 
. 0 
 with color cyan at (1,8)
  _011: 
0 . 
0 0 
 with color yellow at (9,4)
  _0111: 
. 0 
0 0 
 with color red at (5,7)
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: 
1 1 
1 . 
 at (0,0)
  _01: 
8 8 
. 8 
 at (0,2)
  _011: 
4 . 
4 4 
 at (2,0)
  _0111: 
. 2 
2 2 
 at (2,2)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: 
0 0 
0 . 
 with color blue at (3,2)
  _01: 
0 0 
. 0 
 with color cyan at (1,8)
  _011: 
0 . 
0 0 
 with color yellow at (9,4)
  _0111: 
. 0 
0 0 
 with color red at (5,7)
diff: 
correct output grid

TRAIN a61ba2ce.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: 
0 0 
0 . 
 with color green at (9,2)
  _01: 
0 0 
. 0 
 with color cyan at (2,10)
  _011: 
0 . 
0 0 
 with color blue at (6,6)
  _0111: 
. 0 
0 0 
 with color pink at (2,2)
diff: 
correct output grid

TEST a61ba2ce.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 4.6 sec (4.6 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-147] Checking task a61f2674.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 64315.6 = 64317.9
DL output with Mo: L = 2.3 + 64315.6 = 64317.9
DL input+output M: L = 4.6 + 128631.2 = 128635.9

# learning a model for train pairs
2.000	
1.143	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.470	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.376	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.283	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.168	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.143	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.115	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.093	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.083	OUT SPE ^.layer_0 = coloring(^.layer_0, blue)
0.077	OUT SPE ^.size = ^.size
0.072	IN  SPE ^.layer_01.shape.mask = 
0 
0 
0 
0 
0 
0 
0 

0.068	IN  SPE ^.layer_011.shape.mask = 
0 
0 
0 
0 
0 
0 

0.065	OUT SPE ^.layer_01 = coloring(^.layer_0111, red)
0.063	IN  SPE ^.layer_0.shape.color = grey
0.062	IN  SPE ^.layer_01.shape.color = grey
0.060	IN  SPE ^.layer_011.shape.color = grey
0.058	IN  SPE ^.layer_0111.shape.color = grey
0.057	IN  SPE ^.layer_0.shape.mask.model = Full
0.057	IN  SPE ^.layer_0111.shape.mask.model = Full
0.056	IN  SPE ^.color = black
0.055	OUT SPE ^.color = black
0.003	
0.003	IN  GEN ^.layer_0111.shape.color = ?
0.003	IN  GEN ^.layer_01.shape.color = ?
0.003	IN  GEN ^.layer_011.shape.color = ?
0.003	IN  GEN ^.layer_0.shape.color = ?
0.003	IN  GEN ^.layer_0111.shape.mask.model = ?
0.003	IN  GEN ^.layer_0.shape.mask.model = ?
0.003	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, blue)
  _01: coloring(^.layer_0111, red)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color grey at (?,?)
  _01: 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (?,?)
  _011: 
0 
0 
0 
0 
0 
0 
 with color grey at (?,?)
  _0111: rectangle with size (?,?) with model Full with color grey at (?,?)

DL input  with Mi: L = 137.8 + 3352.9 = 3490.6
DL output with Mo: L = 49.2 + 0.0 = 49.2
DL input+output M: L = 186.9 + 3352.9 = 3539.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, blue)
  _01: coloring(^.layer_0111, red)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: 
0 
0 
0 
0 
0 
0 
0 
 with color ? at (?,?)
  _011: 
0 
0 
0 
0 
0 
0 
 with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 123.4 + 31.7 = 155.1
DL output with Mo: L = 49.2 + 0.0 = 49.2
DL input+output M: L = 172.6 + 31.7 = 204.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: rectangle with size (8,1) with model Full with color grey at (1,2)
  _01: 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (2,6)
  _011: 
0 
0 
0 
0 
0 
0 
 with color grey at (3,0)
  _0111: rectangle with size (3,1) with model Full with color grey at (6,8)
  + 4 delta pixels
diff: 
   (3.2 bits)
data: a background with size (9,9) and color black and layers
  _0: 
1 
1 
1 
1 
1 
1 
1 
1 
 at (1,2)
  _01: 
2 
2 
2 
 at (6,8)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (8,1) with model Full with color grey at (1,2)
  _01: 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (2,6)
  _011: 
0 
0 
0 
0 
0 
0 
 with color grey at (3,0)
  _0111: rectangle with size (4,1) with model Full with color grey at (5,4)
  + 3 delta pixels
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (4,1) with model Full with color grey at (5,4)
  _01: 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (2,6)
  _011: 
0 
0 
0 
0 
0 
0 
 with color grey at (3,0)
  _0111: rectangle with size (8,1) with model Full with color grey at (1,2)
  + 3 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (8,1) with model Full with color grey at (1,2)
  _01: 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (2,6)
  _011: 
0 
0 
0 
0 
 with color grey at (5,4)
  _0111: rectangle with size (6,1) with model Full with color grey at (3,0)
  + 3 delta pixels
diff:   ^.layer_011.shape.mask
! 9 wrong pixels (generated / expected)

TRAIN a61f2674.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,1) with model Full with color grey at (0,4)
  _01: 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (2,0)
  _011: 
0 
0 
0 
0 
0 
0 
 with color grey at (3,6)
  _0111: rectangle with size (2,1) with model Full with color grey at (7,2)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: 
1 
1 
1 
1 
1 
1 
1 
1 
1 
 at (0,4)
  _01: 
2 
2 
 at (7,2)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,1) with model Full with color grey at (0,4)
  _01: 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (2,0)
  _011: 
0 
0 
0 
0 
0 
0 
 with color grey at (3,6)
  _0111: rectangle with size (2,1) with model Full with color grey at (7,2)
diff: 
correct output grid

TRAIN a61f2674.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (8,1) with model Full with color grey at (1,7)
  _01: 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (2,3)
  _011: 
0 
 with color grey at (8,1)
  _0111: rectangle with size (5,1) with model Full with color grey at (4,5)
diff:   ^.layer_011.shape.mask
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (5,1) with model Full with color grey at (4,5)
  _01: 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (2,3)
  _011: 
0 
 with color grey at (8,1)
  _0111: rectangle with size (8,1) with model Full with color grey at (1,7)
diff:   ^.layer_011.shape.mask
! 14 wrong pixels (generated / expected)

TEST a61f2674.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 5.3 sec (5.3 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 0.50 tasks (50.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.50
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-146] Checking task a64e4611.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 1154266.3 = 1154268.6
DL output with Mo: L = 2.3 + 1154266.3 = 1154268.6
DL input+output M: L = 4.6 + 2308532.5 = 2308537.2

# learning a model for train pairs
2.000	
1.283	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.863	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.583	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.512	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.430	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.363	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.147	
0.147	IN  GEN ^ = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 249755.1 = 249797.1
DL output with Mo: L = 98.1 + 169294.7 = 169392.8
DL input+output M: L = 140.1 + 419049.8 = 419189.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 98.1 + 169294.7 = 169392.8
DL input+output M: L = 100.4 + 169294.7 = 169395.1

# train input/output grids

## instance 1

> Input and output best reading:

data: 
8 8 0 8 0 8 0 8 8 8 8 8 0 8 8 8 0 8 0 0 8 0 8 0 0 0 8 8 0 8 
0 0 0 8 8 8 8 0 0 8 0 8 0 0 8 8 0 0 8 0 0 0 0 0 8 8 8 8 0 8 
8 0 0 0 8 8 0 0 8 0 8 8 0 8 8 0 8 0 8 0 8 8 8 8 0 0 8 0 0 0 
0 8 8 0 0 0 0 8 8 0 0 0 0 8 8 0 8 8 0 0 0 8 8 0 8 0 0 0 0 0 
8 8 8 0 8 0 0 8 0 0 0 0 0 0 0 0 0 8 8 8 8 0 0 8 0 8 8 0 0 8 
0 8 0 0 0 8 8 8 0 0 0 0 0 0 0 0 0 0 8 8 8 8 0 8 0 8 0 0 0 8 
0 8 8 8 8 0 0 8 0 0 0 0 0 0 0 0 0 8 8 8 0 0 0 0 0 8 0 8 8 8 
0 8 8 8 8 0 0 8 0 0 0 0 0 0 0 0 0 0 0 8 0 8 0 8 8 8 0 0 8 8 
8 0 8 8 0 8 8 8 0 0 0 0 0 0 0 0 0 8 0 0 0 8 0 0 8 0 0 8 0 8 
8 8 8 0 8 8 0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
8 0 8 8 0 0 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 8 0 0 8 0 0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
8 8 8 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 8 8 0 8 8 0 8 
8 0 8 8 0 0 8 8 0 0 0 0 0 0 0 0 0 8 8 0 8 0 0 0 8 0 0 0 8 8 
8 0 8 0 0 8 8 0 0 0 0 0 0 0 0 0 0 0 0 8 0 8 8 0 0 0 8 0 8 8 
0 0 8 8 8 8 0 0 0 0 0 0 0 0 0 0 0 8 8 0 0 0 8 8 0 8 8 0 0 8 
8 0 8 0 0 8 8 8 0 0 0 0 0 0 0 0 0 8 8 8 8 0 8 8 0 0 0 8 8 0 
8 0 8 8 0 8 0 8 0 0 0 0 0 0 0 0 0 0 8 8 8 0 8 0 8 0 8 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0 0 0 8 8 8 0 8 8 8 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0 0 8 0 8 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0 0 0 8 0 8 8 0 0 8 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0 0 0 8 0 8 0 8 8 8 
8 8 0 0 8 8 0 8 0 0 0 0 0 0 0 0 0 8 8 8 0 8 0 0 0 0 8 8 8 8 
0 8 8 8 8 0 0 8 0 0 0 0 0 0 0 0 0 8 0 8 0 8 0 8 8 0 0 0 8 8 
0 8 8 0 8 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 8 0 8 0 8 
8 0 8 8 8 0 8 8 0 0 0 0 0 0 0 0 0 0 8 8 8 0 8 0 8 8 0 0 0 8 
8 0 8 0 8 0 8 0 0 0 0 0 0 0 0 0 0 8 0 8 8 0 8 8 0 8 0 0 8 0 
0 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0 8 8 0 8 8 8 0 0 0 
8 8 8 0 8 0 0 8 0 0 0 0 0 0 0 0 0 8 8 0 8 0 8 8 0 8 0 8 8 0 

diff: 
   (0.0 bits)
data: a background with size (30,30) and color cyan and layers
  _0: rectangle with size (25,30) with mask 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 0 . . . . . . . . . . . . . . 
 with color green at (5,0)
  _01: rectangle with size (20,30) with mask 
. . 0 . . . 0 . . . . . 0 . . . 0 . 0 0 . 0 . 0 0 0 . . 0 . 
0 0 0 . . . . 0 0 . 0 . 0 0 . . 0 0 . 0 0 0 0 0 . . . . 0 . 
. 0 0 0 . . 0 0 . 0 . . 0 . . 0 . 0 . 0 . . . . 0 0 . 0 0 0 
0 . . 0 0 0 0 . . 0 0 0 0 . . 0 . . 0 0 0 . . 0 . 0 0 0 0 0 
. . . 0 . 0 0 . 0 0 0 0 0 0 0 0 0 . . . . 0 0 . 0 . . 0 0 . 
. . 0 0 0 . . . 0 . . . . . . . 0 0 . . . . 0 . 0 . 0 0 0 . 
. . . . . 0 0 . 0 . . . . . . . 0 . . . 0 0 0 0 0 . 0 . . . 
. . . . . 0 0 . 0 . . . . . . . 0 0 0 . 0 . 0 . . . 0 0 . . 
. . . . 0 . . . 0 . . . . . . . 0 . 0 0 0 . 0 0 . 0 0 . 0 . 
. . . 0 . . 0 . 0 . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . 0 0 . . 0 . . . . . . . . . . . . . . . . . . . . . 
. . . 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . . . . 
. . 0 0 . 0 0 . 0 . . . . . . . . . . . . . . . . . . . . . 
. . . . . 0 0 0 0 . . . . . . . . . . . . . . . . . . . . . 
. 0 . . 0 0 . . 0 . . . . . . . . . . . . . . . . . . . . . 
. 0 . 0 0 . . 0 0 . . . . . . . . . . . . . . . . . . . . . 
0 0 . . . . 0 0 0 . . . . . . . . . . . . . . . . . . . . . 
. 0 . 0 0 . . . 0 . . . . . . . . . . . . . . . . . . . . . 
. 0 . . 0 . 0 . 0 . . . . . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . . . . . 
 with color black at (0,0)
  _011: rectangle with size (18,14) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 . 0 . . 0 . . 0 . 
0 . . 0 . 0 0 0 . 0 0 0 . . 
0 0 0 . 0 . . 0 0 0 . 0 . . 
0 . . 0 0 0 . . 0 . . 0 0 . 
0 . . . . 0 . . 0 0 0 . . 0 
0 0 . . . 0 . 0 . 0 . 0 0 0 
0 0 . 0 0 0 0 . . . 0 . . . 
0 0 0 0 0 0 . 0 0 0 . 0 . . 
0 . 0 0 0 0 . 0 . . 0 0 . . 
0 0 . 0 0 0 0 . 0 . 0 . . . 
0 . . . 0 . 0 0 0 0 . . . . 
0 . 0 . 0 . 0 . . 0 0 0 . . 
0 0 0 0 0 0 0 . 0 . 0 . 0 . 
0 0 . . . 0 . 0 . . 0 0 0 . 
0 . 0 . . 0 . . 0 . 0 0 . 0 
0 0 . 0 0 . . 0 . . . 0 0 0 
0 . . 0 . 0 . . 0 . 0 . . 0 
 with color black at (12,16)
  + 50 delta pixels
diff: 
   (3770.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 8 0 8 0 8 0 8 8 8 8 8 0 8 8 8 0 8 0 0 8 0 8 0 0 0 8 8 0 8 
0 0 0 8 8 8 8 0 0 8 0 8 0 0 8 8 0 0 8 0 0 0 0 0 8 8 8 8 0 8 
8 0 0 0 8 8 0 0 8 0 8 8 0 8 8 0 8 0 8 0 8 8 8 8 0 0 8 0 0 0 
0 8 8 0 0 0 0 8 8 0 0 0 0 8 8 0 8 8 0 0 0 8 8 0 8 0 0 0 0 0 
8 8 8 0 8 0 0 8 0 0 0 0 0 0 0 0 0 8 8 8 8 0 0 8 0 8 8 0 0 8 
0 8 0 0 0 8 8 8 0 0 0 0 0 0 0 0 0 0 8 8 8 8 0 8 0 8 0 0 0 8 
0 8 8 8 8 0 0 8 0 0 0 0 0 0 0 0 0 8 8 8 0 0 0 0 0 8 0 8 8 8 
0 8 8 8 8 0 0 8 0 0 0 0 0 0 0 0 0 0 0 8 0 8 0 8 8 8 0 0 8 8 
8 0 8 8 0 8 8 8 0 0 0 0 0 0 0 0 0 8 0 0 0 8 0 0 8 0 0 8 0 8 
8 8 8 0 8 8 0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
8 0 8 8 0 0 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 8 0 0 8 0 0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
8 8 8 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 8 8 0 8 8 0 8 
8 0 8 8 0 0 8 8 0 0 0 0 0 0 0 0 0 8 8 0 8 0 0 0 8 0 0 0 8 8 
8 0 8 0 0 8 8 0 0 0 0 0 0 0 0 0 0 0 0 8 0 8 8 0 0 0 8 0 8 8 
0 0 8 8 8 8 0 0 0 0 0 0 0 0 0 0 0 8 8 0 0 0 8 8 0 8 8 0 0 8 
8 0 8 0 0 8 8 8 0 0 0 0 0 0 0 0 0 8 8 8 8 0 8 8 0 0 0 8 8 0 
8 0 8 8 0 8 0 8 0 0 0 0 0 0 0 0 0 0 8 8 8 0 8 0 8 0 8 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0 0 0 8 8 8 0 8 8 8 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0 0 8 0 8 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0 0 0 8 0 8 8 0 0 8 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0 0 0 8 0 8 0 8 8 8 
8 8 0 0 8 8 0 8 0 0 0 0 0 0 0 0 0 8 8 8 0 8 0 0 0 0 8 8 8 8 
0 8 8 8 8 0 0 8 0 0 0 0 0 0 0 0 0 8 0 8 0 8 0 8 8 0 0 0 8 8 
0 8 8 0 8 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 8 0 8 0 8 
8 0 8 8 8 0 8 8 0 0 0 0 0 0 0 0 0 0 8 8 8 0 8 0 8 8 0 0 0 8 
8 0 8 0 8 0 8 0 0 0 0 0 0 0 0 0 0 8 0 8 8 0 8 8 0 8 0 0 8 0 
0 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0 8 8 0 8 8 8 0 0 0 
8 8 8 0 8 0 0 8 0 0 0 0 0 0 0 0 0 8 8 0 8 0 8 8 0 8 0 8 8 0 

diff: 
! size mismatch, 10x10 instead of 30x30

TRAIN a64e4611.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 
0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 0 
0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 
0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 1 
0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 0 0 1 
0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1 
0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 1 1 
0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 
0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 1 
1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1 0 0 1 1 
1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0 0 1 0 1 
0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 
1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 
0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 
0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 
1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 
0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 0 
1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 
0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0 0 
0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 1 1 1 0 
0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 1 
1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 
1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 1 1 1 0 

diff: 
   (0.0 bits)
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (30,24) with mask 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
0 0 0 0 0 0 0 . . . . . . . . . . . . . . . . . 
 with color green at (0,6)
  _01: rectangle with size (10,16) with mask 
. . . . . . . 0 . . 0 . . 0 . . 
. . . . . . . 0 . 0 . . 0 0 . . 
. . . . 0 0 0 . 0 . . . 0 0 0 0 
. . 0 0 . . 0 0 . . . 0 . . . . 
. . 0 0 . . . 0 0 . . 0 0 0 0 . 
0 . 0 0 0 0 0 0 . 0 . . 0 0 . . 
0 0 . . . . 0 . . 0 . . 0 0 0 . 
. . . 0 0 0 0 . . 0 . . . 0 0 0 
. . . . . . . 0 0 . . 0 0 . . 0 
. . . . . . . 0 . 0 0 . 0 0 0 . 
 with color blue at (20,14)
  _011: rectangle with size (22,5) with mask 
0 0 0 . . 
. . 0 . 0 
. . 0 0 . 
. . 0 0 0 
. 0 . . . 
. . 0 0 0 
. 0 . 0 . 
0 0 0 . 0 
. . 0 . 0 
0 . 0 0 0 
. 0 0 0 0 
. 0 0 . . 
0 0 0 . . 
0 . . . . 
. 0 0 . . 
0 0 . . . 
. 0 0 . . 
0 . . 0 0 
0 . 0 . . 
0 0 . 0 0 
0 . 0 0 0 
. . 0 . . 
 with color blue at (0,0)
  + 142 delta pixels
diff: 
   (7191.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 
0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 0 
0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 
0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 1 
0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 0 0 1 
0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1 
0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 1 1 
0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 
0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 1 
1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1 0 0 1 1 
1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0 0 1 0 1 
0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 
1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 
0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 
0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 
1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 
0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 0 
1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 
0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0 0 
0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 1 1 1 0 
0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 1 
1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 
1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 1 1 1 0 

diff: 
! size mismatch, 10x10 instead of 30x30

TRAIN a64e4611.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
0 2 0 2 2 2 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 2 0 0 0 
0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 2 2 0 
0 2 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 2 0 2 0 0 0 0 2 0 2 0 2 0 
0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 2 2 0 0 2 2 0 2 2 0 0 0 0 
0 2 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 2 0 0 2 0 0 
2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 2 0 2 0 0 0 0 2 
0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 2 2 0 2 0 0 2 2 2 0 0 0 0 
2 2 2 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 2 0 2 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 2 2 0 2 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 2 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 2 2 2 0 0 0 0 2 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 0 2 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 2 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 2 0 2 0 0 2 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 2 0 0 2 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 2 0 2 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 2 0 0 2 2 0 0 0 2 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 0 2 2 2 0 2 0 2 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 0 2 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 2 0 0 
0 0 0 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 2 0 2 0 0 0 0 
0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 2 2 0 2 
0 0 2 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 2 2 0 
0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 0 0 2 0 2 
2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 2 
2 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 2 0 0 2 2 0 0 0 
2 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 2 0 0 0 2 2 2 2 
0 2 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 2 0 0 0 2 0 2 2 
2 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 2 0 0 0 2 0 2 0 
2 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 2 2 2 2 2 2 0 2 2 

diff: 
   (0.0 bits)
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (30,16) with mask 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
. . . . . . . . 0 0 0 0 0 0 0 0 
 with color green at (0,0)
  _01: rectangle with size (12,12) with mask 
. . . . . 0 0 . 0 . . . 
. . . . 0 . . 0 . . . . 
. . . 0 . . 0 . 0 . . . 
0 . 0 0 . . 0 0 . . . . 
0 0 0 0 . 0 0 0 . 0 . . 
. . . . 0 . 0 . 0 . . . 
. . . 0 . . . 0 . 0 . . 
. 0 0 . . 0 . 0 . . . . 
. . . 0 0 . . . 0 0 . 0 
. . . . . . . . 0 0 0 . 
. . . . . . . . . 0 . 0 
. . . . . . . . . . . 0 
 with color red at (13,18)
  _011: rectangle with size (8,13) with mask 
. . 0 . . . . . . . . . . 
. 0 . . . . . . . . . . . 
0 . 0 . . . . . . . . . . 
. 0 0 . . 0 . . 0 0 . . . 
0 . . 0 . 0 . . . 0 0 0 0 
0 . . 0 . 0 . . . 0 . 0 0 
0 . . . 0 0 . . . 0 . 0 . 
0 0 0 . 0 0 0 0 0 0 . 0 0 
 with color red at (22,17)
  + 120 delta pixels
diff: 
   (5968.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 2 0 2 2 2 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 2 0 0 0 
0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 2 2 0 
0 2 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 2 0 2 0 0 0 0 2 0 2 0 2 0 
0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 2 2 0 0 2 2 0 2 2 0 0 0 0 
0 2 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 2 0 0 2 0 0 
2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 2 0 2 0 0 0 0 2 
0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 2 2 0 2 0 0 2 2 2 0 0 0 0 
2 2 2 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 2 0 2 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 2 2 0 2 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 2 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 2 2 2 0 0 0 0 2 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 0 2 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 2 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 2 0 2 0 0 2 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 2 0 0 2 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 2 0 2 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 2 0 0 2 2 0 0 0 2 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 0 2 2 2 0 2 0 2 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 0 2 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 2 0 0 
0 0 0 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 2 0 2 0 0 0 0 
0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 2 2 0 2 
0 0 2 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 2 2 0 
0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 0 0 2 0 2 
2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 2 
2 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 2 0 0 2 2 0 0 0 
2 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 2 0 0 0 2 2 2 2 
0 2 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 2 0 0 0 2 0 2 2 
2 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 2 0 0 0 2 0 2 0 
2 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 2 2 2 2 2 2 0 2 2 

diff: 
! size mismatch, 10x10 instead of 30x30

TRAIN a64e4611.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 4 4 0 4 0 4 4 0 0 0 0 0 0 4 4 4 4 4 0 0 0 4 0 4 4 4 0 0 0 
4 4 4 0 0 4 4 0 0 0 0 0 0 0 0 4 4 0 4 0 0 0 0 0 0 4 4 0 4 4 
0 0 0 4 0 0 0 0 4 4 0 0 0 0 0 4 0 4 4 0 0 0 4 4 0 0 4 0 0 4 
4 0 0 0 4 4 4 0 4 0 0 0 0 0 4 0 0 0 4 0 0 0 0 0 0 0 4 0 0 4 
4 0 4 4 4 0 4 0 0 4 0 0 0 0 0 0 0 4 0 0 0 0 0 4 0 4 4 0 4 0 
0 0 4 0 4 0 0 0 4 4 0 0 0 0 4 0 0 4 0 0 0 0 0 4 0 0 0 0 0 0 
4 0 4 4 0 0 4 0 0 4 0 0 0 0 4 0 4 4 0 0 0 0 4 0 0 4 4 0 4 4 
0 4 0 4 4 4 0 4 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 4 0 0 
0 0 4 0 0 0 4 4 4 0 0 0 0 0 4 4 0 0 4 0 0 0 0 0 0 0 4 0 4 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 4 0 0 0 0 0 4 0 4 0 0 0 0 0 4 0 0 4 0 0 0 4 0 4 4 0 0 4 4 
4 4 0 4 4 0 0 4 0 0 0 0 0 0 0 4 0 4 0 0 4 0 0 4 4 4 0 4 0 0 
0 0 4 0 4 4 4 0 4 0 0 0 0 0 0 0 0 4 0 0 0 0 4 4 4 4 4 4 4 4 
0 4 4 0 4 0 0 0 0 0 0 0 0 0 4 4 4 0 4 0 4 0 0 0 4 0 0 0 4 0 
0 0 0 0 4 0 0 0 0 4 0 0 0 0 4 0 0 0 0 0 0 0 0 0 4 0 0 4 0 0 
4 0 4 0 0 0 4 0 0 0 0 0 0 0 0 0 4 4 0 0 0 0 0 0 4 0 4 4 0 4 
4 0 4 4 0 0 4 4 0 0 0 0 0 0 0 0 4 4 4 0 0 4 0 4 0 4 0 0 4 4 
0 4 4 4 4 0 4 0 0 0 0 0 0 0 4 0 4 4 0 4 0 0 0 4 0 0 4 4 4 4 
4 4 0 0 0 0 4 4 0 4 0 0 0 0 4 4 0 4 0 0 4 0 4 0 4 0 4 4 4 0 
4 0 4 0 0 0 4 0 0 4 0 0 0 0 4 0 4 4 0 0 0 0 4 0 4 4 0 4 0 4 
0 4 0 4 0 0 0 0 0 4 0 0 0 0 4 0 4 0 4 4 4 0 0 4 4 0 0 0 4 0 
0 0 4 0 4 0 4 4 0 0 0 0 0 0 0 0 4 0 4 0 0 0 0 0 0 4 0 0 4 4 
4 0 0 0 0 0 4 4 4 0 0 0 0 0 0 0 0 0 0 0 4 0 4 0 4 4 4 0 4 4 
0 0 0 4 4 4 4 4 4 0 0 0 0 0 0 4 0 0 4 0 0 0 0 4 0 4 4 0 0 0 

diff: 
! size mismatch, 10x10 instead of 30x30

TEST a64e4611.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.9 sec (59.9 sec/task)
bits-train-error = 169294.7 bits (169294.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-145] Checking task a65b410d.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 72578.9 = 72581.2
DL output with Mo: L = 2.3 + 72578.9 = 72581.2
DL input+output M: L = 4.6 + 145157.8 = 145162.5

# learning a model for train pairs
2.000	
1.059	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.376	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.189	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.143	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.106	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.062	OUT ADD ^.layer_00 = ^.layer_0
0.054	OUT SPE ^.size = ^.size
0.050	OUT SPE ^.layer_0.pos = '(0, 0)
0.045	OUT SPE ^.layer_01.pos = ^.layer_0.pos + (1, 0)
0.043	IN  SPE ^.layer_0.shape.color = red
0.041	OUT SPE ^.layer_0.shape.color = green
0.038	OUT SPE ^.layer_01.shape.color = blue
0.037	OUT SPE ^.layer_01.shape.mask.size.i = area(^) - 1
0.035	OUT SPE ^.layer_01.shape.mask.size.j = area(^) - 1
0.034	IN  SPE ^.layer_0.shape.mask.model = Full
0.033	IN  SPE ^.color = black
0.032	OUT SPE ^.color = black
0.016	
0.016	IN  GEN ^.layer_0.shape.color = ?
0.016	IN  GEN ^.layer_0.shape.mask.model = ?
0.016	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color green at '(0, 0)
  _01: rectangle with size (area(^) - 1,area(^) - 1) with model ? with color blue at ^.layer_0.pos + (1, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color red at (?,?)

DL input  with Mi: L = 45.9 + 1162.5 = 1208.4
DL output with Mo: L = 133.1 + 954.3 = 1087.4
DL input+output M: L = 179.1 + 2116.8 = 2295.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color green at '(0, 0)
  _01: rectangle with size (area(^) - 1,area(^) - 1) with model ? with color blue at ^.layer_0.pos + (1, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 133.1 + 954.3 = 1087.4
DL input+output M: L = 175.1 + 954.3 = 1129.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (7,7) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (3,0)
diff: 
   (0.0 bits)
data: a background with size (7,7) and color black and layers
  _00: 
2 2 
 at (3,0)
  _0: rectangle with size (3,5) with mask 
0 0 0 0 0 
0 0 0 0 . 
0 0 0 . . 
 with color green at (0,0)
  _01: rectangle with size (1,1) with model Full with color blue at (4,0)
diff: 
   (30.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (3,0)
diff: 
! 8 wrong pixels (generated / expected)

TRAIN a65b410d.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (8,9) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (3,0)
diff: 
   (0.0 bits)
data: a background with size (8,9) and color black and layers
  _00: 
2 2 2 
 at (3,0)
  _0: rectangle with size (3,6) with mask 
0 0 0 0 0 0 
0 0 0 0 0 . 
0 0 0 0 . . 
 with color green at (0,0)
  _01: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color blue at (4,0)
diff: 
   (33.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,9) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (3,0)
diff: 
! 12 wrong pixels (generated / expected)

TRAIN a65b410d.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (7,9) and color black and layers
  _0: rectangle with size (1,4) with model Full with color red at (2,0)
diff: 
   (0.0 bits)
data: a background with size (7,9) and color black and layers
  _00: 
2 2 2 2 
 at (2,0)
  _0: rectangle with size (2,6) with mask 
0 0 0 0 0 0 
0 0 0 0 0 . 
 with color green at (0,0)
  _01: rectangle with size (3,3) with mask 
0 0 0 
0 0 . 
0 . . 
 with color blue at (3,0)
diff: 
   (31.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,9) and color black and layers
  _0: rectangle with size (1,4) with model Full with color red at (2,0)
diff: 
! 10 wrong pixels (generated / expected)

TRAIN a65b410d.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (1,5) with model Full with color red at (2,0)
diff: 
! 15 wrong pixels (generated / expected)

TEST a65b410d.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 4.6 sec (4.6 sec/task)
bits-train-error = 954.3 bits (954.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-144] Checking task a68b268e.json: 6 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 192946.8 = 192949.2
DL output with Mo: L = 2.3 + 37198.0 = 37200.4
DL input+output M: L = 4.6 + 230144.9 = 230149.5

# learning a model for train pairs
2.000	
1.504	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.086	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.892	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.738	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.649	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.565	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.495	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.429	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.390	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.360	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.330	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.306	OUT SPE ^.size = ^.size / '2
0.298	OUT SPE ^.layer_0111.shape.color = ^.layer_0111.shape.color
0.290	IN  SPE ^.layer_0.shape.mask = 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 

0.281	OUT ADD ^.layer_01111 = point with color ? at (?,?)
0.273	OUT SPE ^.layer_0.shape.mask.size.j = ^.layer_0111.shape.mask.size.j - 1
0.176	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size / '2 and color ? and layers
  _0: rectangle with size (?,^.layer_0111.shape.mask.size.j - 1) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ^.layer_0111.shape.color at (?,?)
  _01111: point with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 220.8 + 18804.6 = 19025.4
DL output with Mo: L = 166.9 + 6303.6 = 6470.6
DL input+output M: L = 387.7 + 25108.3 = 25496.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size / '2 and color ? and layers
  _0: rectangle with size (?,^.layer_0111.shape.mask.size.j - 1) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ^.layer_0111.shape.color at (?,?)
  _01111: point with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 220.8 + 91.7 = 312.5
DL output with Mo: L = 166.9 + 6303.6 = 6470.6
DL input+output M: L = 387.7 + 6395.3 = 6783.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (2,4) with mask 
. 0 0 0 
0 0 0 . 
 with color orange at (0,0)
  _011: rectangle with size (3,2) with mask 
0 0 
0 . 
. 0 
 with color cyan at (6,2)
  _0111: rectangle with size (1,3) with model Full with color pink at (5,5)
  _01111: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color yellow at (0,5)
  + 6 delta pixels
diff: 
   (2.0 bits)
data: a background with size (4,4) and color orange and layers
  _0: rectangle with size (3,2) with model Odd Checkboard with color cyan at (1,2)
  _01: rectangle with size (2,2) with model Full with color black at (2,1)
  _011: point with color cyan at (2,0)
  _0111: point with color pink at (0,0)
  _01111: point with color yellow at (2,3)
diff: 
   (101.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (2,4) with mask 
. 0 0 0 
0 0 0 . 
 with color orange at (0,0)
  _011: rectangle with size (3,2) with mask 
0 0 
0 . 
. 0 
 with color cyan at (6,2)
  _0111: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color yellow at (0,5)
  _01111: rectangle with size (1,3) with model Full with color pink at (5,5)
  + 6 delta pixels
diff: 
! 13 wrong pixels (generated / expected)

TRAIN a68b268e.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
0 0 0 . 
0 . 0 . 
. 0 . 0 
. . . 0 
 with color orange at (0,0)
  _011: rectangle with size (4,4) with mask 
0 . . . 
0 . . . 
0 0 . 0 
0 . 0 0 
 with color pink at (5,5)
  _0111: rectangle with size (3,4) with mask 
. 0 . . 
0 . 0 0 
0 . 0 0 
 with color yellow at (0,5)
  _01111: rectangle with size (1,3) with model Full with color cyan at (8,0)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color orange and layers
  _0: rectangle with size (1,3) with model Full with color cyan at (3,0)
  _01: rectangle with size (2,2) with model Odd Checkboard with color yellow at (1,2)
  _011: point with color pink at (0,3)
  _0111: point with color yellow at (2,0)
  _01111: point with color black at (1,1)
diff: 
   (98.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
0 0 0 . 
0 . 0 . 
. 0 . 0 
. . . 0 
 with color orange at (0,0)
  _011: rectangle with size (4,4) with mask 
0 . . . 
0 . . . 
0 0 . 0 
0 . 0 0 
 with color pink at (5,5)
  _0111: rectangle with size (3,4) with mask 
. 0 . . 
0 . 0 0 
0 . 0 0 
 with color yellow at (0,5)
  _01111: rectangle with size (1,3) with model Full with color cyan at (8,0)
  + 2 delta pixels
diff: 
! 16 wrong pixels (generated / expected)

TRAIN a68b268e.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
. . 0 0 
. . . 0 
0 0 0 0 
. 0 . . 
 with color orange at (0,0)
  _011: rectangle with size (4,4) with mask 
. 0 0 0 
. . 0 . 
0 . 0 . 
0 0 . . 
 with color pink at (5,5)
  _0111: rectangle with size (4,3) with mask 
0 0 . 
. 0 0 
. . 0 
0 0 . 
 with color yellow at (0,6)
  _01111: rectangle with size (1,2) with model Full with color cyan at (5,2)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color orange and layers
  _0: rectangle with size (2,2) with model Even Checkboard with color yellow at (0,1)
  _01: rectangle with size (2,2) with model Full with color black at (0,0)
  _011: point with color cyan at (3,0)
  _0111: point with color yellow at (3,2)
  _01111: point with color black at (3,3)
diff: 
   (100.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
. . 0 0 
. . . 0 
0 0 0 0 
. 0 . . 
 with color orange at (0,0)
  _011: rectangle with size (4,4) with mask 
. 0 0 0 
. . 0 . 
0 . 0 . 
0 0 . . 
 with color pink at (5,5)
  _0111: rectangle with size (4,3) with mask 
0 0 . 
. 0 0 
. . 0 
0 0 . 
 with color yellow at (0,6)
  _01111: rectangle with size (1,2) with model Full with color cyan at (5,2)
  + 2 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
. . 0 0 
. . . 0 
0 0 0 0 
. 0 . . 
 with color orange at (0,0)
  _011: rectangle with size (4,3) with mask 
0 0 . 
. 0 0 
. . 0 
0 0 . 
 with color yellow at (0,6)
  _0111: rectangle with size (4,4) with mask 
. 0 0 0 
. . 0 . 
0 . 0 . 
0 0 . . 
 with color pink at (5,5)
  _01111: rectangle with size (1,2) with model Full with color cyan at (5,2)
  + 2 delta pixels
diff: 
! 15 wrong pixels (generated / expected)

TRAIN a68b268e.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
0 0 . . 
0 . 0 . 
0 . . 0 
0 . 0 0 
 with color orange at (0,0)
  _011: rectangle with size (4,4) with mask 
0 0 . . 
0 . . . 
0 0 0 . 
0 . 0 0 
 with color yellow at (0,5)
  _0111: rectangle with size (4,3) with mask 
. 0 . 
. 0 . 
. 0 . 
0 . 0 
 with color cyan at (5,1)
  _01111: rectangle with size (3,4) with mask 
0 0 . . 
. 0 0 0 
. 0 0 . 
 with color pink at (6,5)
  + 1 delta pixels
diff: 
   (2.0 bits)
data: a background with size (4,4) and color orange and layers
  _0: rectangle with size (1,2) with model Full with color yellow at (2,1)
  _01: rectangle with size (1,1) with model Full with color cyan at (0,2)
  _011: point with color yellow at (0,3)
  _0111: point with color cyan at (3,1)
  _01111: point with color pink at (1,1)
  + 1 delta pixels
diff: 
   (129.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
0 0 . . 
0 . 0 . 
0 . . 0 
0 . 0 0 
 with color orange at (0,0)
  _011: rectangle with size (4,4) with mask 
0 0 . . 
0 . . . 
0 0 0 . 
0 . 0 0 
 with color yellow at (0,5)
  _0111: rectangle with size (3,4) with mask 
0 0 . . 
. 0 0 0 
. 0 0 . 
 with color pink at (6,5)
  _01111: rectangle with size (4,3) with mask 
. 0 . 
. 0 . 
. 0 . 
0 . 0 
 with color cyan at (5,1)
  + 1 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
0 0 . . 
0 . 0 . 
0 . . 0 
0 . 0 0 
 with color orange at (0,0)
  _011: rectangle with size (4,4) with mask 
0 0 . . 
0 . . . 
0 0 0 . 
0 . 0 0 
 with color yellow at (0,5)
  _0111: rectangle with size (4,3) with mask 
. 0 . 
. 0 . 
. 0 . 
0 . 0 
 with color cyan at (5,1)
  _01111: rectangle with size (3,4) with mask 
0 0 . . 
. 0 0 0 
. 0 0 . 
 with color pink at (6,5)
  + 1 delta pixels
diff: 
! 15 wrong pixels (generated / expected)

TRAIN a68b268e.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
. . . 0 
0 0 0 0 
0 . . . 
0 0 0 . 
 with color yellow at (0,5)
  _011: rectangle with size (4,3) with mask 
0 0 . 
0 . . 
0 . 0 
. 0 0 
 with color orange at (0,0)
  _0111: rectangle with size (4,4) with mask 
0 0 0 0 
. . 0 . 
. 0 . 0 
. . . 0 
 with color pink at (5,5)
  _01111: rectangle with size (1,4) with model Full with color cyan at (8,0)
  + 4 delta pixels
diff: 
   (2.0 bits)
data: a background with size (4,4) and color yellow and layers
  _0: rectangle with size (4,3) with mask 
0 0 . 
0 . . 
0 . 0 
. 0 0 
 with color orange at (0,0)
  _01: rectangle with size (1,1) with model Full with color cyan at (0,2)
  _011: point with color pink at (2,1)
  _0111: point with color pink at (2,3)
  _01111: point with color cyan at (3,3)
diff: 
   (105.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
. . . 0 
0 0 0 0 
0 . . . 
0 0 0 . 
 with color yellow at (0,5)
  _011: rectangle with size (4,4) with mask 
0 0 0 0 
. . 0 . 
. 0 . 0 
. . . 0 
 with color pink at (5,5)
  _0111: rectangle with size (4,3) with mask 
0 0 . 
0 . . 
0 . 0 
. 0 0 
 with color orange at (0,0)
  _01111: rectangle with size (1,4) with model Full with color cyan at (8,0)
  + 4 delta pixels
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
. . . 0 
0 0 0 0 
0 . . . 
0 0 0 . 
 with color yellow at (0,5)
  _011: rectangle with size (4,3) with mask 
0 0 . 
0 . . 
0 . 0 
. 0 0 
 with color orange at (0,0)
  _0111: rectangle with size (4,4) with mask 
0 0 0 0 
. . 0 . 
. 0 . 0 
. . . 0 
 with color pink at (5,5)
  _01111: rectangle with size (1,4) with model Full with color cyan at (8,0)
  + 4 delta pixels
diff: 
! 16 wrong pixels (generated / expected)

TRAIN a68b268e.json/5: 0 - (FAILURE)

## instance 6

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
0 . . 0 
. 0 0 0 
0 0 0 . 
0 0 0 . 
 with color orange at (0,0)
  _011: rectangle with size (4,4) with mask 
0 0 0 . 
0 0 . 0 
0 0 . 0 
. 0 . . 
 with color yellow at (0,5)
  _0111: rectangle with size (4,4) with mask 
0 0 . 0 
. 0 0 0 
. 0 . 0 
0 0 . 0 
 with color cyan at (5,0)
  _01111: rectangle with size (4,4) with mask 
0 0 0 0 
. . . 0 
. . 0 . 
. 0 . . 
 with color pink at (5,5)
diff: 
   (3.2 bits)
data: a background with size (4,4) and color yellow and layers
  _0: rectangle with size (2,3) with model Full with color orange at (2,0)
  _01: rectangle with size (1,3) with model Full with color orange at (1,1)
  _011: point with color orange at (0,0)
  _0111: point with color cyan at (3,3)
  _01111: point with color orange at (0,3)
diff: 
   (95.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
0 . . 0 
. 0 0 0 
0 0 0 . 
0 0 0 . 
 with color orange at (0,0)
  _011: rectangle with size (4,4) with mask 
0 0 . 0 
. 0 0 0 
. 0 . 0 
0 0 . 0 
 with color cyan at (5,0)
  _0111: rectangle with size (4,4) with mask 
0 0 0 . 
0 0 . 0 
0 0 . 0 
. 0 . . 
 with color yellow at (0,5)
  _01111: rectangle with size (4,4) with mask 
0 0 0 0 
. . . 0 
. . 0 . 
. 0 . . 
 with color pink at (5,5)
diff: 
! 16 wrong pixels (generated / expected)

TRAIN a68b268e.json/6: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
 with color blue at (0,0)
  _01: rectangle with size (4,4) with mask 
0 0 0 . 
. 0 0 . 
0 0 0 0 
0 . . . 
 with color orange at (0,0)
  _011: rectangle with size (4,4) with mask 
. 0 . 0 
0 . . 0 
0 0 0 0 
. 0 . . 
 with color pink at (5,5)
  _0111: rectangle with size (4,4) with mask 
. . 0 . 
0 0 . 0 
. 0 . 0 
0 . 0 . 
 with color yellow at (0,5)
  _01111: rectangle with size (4,4) with mask 
. . . 0 
0 . . 0 
0 . 0 . 
. 0 . 0 
 with color cyan at (5,0)
diff: 
! 16 wrong pixels (generated / expected)

TEST a68b268e.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.4 sec (59.4 sec/task)
bits-train-error = 6303.6 bits (6303.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-143] Checking task a699fb00.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 89555.4 = 89557.7
DL output with Mo: L = 2.3 + 89555.4 = 89557.7
DL input+output M: L = 4.6 + 179110.7 = 179115.4

# learning a model for train pairs
2.000	
1.119	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.299	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.270	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.254	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.241	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.229	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.221	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.214	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.206	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.198	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.194	OUT ADD ^.layer_01111 = ^.layer_0111
0.184	OUT ADD ^.layer_0110 = ^.layer_011
0.178	OUT SPE ^.size = ^.size
0.176	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.174	OUT SPE ^.layer_0111.shape.color = ^.layer_0111.shape.color
0.173	IN  SPE ^.layer_0.shape.color = blue
0.171	IN  SPE ^.layer_01.shape.color = blue
0.169	IN  SPE ^.layer_011.shape.color = blue
0.167	IN  SPE ^.layer_0111.shape.color = blue
0.166	OUT SPE ^.layer_0.shape.mask.size.i = 1
0.165	OUT SPE ^.layer_0111.pos.j = ^.layer_0111.pos.j / '2
0.163	OUT SPE ^.layer_01.shape.mask.size.i = 1
0.162	OUT SPE ^.layer_011.shape.mask.size.i = 1
0.161	OUT SPE ^.layer_0.pos.j = span(^.layer_0.pos.j, ^.layer_011.pos.j) - 3
0.160	OUT SPE ^.layer_0111.shape.mask.size.i = 1
0.158	OUT SPE ^.layer_011.pos.i = ^.layer_01.pos.i
0.078	
0.078	IN  GEN ^.layer_0111.shape.color = ?
0.078	IN  GEN ^.layer_011.shape.color = ?
0.078	IN  GEN ^.layer_01.shape.color = ?
0.078	IN  GEN ^.layer_0.shape.color = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (1,?) with model ? with color ^.layer_0.shape.color at (?,span(^.layer_0.pos.j, ^.layer_011.pos.j) - 3)
  _01: rectangle with size (1,?) with model ? with color ? at (?,?)
  _0110: ^.layer_011
  _011: rectangle with size (1,?) with model ? with color ? at (^.layer_01.pos.i,?)
  _0111: rectangle with size (1,?) with model ? with color ^.layer_0111.shape.color at (?,^.layer_0111.pos.j / '2)
  _01111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color blue at (?,?)
  _01: point with color blue at (?,?)
  _011: point with color blue at (?,?)
  _0111: point with color blue at (?,?)

DL input  with Mi: L = 99.8 + 7191.9 = 7291.7
DL output with Mo: L = 204.0 + 6685.4 = 6889.4
DL input+output M: L = 303.8 + 13877.3 = 14181.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (1,?) with model ? with color ^.layer_0.shape.color at (?,span(^.layer_0.pos.j, ^.layer_011.pos.j) - 3)
  _01: rectangle with size (1,?) with model ? with color ? at (?,?)
  _0110: ^.layer_011
  _011: rectangle with size (1,?) with model ? with color ? at (^.layer_01.pos.i,?)
  _0111: rectangle with size (1,?) with model ? with color ^.layer_0111.shape.color at (?,^.layer_0111.pos.j / '2)
  _01111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 86.6 + 31.7 = 118.3
DL output with Mo: L = 204.0 + 6685.4 = 6889.4
DL input+output M: L = 290.6 + 6717.1 = 7007.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (5,5) and color black and layers
  _0: point with color blue at (0,0)
  _01: point with color blue at (3,1)
  _011: point with color blue at (0,2)
  _0111: point with color blue at (3,3)
diff: 
   (3.2 bits)
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (1,1) with model Full with color blue at (0,0)
  _01: rectangle with size (1,1) with model Full with color red at (0,1)
  _0110: 
1 
 at (0,2)
  _011: rectangle with size (1,1) with model Full with color red at (3,2)
  _0111: rectangle with size (1,1) with model Full with color blue at (3,1)
  _01111: 
1 
 at (3,3)
diff: 
   (61.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color black and layers
  _0: point with color blue at (0,0)
  _01: point with color blue at (0,2)
  _011: point with color blue at (3,1)
  _0111: point with color blue at (3,3)
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,5) and color black and layers
  _0: point with color blue at (0,0)
  _01: point with color blue at (0,2)
  _011: point with color blue at (3,3)
  _0111: point with color blue at (3,1)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (5,5) and color black and layers
  _0: point with color blue at (0,0)
  _01: point with color blue at (3,1)
  _011: point with color blue at (0,2)
  _0111: point with color blue at (3,3)
diff: 
! 4 wrong pixels (generated / expected)

TRAIN a699fb00.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color blue at (1,1)
  _01: point with color blue at (1,3)
  _011: point with color blue at (1,5)
  _0111: point with color blue at (1,7)
  + 6 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,3) with model Full with color blue at (4,2)
  _01: rectangle with size (1,3) with model Full with color blue at (6,6)
  _0110: 
1 
 at (1,5)
  _011: rectangle with size (1,5) with model Full with color red at (1,2)
  _0111: rectangle with size (1,3) with model Full with color blue at (8,3)
  _01111: 
1 
 at (1,7)
  + 5 delta pixels
diff: 
   (283.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (1,1)
  _01: point with color blue at (1,3)
  _011: point with color blue at (1,5)
  _0111: point with color blue at (1,7)
  + 6 delta pixels
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (1,1)
  _01: point with color blue at (1,3)
  _011: point with color blue at (1,5)
  _0111: point with color blue at (4,2)
  + 6 delta pixels
diff: 
! 19 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (1,1)
  _01: point with color blue at (1,3)
  _011: point with color blue at (1,7)
  _0111: point with color blue at (1,5)
  + 6 delta pixels
diff: 
! 21 wrong pixels (generated / expected)

TRAIN a699fb00.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color blue at (1,6)
  _01: point with color blue at (1,8)
  _011: point with color blue at (2,1)
  _0111: point with color blue at (2,3)
  + 7 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,5) with model Full with color blue at (5,3)
  _01: rectangle with size (1,3) with model Full with color blue at (7,4)
  _0110: 
1 
 at (2,1)
  _011: rectangle with size (1,3) with model Full with color blue at (1,6)
  _0111: rectangle with size (1,3) with model Full with color blue at (9,1)
  _01111: 
1 
 at (2,3)
  + 6 delta pixels
diff: 
   (323.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (1,6)
  _01: point with color blue at (1,8)
  _011: point with color blue at (2,1)
  _0111: point with color blue at (2,3)
  + 7 delta pixels
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (1,6)
  _01: point with color blue at (1,8)
  _011: point with color blue at (2,1)
  _0111: point with color blue at (5,3)
  + 7 delta pixels
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (1,6)
  _01: point with color blue at (1,8)
  _011: point with color blue at (2,3)
  _0111: point with color blue at (2,1)
  + 7 delta pixels
diff: 
! 20 wrong pixels (generated / expected)

TRAIN a699fb00.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (0,1)
  _01: point with color blue at (0,3)
  _011: point with color blue at (2,2)
  _0111: point with color blue at (2,4)
  + 8 delta pixels
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (0,1)
  _01: point with color blue at (0,3)
  _011: point with color blue at (2,2)
  _0111: point with color blue at (2,6)
  + 8 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (0,1)
  _01: point with color blue at (0,3)
  _011: point with color blue at (2,4)
  _0111: point with color blue at (2,2)
  + 8 delta pixels
diff: 
! 17 wrong pixels (generated / expected)

TEST a699fb00.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 60.0 sec (60.0 sec/task)
bits-train-error = 6685.4 bits (6685.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-142] Checking task a740d043.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 49297.3 = 49299.6
DL output with Mo: L = 2.3 + 8257.8 = 8260.1
DL input+output M: L = 4.6 + 57555.1 = 57559.7

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = strip(^)
0.145	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.078	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.054	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.049	IN  SPE ^.color = blue
0.047	IN  SPE ^.layer_01.shape.mask.model = Full
0.003	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
strip(^)
WHERE (Mi)
a background with size (?,?) and color blue and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 77.4 + 2188.6 = 2266.0
DL output with Mo: L = 9.3 + 0.0 = 9.3
DL input+output M: L = 86.7 + 2188.6 = 2275.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
strip(^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 9.3 + 0.0 = 9.3
DL input+output M: L = 11.6 + 0.0 = 11.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
1 1 1 1 1 1 1 
1 2 2 1 1 1 1 
1 2 2 3 1 1 1 
1 1 1 2 1 1 1 
1 1 1 1 1 1 1 

diff: 
   (0.0 bits)
data: 
2 2 0 
2 2 3 
0 0 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 1 1 1 1 1 
1 2 2 1 1 1 1 
1 2 2 3 1 1 1 
1 1 1 2 1 1 1 
1 1 1 1 1 1 1 

diff: 
correct output grid

TRAIN a740d043.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
1 1 1 1 1 1 1 
1 1 3 1 2 1 1 
1 1 3 1 2 1 1 
1 1 1 1 1 1 1 
1 1 1 1 1 1 1 
1 1 1 1 1 1 1 
1 1 1 1 1 1 1 

diff: 
   (0.0 bits)
data: 
3 0 2 
3 0 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 1 1 1 1 1 
1 1 3 1 2 1 1 
1 1 3 1 2 1 1 
1 1 1 1 1 1 1 
1 1 1 1 1 1 1 
1 1 1 1 1 1 1 
1 1 1 1 1 1 1 

diff: 
correct output grid

TRAIN a740d043.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
1 1 1 1 1 1 
1 1 1 1 1 1 
1 5#5#1 1 1 
1 5#5#1 1 1 
1 6 6 1 1 1 
1 1 1 1 1 1 
1 1 1 1 1 1 

diff: 
   (0.0 bits)
data: 
5#5#
5#5#
6 6 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 1 1 1 1 
1 1 1 1 1 1 
1 5#5#1 1 1 
1 5#5#1 1 1 
1 6 6 1 1 1 
1 1 1 1 1 1 
1 1 1 1 1 1 

diff: 
correct output grid

TRAIN a740d043.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 1 1 1 1 
1 1 1 1 1 1 
1 1 1 2 1 1 
1 1 2 3 1 1 
1 1 1 1 1 1 
1 1 1 1 1 1 

diff: 
correct output grid

TEST a740d043.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.0 sec (1.0 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-141] Checking task a78176bb.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.160	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.332	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.252	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.180	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.134	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.091	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.072	OUT SPE ^.layer_0 = ^.layer_0
0.067	OUT SPE ^.size = ^.size
0.066	IN  SPE ^.layer_01.shape.color = grey
0.065	OUT SPE ^.layer_01.shape.color = ^.layer_0.shape.color
0.063	OUT SPE ^.layer_01.pos.i = ^.layer_0.pos.j / '3
0.062	OUT SPE ^.layer_01.pos.j = '0 + ^.layer_01.pos.j - ^.layer_0.pos.j
0.062	IN  SPE ^.color = black
0.061	OUT SPE ^.color = black
0.028	
0.028	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (^.layer_0.pos.j / '3,'0 + ^.layer_01.pos.j - ^.layer_0.pos.j)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color grey at (?,?)

DL input  with Mi: L = 73.7 + 3922.1 = 3995.7
DL output with Mo: L = 110.3 + 3196.4 = 3306.8
DL input+output M: L = 184.0 + 7118.5 = 7302.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (^.layer_0.pos.j / '3,'0 + ^.layer_01.pos.j - ^.layer_0.pos.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color grey at (?,?)

DL input  with Mi: L = 73.5 + 0.0 = 73.5
DL output with Mo: L = 110.3 + 3196.4 = 3306.8
DL input+output M: L = 183.8 + 3196.4 = 3380.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
0 . . . . . . . . . 
. 0 . . . . . . . . 
. . 0 . . . . . . . 
. . . 0 . . . . . . 
. . . . 0 . . . . . 
. . . . . 0 . . . . 
. . . . . . 0 . . . 
. . . . . . . 0 . . 
. . . . . . . . 0 . 
. . . . . . . . . 0 
 with color orange at (0,0)
  _01: rectangle with size (2,2) with model Full with color grey at (3,4)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
7#. . . . . . . . . 
. 7#. . . . . . . . 
. . 7#. . . . . . . 
. . . 7#. . . . . . 
. . . . 7#. . . . . 
. . . . . 7#. . . . 
. . . . . . 7#. . . 
. . . . . . . 7#. . 
. . . . . . . . 7#. 
. . . . . . . . . 7#
 at (0,0)
  _01: rectangle with size (6,6) with mask 
0 . . . . . 
. 0 . . . . 
. . 0 . . . 
. . . 0 . . 
. . . . 0 . 
. . . . . 0 
 with color orange at (0,4)
diff: 
   (43.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
0 . . . . . . . . . 
. 0 . . . . . . . . 
. . 0 . . . . . . . 
. . . 0 . . . . . . 
. . . . 0 . . . . . 
. . . . . 0 . . . . 
. . . . . . 0 . . . 
. . . . . . . 0 . . 
. . . . . . . . 0 . 
. . . . . . . . . 0 
 with color orange at (0,0)
  _01: rectangle with size (2,2) with model Full with color grey at (3,4)
diff: 
! 6 wrong pixels (generated / expected)

TRAIN a78176bb.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color brown at (0,5)
  _01: rectangle with size (4,4) with mask 
0 . . . 
0 0 . . 
0 0 0 . 
0 0 0 0 
 with color grey at (1,5)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
9#. . . . 
. 9#. . . 
. . 9#. . 
. . . 9#. 
. . . . 9#
 at (0,5)
  _01: rectangle with size (9,9) with mask 
0 . . . . . . . . 
. 0 . . . . . . . 
. . 0 . . . . . . 
. . . 0 . . . . . 
. . . . 0 . . . . 
. . . . . 0 . . . 
. . . . . . 0 . . 
. . . . . . . 0 . 
. . . . . . . . 0 
 with color brown at (1,0)
diff: 
   (63.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color brown at (0,5)
  _01: rectangle with size (4,4) with mask 
0 . . . 
0 0 . . 
0 0 0 . 
0 0 0 0 
 with color grey at (1,5)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color brown at (0,5)
  _01: rectangle with size (4,4) with mask 
0 . . . 
0 0 . . 
0 0 0 . 
0 0 0 0 
 with color grey at (1,5)
  + 4 delta pixels
diff: 
! 13 wrong pixels (generated / expected)

TRAIN a78176bb.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (9,9) with mask 
0 . . . . . . . . 
. 0 . . . . . . . 
. . 0 . . . . . . 
. . . 0 . . . . . 
. . . . 0 . . . . 
. . . . . 0 . . . 
. . . . . . 0 . . 
. . . . . . . 0 . 
. . . . . . . . 0 
 with color red at (1,0)
  _01: rectangle with size (5,3) with mask 
0 0 . 
. 0 . 
0 . . 
0 0 . 
0 0 0 
 with color grey at (3,3)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
2 . . . . . . . . 
. 2 . . . . . . . 
. . 2 . . . . . . 
. . . 2 . . . . . 
. . . . 2 . . . . 
. . . . . 2 . . . 
. . . . . . 2 . . 
. . . . . . . 2 . 
. . . . . . . . 2 
 at (1,0)
  _01: rectangle with size (7,7) with mask 
0 . . . . . . 
. 0 . . . . . 
. . 0 . . . . 
. . . 0 . . . 
. . . . 0 . . 
. . . . . 0 . 
. . . . . . 0 
 with color red at (0,3)
  + 4 delta pixels
diff: 
   (212.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (9,9) with mask 
0 . . . . . . . . 
. 0 . . . . . . . 
. . 0 . . . . . . 
. . . 0 . . . . . 
. . . . 0 . . . . 
. . . . . 0 . . . 
. . . . . . 0 . . 
. . . . . . . 0 . 
. . . . . . . . 0 
 with color red at (1,0)
  _01: rectangle with size (5,3) with mask 
0 0 . 
. 0 . 
0 . . 
0 0 . 
0 0 0 
 with color grey at (3,3)
diff: 
! 11 wrong pixels (generated / expected)

TRAIN a78176bb.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
undefined expression: ScaleDown: not an integer

TEST a78176bb.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 10.5 sec (10.5 sec/task)
bits-train-error = 3196.4 bits (3196.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-140] Checking task a79310a0.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 22921.2 = 22923.5
DL output with Mo: L = 2.3 + 22921.2 = 22923.5
DL input+output M: L = 4.6 + 45842.4 = 45847.0

# learning a model for train pairs
2.000	
1.158	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.317	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.217	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.118	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.095	OUT SPE ^.layer_0.shape = coloring(^.layer_0.shape, red)
0.075	OUT SPE ^.size = ^.size
0.064	OUT SPE ^.layer_0.pos = ^.layer_0.pos + (1, 0)
0.057	IN  SPE ^.layer_0.shape.color = cyan
0.053	IN  SPE ^.layer_0.shape.mask.model = Full
0.050	IN  SPE ^.color = black
0.047	OUT SPE ^.color = black
0.004	
0.004	IN  GEN ^.layer_0.shape.color = ?
0.004	IN  GEN ^.layer_0.shape.mask.model = ?
0.004	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0.shape, red) at ^.layer_0.pos + (1, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color cyan at (?,?)

DL input  with Mi: L = 45.9 + 983.4 = 1029.3
DL output with Mo: L = 42.3 + 0.0 = 42.3
DL input+output M: L = 88.3 + 983.4 = 1071.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0.shape, red) at ^.layer_0.pos + (1, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 42.3 + 0.0 = 42.3
DL input+output M: L = 84.3 + 0.0 = 84.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,2) with model Full with color cyan at (0,0)
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: 
2 2 
2 2 
 at (1,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,2) with model Full with color cyan at (0,0)
diff: 
correct output grid

TRAIN a79310a0.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (0,1)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
2 
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (0,1)
diff: 
correct output grid

TRAIN a79310a0.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (5,5) and color black and layers
  _0: rectangle with size (1,3) with model Full with color cyan at (1,1)
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: 
2 2 2 
 at (2,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (1,3) with model Full with color cyan at (1,1)
diff: 
correct output grid

TRAIN a79310a0.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color cyan at (0,1)
diff: 
correct output grid

TEST a79310a0.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.7 sec (1.7 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-139] Checking task a85d4709.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 14046.4 = 14048.7
DL output with Mo: L = 2.3 + 14046.4 = 14048.7
DL input+output M: L = 4.6 + 28092.8 = 28097.5

# learning a model for train pairs
2.000	
1.364	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.745	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.518	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.354	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.317	OUT SPE ^.size = ^.size
0.299	OUT SPE ^.layer_0.shape.mask.size.j = 3
0.283	IN  SPE ^.layer_0.shape.color = grey
0.272	OUT SPE ^.layer_0.pos.j = '0
0.264	OUT SPE ^.layer_0.shape.mask.model = Full
0.257	IN  SPE ^.color = black
0.146	
0.143	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (?,3) with model Full with color ? at (?,'0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)

DL input  with Mi: L = 45.4 + 1559.6 = 1605.0
DL output with Mo: L = 48.5 + 1961.0 = 2009.6
DL input+output M: L = 94.0 + 3520.6 = 3614.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (?,3) with model Full with color ? at (?,'0)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 48.5 + 1961.0 = 2009.6
DL input+output M: L = 50.9 + 1961.0 = 2011.9

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 5#
0 5#0 
5#0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color red and layers
  _0: rectangle with size (1,3) with model Full with color green at (0,0)
  + 3 delta pixels
diff: 
   (134.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 5#
0 5#0 
5#0 0 

diff: 
! 9 wrong pixels (generated / expected)

TRAIN a85d4709.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
0 0 5#
0 0 5#
0 0 5#

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with model Full with color green at (0,0)
diff: 
   (18.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 5#
0 0 5#
0 0 5#

diff: 
! 9 wrong pixels (generated / expected)

TRAIN a85d4709.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
5#0 0 
0 5#0 
5#0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color red and layers
  _0: rectangle with size (1,3) with model Full with color yellow at (1,0)
diff: 
   (21.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#0 0 
0 5#0 
5#0 0 

diff: 
! 9 wrong pixels (generated / expected)

TRAIN a85d4709.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: 
0 5#0 
0 0 5#
0 5#0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color yellow and layers
  _0: rectangle with size (1,3) with model Full with color green at (1,0)
diff: 
   (21.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 5#0 
0 0 5#
0 5#0 

diff: 
! 9 wrong pixels (generated / expected)

TRAIN a85d4709.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 5#
5#0 0 
0 5#0 

diff: 
! 9 wrong pixels (generated / expected)

TEST a85d4709.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 4.1 sec (4.1 sec/task)
bits-train-error = 1961.0 bits (1961.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-138] Checking task a87f7484.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 56198.3 = 56200.6
DL output with Mo: L = 2.3 + 14046.4 = 14048.7
DL input+output M: L = 4.6 + 70244.7 = 70249.3

# learning a model for train pairs
2.000	
1.330	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.872	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.685	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.541	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.446	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.351	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.277	OUT SPE ^.layer_0.shape = ^.layer_0.shape
0.240	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.218	OUT SPE ^.layer_0.pos = '(0, 0)
0.211	OUT SPE ^.color = black
0.210	IN  SPE ^.color = black
0.160	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.153	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.005	
0.005	IN  DEL ^.layer_01111
0.004	IN  DEL ^.layer_0111
0.004	IN  DEL ^.layer_011
0.003	IN  DEL ^.layer_01
0.003	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: ^.layer_0.shape at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 153.5 + 8286.8 = 8440.3
DL output with Mo: L = 37.8 + 0.0 = 37.8
DL input+output M: L = 191.3 + 8286.8 = 8478.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: ^.layer_0.shape at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 37.8 + 0.0 = 37.8
DL input+output M: L = 79.8 + 0.0 = 79.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,3) and color black and layers
  _0: rectangle with size (3,3) with model Border with color cyan at (6,0)
  + 12 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
8 8 8 
8 . 8 
8 8 8 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,3) and color black and layers
  _0: rectangle with size (3,3) with model Border with color cyan at (6,0)
  + 12 delta pixels
diff: 
correct output grid

TRAIN a87f7484.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (3,12) and color black and layers
  _0: rectangle with size (3,3) with model Even Checkboard with color orange at (0,6)
  + 12 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
7#. 7#
. 7#. 
7#. 7#
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,12) and color black and layers
  _0: rectangle with size (3,3) with model Even Checkboard with color orange at (0,6)
  + 12 delta pixels
diff: 
correct output grid

TRAIN a87f7484.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (3,15) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 0 
0 . 0 
 with color yellow at (0,3)
  + 16 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
4 . 4 
4 4 4 
4 . 4 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,15) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 0 
0 . 0 
 with color yellow at (0,3)
  + 16 delta pixels
diff: 
correct output grid

TRAIN a87f7484.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: a background with size (12,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
0 0 . 
0 . 0 
 with color orange at (0,0)
  + 12 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
. 7#7#
7#7#. 
7#. 7#
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
0 0 . 
0 . 0 
 with color orange at (0,0)
  + 12 delta pixels
diff: 
correct output grid

TRAIN a87f7484.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 . 
0 . 0 
 with color pink at (6,0)
  + 16 delta pixels
diff: 
correct output grid

TEST a87f7484.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 4.3 sec (4.3 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-137] Checking task a8c38be5.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 171392.7 = 171395.0
DL output with Mo: L = 2.3 + 64315.6 = 64317.9
DL input+output M: L = 4.6 + 235708.3 = 235712.9

# learning a model for train pairs
2.000	
1.353	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.742	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.700	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.663	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.625	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.588	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.550	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.519	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.492	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.466	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.151	
0.151	IN  GEN ^ = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 53954.6 = 54024.8
DL output with Mo: L = 180.9 + 9511.2 = 9692.1
DL input+output M: L = 251.1 + 63465.8 = 63716.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 180.9 + 9511.2 = 9692.1
DL input+output M: L = 183.2 + 9511.2 = 9694.4

# train input/output grids

## instance 1

> Input and output best reading:

data: 
5#5#5#0 0 0 0 0 0 0 0 0 0 0 
8 5#5#0 0 0 0 0 2 2 2 0 0 0 
8 8 5#0 0 0 0 0 5#2 5#0 0 0 
0 0 2 5#5#0 0 0 5#5#5#0 0 0 
0 0 2 2 5#0 0 0 0 0 0 0 0 0 
0 0 2 5#5#0 5#5#5#0 0 0 0 0 
0 0 0 0 0 0 5#5#5#0 5#5#5#0 
0 5#1 1 0 0 5#5#5#0 5#4 5#0 
0 5#5#1 0 0 0 0 0 0 4 4 4 0 
0 5#5#5#0 0 5#5#3 0 0 0 0 0 
0 0 0 0 0 0 5#3 3 0 0 0 0 0 
5#5#5#0 0 0 5#5#3 0 6 6 5#0 
5#5#9#0 0 0 0 0 0 0 6 5#5#0 
5#9#9#0 0 0 0 0 0 0 5#5#5#0 

diff: 
   (0.0 bits)
data: a background with size (9,9) and color grey and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color red at (0,3)
  _01: rectangle with size (3,2) with mask 
0 . 
0 0 
0 . 
 with color red at (3,0)
  _011: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color green at (3,7)
  _0111: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color yellow at (7,3)
  _01111: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color pink at (0,0)
  _011111: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color blue at (0,7)
  + 6 delta pixels
diff: 
   (475.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#5#5#0 0 0 0 0 0 0 0 0 0 0 
8 5#5#0 0 0 0 0 2 2 2 0 0 0 
8 8 5#0 0 0 0 0 5#2 5#0 0 0 
0 0 2 5#5#0 0 0 5#5#5#0 0 0 
0 0 2 2 5#0 0 0 0 0 0 0 0 0 
0 0 2 5#5#0 5#5#5#0 0 0 0 0 
0 0 0 0 0 0 5#5#5#0 5#5#5#0 
0 5#1 1 0 0 5#5#5#0 5#4 5#0 
0 5#5#1 0 0 0 0 0 0 4 4 4 0 
0 5#5#5#0 0 5#5#3 0 0 0 0 0 
0 0 0 0 0 0 5#3 3 0 0 0 0 0 
5#5#5#0 0 0 5#5#3 0 6 6 5#0 
5#5#9#0 0 0 0 0 0 0 6 5#5#0 
5#9#9#0 0 0 0 0 0 0 5#5#5#0 

diff: 
! size mismatch, 10x10 instead of 9x9

TRAIN a8c38be5.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 5#5#4 
0 5#5#5#0 0 0 0 0 0 0 5#4 4 
0 3 5#5#0 5#8 8 0 0 0 5#5#4 
0 3 3 5#0 5#5#8 0 0 0 0 0 0 
0 0 0 0 0 5#5#5#0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 5#5#5#0 
0 0 0 0 0 0 0 0 0 0 5#5#9#0 
0 0 0 0 0 0 0 0 0 0 5#9#9#0 
0 1 1 1 0 0 5#5#5#0 0 0 0 0 
0 5#1 5#0 0 5#5#5#0 6 5#5#0 
0 5#5#5#0 0 5#5#5#0 6 6 5#0 
0 0 0 0 0 0 0 0 0 0 6 5#5#0 
0 0 0 0 7#7#5#0 0 0 0 0 0 0 
0 0 0 0 7#5#5#0 0 5#5#5#0 0 
0 0 0 0 5#5#5#0 0 5#2 5#0 0 
0 0 0 0 0 0 0 0 0 2 2 2 0 0 

diff: 
   (0.0 bits)
data: a background with size (9,9) and color grey and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color blue at (0,3)
  _01: rectangle with size (3,2) with mask 
0 . 
0 0 
0 . 
 with color pink at (3,0)
  _011: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color yellow at (3,7)
  _0111: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color red at (7,3)
  _01111: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color orange at (0,0)
  _011111: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color cyan at (0,7)
  + 6 delta pixels
diff: 
   (475.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 5#5#4 
0 5#5#5#0 0 0 0 0 0 0 5#4 4 
0 3 5#5#0 5#8 8 0 0 0 5#5#4 
0 3 3 5#0 5#5#8 0 0 0 0 0 0 
0 0 0 0 0 5#5#5#0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 5#5#5#0 
0 0 0 0 0 0 0 0 0 0 5#5#9#0 
0 0 0 0 0 0 0 0 0 0 5#9#9#0 
0 1 1 1 0 0 5#5#5#0 0 0 0 0 
0 5#1 5#0 0 5#5#5#0 6 5#5#0 
0 5#5#5#0 0 5#5#5#0 6 6 5#0 
0 0 0 0 0 0 0 0 0 0 6 5#5#0 
0 0 0 0 7#7#5#0 0 0 0 0 0 0 
0 0 0 0 7#5#5#0 0 5#5#5#0 0 
0 0 0 0 5#5#5#0 0 5#2 5#0 0 
0 0 0 0 0 0 0 0 0 2 2 2 0 0 

diff: 
! size mismatch, 10x10 instead of 9x9

TRAIN a8c38be5.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 5#5#5#0 0 
0 1 5#5#0 0 0 0 0 0 6 5#5#0 0 
0 1 1 5#0 2 2 2 0 0 6 6 5#0 0 
0 1 5#5#0 5#2 5#0 0 0 0 0 0 0 
0 0 0 0 0 5#5#5#0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 5#5#5#0 0 
0 0 5#5#5#0 0 0 0 0 5#5#5#0 0 
0 0 5#8 5#0 5#5#1 0 5#5#5#0 0 
0 0 8 8 8 0 5#1 1 0 0 0 0 0 0 
0 0 0 0 0 0 5#5#1 0 0 0 0 0 0 
0 5#4 4 0 0 0 0 0 0 0 3 3 5#0 
0 5#5#4 0 0 0 0 0 0 0 3 5#5#0 
0 5#5#5#0 0 5#5#5#0 0 5#5#5#0 
0 0 0 0 0 0 5#5#7#0 0 0 0 0 0 
0 0 0 0 0 0 5#7#7#0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
! size mismatch, 10x10 instead of 9x9

TEST a8c38be5.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.8 sec (59.8 sec/task)
bits-train-error = 9511.2 bits (9511.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-136] Checking task a8d7556c.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 402050.2 = 402052.5
DL output with Mo: L = 2.3 + 402050.2 = 402052.5
DL input+output M: L = 4.6 + 804100.4 = 804105.1

# learning a model for train pairs
2.000	
1.393	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.786	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.432	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.116	OUT ADD ^.layer_0 = ^.layer_0
0.098	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.086	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.076	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.069	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.067	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.065	OUT SPE ^.size = ^.size
0.064	OUT SPE ^.layer_0111.shape = scaleTo(coloring(^.layer_01.shape, red), '(2, 2))
0.063	IN  SPE ^.layer_0.shape.color = grey
0.063	IN  SPE ^.layer_01.shape.color = grey
0.063	OUT SPE ^.layer_01.shape.color = red
0.062	OUT SPE ^.layer_011.shape.color = red
0.062	OUT SPE ^.layer_01.shape.mask.size.j = ^.layer_01.shape.mask.size.j + 1
0.061	OUT SPE ^.layer_01111.pos.j = right(^.layer_01) * '2
0.061	OUT SPE ^.layer_01.shape.mask = scaleTo(^.layer_01.shape.mask, ^.layer_01.shape.mask.size + (1, 1))
0.060	OUT SPE ^.layer_011.shape.mask.size.j = 2
0.060	IN  SPE ^.layer_01.shape.mask.model = Full
0.060	OUT SPE ^.layer_011.shape.mask.model = Full
0.060	OUT SPE ^.layer_01111.shape.mask.model = Full
0.060	IN  SPE ^.color = black
0.059	OUT SPE ^.color = black
0.023	
0.023	IN  GEN ^.layer_01.shape.color = ?
0.023	IN  GEN ^.layer_0.shape.color = ?
0.023	IN  GEN ^.layer_01.shape.mask.model = ?
0.023	IN  GEN ^.color = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: scaleTo(^.layer_01.shape.mask, ^.layer_01.shape.mask.size + (1, 1)) with color red at (?,?)
  _011: rectangle with size (?,2) with model Full with color red at (?,?)
  _0111: scaleTo(coloring(^.layer_01.shape, red), '(2, 2)) at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,right(^.layer_01) * '2)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)
  _01: rectangle with size (?,?) with model Full with color grey at (?,?)

DL input  with Mi: L = 77.5 + 14474.3 = 14551.8
DL output with Mo: L = 201.2 + 9151.4 = 9352.6
DL input+output M: L = 278.6 + 23625.7 = 23904.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: scaleTo(^.layer_01.shape.mask, ^.layer_01.shape.mask.size + (1, 1)) with color red at (?,?)
  _011: rectangle with size (?,2) with model Full with color red at (?,?)
  _0111: scaleTo(coloring(^.layer_01.shape, red), '(2, 2)) at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,right(^.layer_01) * '2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 201.2 + 9151.4 = 9352.6
DL input+output M: L = 271.4 + 9151.4 = 9422.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (18,18) and color black and layers
  _0: rectangle with size (18,18) with mask 
0 0 0 . 0 . . 0 0 0 0 0 0 0 . 0 0 0 
0 0 . . . 0 . 0 . 0 0 . . 0 . 0 . 0 
. 0 0 . 0 0 . . 0 0 . 0 0 0 0 0 . 0 
0 0 . 0 0 0 0 0 0 . 0 0 0 0 0 . 0 0 
0 . 0 0 0 0 0 0 0 0 . 0 0 0 . 0 . 0 
. 0 0 0 0 . . 0 . . 0 . 0 0 0 0 0 . 
. . 0 0 0 . . 0 . 0 . . . 0 0 0 0 0 
. . 0 0 . . 0 0 0 0 0 0 0 0 0 . . 0 
. . 0 . 0 . . . 0 0 0 0 0 0 0 . . 0 
. . 0 0 . . 0 0 0 0 0 0 0 0 0 0 . 0 
0 0 . 0 0 0 . . 0 . 0 . . 0 0 0 . 0 
0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 0 0 0 
0 0 0 0 . . 0 0 0 0 . 0 0 . . 0 . . 
. 0 . . . 0 . 0 0 . . 0 0 0 . . . . 
. . 0 0 0 0 0 . 0 . 0 . 0 . 0 0 . . 
0 . 0 . . . 0 0 0 0 0 0 0 . . 0 . . 
0 . 0 0 . . . 0 0 0 . . . . . 0 . . 
0 0 . 0 . . 0 . . 0 0 . . . 0 . 0 0 
 with color grey at (0,0)
  _01: rectangle with size (1,1) with model Full with color grey at (8,0)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (18,18) and color black and layers
  _0: 
5#5#5#. 5#. . 5#5#5#5#5#5#5#. 5#5#5#
5#5#. . . 5#. 5#. 5#5#. . 5#. 5#. 5#
. 5#5#. 5#5#. . 5#5#. 5#5#5#5#5#. 5#
5#5#. 5#5#5#5#5#5#. 5#5#5#5#5#. 5#5#
5#. 5#5#5#5#5#5#5#5#. 5#5#5#. 5#. 5#
. 5#5#5#5#. . 5#. . 5#. 5#5#5#5#5#. 
. . 5#5#5#. . 5#. 5#. . . 5#5#5#5#5#
. . 5#5#. . 5#5#5#5#5#5#5#5#5#. . 5#
. . 5#. 5#. . . 5#5#5#5#5#5#5#. . 5#
. . 5#5#. . 5#5#5#5#5#5#5#5#5#5#. 5#
5#5#. 5#5#5#. . 5#. 5#. . 5#5#5#. 5#
5#5#5#5#5#5#5#5#5#5#5#5#. 5#5#5#5#5#
5#5#5#5#. . 5#5#5#5#. 5#5#. . 5#. . 
. 5#. . . 5#. 5#5#. . 5#5#5#. . . . 
. . 5#5#5#5#5#. 5#. 5#. 5#. 5#5#. . 
5#. 5#. . . 5#5#5#5#5#5#5#. . 5#. . 
5#. 5#5#. . . 5#5#5#. . . . . 5#. . 
5#5#. 5#. . 5#. . 5#5#. . . 5#. 5#5#
 at (0,0)
  _01: 
0 0 
0 0 
 with color red at (5,5)
  _011: rectangle with size (3,2) with model Full with color red at (15,4)
  _0111: 
2 2 
2 2 
 at (7,15)
  _01111: rectangle with size (2,2) with model Full with color red at (6,0)
  + 8 delta pixels
diff: 
   (404.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,18) and color black and layers
  _0: rectangle with size (18,18) with mask 
0 0 0 . 0 . . 0 0 0 0 0 0 0 . 0 0 0 
0 0 . . . 0 . 0 . 0 0 . . 0 . 0 . 0 
. 0 0 . 0 0 . . 0 0 . 0 0 0 0 0 . 0 
0 0 . 0 0 0 0 0 0 . 0 0 0 0 0 . 0 0 
0 . 0 0 0 0 0 0 0 0 . 0 0 0 . 0 . 0 
. 0 0 0 0 . . 0 . . 0 . 0 0 0 0 0 . 
. . 0 0 0 . . 0 . 0 . . . 0 0 0 0 0 
. . 0 0 . . 0 0 0 0 0 0 0 0 0 . . 0 
. . 0 . 0 . . . 0 0 0 0 0 0 0 . . 0 
. . 0 0 . . 0 0 0 0 0 0 0 0 0 0 . 0 
0 0 . 0 0 0 . . 0 . 0 . . 0 0 0 . 0 
0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 0 0 0 
0 0 0 0 . . 0 0 0 0 . 0 0 . . 0 . . 
. 0 . . . 0 . 0 0 . . 0 0 0 . . . . 
. . 0 0 0 0 0 . 0 . 0 . 0 . 0 0 . . 
0 . 0 . . . 0 0 0 0 0 0 0 . . 0 . . 
0 . 0 0 . . . 0 0 0 . . . . . 0 . . 
0 0 . 0 . . 0 . . 0 0 . . . 0 . 0 0 
 with color grey at (0,0)
  _01: rectangle with size (1,1) with model Full with color grey at (8,0)
  + 3 delta pixels
diff: 
! 26 wrong pixels (generated / expected)

TRAIN a8d7556c.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (18,18) and color black and layers
  _0: rectangle with size (18,18) with mask 
0 0 0 0 . 0 . 0 . 0 0 0 . . 0 . 0 0 
0 0 0 0 . . 0 0 . 0 . . 0 . . 0 0 . 
0 0 0 0 0 0 . 0 0 0 0 . . . . 0 0 . 
0 . 0 0 0 0 . . . . 0 0 0 0 0 0 . . 
. . 0 . 0 0 . . . 0 0 . . . 0 0 0 . 
0 . . . 0 . 0 0 0 0 . . . 0 . . . . 
. 0 . 0 0 0 . . . 0 0 . . 0 . 0 0 0 
0 . . 0 0 . 0 0 . 0 . . 0 . 0 . 0 . 
0 0 0 0 . 0 0 0 . 0 0 . 0 . 0 . 0 . 
0 . 0 0 0 0 . 0 . 0 . 0 0 0 . 0 0 . 
0 . 0 0 0 . 0 . 0 . . 0 . . 0 0 0 0 
. . . . 0 . 0 . . . 0 . 0 0 0 . . . 
0 . 0 . . 0 . 0 0 . . 0 . . . 0 0 0 
0 0 0 . 0 . . 0 0 0 . 0 0 0 . 0 0 . 
. . 0 0 0 0 0 . 0 0 0 0 . . . . . 0 
. . 0 0 0 0 . . 0 0 . 0 . 0 0 . 0 . 
. . . . . . . . 0 0 0 . . . . 0 . . 
. . . . . . . 0 . 0 0 0 . 0 0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (1,2) with model Full with color grey at (17,0)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (18,18) and color black and layers
  _0: 
5#5#5#5#. 5#. 5#. 5#5#5#. . 5#. 5#5#
5#5#5#5#. . 5#5#. 5#. . 5#. . 5#5#. 
5#5#5#5#5#5#. 5#5#5#5#. . . . 5#5#. 
5#. 5#5#5#5#. . . . 5#5#5#5#5#5#. . 
. . 5#. 5#5#. . . 5#5#. . . 5#5#5#. 
5#. . . 5#. 5#5#5#5#. . . 5#. . . . 
. 5#. 5#5#5#. . . 5#5#. . 5#. 5#5#5#
5#. . 5#5#. 5#5#. 5#. . 5#. 5#. 5#. 
5#5#5#5#. 5#5#5#. 5#5#. 5#. 5#. 5#. 
5#. 5#5#5#5#. 5#. 5#. 5#5#5#. 5#5#. 
5#. 5#5#5#. 5#. 5#. . 5#. . 5#5#5#5#
. . . . 5#. 5#. . . 5#. 5#5#5#. . . 
5#. 5#. . 5#. 5#5#. . 5#. . . 5#5#5#
5#5#5#. 5#. . 5#5#5#. 5#5#5#. 5#5#. 
. . 5#5#5#5#5#. 5#5#5#5#. . . . . 5#
. . 5#5#5#5#. . 5#5#. 5#. 5#5#. 5#. 
. . . . . . . . 5#5#5#. . . . 5#. . 
. . . . . . . 5#. 5#5#5#. 5#5#5#5#5#
 at (0,0)
  _01: 
0 0 0 
0 0 0 
 with color red at (3,6)
  _011: rectangle with size (3,2) with model Full with color red at (4,11)
  _0111: 
2 2 
2 2 
 at (1,13)
  _01111: rectangle with size (2,2) with model Full with color red at (16,2)
  + 9 delta pixels
diff: 
   (445.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,18) and color black and layers
  _0: rectangle with size (18,18) with mask 
0 0 0 0 . 0 . 0 . 0 0 0 . . 0 . 0 0 
0 0 0 0 . . 0 0 . 0 . . 0 . . 0 0 . 
0 0 0 0 0 0 . 0 0 0 0 . . . . 0 0 . 
0 . 0 0 0 0 . . . . 0 0 0 0 0 0 . . 
. . 0 . 0 0 . . . 0 0 . . . 0 0 0 . 
0 . . . 0 . 0 0 0 0 . . . 0 . . . . 
. 0 . 0 0 0 . . . 0 0 . . 0 . 0 0 0 
0 . . 0 0 . 0 0 . 0 . . 0 . 0 . 0 . 
0 0 0 0 . 0 0 0 . 0 0 . 0 . 0 . 0 . 
0 . 0 0 0 0 . 0 . 0 . 0 0 0 . 0 0 . 
0 . 0 0 0 . 0 . 0 . . 0 . . 0 0 0 0 
. . . . 0 . 0 . . . 0 . 0 0 0 . . . 
0 . 0 . . 0 . 0 0 . . 0 . . . 0 0 0 
0 0 0 . 0 . . 0 0 0 . 0 0 0 . 0 0 . 
. . 0 0 0 0 0 . 0 0 0 0 . . . . . 0 
. . 0 0 0 0 . . 0 0 . 0 . 0 0 . 0 . 
. . . . . . . . 0 0 0 . . . . 0 . . 
. . . . . . . 0 . 0 0 0 . 0 0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (1,2) with model Full with color grey at (17,0)
  + 3 delta pixels
diff: 
! 29 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (18,18) and color black and layers
  _0: rectangle with size (18,18) with mask 
0 0 0 0 . 0 . 0 . 0 0 0 . . 0 . 0 0 
0 0 0 0 . . 0 0 . 0 . . 0 . . 0 0 . 
0 0 0 0 0 0 . 0 0 0 0 . . . . 0 0 . 
0 . 0 0 0 0 . . . . 0 0 0 0 0 0 . . 
. . 0 . 0 0 . . . 0 0 . . . 0 0 0 . 
0 . . . 0 . 0 0 0 0 . . . 0 . . . . 
. 0 . 0 0 0 . . . 0 0 . . 0 . 0 0 0 
0 . . 0 0 . 0 0 . 0 . . 0 . 0 . 0 . 
0 0 0 0 . 0 0 0 . 0 0 . 0 . 0 . 0 . 
0 . 0 0 0 0 . 0 . 0 . 0 0 0 . 0 0 . 
0 . 0 0 0 . 0 . 0 . . 0 . . 0 0 0 0 
. . . . 0 . 0 . . . 0 . 0 0 0 . . . 
0 . 0 . . 0 . 0 0 . . 0 . . . 0 0 0 
0 0 0 . 0 . . 0 0 0 . 0 0 0 . 0 0 . 
. . 0 0 0 0 0 . 0 0 0 0 . . . . . 0 
. . 0 0 0 0 . . 0 0 . 0 . 0 0 . 0 . 
. . . . . . . . 0 0 0 . . . . 0 . . 
. . . . . . . 0 . 0 0 0 . 0 0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (1,2) with model Full with color grey at (17,4)
  + 3 delta pixels
diff: 
! 31 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (18,18) and color black and layers
  _0: rectangle with size (18,18) with mask 
0 0 0 0 . 0 . 0 . 0 0 0 . . 0 . 0 0 
0 0 0 0 . . 0 0 . 0 . . 0 . . 0 0 . 
0 0 0 0 0 0 . 0 0 0 0 . . . . 0 0 . 
0 . 0 0 0 0 . . . . 0 0 0 0 0 0 . . 
. . 0 . 0 0 . . . 0 0 . . . 0 0 0 . 
0 . . . 0 . 0 0 0 0 . . . 0 . . . . 
. 0 . 0 0 0 . . . 0 0 . . 0 . 0 0 0 
0 . . 0 0 . 0 0 . 0 . . 0 . 0 . 0 . 
0 0 0 0 . 0 0 0 . 0 0 . 0 . 0 . 0 . 
0 . 0 0 0 0 . 0 . 0 . 0 0 0 . 0 0 . 
0 . 0 0 0 . 0 . 0 . . 0 . . 0 0 0 0 
. . . . 0 . 0 . . . 0 . 0 0 0 . . . 
0 . 0 . . 0 . 0 0 . . 0 . . . 0 0 0 
0 0 0 . 0 . . 0 0 0 . 0 0 0 . 0 0 . 
. . 0 0 0 0 0 . 0 0 0 0 . . . . . 0 
. . 0 0 0 0 . . 0 0 . 0 . 0 0 . 0 . 
. . . . . . . . 0 0 0 . . . . 0 . . 
. . . . . . . 0 . 0 0 0 . 0 0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (1,6) with model Full with color grey at (17,0)
  + 3 delta pixels
diff: 
! 35 wrong pixels (generated / expected)

TRAIN a8d7556c.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (18,18) and color black and layers
  _0: rectangle with size (18,18) with mask 
. . 0 0 0 0 0 0 0 . . 0 0 0 . 0 0 . 
. . . . 0 0 . . . . 0 . 0 0 . 0 0 0 
. . 0 0 0 0 . . 0 0 0 0 . . . 0 0 0 
0 0 0 . 0 0 0 0 0 0 . . 0 0 0 0 0 0 
0 0 . 0 0 0 0 . 0 0 0 0 . 0 . . . . 
0 . . 0 0 0 0 0 0 . 0 0 0 . 0 . . 0 
0 0 0 . 0 0 0 . . . 0 0 0 0 0 0 0 . 
. 0 0 . 0 0 0 0 . 0 . . 0 . 0 0 0 . 
0 0 0 0 0 . 0 0 . 0 . . . 0 . 0 . 0 
0 . 0 . 0 . 0 0 0 0 . . . 0 0 0 0 0 
. . 0 . 0 0 . 0 0 0 . . 0 . 0 0 0 0 
0 0 0 0 . 0 0 0 0 . 0 0 0 0 0 . 0 0 
. . 0 0 0 . 0 0 . 0 0 . 0 . 0 0 0 0 
0 0 . 0 0 0 . . . . 0 . 0 0 . 0 . . 
. . 0 0 0 0 . 0 0 . 0 . . . 0 . 0 . 
. 0 0 0 0 0 . 0 0 0 . 0 . 0 0 . . 0 
. 0 0 . . 0 0 0 . . . 0 0 . 0 0 0 0 
0 . . 0 0 . 0 0 0 0 0 . 0 0 . . 0 . 
 with color grey at (0,0)
  _01: rectangle with size (1,1) with model Full with color grey at (1,0)
diff: 
   (0.0 bits)
data: a background with size (18,18) and color black and layers
  _0: 
. . 5#5#5#5#5#5#5#. . 5#5#5#. 5#5#. 
. . . . 5#5#. . . . 5#. 5#5#. 5#5#5#
. . 5#5#5#5#. . 5#5#5#5#. . . 5#5#5#
5#5#5#. 5#5#5#5#5#5#. . 5#5#5#5#5#5#
5#5#. 5#5#5#5#. 5#5#5#5#. 5#. . . . 
5#. . 5#5#5#5#5#5#. 5#5#5#. 5#. . 5#
5#5#5#. 5#5#5#. . . 5#5#5#5#5#5#5#. 
. 5#5#. 5#5#5#5#. 5#. . 5#. 5#5#5#. 
5#5#5#5#5#. 5#5#. 5#. . . 5#. 5#. 5#
5#. 5#. 5#. 5#5#5#5#. . . 5#5#5#5#5#
. . 5#. 5#5#. 5#5#5#. . 5#. 5#5#5#5#
5#5#5#5#. 5#5#5#5#. 5#5#5#5#5#. 5#5#
. . 5#5#5#. 5#5#. 5#5#. 5#. 5#5#5#5#
5#5#. 5#5#5#. . . . 5#. 5#5#. 5#. . 
. . 5#5#5#5#. 5#5#. 5#. . . 5#. 5#. 
. 5#5#5#5#5#. 5#5#5#. 5#. 5#5#. . 5#
. 5#5#. . 5#5#5#. . . 5#5#. 5#5#5#5#
5#. . 5#5#. 5#5#5#5#5#. 5#5#. . 5#. 
 at (0,0)
  _01: 
0 0 
0 0 
 with color red at (1,6)
  _011: rectangle with size (4,2) with model Full with color red at (7,10)
  _0111: 
2 2 
2 2 
 at (4,15)
  _01111: rectangle with size (1,1) with model Full with color grey at (1,0)
diff: 
   (65.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,18) and color black and layers
  _0: rectangle with size (18,18) with mask 
. . 0 0 0 0 0 0 0 . . 0 0 0 . 0 0 . 
. . . . 0 0 . . . . 0 . 0 0 . 0 0 0 
. . 0 0 0 0 . . 0 0 0 0 . . . 0 0 0 
0 0 0 . 0 0 0 0 0 0 . . 0 0 0 0 0 0 
0 0 . 0 0 0 0 . 0 0 0 0 . 0 . . . . 
0 . . 0 0 0 0 0 0 . 0 0 0 . 0 . . 0 
0 0 0 . 0 0 0 . . . 0 0 0 0 0 0 0 . 
. 0 0 . 0 0 0 0 . 0 . . 0 . 0 0 0 . 
0 0 0 0 0 . 0 0 . 0 . . . 0 . 0 . 0 
0 . 0 . 0 . 0 0 0 0 . . . 0 0 0 0 0 
. . 0 . 0 0 . 0 0 0 . . 0 . 0 0 0 0 
0 0 0 0 . 0 0 0 0 . 0 0 0 0 0 . 0 0 
. . 0 0 0 . 0 0 . 0 0 . 0 . 0 0 0 0 
0 0 . 0 0 0 . . . . 0 . 0 0 . 0 . . 
. . 0 0 0 0 . 0 0 . 0 . . . 0 . 0 . 
. 0 0 0 0 0 . 0 0 0 . 0 . 0 0 . . 0 
. 0 0 . . 0 0 0 . . . 0 0 . 0 0 0 0 
0 . . 0 0 . 0 0 0 0 0 . 0 0 . . 0 . 
 with color grey at (0,0)
  _01: rectangle with size (1,1) with model Full with color grey at (1,0)
diff: 
! 20 wrong pixels (generated / expected)

TRAIN a8d7556c.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,18) and color black and layers
  _0: rectangle with size (18,18) with mask 
. . . 0 . 0 . . 0 0 . 0 0 0 0 0 . . 
. . 0 0 . 0 . 0 . . . 0 0 0 0 . 0 0 
0 . . . 0 0 . 0 . . 0 . 0 . 0 0 . 0 
. 0 0 0 . 0 0 . 0 0 . . . 0 0 . 0 0 
0 0 0 0 0 0 0 . . 0 0 . . . . 0 0 0 
. 0 0 0 0 . 0 0 0 . 0 . . 0 0 . 0 . 
0 0 . 0 0 0 0 0 0 . . 0 . . 0 . 0 0 
0 0 0 0 . . 0 0 . 0 0 0 0 0 . 0 0 . 
0 . 0 . . 0 0 0 . . . 0 0 0 0 . . . 
. . . . 0 . . . 0 0 0 0 . . 0 . 0 0 
. . 0 0 . 0 0 0 . . 0 . 0 0 0 0 0 . 
. . . 0 0 . 0 . . 0 0 . 0 0 0 0 0 0 
. 0 0 0 0 . . 0 . . . 0 0 0 0 0 . 0 
0 0 0 0 0 0 0 . 0 0 0 0 0 0 0 . . 0 
0 0 . 0 0 0 . 0 . 0 0 0 0 . 0 . . 0 
0 . 0 0 0 0 . 0 0 . . . 0 0 0 0 . 0 
. 0 . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 . . . . . . 0 . 0 . 0 0 . 0 0 . . 
 with color grey at (0,0)
  _01: rectangle with size (1,1) with model Full with color grey at (10,0)
diff: 
! 19 wrong pixels (generated / expected)

TEST a8d7556c.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.5 sec (59.5 sec/task)
bits-train-error = 9151.4 bits (9151.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-135] Checking task a9f96cdd.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 23253.3 = 23255.6
DL output with Mo: L = 2.3 + 23253.3 = 23255.6
DL input+output M: L = 4.6 + 46506.5 = 46511.2

# learning a model for train pairs
2.000	
1.096	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.306	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.265	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.225	OUT ADD ^.layer_0 = point with color ? at (?,?)
0.200	OUT SPE ^.size = ^.size
0.190	IN  SPE ^.layer_0.shape.color = red
0.183	OUT SPE ^.layer_0.pos.j = ^.layer_0.pos.j - 1
0.178	IN  SPE ^.color = black
0.174	OUT SPE ^.color = black
0.135	
0.134	IN  GEN ^.layer_0.shape.color = ?
0.134	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: point with color ? at (?,^.layer_0.pos.j - 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color red at (?,?)

DL input  with Mi: L = 35.6 + 920.3 = 956.0
DL output with Mo: L = 36.9 + 3056.4 = 3093.3
DL input+output M: L = 72.5 + 3976.7 = 4049.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: point with color ? at (?,^.layer_0.pos.j - 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 0.0 = 32.2
DL output with Mo: L = 36.9 + 3056.4 = 3093.3
DL input+output M: L = 69.1 + 3056.4 = 3125.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,5) and color black and layers
  _0: point with color red at (1,1)
diff: 
   (0.0 bits)
data: a background with size (3,5) and color black and layers
  _0: point with color green at (0,0)
  + 3 delta pixels
diff: 
   (123.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,5) and color black and layers
  _0: point with color red at (1,1)
diff: 
! 4 wrong pixels (generated / expected)

TRAIN a9f96cdd.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,5) and color black and layers
  _0: point with color red at (2,4)
diff: 
   (0.0 bits)
data: a background with size (3,5) and color black and layers
  _0: point with color green at (1,3)
diff: 
   (9.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,5) and color black and layers
  _0: point with color red at (2,4)
diff: 
! 2 wrong pixels (generated / expected)

TRAIN a9f96cdd.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,5) and color black and layers
  _0: point with color red at (0,2)
diff: 
   (0.0 bits)
data: a background with size (3,5) and color black and layers
  _0: point with color cyan at (1,1)
  + 1 delta pixels
diff: 
   (48.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,5) and color black and layers
  _0: point with color red at (0,2)
diff: 
! 3 wrong pixels (generated / expected)

TRAIN a9f96cdd.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (3,5) and color black and layers
  _0: point with color red at (1,3)
diff: 
   (0.0 bits)
data: a background with size (3,5) and color black and layers
  _0: point with color green at (0,2)
  + 3 delta pixels
diff: 
   (123.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,5) and color black and layers
  _0: point with color red at (1,3)
diff: 
! 4 wrong pixels (generated / expected)

TRAIN a9f96cdd.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,5) and color black and layers
  _0: point with color red at (1,4)
diff: 
! 2 wrong pixels (generated / expected)

TEST a9f96cdd.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 1.2 sec (1.2 sec/task)
bits-train-error = 3056.4 bits (3056.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-134] Checking task aabf363d.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 38448.0 = 38450.4
DL output with Mo: L = 2.3 + 38448.0 = 38450.4
DL input+output M: L = 4.6 + 76896.1 = 76900.7

# learning a model for train pairs
2.000	
1.255	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.530	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.314	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.100	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.080	OUT SPE ^.layer_0.shape.mask = ^.layer_0.shape.mask
0.068	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.058	OUT SPE ^.size = ^.size
0.050	OUT SPE ^.layer_0 = coloring(^.layer_0, ^.layer_01.shape.color)
0.049	IN  SPE ^.color = black
0.048	OUT SPE ^.color = black
0.002	
0.002	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, ^.layer_01.shape.color)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 60.5 + 1737.2 = 1797.8
DL output with Mo: L = 31.2 + 0.0 = 31.2
DL input+output M: L = 91.7 + 1737.2 = 1829.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, ^.layer_01.shape.color)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 60.4 + 0.0 = 60.4
DL output with Mo: L = 31.2 + 0.0 = 31.2
DL input+output M: L = 91.6 + 0.0 = 91.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (7,7) and color black and layers
  _0: rectangle with size (5,4) with mask 
0 0 0 . 
. 0 . . 
0 0 0 0 
. 0 0 0 
. . 0 . 
 with color red at (1,1)
  _01: point with color yellow at (6,0)
diff: 
   (0.0 bits)
data: a background with size (7,7) and color black and layers
  _0: 
4 4 4 . 
. 4 . . 
4 4 4 4 
. 4 4 4 
. . 4 . 
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (5,4) with mask 
0 0 0 . 
. 0 . . 
0 0 0 0 
. 0 0 0 
. . 0 . 
 with color red at (1,1)
  _01: point with color yellow at (6,0)
diff: 
correct output grid

TRAIN aabf363d.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (7,7) and color black and layers
  _0: rectangle with size (5,4) with mask 
. . 0 . 
. 0 0 0 
0 0 0 0 
0 0 . . 
. 0 0 . 
 with color green at (1,1)
  _01: point with color pink at (6,0)
diff: 
   (0.0 bits)
data: a background with size (7,7) and color black and layers
  _0: 
. . 6 . 
. 6 6 6 
6 6 6 6 
6 6 . . 
. 6 6 . 
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (5,4) with mask 
. . 0 . 
. 0 0 0 
0 0 0 0 
0 0 . . 
. 0 0 . 
 with color green at (1,1)
  _01: point with color pink at (6,0)
diff: 
correct output grid

TRAIN aabf363d.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 . . 
0 0 0 0 0 
. . 0 0 . 
. 0 0 . . 
. 0 0 0 . 
 with color cyan at (1,1)
  _01: point with color red at (6,0)
diff: 
correct output grid

TEST aabf363d.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 2.0 sec (2.0 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-133] Checking task aba27056.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 65424.1 = 65426.4
DL output with Mo: L = 2.3 + 65424.1 = 65426.4
DL input+output M: L = 4.6 + 130848.2 = 130852.8

# learning a model for train pairs
2.000	
1.261	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.799	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.502	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.278	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.085	OUT ADD ^.layer_01 = ^.layer_0
0.077	OUT SPE ^.size = ^.size
0.074	OUT SPE ^.layer_0.shape.color = yellow
0.072	OUT SPE ^.layer_0.pos.j = '0
0.071	IN  SPE ^.color = black
0.070	OUT SPE ^.color = black
0.035	
0.035	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color yellow at (?,'0)
  _01: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.1 + 2281.9 = 2324.0
DL output with Mo: L = 55.4 + 2173.3 = 2228.7
DL input+output M: L = 97.5 + 4455.2 = 4552.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color yellow at (?,'0)
  _01: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 55.4 + 2173.3 = 2228.7
DL input+output M: L = 97.4 + 2173.3 = 2270.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (7,7) and color black and layers
  _0: rectangle with size (3,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 0 0 0 0 
 with color pink at (4,1)
diff: 
   (0.0 bits)
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (6,7) with mask 
. . . 0 . . . 
0 . . 0 . . 0 
. 0 . 0 . 0 . 
. . 0 0 0 . . 
. . . 0 . . . 
. . 0 0 0 . . 
 with color yellow at (0,0)
  _01: 
6 6 . 6 6 
6 . . . 6 
6 6 6 6 6 
 at (4,1)
diff: 
   (64.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (3,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 0 0 0 0 
 with color pink at (4,1)
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (3,5) with model Full with color pink at (4,1)
  + 4 delta pixels
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (1,5) with model Full with color pink at (6,1)
  + 6 delta pixels
diff: 
! 22 wrong pixels (generated / expected)

TRAIN aba27056.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: rectangle with size (7,5) with mask 
0 0 0 0 0 
0 . . . 0 
. . . . 0 
. . . . 0 
. . . . 0 
0 . . . 0 
0 0 0 0 0 
 with color orange at (2,4)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,8) with mask 
0 . . . . . . . 
. 0 . . . . . . 
. . 0 . . . . . 
. . . 0 . 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
. . . 0 . 0 0 0 
. . 0 . . . . . 
 with color yellow at (0,0)
  _01: 
7#7#7#7#7#
7#. . . 7#
. . . . 7#
. . . . 7#
. . . . 7#
7#. . . 7#
7#7#7#7#7#
 at (2,4)
diff: 
   (99.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (7,5) with mask 
0 0 0 0 0 
0 . . . 0 
. . . . 0 
. . . . 0 
. . . . 0 
0 . . . 0 
0 0 0 0 0 
 with color orange at (2,4)
diff: 
! 36 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (7,1) with model Full with color orange at (2,8)
  + 10 delta pixels
diff: 
! 46 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (1,5) with model Full with color orange at (2,4)
  + 12 delta pixels
diff: 
! 48 wrong pixels (generated / expected)

TRAIN aba27056.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _0: rectangle with size (4,6) with mask 
0 0 0 0 0 0 
0 . . . . 0 
0 . . . . 0 
0 0 . . 0 0 
 with color green at (0,0)
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (5,6) with mask 
. 0 0 0 0 . 
. 0 0 0 0 . 
. . 0 0 . . 
. 0 0 0 0 . 
0 . 0 0 . 0 
 with color yellow at (1,0)
  _01: 
3 3 3 3 3 3 
3 . . . . 3 
3 . . . . 3 
3 3 . . 3 3 
 at (0,0)
diff: 
   (53.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (4,6) with mask 
0 0 0 0 0 0 
0 . . . . 0 
0 . . . . 0 
0 0 . . 0 0 
 with color green at (0,0)
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,6) and color green and layers
  _0: rectangle with size (5,6) with mask 
. 0 0 0 0 . 
. 0 0 0 0 . 
. . 0 0 . . 
0 0 0 0 0 0 
0 0 0 0 0 0 
 with color black at (1,0)
diff: 
! 31 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (1,6) with model Full with color green at (0,0)
  + 8 delta pixels
diff: 
! 27 wrong pixels (generated / expected)

TRAIN aba27056.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (9,4) with mask 
0 0 0 0 
0 . . 0 
0 . . . 
0 . . . 
0 . . . 
0 . . . 
0 . . . 
0 . . 0 
0 0 0 0 
 with color red at (0,1)
diff: 
! 53 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (9,1) with model Full with color red at (0,1)
  + 8 delta pixels
diff: 
! 61 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,4) with model Full with color red at (0,1)
  + 13 delta pixels
diff: 
! 65 wrong pixels (generated / expected)

TEST aba27056.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 4.3 sec (4.3 sec/task)
bits-train-error = 2173.3 bits (2173.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-132] Checking task ac0a08a4.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 10534.8 = 10537.1
DL output with Mo: L = 2.3 + 138206.6 = 138208.9
DL input+output M: L = 4.6 + 148741.4 = 148746.0

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = ^ * colorCount(^)
0.399	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.334	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.268	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.261	IN  SPE ^.color = black
0.005	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
^ * colorCount(^)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.7 + 2698.0 = 2748.8
DL output with Mo: L = 17.5 + 0.0 = 17.5
DL input+output M: L = 68.2 + 2698.0 = 2766.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
^ * colorCount(^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 17.5 + 0.0 = 17.5
DL input+output M: L = 19.8 + 0.0 = 19.8

# train input/output grids

## instance 1

> Input and output best reading:

data: 
2 0 0 
0 0 7#
0 0 0 

diff: 
   (0.0 bits)
data: 
2 2 0 0 0 0 
2 2 0 0 0 0 
0 0 0 0 7#7#
0 0 0 0 7#7#
0 0 0 0 0 0 
0 0 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 0 0 
0 0 7#
0 0 0 

diff: 
correct output grid

TRAIN ac0a08a4.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 4 0 
0 0 8 
6 0 0 

diff: 
   (0.0 bits)
data: 
0 0 0 4 4 4 0 0 0 
0 0 0 4 4 4 0 0 0 
0 0 0 4 4 4 0 0 0 
0 0 0 0 0 0 8 8 8 
0 0 0 0 0 0 8 8 8 
0 0 0 0 0 0 8 8 8 
6 6 6 0 0 0 0 0 0 
6 6 6 0 0 0 0 0 0 
6 6 6 0 0 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 4 0 
0 0 8 
6 0 0 

diff: 
correct output grid

TRAIN ac0a08a4.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 6 9#
3 0 2 
0 7#0 

diff: 
   (0.0 bits)
data: 
0 0 0 0 0 6 6 6 6 6 9#9#9#9#9#
0 0 0 0 0 6 6 6 6 6 9#9#9#9#9#
0 0 0 0 0 6 6 6 6 6 9#9#9#9#9#
0 0 0 0 0 6 6 6 6 6 9#9#9#9#9#
0 0 0 0 0 6 6 6 6 6 9#9#9#9#9#
3 3 3 3 3 0 0 0 0 0 2 2 2 2 2 
3 3 3 3 3 0 0 0 0 0 2 2 2 2 2 
3 3 3 3 3 0 0 0 0 0 2 2 2 2 2 
3 3 3 3 3 0 0 0 0 0 2 2 2 2 2 
3 3 3 3 3 0 0 0 0 0 2 2 2 2 2 
0 0 0 0 0 7#7#7#7#7#0 0 0 0 0 
0 0 0 0 0 7#7#7#7#7#0 0 0 0 0 
0 0 0 0 0 7#7#7#7#7#0 0 0 0 0 
0 0 0 0 0 7#7#7#7#7#0 0 0 0 0 
0 0 0 0 0 7#7#7#7#7#0 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 6 9#
3 0 2 
0 7#0 

diff: 
correct output grid

TRAIN ac0a08a4.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 0 0 
0 9#6 
8 0 0 

diff: 
correct output grid

TEST ac0a08a4.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 0.5 sec (0.5 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-131] Checking task ae3edfdc.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 276019.4 = 276021.8
DL output with Mo: L = 2.3 + 276019.4 = 276021.8
DL input+output M: L = 4.6 + 552038.9 = 552043.5

# learning a model for train pairs
2.000	
1.040	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.081	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.068	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.060	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.058	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.055	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.053	OUT SPE ^.size = ^.size
0.050	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.048	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.046	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.043	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.041	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.038	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.036	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.034	OUT SPE ^.layer_011 = ^.layer_011
0.033	OUT SPE ^.layer_0.shape.mask.size.i = 3
0.032	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.032	IN  SPE ^.layer_011111.shape.color = green
0.031	OUT SPE ^.layer_0.pos.i = ^.layer_0111.pos.i - 1
0.031	OUT SPE ^.layer_01.pos.i = span(^.layer_01.pos.j, ^.layer_0111.pos.j)
0.030	OUT SPE ^.layer_01.pos.j = ^.layer_0111111.pos.j - 1
0.030	OUT SPE ^.layer_0111.pos.j = ^.layer_0111111.pos.j - ^.layer_011.pos.j - ^.layer_0.pos.j
0.029	IN  SPE ^.color = black
0.029	OUT SPE ^.color = black
0.007	
0.007	IN  GEN ^.layer_011111.shape.color = ?
0.007	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (3,?) with model ? with color ^.layer_0.shape.color at (^.layer_0111.pos.i - 1,?)
  _01: rectangle with size (?,?) with model ? with color ? at (span(^.layer_01.pos.j, ^.layer_0111.pos.j),^.layer_0111111.pos.j - 1)
  _011: ^.layer_011
  _0111: point with color ? at (?,^.layer_0111111.pos.j - ^.layer_011.pos.j - ^.layer_0.pos.j)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color green at (?,?)
  _0111111: point with color ? at (?,?)

DL input  with Mi: L = 143.1 + 6005.2 = 6148.4
DL output with Mo: L = 228.2 + 1635.9 = 1864.1
DL input+output M: L = 371.4 + 7641.1 = 8012.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (3,?) with model ? with color ^.layer_0.shape.color at (^.layer_0111.pos.i - 1,?)
  _01: rectangle with size (?,?) with model ? with color ? at (span(^.layer_01.pos.j, ^.layer_0111.pos.j),^.layer_0111111.pos.j - 1)
  _011: ^.layer_011
  _0111: point with color ? at (?,^.layer_0111111.pos.j - ^.layer_011.pos.j - ^.layer_0.pos.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)

DL input  with Mi: L = 139.7 + 20.0 = 159.7
DL output with Mo: L = 228.2 + 1635.9 = 1864.1
DL input+output M: L = 367.9 + 1655.9 = 2023.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: point with color green at (0,3)
  _01: point with color green at (4,0)
  _011: point with color red at (4,3)
  _0111: point with color green at (4,8)
  _01111: point with color orange at (6,11)
  _011111: point with color green at (9,3)
  _0111111: point with color blue at (10,11)
  + 3 delta pixels
diff: 
   (2.0 bits)
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (3,3) with model Odd Checkboard with color green at (3,2)
  _01: rectangle with size (3,3) with model Odd Checkboard with color orange at (9,10)
  _011: 
2 
 at (4,3)
  _0111: point with color blue at (10,11)
diff: 
   (56.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: point with color green at (0,3)
  _01: point with color green at (4,0)
  _011: point with color red at (4,3)
  _0111: point with color green at (4,8)
  _01111: point with color orange at (6,11)
  _011111: point with color green at (9,3)
  _0111111: point with color orange at (10,5)
  + 3 delta pixels
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: point with color green at (0,3)
  _01: point with color green at (4,0)
  _011: point with color red at (4,3)
  _0111: point with color green at (4,8)
  _01111: point with color orange at (6,11)
  _011111: point with color green at (9,3)
  _0111111: point with color blue at (10,11)
  + 3 delta pixels
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,15) and color black and layers
  _0: point with color green at (0,3)
  _01: point with color green at (4,0)
  _011: point with color red at (4,3)
  _0111: point with color green at (4,8)
  _01111: point with color orange at (6,11)
  _011111: point with color orange at (10,5)
  _0111111: point with color green at (9,3)
  + 3 delta pixels
diff: 
! 20 wrong pixels (generated / expected)

TRAIN ae3edfdc.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: point with color orange at (0,3)
  _01: point with color orange at (2,0)
  _011: point with color blue at (2,3)
  _0111: point with color orange at (2,9)
  _01111: point with color orange at (8,3)
  _011111: point with color green at (10,5)
  _0111111: point with color red at (10,11)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (3,3) with model Odd Checkboard with color orange at (1,2)
  _01: rectangle with size (2,2) with model Even Checkboard with color green at (10,10)
  _011: 
1 
 at (2,3)
  _0111: point with color red at (10,11)
diff: 
   (54.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: point with color orange at (0,3)
  _01: point with color orange at (2,0)
  _011: point with color blue at (2,3)
  _0111: point with color orange at (2,9)
  _01111: point with color orange at (8,3)
  _011111: point with color green at (10,5)
  _0111111: point with color red at (10,11)
  + 1 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: point with color orange at (0,3)
  _01: point with color orange at (2,0)
  _011: point with color blue at (2,3)
  _0111: point with color orange at (2,9)
  _01111: point with color orange at (8,3)
  _011111: point with color red at (10,11)
  _0111111: point with color green at (10,5)
  + 1 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TRAIN ae3edfdc.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: point with color green at (0,6)
  _01: point with color orange at (6,1)
  _011: point with color blue at (6,10)
  _0111: point with color red at (11,6)
  _01111: point with color green at (11,14)
  _011111: point with color green at (14,6)
  _0111111: point with color orange at (14,10)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (3,2) with model Even Checkboard with color green at (10,6)
  _01: rectangle with size (2,2) with model Even Checkboard with color orange at (6,9)
  _011: 
1 
 at (6,10)
  _0111: point with color red at (11,6)
diff: 
   (53.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: point with color green at (0,6)
  _01: point with color orange at (6,1)
  _011: point with color blue at (6,10)
  _0111: point with color red at (11,6)
  _01111: point with color green at (11,14)
  _011111: point with color green at (14,6)
  _0111111: point with color orange at (14,10)
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: point with color green at (0,6)
  _01: point with color orange at (6,1)
  _011: point with color blue at (6,10)
  _0111: point with color red at (11,6)
  _01111: point with color green at (11,14)
  _011111: point with color orange at (14,10)
  _0111111: point with color green at (14,6)
diff: 
! 17 wrong pixels (generated / expected)

TRAIN ae3edfdc.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
undefined expression: Span: same int

TEST ae3edfdc.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 46.3 sec (46.3 sec/task)
bits-train-error = 1635.9 bits (1635.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-130] Checking task ae4f1146.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 128631.2 = 128633.5
DL output with Mo: L = 2.3 + 14046.4 = 14048.7
DL input+output M: L = 4.6 + 142677.6 = 142682.3

# learning a model for train pairs
2.000	
1.449	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.910	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.620	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.520	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.442	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.382	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.342	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.305	OUT SPE ^.layer_0.shape.mask.size = ^.layer_0.shape.mask.size
0.269	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.241	IN  ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.216	OUT SPE ^.color = cyan
0.193	OUT SPE ^.layer_0.pos = '(0, 0)
0.177	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.161	OUT SPE ^.layer_0.shape.color = blue
0.159	IN  SPE ^.layer_011.shape.color = blue
0.156	IN  SPE ^.layer_0111.shape.color = cyan
0.150	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.143	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.138	IN  SPE ^.layer_0111.shape.mask = 
0 0 0 
0 0 0 
0 0 0 

0.136	IN  SPE ^.layer_00.shape.color = cyan
0.134	IN  SPE ^.layer_011111.shape.color = blue
0.133	IN  SPE ^.layer_01111.shape.mask.model = Full
0.133	IN  SPE ^.color = black
0.036	
0.036	IN  DEL ^.layer_011
0.036	IN  DEL ^.layer_0111
0.036	IN  DEL ^.layer_01111
0.035	IN  DEL ^.layer_01
0.035	IN  DEL ^.layer_011111
0.035	IN  DEL ^.layer_0111111
0.035	IN  GEN ^.layer_00.shape.color = ?
0.035	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color cyan and layers
  _0: rectangle with size ^.layer_0.shape.mask.size with model ? with color blue at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: rectangle with size (?,?) with model ? with color cyan at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color blue at (?,?)
  _0111: 
0 0 0 
0 0 0 
0 0 0 
 with color cyan at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011111: point with color blue at (?,?)
  _0111111: point with color ? at (?,?)

DL input  with Mi: L = 230.0 + 12406.1 = 12636.1
DL output with Mo: L = 56.1 + 428.3 = 484.4
DL input+output M: L = 286.1 + 12834.4 = 13120.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color cyan and layers
  _0: rectangle with size ^.layer_0.shape.mask.size with model ? with color blue at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 56.1 + 428.3 = 484.4
DL input+output M: L = 126.3 + 428.3 = 554.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _00: rectangle with size (3,3) with model Full with color cyan at (0,0)
  _0: rectangle with size (3,3) with model Full with color cyan at (4,1)
  + 21 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color cyan and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 . 0 
0 . 0 
 with color blue at (0,0)
diff: 
   (10.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _00: rectangle with size (3,3) with model Full with color cyan at (0,0)
  _0: rectangle with size (3,3) with model Full with color cyan at (4,1)
  + 21 delta pixels
diff: 
! 4 wrong pixels (generated / expected)

TRAIN ae4f1146.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _00: rectangle with size (6,6) with mask 
. . . 0 . 0 
. . . . 0 0 
. . . 0 0 . 
. . 0 . . . 
. . 0 . . . 
0 0 . . . . 
 with color cyan at (1,2)
  _0: rectangle with size (3,3) with model Full with color cyan at (6,6)
  + 18 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color cyan and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 . 
. . 0 
 with color blue at (0,0)
diff: 
   (10.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _00: rectangle with size (6,6) with mask 
. . . 0 . 0 
. . . . 0 0 
. . . 0 0 . 
. . 0 . . . 
. . 0 . . . 
0 0 . . . . 
 with color cyan at (1,2)
  _0: rectangle with size (3,3) with model Full with color cyan at (6,6)
  + 18 delta pixels
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _00: rectangle with size (3,3) with model Full with color cyan at (6,6)
  _0: rectangle with size (6,6) with mask 
. . . 0 . 0 
. . . . 0 0 
. . . 0 0 . 
. . 0 . . . 
. . 0 . . . 
0 0 . . . . 
 with color cyan at (1,2)
  + 18 delta pixels
diff: 
! size mismatch, 6x6 instead of 3x3

TRAIN ae4f1146.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _00: rectangle with size (7,3) with model Full with color cyan at (1,0)
  _0: rectangle with size (3,3) with model Full with color cyan at (0,4)
  + 16 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color cyan and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 . 
0 . 0 
 with color blue at (0,0)
diff: 
   (10.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _00: rectangle with size (7,3) with model Full with color cyan at (1,0)
  _0: rectangle with size (3,3) with model Full with color cyan at (0,4)
  + 16 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _00: rectangle with size (3,3) with model Full with color cyan at (0,4)
  _0: rectangle with size (7,3) with model Full with color cyan at (1,0)
  + 16 delta pixels
diff: 
! size mismatch, 7x3 instead of 3x3

TRAIN ae4f1146.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _00: rectangle with size (3,3) with model Full with color cyan at (4,0)
  _0: rectangle with size (3,3) with model Full with color blue at (1,6)
  + 23 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color cyan and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
0 0 0 
. 0 . 
 with color blue at (0,0)
diff: 
   (10.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _00: rectangle with size (3,3) with model Full with color cyan at (4,0)
  _0: rectangle with size (3,3) with model Full with color blue at (1,6)
  + 23 delta pixels
diff: 
! 3 wrong pixels (generated / expected)

TRAIN ae4f1146.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _00: rectangle with size (6,9) with mask 
0 0 0 . . . 0 . 0 
0 0 0 . . . . 0 . 
. 0 0 . . . 0 . 0 
. . . 0 . 0 . . . 
. . . 0 0 . . . . 
. . . . 0 0 . . . 
 with color cyan at (0,0)
  _0: rectangle with size (3,3) with model Full with color blue at (6,6)
  + 11 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _00: rectangle with size (3,3) with model Full with color blue at (6,6)
  _0: rectangle with size (6,9) with mask 
0 0 0 . . . 0 . 0 
0 0 0 . . . . 0 . 
. 0 0 . . . 0 . 0 
. . . 0 . 0 . . . 
. . . 0 0 . . . . 
. . . . 0 0 . . . 
 with color cyan at (0,0)
  + 11 delta pixels
diff: 
! size mismatch, 6x9 instead of 3x3

TEST ae4f1146.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 41.1 sec (41.1 sec/task)
bits-train-error = 428.3 bits (428.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-129] Checking task aedd82e4.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 20974.6 = 20976.9
DL output with Mo: L = 2.3 + 20974.6 = 20976.9
DL input+output M: L = 4.6 + 41949.2 = 41953.8

# learning a model for train pairs
2.000	
1.451	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.931	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.648	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.346	OUT ADD ^.layer_0 = ^.layer_0
0.301	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.274	OUT SPE ^.size = ^.size
0.260	OUT SPE ^.color = ^.color
0.250	OUT SPE ^.layer_01.shape.color = blue
0.242	OUT SPE ^.layer_01.pos.i = 2
0.069	

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.color and layers
  _0: ^.layer_0
  _01: point with color blue at (2,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 3660.9 = 3702.9
DL output with Mo: L = 43.5 + 1325.8 = 1369.3
DL input+output M: L = 85.5 + 4986.8 = 5072.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.color and layers
  _0: ^.layer_0
  _01: point with color blue at (2,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 40.0 = 82.0
DL output with Mo: L = 43.5 + 1325.8 = 1369.3
DL input+output M: L = 85.5 + 1365.8 = 1451.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color red and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
0 . . 
. 0 0 
 with color black at (0,0)
diff: 
   (2.0 bits)
data: a background with size (3,3) and color red and layers
  _0: 
0 . . 
0 . . 
. 0 0 
 at (0,0)
  _01: point with color blue at (2,0)
diff: 
   (3.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
. 0 0 
0 . . 
 with color red at (0,0)
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color red and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
0 . . 
. 0 0 
 with color black at (0,0)
diff: 
correct output grid

TRAIN aedd82e4.json/1: 1 2nd (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (4,4) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color red at (0,0)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: 
2 2 2 
. 2 . 
 at (0,0)
  _01: point with color blue at (2,3)
  + 1 delta pixels
diff: 
   (43.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
. 0 . 
 with color red at (0,0)
  + 2 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (0,0)
  + 3 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (2,1) with model Full with color red at (0,1)
  + 4 delta pixels
diff: 
! 5 wrong pixels (generated / expected)

TRAIN aedd82e4.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (5,4) and color red and layers
  _0: rectangle with size (5,4) with mask 
. . 0 0 
. . 0 0 
. . 0 . 
0 0 0 0 
0 . . . 
 with color black at (0,0)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,4) and color red and layers
  _0: 
. . 0 0 
. . 0 0 
. . 0 . 
0 0 0 0 
0 . . . 
 at (0,0)
  _01: point with color blue at (2,3)
  + 1 delta pixels
diff: 
   (43.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,4) and color red and layers
  _0: rectangle with size (5,4) with mask 
. . 0 0 
. . 0 0 
. . 0 . 
0 0 0 0 
0 . . . 
 with color black at (0,0)
  + 1 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,4) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 0 
. 0 
0 0 
 with color red at (0,0)
  + 4 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (5,4) and color black and layers
  _0: rectangle with size (3,2) with model Full with color red at (0,0)
  + 5 delta pixels
diff: 
! 5 wrong pixels (generated / expected)

TRAIN aedd82e4.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (3,3) and color red and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
. 0 . 
0 . 0 
 with color black at (0,0)
diff: 
   (2.0 bits)
data: a background with size (3,3) and color red and layers
  _0: 
. . 0 
. 0 . 
0 . 0 
 at (0,0)
  _01: point with color blue at (2,1)
  + 1 delta pixels
diff: 
   (42.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
0 . 0 
. 0 . 
 with color red at (0,0)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color red and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
. 0 . 
0 . 0 
 with color black at (0,0)
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (0,0)
  + 3 delta pixels
diff: 
! 4 wrong pixels (generated / expected)

TRAIN aedd82e4.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,4) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 . 
. . 0 
 with color red at (0,0)
  + 4 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,4) and color black and layers
  _0: rectangle with size (1,2) with model Full with color red at (0,0)
  + 6 delta pixels
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (5,4) and color black and layers
  _0: rectangle with size (2,1) with model Full with color red at (0,1)
  + 6 delta pixels
diff: 
! 7 wrong pixels (generated / expected)

TEST aedd82e4.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 2.1 sec (2.1 sec/task)
bits-train-error = 1325.8 bits (1325.8 bits/task)
acc-train-micro = 0.25 tasks (25.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.12
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-128] Checking task af902bf9.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.060	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.206	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.131	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.125	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.120	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.114	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.108	OUT ADD ^.layer_01111 = point with color ? at (?,?)
0.102	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.097	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.091	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.085	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.080	OUT SPE ^.size = ^.size
0.076	OUT SPE ^.layer_0111 = ^.layer_0111
0.071	OUT SPE ^.layer_011 = ^.layer_01
0.067	OUT SPE ^.layer_01111 = ^.layer_011
0.066	IN  SPE ^.layer_0.shape.color = yellow
0.064	IN  SPE ^.layer_01.shape.color = yellow
0.063	IN  SPE ^.layer_011.shape.color = yellow
0.062	IN  SPE ^.layer_0111.shape.color = yellow
0.060	OUT SPE ^.layer_01.pos.i = average(^.layer_0.pos.i, ^.layer_01.pos.i)
0.057	OUT SPE ^.layer_01 = ^.layer_0
0.056	OUT SPE ^.layer_0.shape.color = red
0.055	OUT SPE ^.layer_0.pos.j = center(^.layer_0111)
0.054	OUT SPE ^.layer_0.pos.i = middle(^.layer_0111) - ^.layer_011.pos.j - ^.layer_0.pos.j
0.053	OUT SPE ^.layer_0.shape.mask.model = Full
0.053	IN  SPE ^.color = black
0.052	OUT SPE ^.color = black
0.022	
0.022	IN  GEN ^.layer_0111.shape.color = ?
0.022	IN  GEN ^.layer_011.shape.color = ?
0.022	IN  GEN ^.layer_01.shape.color = ?
0.022	IN  GEN ^.layer_0.shape.color = ?
0.022	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model Full with color red at (middle(^.layer_0111) - ^.layer_011.pos.j - ^.layer_0.pos.j,center(^.layer_0111))
  _01: ^.layer_0
  _011: ^.layer_01
  _0111: ^.layer_0111
  _01111: ^.layer_011
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color yellow at (?,?)
  _01: point with color yellow at (?,?)
  _011: point with color yellow at (?,?)
  _0111: point with color yellow at (?,?)

DL input  with Mi: L = 100.0 + 3639.8 = 3739.7
DL output with Mo: L = 152.2 + 2367.1 = 2519.3
DL input+output M: L = 252.1 + 6006.9 = 6259.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model Full with color red at (middle(^.layer_0111) - ^.layer_011.pos.j - ^.layer_0.pos.j,center(^.layer_0111))
  _01: ^.layer_0
  _011: ^.layer_01
  _0111: ^.layer_0111
  _01111: ^.layer_011
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 86.6 + 60.0 = 146.6
DL output with Mo: L = 152.2 + 2367.1 = 2519.3
DL input+output M: L = 238.8 + 2427.1 = 2665.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (3,3)
  _01: point with color yellow at (3,5)
  _011: point with color yellow at (5,5)
  _0111: point with color yellow at (5,3)
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (4,4)
  _01: 
4 
 at (3,3)
  _011: 
4 
 at (3,5)
  _0111: 
4 
 at (5,3)
  _01111: 
4 
 at (5,5)
diff: 
   (6.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (3,3)
  _01: point with color yellow at (3,5)
  _011: point with color yellow at (5,3)
  _0111: point with color yellow at (5,5)
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (3,3)
  _01: point with color yellow at (3,5)
  _011: point with color yellow at (5,5)
  _0111: point with color yellow at (5,3)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (3,3)
  _01: point with color yellow at (5,3)
  _011: point with color yellow at (3,5)
  _0111: point with color yellow at (5,5)
diff: 
! 5 wrong pixels (generated / expected)

TRAIN af902bf9.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (1,1)
  _01: point with color yellow at (1,6)
  _011: point with color yellow at (6,6)
  _0111: point with color yellow at (6,1)
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with model Full with color red at (2,2)
  _01: 
4 
 at (1,1)
  _011: 
4 
 at (1,6)
  _0111: 
4 
 at (6,1)
  _01111: 
4 
 at (6,6)
diff: 
   (14.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (1,1)
  _01: point with color yellow at (1,6)
  _011: point with color yellow at (6,1)
  _0111: point with color yellow at (6,6)
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (1,1)
  _01: point with color yellow at (1,6)
  _011: point with color yellow at (6,6)
  _0111: point with color yellow at (6,1)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (1,1)
  _01: point with color yellow at (6,1)
  _011: point with color yellow at (1,6)
  _0111: point with color yellow at (6,6)
diff: 
! 20 wrong pixels (generated / expected)

TRAIN af902bf9.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (1,1)
  _01: point with color yellow at (1,3)
  _011: point with color yellow at (3,1)
  _0111: point with color yellow at (6,4)
  + 4 delta pixels
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,4) with model Full with color red at (7,5)
  _01: 
4 
 at (1,1)
  _011: 
4 
 at (1,3)
  _0111: 
4 
 at (6,4)
  _01111: 
4 
 at (3,1)
  + 5 delta pixels
diff: 
   (215.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (1,1)
  _01: point with color yellow at (1,3)
  _011: point with color yellow at (3,1)
  _0111: point with color yellow at (3,3)
  + 4 delta pixels
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (1,1)
  _01: point with color yellow at (1,3)
  _011: point with color yellow at (3,1)
  _0111: point with color yellow at (6,4)
  + 4 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (1,1)
  _01: point with color yellow at (1,3)
  _011: point with color yellow at (3,3)
  _0111: point with color yellow at (3,1)
  + 4 delta pixels
diff: 
! 15 wrong pixels (generated / expected)

TRAIN af902bf9.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (0,5)
  _01: point with color yellow at (0,9)
  _011: point with color yellow at (4,5)
  _0111: point with color yellow at (4,9)
  + 4 delta pixels
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (0,5)
  _01: point with color yellow at (0,9)
  _011: point with color yellow at (4,5)
  _0111: point with color yellow at (5,0)
  + 4 delta pixels
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (0,5)
  _01: point with color yellow at (0,9)
  _011: point with color yellow at (4,9)
  _0111: point with color yellow at (4,5)
  + 4 delta pixels
diff: 
! 13 wrong pixels (generated / expected)

TEST af902bf9.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 33.6 sec (33.6 sec/task)
bits-train-error = 2367.1 bits (2367.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-127] Checking task b0c4d837.json: 6 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 141409.8 = 141412.2
DL output with Mo: L = 2.3 + 21069.6 = 21071.9
DL input+output M: L = 4.6 + 162479.4 = 162484.1

# learning a model for train pairs
2.000	
1.311	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.703	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.483	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.292	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.171	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.134	OUT SPE ^.size = '(3, 3)
0.112	OUT SPE ^.layer_0.pos = '(0, 0)
0.096	OUT SPE ^.layer_0.shape.color = cyan
0.089	OUT SPE ^.color = black
0.087	IN  SPE ^.layer_0.shape.color = grey
0.085	IN  SPE ^.layer_01.shape.color = cyan
0.083	IN  SPE ^.layer_01.shape.mask.model = Full
0.082	IN  SPE ^.color = black
0.040	
0.039	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: rectangle with size (?,?) with model ? with color cyan at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)
  _01: rectangle with size (?,?) with model Full with color cyan at (?,?)

DL input  with Mi: L = 77.5 + 6030.4 = 6107.9
DL output with Mo: L = 56.5 + 767.5 = 824.0
DL input+output M: L = 134.0 + 6797.9 = 6931.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: rectangle with size (?,?) with model ? with color cyan at '(0, 0)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 56.5 + 767.5 = 824.0
DL input+output M: L = 58.8 + 767.5 = 826.3

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 0 0 
0 5#0 0 5#0 
0 5#0 0 5#0 
0 5#0 0 5#0 
0 5#8 8 5#0 
0 5#5#5#5#0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color cyan at (0,0)
diff: 
   (12.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 
0 5#0 0 5#0 
0 5#0 0 5#0 
0 5#0 0 5#0 
0 5#8 8 5#0 
0 5#5#5#5#0 

diff: 
! 3 wrong pixels (generated / expected)

TRAIN b0c4d837.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 
0 0 5#0 0 0 5#0 0 
0 0 5#0 0 0 5#0 0 
0 0 5#0 0 0 5#0 0 
0 0 5#0 0 0 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#5#5#5#5#0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color cyan at (0,0)
diff: 
   (19.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 
0 0 5#0 0 0 5#0 0 
0 0 5#0 0 0 5#0 0 
0 0 5#0 0 0 5#0 0 
0 0 5#0 0 0 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#5#5#5#5#0 0 

diff: 
! 4 wrong pixels (generated / expected)

TRAIN b0c4d837.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 5#0 0 0 0 0 5#0 
0 5#0 0 0 0 0 5#0 
0 5#0 0 0 0 0 5#0 
0 5#8 8 8 8 8 5#0 
0 5#8 8 8 8 8 5#0 
0 5#8 8 8 8 8 5#0 
0 5#5#5#5#5#5#5#0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color cyan at (0,0)
diff: 
   (12.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 5#0 0 0 0 0 5#0 
0 5#0 0 0 0 0 5#0 
0 5#0 0 0 0 0 5#0 
0 5#8 8 8 8 8 5#0 
0 5#8 8 8 8 8 5#0 
0 5#8 8 8 8 8 5#0 
0 5#5#5#5#5#5#5#0 

diff: 
! 3 wrong pixels (generated / expected)

TRAIN b0c4d837.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 5#0 0 0 5#0 0 
0 0 5#0 0 0 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#5#5#5#5#0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,2) with model Full with color cyan at (0,0)
diff: 
   (11.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 5#0 0 0 5#0 0 
0 0 5#0 0 0 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#5#5#5#5#0 0 

diff: 
! 2 wrong pixels (generated / expected)

TRAIN b0c4d837.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: 
0 0 0 0 0 0 
0 5#0 0 5#0 
0 5#8 8 5#0 
0 5#8 8 5#0 
0 5#5#5#5#0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (0,0)
diff: 
   (9.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 
0 5#0 0 5#0 
0 5#8 8 5#0 
0 5#8 8 5#0 
0 5#5#5#5#0 

diff: 
! 3 wrong pixels (generated / expected)

TRAIN b0c4d837.json/5: 0 - (FAILURE)

## instance 6

> Input and output best reading:

data: 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 5#0 0 0 5#0 
0 5#0 0 0 5#0 
0 5#8 8 8 5#0 
0 5#8 8 8 5#0 
0 5#5#5#5#5#0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,2) with model Full with color cyan at (0,0)
diff: 
   (11.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 5#0 0 0 5#0 
0 5#0 0 0 5#0 
0 5#8 8 8 5#0 
0 5#8 8 8 5#0 
0 5#5#5#5#5#0 

diff: 
! 2 wrong pixels (generated / expected)

TRAIN b0c4d837.json/6: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 
0 0 5#0 0 0 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#8 8 8 5#0 0 
0 0 5#5#5#5#5#0 0 

diff: 
! 3 wrong pixels (generated / expected)

TEST b0c4d837.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 4.6 sec (4.6 sec/task)
bits-train-error = 767.5 bits (767.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-126] Checking task b190f7f5.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 26408.1 = 26410.5
DL output with Mo: L = 2.3 + 169420.7 = 169423.0
DL input+output M: L = 4.6 + 195828.8 = 195833.5

# learning a model for train pairs
2.000	
1.222	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.704	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.533	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.472	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.406	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.377	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.349	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.320	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.303	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.285	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.272	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.265	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.259	IN  SPE ^.layer_0.shape.color = cyan
0.253	IN  SPE ^.layer_01.shape.color = yellow
0.247	IN  SPE ^.layer_0111.shape.color = red
0.244	IN  SPE ^.color = black
0.243	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_0.shape.mask.size.i
0.092	
0.091	IN  DEL ^.layer_0111
0.090	IN  DEL ^.layer_01
0.089	IN  DEL ^.layer_011
0.089	IN  GEN ^.layer_0.shape.color = ?
0.089	IN  GEN ^.color = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color cyan at (?,?)
  _01: rectangle with size (?,?) with model ? with color yellow at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color red at (?,?)

DL input  with Mi: L = 135.9 + 3973.1 = 4108.9
DL output with Mo: L = 182.3 + 14590.1 = 14772.4
DL input+output M: L = 318.2 + 18563.1 = 18881.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 182.3 + 14590.1 = 14772.4
DL input+output M: L = 224.3 + 14590.1 = 14814.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,6) and color black and layers
  _0: rectangle with size (3,3) with model +-cross with color cyan at (0,3)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (3,1) with model Full with color red at (0,1)
  _01: rectangle with size (3,1) with model Full with color yellow at (0,7)
  _011: rectangle with size (3,1) with model Full with color green at (3,4)
  _0111: rectangle with size (1,3) with model Full with color red at (1,0)
  _01111: rectangle with size (1,3) with model Full with color yellow at (1,6)
  _011111: rectangle with size (1,3) with model Full with color green at (4,3)
diff: 
   (190.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (3,3) with model +-cross with color cyan at (0,3)
  + 3 delta pixels
diff: 
! size mismatch, 10x10 instead of 9x9
>> Trial 2
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (1,3) with model Full with color cyan at (1,3)
  + 5 delta pixels
diff: 
! size mismatch, 10x10 instead of 9x9

TRAIN b190f7f5.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,6) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color cyan at (1,0)
  + 6 delta pixels
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color yellow at (1,3)
  _01: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color blue at (4,0)
  _011: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color red at (4,3)
  _0111: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color yellow at (4,6)
  _01111: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color blue at (7,3)
  _011111: rectangle with size (1,1) with model Full with color yellow at (0,5)
  + 4 delta pixels
diff: 
   (363.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color cyan at (1,0)
  + 6 delta pixels
diff: 
! size mismatch, 10x10 instead of 9x9

TRAIN b190f7f5.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (4,8) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . 0 . 
0 0 0 0 
. . 0 . 
. . 0 . 
 with color cyan at (0,4)
  + 8 delta pixels
diff: 
   (0.0 bits)
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . 0 . 
0 0 0 0 
. . 0 . 
. . 0 . 
 with color red at (0,0)
  _01: rectangle with size (4,4) with mask 
. . 0 . 
0 0 0 0 
. . 0 . 
. . 0 . 
 with color yellow at (0,12)
  _011: rectangle with size (4,4) with mask 
. . 0 . 
0 0 0 0 
. . 0 . 
. . 0 . 
 with color red at (4,4)
  _0111: rectangle with size (4,4) with mask 
. . 0 . 
0 0 0 0 
. . 0 . 
. . 0 . 
 with color yellow at (4,8)
  _01111: rectangle with size (4,4) with mask 
. . 0 . 
0 0 0 0 
. . 0 . 
. . 0 . 
 with color yellow at (8,4)
  _011111: rectangle with size (4,4) with mask 
. . 0 . 
0 0 0 0 
. . 0 . 
. . 0 . 
 with color red at (8,8)
  + 14 delta pixels
diff: 
   (904.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,8) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . 0 . 
0 0 0 0 
. . 0 . 
. . 0 . 
 with color cyan at (0,4)
  + 8 delta pixels
diff: 
! size mismatch, 10x10 instead of 16x16
>> Trial 2
data: a background with size (4,8) and color black and layers
  _0: rectangle with size (1,4) with model Full with color cyan at (1,4)
  + 11 delta pixels
diff: 
! size mismatch, 10x10 instead of 16x16

TRAIN b190f7f5.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 0 . 
0 0 0 0 
0 . . 0 
0 0 0 0 
 with color cyan at (4,0)
  + 8 delta pixels
diff: 
! size mismatch, 10x10 instead of 16x16
>> Trial 2
data: a background with size (8,4) and color cyan and layers
  _0: rectangle with size (5,4) with mask 
. 0 0 . 
0 . . 0 
0 . . 0 
. 0 0 . 
0 . . 0 
 with color black at (0,0)
  + 10 delta pixels
diff: 
! size mismatch, 10x10 instead of 16x16

TEST b190f7f5.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 60.5 sec (60.5 sec/task)
bits-train-error = 14590.1 bits (14590.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-125] Checking task b1948b0a.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 20946.3 = 20948.6
DL output with Mo: L = 2.3 + 20946.3 = 20948.6
DL input+output M: L = 4.6 + 41892.5 = 41897.2

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = swapColor(^, pink, red)
0.487	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.108	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.096	IN  SPE ^.color = pink
0.088	IN  SPE ^.layer_0.shape.color = orange
0.003	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
swapColor(^, pink, red)
WHERE (Mi)
a background with size (?,?) and color pink and layers
  _0: rectangle with size (?,?) with model ? with color orange at (?,?)

DL input  with Mi: L = 51.9 + 1764.3 = 1816.2
DL output with Mo: L = 20.6 + 0.0 = 20.6
DL input+output M: L = 72.5 + 1764.3 = 1836.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
swapColor(^, pink, red)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 20.6 + 0.0 = 20.6
DL input+output M: L = 22.9 + 0.0 = 22.9

# train input/output grids

## instance 1

> Input and output best reading:

data: 
6 6 7#6 
6 6 7#7#
7#7#6 7#

diff: 
   (0.0 bits)
data: 
2 2 7#2 
2 2 7#7#
7#7#2 7#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
6 6 7#6 
6 6 7#7#
7#7#6 7#

diff: 
correct output grid

TRAIN b1948b0a.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
7#7#7#6 
6 6 7#6 
7#7#6 7#
7#6 7#7#
7#6 7#6 
6 6 6 7#

diff: 
   (0.0 bits)
data: 
7#7#7#2 
2 2 7#2 
7#7#2 7#
7#2 7#7#
7#2 7#2 
2 2 2 7#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
7#7#7#6 
6 6 7#6 
7#7#6 7#
7#6 7#7#
7#6 7#6 
6 6 6 7#

diff: 
correct output grid

TRAIN b1948b0a.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
7#7#6 6 6 6 
6 7#6 7#7#7#
7#6 7#7#6 7#

diff: 
   (0.0 bits)
data: 
7#7#2 2 2 2 
2 7#2 7#7#7#
7#2 7#7#2 7#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
7#7#6 6 6 6 
6 7#6 7#7#7#
7#6 7#7#6 7#

diff: 
correct output grid

TRAIN b1948b0a.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
6 7#7#6 
6 7#6 7#
7#7#7#6 
7#6 7#6 

diff: 
correct output grid

TEST b1948b0a.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 0.8 sec (0.8 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-124] Checking task b230c067.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79850.6 = 79852.9
DL output with Mo: L = 2.3 + 79850.6 = 79852.9
DL input+output M: L = 4.6 + 159701.1 = 159705.8

# learning a model for train pairs
2.000	
1.275	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.551	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.468	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.384	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.301	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.217	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.146	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.076	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.065	OUT SPE ^.layer_01 = coloring(^.layer_01, blue)
0.054	OUT SPE ^.layer_0 = coloring(^.layer_0, blue)
0.044	OUT SPE ^.layer_011 = coloring(^.layer_011, red)
0.039	OUT SPE ^.size = ^.size
0.038	IN  SPE ^.layer_0.shape.color = cyan
0.037	IN  SPE ^.layer_01.shape.color = cyan
0.035	IN  SPE ^.layer_011.shape.color = cyan
0.035	IN  SPE ^.color = black
0.034	OUT SPE ^.color = black
0.002	
0.002	IN  GEN ^.layer_011.shape.color = ?
0.002	IN  GEN ^.layer_01.shape.color = ?
0.002	IN  GEN ^.layer_0.shape.color = ?
0.002	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, blue)
  _01: coloring(^.layer_01, blue)
  _011: coloring(^.layer_011, red)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color cyan at (?,?)
  _01: rectangle with size (?,?) with model ? with color cyan at (?,?)
  _011: rectangle with size (?,?) with model ? with color cyan at (?,?)

DL input  with Mi: L = 108.2 + 2547.7 = 2655.8
DL output with Mo: L = 53.7 + 0.0 = 53.7
DL input+output M: L = 161.9 + 2547.7 = 2709.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, blue)
  _01: coloring(^.layer_01, blue)
  _011: coloring(^.layer_011, red)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 0.0 = 98.1
DL output with Mo: L = 53.7 + 0.0 = 53.7
DL input+output M: L = 151.8 + 0.0 = 151.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,4) with model Border with color cyan at (2,1)
  _01: rectangle with size (3,4) with model Border with color cyan at (7,5)
  _011: rectangle with size (3,3) with model Border with color cyan at (1,7)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
1 1 1 1 
1 . . 1 
1 1 1 1 
 at (2,1)
  _01: 
1 1 1 1 
1 . . 1 
1 1 1 1 
 at (7,5)
  _011: 
2 2 2 
2 . 2 
2 2 2 
 at (1,7)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,4) with model Border with color cyan at (2,1)
  _01: rectangle with size (3,4) with model Border with color cyan at (7,5)
  _011: rectangle with size (3,3) with model Border with color cyan at (1,7)
diff: 
correct output grid

TRAIN b230c067.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,5) with mask 
0 0 0 0 . 
. . 0 0 . 
. . 0 0 0 
 with color cyan at (2,1)
  _01: rectangle with size (3,5) with mask 
0 0 0 0 . 
. . 0 0 . 
. . 0 0 0 
 with color cyan at (6,3)
  _011: rectangle with size (3,4) with mask 
0 0 0 0 
. . 0 0 
. . 0 0 
 with color cyan at (1,6)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
1 1 1 1 . 
. . 1 1 . 
. . 1 1 1 
 at (2,1)
  _01: 
1 1 1 1 . 
. . 1 1 . 
. . 1 1 1 
 at (6,3)
  _011: 
2 2 2 2 
. . 2 2 
. . 2 2 
 at (1,6)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,5) with mask 
0 0 0 0 . 
. . 0 0 . 
. . 0 0 0 
 with color cyan at (2,1)
  _01: rectangle with size (3,5) with mask 
0 0 0 0 . 
. . 0 0 . 
. . 0 0 0 
 with color cyan at (6,3)
  _011: rectangle with size (3,4) with mask 
0 0 0 0 
. . 0 0 
. . 0 0 
 with color cyan at (1,6)
diff: 
correct output grid

TRAIN b230c067.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 . 
. . 0 . 
. 0 . . 
0 0 0 0 
 with color cyan at (1,6)
  _01: rectangle with size (4,4) with mask 
0 0 0 . 
. . 0 . 
. 0 . . 
0 0 0 0 
 with color cyan at (6,3)
  _011: rectangle with size (4,3) with mask 
0 0 . 
. 0 . 
0 . . 
0 0 0 
 with color cyan at (1,1)
diff: 
correct output grid

TEST b230c067.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 6.9 sec (6.9 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-123] Checking task b27ca6d3.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 209375.9 = 209378.2
DL output with Mo: L = 2.3 + 209375.9 = 209378.2
DL input+output M: L = 4.6 + 418751.7 = 418756.4

# learning a model for train pairs
2.000	
1.056	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.168	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.128	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.116	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.111	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.105	OUT ADD ^.layer_00 = ^.layer_0
0.102	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.099	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.096	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.092	OUT ADD ^.layer_010 = ^.layer_01
0.089	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.085	OUT ADD ^.layer_0101 = ^.layer_011
0.083	OUT ADD ^.layer_01111 = point with color ? at (?,?)
0.081	OUT SPE ^.size = ^.size
0.079	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.076	OUT SPE ^.layer_011 = ^.layer_0111
0.074	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.072	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.070	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.067	IN  ADD ^.layer_01111111 = point with color ? at (?,?)
0.065	OUT SPE ^.layer_0111 = ^.layer_01111
0.063	OUT SPE ^.layer_01111 = ^.layer_0111111
0.062	IN  SPE ^.layer_0.shape.mask = 
0 
0 

0.061	OUT SPE ^.layer_0.pos.j = ^.layer_0.pos.j - 1
0.061	IN  SPE ^.layer_0.shape.color = red
0.060	IN  SPE ^.layer_01.shape.color = red
0.060	IN  SPE ^.layer_011.shape.color = red
0.059	IN  SPE ^.layer_0111.shape.color = red
0.059	IN  SPE ^.layer_01111.shape.color = red
0.058	IN  SPE ^.layer_011111.shape.color = red
0.058	IN  SPE ^.layer_0111111.shape.color = red
0.057	OUT SPE ^.layer_0.shape.mask.size.j = area(^.layer_01.shape) + 2
0.056	IN  SPE ^.layer_01111111.shape.color = red
0.056	OUT SPE ^.layer_0.shape.color = green
0.055	OUT SPE ^.layer_0.pos.i = ^.layer_0.pos.i / '2
0.055	OUT SPE ^.layer_01.shape.mask.size.i = ^.layer_01.shape.mask.size.j
0.055	OUT SPE ^.layer_01.pos.i = middle(^.layer_0111) - ^.layer_0111111.pos.j - ^.layer_01.pos.j
0.054	OUT SPE ^.layer_01.pos.j = ^.layer_0111111.pos.i - ^.layer_0111.pos.i - ^.layer_011.pos.i
0.054	OUT SPE ^.layer_0.shape.mask.size.i = area(^.layer_01.shape) - ^.layer_01111.pos.j - ^.layer_0.pos.j
0.054	IN  SPE ^.layer_01.shape.mask.model = Full
0.054	IN  SPE ^.layer_011.shape.mask.model = Full
0.053	OUT SPE ^.layer_01.shape.mask.model = Full
0.053	IN  SPE ^.color = black
0.053	OUT SPE ^.color = black
0.053	OUT SPE ^.layer_01.shape.mask.size.j = ^.layer_01.shape.mask.size.i + ^.layer_01111111.pos.j - ^.layer_0111111.pos.j
0.025	
0.025	IN  GEN ^.layer_01111111.shape.color = ?
0.025	IN  GEN ^.layer_0111111.shape.color = ?
0.025	IN  GEN ^.layer_011111.shape.color = ?
0.025	IN  GEN ^.layer_01111.shape.color = ?
0.025	IN  GEN ^.layer_0111.shape.color = ?
0.025	IN  GEN ^.layer_011.shape.color = ?
0.025	IN  GEN ^.layer_01.shape.color = ?
0.025	IN  GEN ^.layer_0.shape.color = ?
0.025	IN  GEN ^.layer_011.shape.mask.model = ?
0.025	IN  GEN ^.layer_01.shape.mask.model = ?
0.025	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (area(^.layer_01.shape) - ^.layer_01111.pos.j - ^.layer_0.pos.j,area(^.layer_01.shape) + 2) with model ? with color green at (^.layer_0.pos.i / '2,^.layer_0.pos.j - 1)
  _010: ^.layer_01
  _0101: ^.layer_011
  _01: rectangle with size (^.layer_01.shape.mask.size.j,^.layer_01.shape.mask.size.i + ^.layer_01111111.pos.j - ^.layer_0111111.pos.j) with model Full with color ? at (middle(^.layer_0111) - ^.layer_0111111.pos.j - ^.layer_01.pos.j,^.layer_0111111.pos.i - ^.layer_0111.pos.i - ^.layer_011.pos.i)
  _011: ^.layer_0111
  _0111: ^.layer_01111
  _01111: ^.layer_0111111
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
0 
0 
 with color red at (?,?)
  _01: rectangle with size (?,?) with model Full with color red at (?,?)
  _011: rectangle with size (?,?) with model Full with color red at (?,?)
  _0111: point with color red at (?,?)
  _01111: point with color red at (?,?)
  _011111: point with color red at (?,?)
  _0111111: point with color red at (?,?)
  _01111111: point with color red at (?,?)

DL input  with Mi: L = 208.9 + 5712.8 = 5921.7
DL output with Mo: L = 470.3 + 4624.3 = 5094.6
DL input+output M: L = 679.2 + 10337.1 = 11016.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (area(^.layer_01.shape) - ^.layer_01111.pos.j - ^.layer_0.pos.j,area(^.layer_01.shape) + 2) with model ? with color green at (^.layer_0.pos.i / '2,^.layer_0.pos.j - 1)
  _010: ^.layer_01
  _0101: ^.layer_011
  _01: rectangle with size (^.layer_01.shape.mask.size.j,^.layer_01.shape.mask.size.i + ^.layer_01111111.pos.j - ^.layer_0111111.pos.j) with model Full with color ? at (middle(^.layer_0111) - ^.layer_0111111.pos.j - ^.layer_01.pos.j,^.layer_0111111.pos.i - ^.layer_0111.pos.i - ^.layer_011.pos.i)
  _011: ^.layer_0111
  _0111: ^.layer_01111
  _01111: ^.layer_0111111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 
0 
 with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)

DL input  with Mi: L = 181.3 + 0.0 = 181.3
DL output with Mo: L = 470.3 + 4624.3 = 5094.6
DL input+output M: L = 651.6 + 4624.3 = 5275.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (15,18) and color black and layers
  _0: 
0 
0 
 with color red at (2,7)
  _01: rectangle with size (1,1) with model Full with color red at (2,2)
  _011: rectangle with size (1,1) with model Full with color red at (4,13)
  _0111: point with color red at (8,17)
  _01111: point with color red at (11,4)
  _011111: point with color red at (11,8)
  _0111111: point with color red at (12,0)
  _01111111: point with color red at (14,0)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (15,18) and color black and layers
  _00: 
2 
2 
 at (2,7)
  _0: rectangle with size (4,3) with model Full with color green at (1,6)
  _010: 
2 
 at (2,2)
  _0101: 
2 
 at (4,13)
  _01: rectangle with size (1,1) with model Full with color red at (11,8)
  _011: 
2 
 at (8,17)
  _0111: 
2 
 at (11,4)
  _01111: 
2 
 at (12,0)
  + 2 delta pixels
diff: 
   (93.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,18) and color black and layers
  _0: 
0 
0 
 with color red at (2,7)
  _01: rectangle with size (1,1) with model Full with color red at (2,2)
  _011: rectangle with size (1,1) with model Full with color red at (4,13)
  _0111: point with color red at (8,17)
  _01111: point with color red at (11,4)
  _011111: point with color red at (11,8)
  _0111111: point with color red at (12,0)
  _01111111: point with color red at (14,0)
  + 1 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,18) and color black and layers
  _0: 
0 
0 
 with color red at (2,7)
  _01: rectangle with size (1,1) with model Full with color red at (2,2)
  _011: rectangle with size (1,1) with model Full with color red at (4,13)
  _0111: point with color red at (8,17)
  _01111: point with color red at (11,4)
  _011111: point with color red at (11,8)
  _0111111: point with color red at (12,0)
  _01111111: point with color red at (14,17)
  + 1 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,18) and color black and layers
  _0: 
0 
0 
 with color red at (2,7)
  _01: rectangle with size (1,1) with model Full with color red at (2,2)
  _011: rectangle with size (1,1) with model Full with color red at (4,13)
  _0111: point with color red at (8,17)
  _01111: point with color red at (11,4)
  _011111: point with color red at (11,8)
  _0111111: point with color red at (14,0)
  _01111111: point with color red at (12,0)
  + 1 delta pixels
diff: 
! 4 wrong pixels (generated / expected)

TRAIN b27ca6d3.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (15,16) and color black and layers
  _0: 
0 
0 
 with color red at (0,13)
  _01: rectangle with size (1,2) with model Full with color red at (0,8)
  _011: rectangle with size (2,1) with model Full with color red at (4,15)
  _0111: point with color red at (1,0)
  _01111: point with color red at (3,8)
  _011111: point with color red at (4,2)
  _0111111: point with color red at (4,10)
  _01111111: point with color red at (4,13)
  + 6 delta pixels
diff: 
   (0.0 bits)
data: a background with size (15,16) and color black and layers
  _00: 
2 
2 
 at (0,13)
  _0: rectangle with size (7,4) with mask 
0 . 0 . 
0 . 0 . 
0 0 0 . 
. . 0 0 
. . 0 . 
. . 0 . 
. . 0 0 
 with color green at (0,12)
  _010: 
2 2 
 at (0,8)
  _0101: 
2 
2 
 at (4,15)
  _01: rectangle with size (2,4) with model Full with color green at (0,7)
  _011: 
2 
 at (1,0)
  _0111: 
2 
 at (3,8)
  _01111: 
2 
 at (4,10)
  + 8 delta pixels
diff: 
   (368.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,16) and color black and layers
  _0: 
0 
0 
 with color red at (0,13)
  _01: rectangle with size (1,2) with model Full with color red at (0,8)
  _011: rectangle with size (2,1) with model Full with color red at (4,15)
  _0111: point with color red at (1,0)
  _01111: point with color red at (3,8)
  _011111: point with color red at (4,2)
  _0111111: point with color red at (4,10)
  _01111111: point with color red at (4,13)
  + 6 delta pixels
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,16) and color black and layers
  _0: 
0 
0 
 with color red at (0,13)
  _01: rectangle with size (1,2) with model Full with color red at (0,8)
  _011: rectangle with size (2,1) with model Full with color red at (4,15)
  _0111: point with color red at (1,0)
  _01111: point with color red at (3,8)
  _011111: point with color red at (4,2)
  _0111111: point with color red at (4,10)
  _01111111: point with color red at (6,10)
  + 6 delta pixels
diff: 
! 26 wrong pixels (generated / expected)

TRAIN b27ca6d3.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,16) and color black and layers
  _0: 
0 
0 
 with color red at (8,14)
  _01: rectangle with size (1,3) with model Full with color red at (3,13)
  _011: rectangle with size (1,2) with model Full with color red at (4,8)
  _0111: point with color red at (0,15)
  _01111: point with color red at (1,4)
  _011111: point with color red at (5,12)
  _0111111: point with color red at (7,2)
  _01111111: point with color red at (9,6)
  + 18 delta pixels
diff: 
! 88 wrong pixels (generated / expected)

TEST b27ca6d3.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 56.8 sec (56.8 sec/task)
bits-train-error = 4624.3 bits (4624.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-122] Checking task b2862040.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 241405.6 = 241408.0
DL output with Mo: L = 2.3 + 241405.6 = 241408.0
DL input+output M: L = 4.6 + 482811.3 = 482815.9

# learning a model for train pairs
2.000	
1.270	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.540	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.339	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.263	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.205	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.163	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.135	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.112	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.098	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.051	
0.050	IN  GEN ^ = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 11309.1 = 11379.3
DL output with Mo: L = 153.4 + 12024.2 = 12177.5
DL input+output M: L = 223.6 + 23333.2 = 23556.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 153.4 + 12024.2 = 12177.5
DL input+output M: L = 155.7 + 12024.2 = 12179.9

# train input/output grids

## instance 1

> Input and output best reading:

data: 
9#9#9#9#9#9#9#9#9#9#9#
9#9#9#9#9#9#9#9#9#9#9#
9#1 1 1 9#9#9#1 9#9#9#
9#1 9#1 9#9#9#1 9#9#9#
9#1 9#1 9#9#1 1 1 1 9#
9#1 1 1 9#9#9#1 9#9#9#
9#9#9#9#9#9#9#1 9#9#9#
9#9#9#9#9#9#9#9#9#9#9#
9#9#9#9#9#9#9#9#9#9#9#

diff: 
   (0.0 bits)
data: a background with size (9,11) and color brown and layers
  _0: rectangle with size (5,4) with mask 
. 0 . . 
. 0 . . 
0 0 0 0 
. 0 . . 
. 0 . . 
 with color blue at (2,6)
  _01: rectangle with size (4,1) with model Full with color cyan at (2,1)
  _011: rectangle with size (4,1) with model Full with color cyan at (2,3)
  _0111: rectangle with size (1,3) with model Full with color cyan at (2,1)
  _01111: rectangle with size (1,3) with model Full with color cyan at (5,1)
diff: 
   (202.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
9#9#9#9#9#9#9#9#9#9#9#
9#9#9#9#9#9#9#9#9#9#9#
9#1 1 1 9#9#9#1 9#9#9#
9#1 9#1 9#9#9#1 9#9#9#
9#1 9#1 9#9#1 1 1 1 9#
9#1 1 1 9#9#9#1 9#9#9#
9#9#9#9#9#9#9#1 9#9#9#
9#9#9#9#9#9#9#9#9#9#9#
9#9#9#9#9#9#9#9#9#9#9#

diff: 
! size mismatch, 10x10 instead of 9x11

TRAIN b2862040.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
9#9#9#9#9#9#9#9#9#9#9#
9#1 1 1 1 1 9#9#1 9#9#
9#1 9#9#9#1 9#9#1 9#1 
9#1 1 1 1 1 9#9#1 1 1 
9#9#9#9#9#9#9#9#9#9#9#
9#9#9#9#9#9#9#9#9#9#9#
9#9#9#1 9#9#9#9#9#9#9#
9#9#1 1 1 1 1 9#9#9#9#
9#9#9#1 9#1 9#9#9#9#9#
9#9#9#1 1 1 9#9#1 1 1 
9#9#9#9#9#9#9#9#1 9#1 
1 1 9#9#9#9#9#9#1 1 1 

diff: 
   (0.0 bits)
data: a background with size (12,11) and color brown and layers
  _0: rectangle with size (3,5) with model Border with color cyan at (1,1)
  _01: rectangle with size (4,5) with mask 
. 0 . . . 
0 0 0 0 0 
. 0 . 0 . 
. 0 0 0 . 
 with color cyan at (6,2)
  _011: rectangle with size (3,3) with model Border with color cyan at (9,8)
  _0111: rectangle with size (3,3) with mask 
0 . . 
0 . 0 
0 0 0 
 with color blue at (1,8)
  _01111: rectangle with size (1,2) with model Full with color blue at (11,0)
diff: 
   (227.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
9#9#9#9#9#9#9#9#9#9#9#
9#1 1 1 1 1 9#9#1 9#9#
9#1 9#9#9#1 9#9#1 9#1 
9#1 1 1 1 1 9#9#1 1 1 
9#9#9#9#9#9#9#9#9#9#9#
9#9#9#9#9#9#9#9#9#9#9#
9#9#9#1 9#9#9#9#9#9#9#
9#9#1 1 1 1 1 9#9#9#9#
9#9#9#1 9#1 9#9#9#9#9#
9#9#9#1 1 1 9#9#1 1 1 
9#9#9#9#9#9#9#9#1 9#1 
1 1 9#9#9#9#9#9#1 1 1 

diff: 
! size mismatch, 10x10 instead of 12x11

TRAIN b2862040.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
9#9#9#9#9#1 9#9#9#9#9#9#9#
9#9#9#9#9#9#9#9#1 9#9#9#9#
9#9#1 9#9#9#9#1 1 1 1 9#9#
9#1 1 1 1 9#9#9#1 9#9#9#9#
9#1 9#9#1 9#9#9#1 9#9#9#9#
9#1 1 1 1 9#9#9#1 1 1 9#9#
9#9#9#9#1 9#9#9#9#9#9#9#9#
9#9#9#9#1 9#9#9#9#9#9#9#9#
9#1 9#9#9#9#9#1 1 1 9#9#9#
1 1 1 9#9#9#9#9#9#1 9#9#9#
9#1 9#9#9#9#1 9#1 1 9#9#9#
1 1 9#9#9#9#1 1 1 9#9#9#9#

diff: 
   (0.0 bits)
data: a background with size (12,13) and color brown and layers
  _0: rectangle with size (6,4) with mask 
. 0 . . 
0 0 0 0 
0 . . 0 
0 0 0 0 
. . . 0 
. . . 0 
 with color cyan at (2,1)
  _01: rectangle with size (5,4) with mask 
. 0 . . 
0 0 0 0 
. 0 . . 
. 0 . . 
. 0 0 0 
 with color blue at (1,7)
  _011: rectangle with size (4,4) with mask 
. 0 0 0 
. . . 0 
0 . 0 0 
0 0 0 . 
 with color blue at (8,6)
  _0111: rectangle with size (4,3) with mask 
. 0 . 
0 0 0 
. 0 . 
0 0 . 
 with color blue at (8,0)
  _01111: rectangle with size (1,1) with model Full with color blue at (0,5)
diff: 
   (267.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
9#9#9#9#9#1 9#9#9#9#9#9#9#
9#9#9#9#9#9#9#9#1 9#9#9#9#
9#9#1 9#9#9#9#1 1 1 1 9#9#
9#1 1 1 1 9#9#9#1 9#9#9#9#
9#1 9#9#1 9#9#9#1 9#9#9#9#
9#1 1 1 1 9#9#9#1 1 1 9#9#
9#9#9#9#1 9#9#9#9#9#9#9#9#
9#9#9#9#1 9#9#9#9#9#9#9#9#
9#1 9#9#9#9#9#1 1 1 9#9#9#
1 1 1 9#9#9#9#9#9#1 9#9#9#
9#1 9#9#9#9#1 9#1 1 9#9#9#
1 1 9#9#9#9#1 1 1 9#9#9#9#

diff: 
! size mismatch, 10x10 instead of 12x13

TRAIN b2862040.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: 
9#9#9#9#9#9#9#9#9#9#9#9#9#9#9#
9#1 1 1 1 1 1 9#9#9#9#1 1 1 1 
9#9#1 9#9#9#1 9#9#9#9#1 9#9#1 
9#9#1 1 1 9#1 9#9#9#1 1 1 9#1 
9#9#9#9#1 1 1 9#9#9#9#9#9#9#1 
9#9#9#9#1 9#9#9#1 1 1 9#9#9#9#
9#9#9#9#9#9#9#9#1 9#1 1 9#9#9#
9#9#9#9#9#9#9#9#1 1 1 9#9#9#9#
1 1 1 1 9#9#9#9#9#9#9#9#9#9#9#
1 9#9#1 9#9#9#1 9#1 9#9#9#9#9#
1 1 1 1 9#9#9#1 1 1 1 1 9#9#9#
1 9#9#9#9#9#9#9#9#1 9#9#9#9#9#
9#9#9#9#9#1 9#9#9#9#9#9#9#9#9#
9#9#9#9#1 1 9#9#9#9#9#9#1 1 9#

diff: 
   (0.0 bits)
data: a background with size (14,15) and color brown and layers
  _0: rectangle with size (5,6) with mask 
0 0 0 0 0 0 
. 0 . . . 0 
. 0 0 0 . 0 
. . . 0 0 0 
. . . 0 . . 
 with color cyan at (1,1)
  _01: rectangle with size (4,5) with mask 
. 0 0 0 0 
. 0 . . 0 
0 0 0 . 0 
. . . . 0 
 with color blue at (1,10)
  _011: rectangle with size (4,4) with mask 
0 0 0 0 
0 . . 0 
0 0 0 0 
0 . . . 
 with color cyan at (8,0)
  _0111: rectangle with size (3,4) with mask 
0 0 0 . 
0 . 0 0 
0 0 0 . 
 with color cyan at (5,8)
  _01111: rectangle with size (3,5) with mask 
0 . 0 . . 
0 0 0 0 0 
. . 0 . . 
 with color blue at (9,7)
  + 5 delta pixels
diff: 
   (504.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
9#9#9#9#9#9#9#9#9#9#9#9#9#9#9#
9#1 1 1 1 1 1 9#9#9#9#1 1 1 1 
9#9#1 9#9#9#1 9#9#9#9#1 9#9#1 
9#9#1 1 1 9#1 9#9#9#1 1 1 9#1 
9#9#9#9#1 1 1 9#9#9#9#9#9#9#1 
9#9#9#9#1 9#9#9#1 1 1 9#9#9#9#
9#9#9#9#9#9#9#9#1 9#1 1 9#9#9#
9#9#9#9#9#9#9#9#1 1 1 9#9#9#9#
1 1 1 1 9#9#9#9#9#9#9#9#9#9#9#
1 9#9#1 9#9#9#1 9#1 9#9#9#9#9#
1 1 1 1 9#9#9#1 1 1 1 1 9#9#9#
1 9#9#9#9#9#9#9#9#1 9#9#9#9#9#
9#9#9#9#9#1 9#9#9#9#9#9#9#9#9#
9#9#9#9#1 1 9#9#9#9#9#9#1 1 9#

diff: 
! size mismatch, 10x10 instead of 14x15

TRAIN b2862040.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 9#9#9#9#9#9#9#9#9#9#9#9#9#
9#9#9#9#9#9#9#9#9#9#9#1 9#9#9#
9#9#9#1 1 1 1 1 9#9#9#1 9#9#9#
9#9#9#9#1 9#9#1 9#9#9#1 9#9#9#
9#9#9#9#1 9#9#1 9#9#9#1 9#9#9#
9#9#9#9#1 1 1 1 9#9#9#1 9#9#1 
9#9#9#9#9#9#9#1 9#9#9#1 1 1 1 
1 1 1 1 9#9#9#1 9#9#9#1 9#9#1 
1 9#9#1 9#9#9#9#9#9#9#9#9#9#1 
1 9#9#1 9#9#9#9#9#9#9#9#9#1 1 
1 1 9#9#9#9#9#9#9#9#9#9#9#9#9#
9#9#9#9#9#9#9#9#9#9#9#9#9#9#9#
9#9#9#1 1 1 1 1 1 9#9#9#1 1 9#
9#9#9#1 9#9#9#9#1 9#9#9#9#1 9#
9#9#9#1 9#9#9#9#1 9#9#9#9#1 9#
9#9#9#1 1 1 1 1 1 1 9#9#9#1 9#

diff: 
! size mismatch, 10x10 instead of 16x15

TEST b2862040.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.5 sec (59.5 sec/task)
bits-train-error = 12024.2 bits (12024.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-121] Checking task b527c5c6.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 539636.5 = 539638.9
DL output with Mo: L = 2.3 + 539636.5 = 539638.9
DL input+output M: L = 4.6 + 1079273.1 = 1079277.7

# learning a model for train pairs
2.000	
1.234	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.628	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.360	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.229	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.140	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.070	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.048	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.043	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.041	IN  ADD ^.layer_010 = point with color ? at (?,?)
0.039	OUT SPE ^.size = ^.size
0.038	IN  ADD ^.layer_0101 = point with color ? at (?,?)
0.037	OUT SPE ^.layer_01.shape.mask.size.j = ^.layer_01.shape.mask.size.j
0.036	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_0.shape.mask.size.i
0.036	OUT SPE ^.layer_01.pos.j = ^.layer_01.pos.j
0.035	OUT SPE ^.layer_0.pos.i = ^.layer_0.pos.i
0.035	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.035	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.034	IN  SPE ^.layer_0.shape.color = green
0.034	IN  SPE ^.layer_010.shape.color = red
0.033	OUT SPE ^.layer_011.pos.j = ^.layer_010.pos.j
0.033	OUT SPE ^.layer_0111.pos.i = ^.layer_0101.pos.i
0.033	IN  SPE ^.layer_01.shape.color = green
0.032	OUT SPE ^.layer_011.shape.color = red
0.032	OUT SPE ^.layer_0111.shape.color = red
0.031	OUT SPE ^.layer_011.shape.mask.size.j = 1
0.031	OUT SPE ^.layer_0111.shape.mask.size.i = 1
0.031	OUT SPE ^.layer_011.shape.mask.model = Full
0.022	
0.022	IN  GEN ^.layer_01.shape.color = ?
0.022	IN  GEN ^.layer_0.shape.color = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i,?) with model ? with color ^.layer_0.shape.color at (^.layer_0.pos.i,?)
  _01: rectangle with size (?,^.layer_01.shape.mask.size.j) with model ? with color ^.layer_01.shape.color at (?,^.layer_01.pos.j)
  _011: rectangle with size (?,1) with model Full with color red at (?,^.layer_010.pos.j)
  _0111: rectangle with size (1,?) with model ? with color red at (^.layer_0101.pos.i,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color green at (?,?)
  _010: point with color red at (?,?)
  _0101: point with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color green at (?,?)

DL input  with Mi: L = 116.1 + 5122.1 = 5238.2
DL output with Mo: L = 175.0 + 11315.0 = 11490.0
DL input+output M: L = 291.1 + 16437.1 = 16728.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i,?) with model ? with color ^.layer_0.shape.color at (^.layer_0.pos.i,?)
  _01: rectangle with size (?,^.layer_01.shape.mask.size.j) with model ? with color ^.layer_01.shape.color at (?,^.layer_01.pos.j)
  _011: rectangle with size (?,1) with model Full with color red at (?,^.layer_010.pos.j)
  _0111: rectangle with size (1,?) with model ? with color red at (^.layer_0101.pos.i,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: point with color red at (?,?)
  _0101: point with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 109.5 + 31.7 = 141.2
DL output with Mo: L = 175.0 + 11315.0 = 11490.0
DL input+output M: L = 284.5 + 11346.7 = 11631.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,2) with mask 
0 0 
0 0 
. 0 
0 0 
0 0 
0 0 
 with color green at (2,3)
  _010: point with color red at (5,8)
  _0101: point with color red at (4,3)
  _01: rectangle with size (2,4) with model Full with color green at (4,6)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,5) with mask 
. . . 0 0 
0 0 0 0 0 
. . . . 0 
0 0 0 0 0 
. . . 0 0 
. . . 0 0 
 with color green at (2,0)
  _01: rectangle with size (6,4) with mask 
0 0 0 0 
0 0 . 0 
. 0 . 0 
. 0 . 0 
. 0 . 0 
. 0 . 0 
 with color green at (4,6)
  _011: rectangle with size (5,1) with model Full with color red at (5,8)
  _0111: rectangle with size (1,4) with model Full with color red at (4,0)
diff: 
   (117.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,2) with mask 
0 0 
0 0 
. 0 
0 0 
0 0 
0 0 
 with color green at (2,3)
  _010: point with color red at (5,8)
  _0101: point with color red at (4,3)
  _01: rectangle with size (2,4) with model Full with color green at (4,6)
diff: 
! 51 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,2) with mask 
0 0 
0 0 
. 0 
0 0 
0 0 
0 0 
 with color green at (2,3)
  _010: point with color red at (4,3)
  _0101: point with color red at (5,8)
  _01: rectangle with size (2,4) with model Full with color green at (4,6)
diff: 
! 53 wrong pixels (generated / expected)

TRAIN b527c5c6.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (10,3) with mask 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 . 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
 with color green at (10,7)
  _010: point with color red at (4,14)
  _0101: point with color red at (15,9)
  _01: rectangle with size (2,18) with model Full with color green at (4,1)
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (10,13) with mask 
0 0 0 . . . . . . . . . . 
0 0 0 . . . . . . . . . . 
0 0 0 . . . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 . . . . . . . . . . 
0 0 0 . . . . . . . . . . 
 with color green at (10,7)
  _01: rectangle with size (6,18) with mask 
. . . . . . . . . . . . 0 . 0 . . . 
. . . . . . . . . . . . 0 . 0 . . . 
. . . . . . . . . . . . 0 . 0 . . . 
. . . . . . . . . . . . 0 . 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color green at (0,1)
  _011: rectangle with size (5,1) with model Full with color red at (0,14)
  _0111: rectangle with size (1,11) with model Full with color red at (15,9)
diff: 
   (311.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (10,3) with mask 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 . 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
 with color green at (10,7)
  _010: point with color red at (4,14)
  _0101: point with color red at (15,9)
  _01: rectangle with size (2,18) with model Full with color green at (4,1)
diff: 
! 174 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (10,3) with mask 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 . 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
 with color green at (10,7)
  _010: point with color red at (15,9)
  _0101: point with color red at (4,14)
  _01: rectangle with size (2,18) with model Full with color green at (4,1)
diff: 
! 175 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (2,18) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color green at (4,1)
  _010: point with color red at (4,14)
  _0101: point with color red at (15,9)
  _01: rectangle with size (10,3) with model Full with color green at (10,7)
diff: 
! 134 wrong pixels (generated / expected)

TRAIN b527c5c6.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (11,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
. 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
 with color green at (9,10)
  _010: point with color red at (3,5)
  _0101: point with color red at (14,10)
  _01: rectangle with size (3,14) with model Full with color green at (3,0)
diff: 
   (3.2 bits)
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (11,15) with mask 
. . . . . . . . . . 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . 0 0 0 0 0 
 with color green at (9,0)
  _01: rectangle with size (6,14) with mask 
. . . 0 0 . 0 0 . . . . . . 
. . . 0 0 . 0 0 . . . . . . 
. . . 0 0 . 0 0 . . . . . . 
0 0 0 0 0 . 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color green at (0,0)
  _011: rectangle with size (4,1) with model Full with color red at (0,5)
  _0111: rectangle with size (1,11) with model Full with color red at (14,0)
diff: 
   (271.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (3,14) with mask 
0 0 0 0 0 . 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color green at (3,0)
  _010: point with color red at (3,5)
  _0101: point with color red at (14,10)
  _01: rectangle with size (11,5) with model Full with color green at (9,10)
diff: 
! 202 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (3,14) with mask 
0 0 0 0 0 . 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color green at (3,0)
  _010: point with color red at (14,10)
  _0101: point with color red at (3,5)
  _01: rectangle with size (11,5) with model Full with color green at (9,10)
diff: 
! 206 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (11,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
. 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
 with color green at (9,10)
  _010: point with color red at (3,5)
  _0101: point with color red at (14,10)
  _01: rectangle with size (3,14) with model Full with color green at (3,0)
diff: 
! 200 wrong pixels (generated / expected)

TRAIN b527c5c6.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (11,4) with mask 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 . 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color green at (6,12)
  _010: point with color red at (4,4)
  _0101: point with color red at (12,15)
  _01: rectangle with size (5,15) with model Full with color green at (0,0)
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (11,8) with mask 
0 0 0 0 . . . . 
0 0 0 0 . . . . 
0 0 0 0 . . . . 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 . . . . . 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 . . . . 
 with color green at (6,12)
  _01: rectangle with size (20,15) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 . . . . . . 
0 0 0 0 . 0 0 0 0 . . . . . . 
0 0 0 0 . 0 0 0 0 . . . . . . 
0 0 0 0 . 0 0 0 0 . . . . . . 
0 0 0 0 . 0 0 0 0 . . . . . . 
0 0 0 0 . 0 0 0 0 . . . . . . 
0 0 0 0 . 0 0 0 0 . . . . . . 
0 0 0 0 . 0 0 0 0 . . . . . . 
0 0 0 0 . 0 0 0 0 . . . . . . 
0 0 0 0 . 0 0 0 0 . . . . . . 
0 0 0 0 . 0 0 0 0 . . . . . . 
0 0 0 0 . 0 0 0 0 . . . . . . 
0 0 0 0 . 0 0 0 0 . . . . . . 
0 0 0 0 . 0 0 0 0 . . . . . . 
0 0 0 0 . 0 0 0 0 . . . . . . 
 with color green at (0,0)
  _011: rectangle with size (16,1) with model Full with color red at (4,4)
  _0111: rectangle with size (1,5) with model Full with color red at (12,15)
diff: 
   (431.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (11,4) with mask 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 . 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color green at (6,12)
  _010: point with color red at (4,4)
  _0101: point with color red at (12,15)
  _01: rectangle with size (5,15) with model Full with color green at (0,0)
diff: 
! 230 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (11,4) with mask 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 . 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color green at (6,12)
  _010: point with color red at (12,15)
  _0101: point with color red at (4,4)
  _01: rectangle with size (5,15) with model Full with color green at (0,0)
diff: 
! 232 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (5,15) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 0 0 0 0 0 0 
 with color green at (0,0)
  _010: point with color red at (4,4)
  _0101: point with color red at (12,15)
  _01: rectangle with size (11,4) with model Full with color green at (6,12)
diff: 
! 268 wrong pixels (generated / expected)

TRAIN b527c5c6.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (11,3) with mask 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
. 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
 with color green at (0,4)
  _010: point with color red at (5,4)
  _0101: point with color red at (14,13)
  _01: rectangle with size (6,13) with model Full with color green at (14,7)
diff: 
! 275 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (11,3) with mask 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
. 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
 with color green at (0,4)
  _010: point with color red at (14,13)
  _0101: point with color red at (5,4)
  _01: rectangle with size (6,13) with model Full with color green at (14,7)
diff: 
! 273 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (6,13) with mask 
0 0 0 0 0 0 . 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color green at (14,7)
  _010: point with color red at (5,4)
  _0101: point with color red at (14,13)
  _01: rectangle with size (11,3) with model Full with color green at (0,4)
diff: 
! 291 wrong pixels (generated / expected)

TEST b527c5c6.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.1 sec (59.1 sec/task)
bits-train-error = 11315.0 bits (11315.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-120] Checking task b548a754.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 160221.0 = 160223.3
DL output with Mo: L = 2.3 + 160221.0 = 160223.3
DL input+output M: L = 4.6 + 320442.0 = 320446.6

# learning a model for train pairs
2.000	
1.141	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.439	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.276	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.159	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.070	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.043	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.039	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.034	OUT SPE ^.layer_01.shape = scaleTo(^.layer_01.shape, ^.layer_01.shape.mask.size + translationOnto(^.layer_0, ^.layer_011))
0.030	OUT SPE ^.layer_0.shape = scaleTo(^.layer_0.shape, ^.layer_0.shape.mask.size + translationOnto(^.layer_0, ^.layer_011))
0.026	OUT SPE ^.size = ^.size
0.024	OUT SPE ^.layer_01.pos = ^.layer_01.pos
0.022	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.021	IN  SPE ^.layer_011.shape.color = cyan
0.020	IN  SPE ^.layer_0.shape.mask.model = Full
0.020	IN  SPE ^.layer_01.shape.mask.model = Full
0.019	IN  SPE ^.color = black
0.019	OUT SPE ^.color = black
0.001	
0.001	IN  GEN ^.layer_011.shape.color = ?
0.001	IN  GEN ^.layer_01.shape.mask.model = ?
0.001	IN  GEN ^.layer_0.shape.mask.model = ?
0.001	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: scaleTo(^.layer_0.shape, ^.layer_0.shape.mask.size + translationOnto(^.layer_0, ^.layer_011)) at ^.layer_0.pos
  _01: scaleTo(^.layer_01.shape, ^.layer_01.shape.mask.size + translationOnto(^.layer_0, ^.layer_011)) at ^.layer_01.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: point with color cyan at (?,?)

DL input  with Mi: L = 92.8 + 2777.8 = 2870.6
DL output with Mo: L = 122.2 + 0.0 = 122.2
DL input+output M: L = 214.9 + 2777.8 = 2992.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: scaleTo(^.layer_0.shape, ^.layer_0.shape.mask.size + translationOnto(^.layer_0, ^.layer_011)) at ^.layer_0.pos
  _01: scaleTo(^.layer_01.shape, ^.layer_01.shape.mask.size + translationOnto(^.layer_0, ^.layer_011)) at ^.layer_01.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 88.3 + 0.0 = 88.3
DL output with Mo: L = 122.2 + 0.0 = 122.2
DL input+output M: L = 210.5 + 0.0 = 210.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _0: rectangle with size (2,2) with model Full with color blue at (2,2)
  _01: rectangle with size (4,4) with model Full with color red at (1,1)
  _011: point with color cyan at (8,3)
diff: 
   (0.0 bits)
data: a background with size (11,11) and color black and layers
  _0: 
1 1 
1 1 
1 1 
1 1 
1 1 
1 1 
 at (2,2)
  _01: 
2 2 2 2 
2 2 2 2 
2 2 2 2 
2 2 2 2 
2 2 2 2 
2 2 2 2 
2 2 2 2 
2 2 2 2 
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: rectangle with size (2,2) with model Full with color blue at (2,2)
  _01: rectangle with size (4,4) with model Full with color red at (1,1)
  _011: point with color cyan at (8,3)
diff: 
correct output grid

TRAIN b548a754.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _0: rectangle with size (2,3) with model Full with color red at (2,2)
  _01: rectangle with size (4,5) with model Full with color green at (1,1)
  _011: point with color cyan at (2,10)
diff: 
   (0.0 bits)
data: a background with size (11,11) and color black and layers
  _0: 
2 2 2 2 2 2 2 2 
2 2 2 2 2 2 2 2 
 at (2,2)
  _01: 
3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _0: rectangle with size (2,3) with model Full with color red at (2,2)
  _01: rectangle with size (4,5) with model Full with color green at (1,1)
  _011: point with color cyan at (2,10)
diff: 
correct output grid

TRAIN b548a754.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (13,12) and color black and layers
  _0: rectangle with size (3,1) with model Full with color pink at (2,3)
  _01: rectangle with size (5,3) with model Full with color blue at (1,2)
  _011: point with color cyan at (5,10)
diff: 
   (0.0 bits)
data: a background with size (13,12) and color black and layers
  _0: 
6 6 6 6 6 6 6 
6 6 6 6 6 6 6 
6 6 6 6 6 6 6 
 at (2,3)
  _01: 
1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 
 at (1,2)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,12) and color black and layers
  _0: rectangle with size (3,1) with model Full with color pink at (2,3)
  _01: rectangle with size (5,3) with model Full with color blue at (1,2)
  _011: point with color cyan at (5,10)
diff: 
correct output grid

TRAIN b548a754.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
Arc_common.Undefined_result("Grid.Transf.scale_to: negative scaling vector")

TEST b548a754.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 4.9 sec (4.9 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-119] Checking task b60334d2.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 64315.6 = 64317.9
DL output with Mo: L = 2.3 + 64315.6 = 64317.9
DL input+output M: L = 4.6 + 128631.2 = 128635.9

# learning a model for train pairs
2.000	
1.051	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.402	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.365	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.328	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.296	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.264	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.244	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.228	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.213	OUT ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.199	OUT ADD ^.layer_01111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.192	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.185	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.178	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.171	OUT SPE ^.layer_0111111.shape = tiling(^.layer_011.shape, 1, 3)
0.165	OUT SPE ^.size = ^.size
0.159	OUT SPE ^.layer_0.shape.mask = 
. 0 . 
0 . 0 
. 0 . 

0.148	OUT SPE ^.layer_011111.shape = tiling(^.layer_011.shape, 3, 1)
0.143	OUT SPE ^.layer_01.shape.mask = 
. 0 . 
0 . 0 
. 0 . 

0.134	OUT SPE ^.layer_01.pos = ^.layer_01.pos - (1, 1)
0.130	OUT SPE ^.layer_0.pos = ^.layer_0.pos - (1, 1)
0.127	OUT SPE ^.layer_0111.pos = ^.layer_011.pos - (1, 1)
0.125	OUT SPE ^.layer_0111.shape.mask.size.j = 3
0.121	OUT SPE ^.layer_0111.shape.mask = 
. 0 . 
0 . 0 
. 0 . 

0.118	OUT SPE ^.layer_011.pos = ^.layer_0.pos - (1, 1)
0.116	OUT SPE ^.layer_01111.shape.mask.size.j = 3
0.114	OUT SPE ^.layer_011.shape.color = ^.layer_011.shape.color
0.113	IN  SPE ^.layer_0.shape.color = grey
0.111	IN  SPE ^.layer_01.shape.color = grey
0.109	IN  SPE ^.layer_011.shape.color = grey
0.107	OUT SPE ^.layer_0.shape.color = blue
0.106	OUT SPE ^.layer_01.shape.color = blue
0.104	OUT SPE ^.layer_0111.shape.color = blue
0.102	OUT SPE ^.layer_01111111.shape.color = grey
0.101	OUT SPE ^.layer_01111.pos.j = ^.layer_01.pos.i
0.099	OUT SPE ^.layer_01111111.pos.i = ^.layer_011.pos.i - 1
0.098	OUT SPE ^.layer_011111.pos.i = ^.layer_0.pos.i - 1
0.097	OUT SPE ^.layer_0111111.pos.i = ^.layer_01.pos.i + 3
0.095	OUT SPE ^.layer_01111111.pos.j = ^.layer_011.pos.j / '2
0.094	OUT SPE ^.layer_01111.pos.i = span(^.layer_01.pos.i, ^.layer_011.pos.i) + 1
0.093	OUT SPE ^.layer_0111111.pos.j = span(^.layer_0.pos.j, ^.layer_011.pos.j) - 1
0.092	OUT SPE ^.layer_011111.pos.j = span(^.layer_01.pos.i, ^.layer_011.pos.i) + 1
0.091	OUT SPE ^.layer_011.shape.mask.size.j = 1
0.090	OUT SPE ^.layer_011.shape.mask.model = Full
0.067	
0.066	IN  GEN ^.layer_011.shape.color = ?
0.066	IN  GEN ^.layer_01.shape.color = ?
0.066	IN  GEN ^.layer_0.shape.color = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: 
. 0 . 
0 . 0 
. 0 . 
 with color blue at ^.layer_0.pos - (1, 1)
  _01: 
. 0 . 
0 . 0 
. 0 . 
 with color blue at ^.layer_01.pos - (1, 1)
  _011: rectangle with size (?,1) with model Full with color ^.layer_011.shape.color at ^.layer_0.pos - (1, 1)
  _0111: 
. 0 . 
0 . 0 
. 0 . 
 with color blue at ^.layer_011.pos - (1, 1)
  _01111: rectangle with size (?,3) with model ? with color ? at (span(^.layer_01.pos.i, ^.layer_011.pos.i) + 1,^.layer_01.pos.i)
  _011111: tiling(^.layer_011.shape, 3, 1) at (^.layer_0.pos.i - 1,span(^.layer_01.pos.i, ^.layer_011.pos.i) + 1)
  _0111111: tiling(^.layer_011.shape, 1, 3) at (^.layer_01.pos.i + 3,span(^.layer_0.pos.j, ^.layer_011.pos.j) - 1)
  _01111111: rectangle with size (?,?) with model ? with color grey at (^.layer_011.pos.i - 1,^.layer_011.pos.j / '2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color grey at (?,?)
  _01: point with color grey at (?,?)
  _011: point with color grey at (?,?)

DL input  with Mi: L = 78.6 + 1538.5 = 1617.1
DL output with Mo: L = 537.1 + 3632.3 = 4169.4
DL input+output M: L = 615.8 + 5170.8 = 5786.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: 
. 0 . 
0 . 0 
. 0 . 
 with color blue at ^.layer_0.pos - (1, 1)
  _01: 
. 0 . 
0 . 0 
. 0 . 
 with color blue at ^.layer_01.pos - (1, 1)
  _011: rectangle with size (?,1) with model Full with color ^.layer_011.shape.color at ^.layer_0.pos - (1, 1)
  _0111: 
. 0 . 
0 . 0 
. 0 . 
 with color blue at ^.layer_011.pos - (1, 1)
  _01111: rectangle with size (?,3) with model ? with color ? at (span(^.layer_01.pos.i, ^.layer_011.pos.i) + 1,^.layer_01.pos.i)
  _011111: tiling(^.layer_011.shape, 3, 1) at (^.layer_0.pos.i - 1,span(^.layer_01.pos.i, ^.layer_011.pos.i) + 1)
  _0111111: tiling(^.layer_011.shape, 1, 3) at (^.layer_01.pos.i + 3,span(^.layer_0.pos.j, ^.layer_011.pos.j) - 1)
  _01111111: rectangle with size (?,?) with model ? with color grey at (^.layer_011.pos.i - 1,^.layer_011.pos.j / '2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 68.7 + 31.7 = 100.4
DL output with Mo: L = 537.1 + 3632.3 = 4169.4
DL input+output M: L = 605.8 + 3664.0 = 4269.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: point with color grey at (2,3)
  _01: point with color grey at (5,6)
  _011: point with color grey at (7,2)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: 
. 0 . 
0 . 0 
. 0 . 
 with color blue at (1,2)
  _01: 
. 0 . 
0 . 0 
. 0 . 
 with color blue at (4,5)
  _011: rectangle with size (3,1) with model Full with color grey at (1,2)
  _0111: 
. 0 . 
0 . 0 
. 0 . 
 with color blue at (6,1)
  _01111: rectangle with size (1,3) with model Full with color grey at (4,5)
  _011111: 
5#
5#
5#
 at (1,4)
  _0111111: 
5#5#5#
 at (8,1)
  _01111111: rectangle with size (1,7) with model Full with color grey at (6,1)
  + 1 delta pixels
diff: 
   (77.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (2,3)
  _01: point with color grey at (5,6)
  _011: point with color grey at (7,2)
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (2,3)
  _01: point with color grey at (7,2)
  _011: point with color grey at (5,6)
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (5,6)
  _01: point with color grey at (2,3)
  _011: point with color grey at (7,2)
diff: 
! 13 wrong pixels (generated / expected)

TRAIN b60334d2.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,2)
  _01: point with color grey at (5,2)
  _011: point with color grey at (1,7)
  + 1 delta pixels
diff: 
   (3.2 bits)
data: a background with size (9,9) and color black and layers
  _0: 
. 0 . 
0 . 0 
. 0 . 
 with color blue at (0,1)
  _01: 
. 0 . 
0 . 0 
. 0 . 
 with color blue at (4,1)
  _011: rectangle with size (7,1) with model Full with color grey at (0,1)
  _0111: 
. 0 . 
0 . 0 
. 0 . 
 with color blue at (0,6)
  _01111: rectangle with size (3,3) with model Odd Checkboard with color blue at (6,5)
  _011111: 
5#
5#
5#
 at (0,6)
  _0111111: 
5#5#5#
 at (8,5)
  _01111111: rectangle with size (7,1) with model Full with color grey at (0,3)
  + 6 delta pixels
diff: 
   (286.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,2)
  _01: point with color grey at (1,7)
  _011: point with color grey at (7,6)
  + 1 delta pixels
diff: 
! 25 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,2)
  _01: point with color grey at (5,2)
  _011: point with color grey at (1,7)
  + 1 delta pixels
diff: 
! 17 wrong pixels (generated / expected)

TRAIN b60334d2.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,1)
  _01: point with color grey at (3,4)
  _011: point with color grey at (5,7)
  + 1 delta pixels
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,1)
  _01: point with color grey at (3,4)
  _011: point with color grey at (7,2)
  + 1 delta pixels
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,1)
  _01: point with color grey at (5,7)
  _011: point with color grey at (3,4)
  + 1 delta pixels
diff: 
! 23 wrong pixels (generated / expected)

TEST b60334d2.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.2 sec (59.2 sec/task)
bits-train-error = 3632.3 bits (3632.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-118] Checking task b6afb2da.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79850.6 = 79852.9
DL output with Mo: L = 2.3 + 79850.6 = 79852.9
DL input+output M: L = 4.6 + 159701.1 = 159705.8

# learning a model for train pairs
2.000	
1.415	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.869	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.563	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.410	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.322	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.237	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.173	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.149	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.135	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.123	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.115	OUT ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.091	
0.090	IN  GEN ^ = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 1860.0 = 1930.2
DL output with Mo: L = 208.3 + 7008.1 = 7216.4
DL input+output M: L = 278.5 + 8868.0 = 9146.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 208.3 + 7008.1 = 7216.4
DL input+output M: L = 210.6 + 7008.1 = 7218.7

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 5#5#5#5#0 0 0 0 0 
0 5#5#5#5#0 0 0 0 0 
0 5#5#5#5#0 0 0 0 0 
0 5#5#5#5#0 5#5#5#5#
0 0 0 0 0 0 5#5#5#5#
0 0 0 0 0 0 5#5#5#5#
0 0 0 0 0 0 5#5#5#5#
0 0 0 0 0 0 5#5#5#5#

diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,4) with mask 
. 0 0 . 
0 . . 0 
0 . . 0 
0 . . 0 
. 0 0 . 
 with color yellow at (5,6)
  _01: rectangle with size (3,2) with model Full with color red at (6,7)
  _011: rectangle with size (2,2) with model Full with color red at (3,2)
  _0111: rectangle with size (4,4) with model +-cross with color yellow at (2,1)
  _01111: rectangle with size (1,9) with model Full with color blue at (5,1)
  _011111: rectangle with size (1,4) with model Full with color blue at (2,1)
  _0111111: rectangle with size (1,4) with model Full with color blue at (9,6)
  + 1 delta pixels
diff: 
   (312.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 5#5#5#5#0 0 0 0 0 
0 5#5#5#5#0 0 0 0 0 
0 5#5#5#5#0 0 0 0 0 
0 5#5#5#5#0 5#5#5#5#
0 0 0 0 0 0 5#5#5#5#
0 0 0 0 0 0 5#5#5#5#
0 0 0 0 0 0 5#5#5#5#
0 0 0 0 0 0 5#5#5#5#

diff: 
! 40 wrong pixels (generated / expected)

TRAIN b6afb2da.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
5#5#5#5#5#5#0 0 0 0 
5#5#5#5#5#5#0 0 0 0 
5#5#5#5#5#5#0 0 0 0 
5#5#5#5#5#5#0 0 0 0 
5#5#5#5#5#5#0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 5#5#5#5#5#5#
0 0 0 0 5#5#5#5#5#5#
0 0 0 0 5#5#5#5#5#5#
0 0 0 0 5#5#5#5#5#5#

diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,6) with mask 
. 0 0 0 0 . 
0 . . . . 0 
0 . . . . 0 
0 . . . . 0 
. 0 0 0 0 . 
 with color yellow at (0,0)
  _01: rectangle with size (3,4) with model Full with color red at (1,1)
  _011: rectangle with size (4,6) with mask 
. 0 0 0 0 . 
0 . . . . 0 
0 . . . . 0 
. 0 0 0 0 . 
 with color yellow at (6,4)
  _0111: rectangle with size (2,4) with model Full with color red at (7,5)
  _01111: rectangle with size (5,1) with model Full with color blue at (0,0)
  _011111: rectangle with size (5,1) with model Full with color blue at (0,5)
  _0111111: rectangle with size (4,1) with model Full with color blue at (6,4)
  + 2 delta pixels
diff: 
   (388.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#5#5#5#5#5#0 0 0 0 
5#5#5#5#5#5#0 0 0 0 
5#5#5#5#5#5#0 0 0 0 
5#5#5#5#5#5#0 0 0 0 
5#5#5#5#5#5#0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 5#5#5#5#5#5#
0 0 0 0 5#5#5#5#5#5#
0 0 0 0 5#5#5#5#5#5#
0 0 0 0 5#5#5#5#5#5#

diff: 
! 54 wrong pixels (generated / expected)

TRAIN b6afb2da.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 5#5#5#5#0 0 0 0 0 
0 5#5#5#5#0 0 0 0 0 
0 5#5#5#5#0 0 0 0 0 
0 5#5#5#5#0 0 0 0 0 
0 5#5#5#5#0 0 0 0 0 
0 5#5#5#5#0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 5#5#5#5#5#5#
0 0 0 0 5#5#5#5#5#5#
0 0 0 0 5#5#5#5#5#5#

diff: 
! 44 wrong pixels (generated / expected)

TEST b6afb2da.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.3 sec (59.3 sec/task)
bits-train-error = 7008.1 bits (7008.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-117] Checking task b7249182.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 181824.8 = 181827.1
DL output with Mo: L = 2.3 + 181824.8 = 181827.1
DL input+output M: L = 4.6 + 363649.6 = 363654.2

# learning a model for train pairs
2.000	
1.018	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.169	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.107	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.043	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.040	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.036	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.032	OUT SPE ^.size = ^.size
0.031	OUT SPE ^.layer_0.shape.mask.size.i = area(^) + 3
0.030	OUT SPE ^.layer_01.shape.mask.size.i = area(^) + 3
0.029	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.028	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.028	IN  SPE ^.color = black
0.027	OUT SPE ^.color = black
0.018	
0.018	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (area(^) + 3,?) with model ? with color ^.layer_0.shape.color at (?,?)
  _01: rectangle with size (area(^) + 3,?) with model ? with color ^.layer_01.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.7 + 1681.5 = 1732.2
DL output with Mo: L = 113.5 + 3090.1 = 3203.6
DL input+output M: L = 164.3 + 4771.6 = 4935.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (area(^) + 3,?) with model ? with color ^.layer_0.shape.color at (?,?)
  _01: rectangle with size (area(^) + 3,?) with model ? with color ^.layer_01.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.6 + 0.0 = 50.6
DL output with Mo: L = 113.5 + 3090.1 = 3203.6
DL input+output M: L = 164.2 + 3090.1 = 3254.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (14,10) and color black and layers
  _0: point with color red at (1,4)
  _01: point with color cyan at (10,4)
diff: 
   (0.0 bits)
data: a background with size (14,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
. . 0 . . 
. . 0 . . 
. . 0 . . 
0 0 0 0 0 
0 . . . 0 
 with color red at (1,2)
  _01: rectangle with size (5,5) with mask 
0 . . . 0 
0 0 0 0 0 
. . 0 . . 
. . 0 . . 
. . 0 . . 
 with color cyan at (6,2)
diff: 
   (93.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,10) and color black and layers
  _0: point with color red at (1,4)
  _01: point with color cyan at (10,4)
diff: 
! 30 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,10) and color black and layers
  _0: point with color cyan at (10,4)
  _01: point with color red at (1,4)
diff: 
! 30 wrong pixels (generated / expected)

TRAIN b7249182.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,13) and color black and layers
  _0: point with color green at (6,1)
  _01: point with color blue at (6,12)
diff: 
   (0.0 bits)
data: a background with size (10,13) and color black and layers
  _0: rectangle with size (5,6) with mask 
. . . . 0 0 
. . . . 0 . 
0 0 0 0 0 . 
. . . . 0 . 
. . . . 0 0 
 with color green at (4,1)
  _01: rectangle with size (5,6) with mask 
0 0 . . . . 
. 0 . . . . 
. 0 0 0 0 0 
. 0 . . . . 
0 0 . . . . 
 with color blue at (4,7)
diff: 
   (102.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,13) and color black and layers
  _0: point with color green at (6,1)
  _01: point with color blue at (6,12)
diff: 
! 32 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,13) and color black and layers
  _0: point with color blue at (6,12)
  _01: point with color green at (6,1)
diff: 
! 32 wrong pixels (generated / expected)

TRAIN b7249182.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,18) and color black and layers
  _0: point with color grey at (5,3)
  _01: point with color cyan at (5,16)
diff: 
   (0.0 bits)
data: a background with size (10,18) and color black and layers
  _0: rectangle with size (5,7) with mask 
. . . . . 0 0 
. . . . . 0 . 
0 0 0 0 0 0 . 
. . . . . 0 . 
. . . . . 0 0 
 with color grey at (3,3)
  _01: rectangle with size (5,7) with mask 
0 0 . . . . . 
. 0 . . . . . 
. 0 0 0 0 0 0 
. 0 . . . . . 
0 0 . . . . . 
 with color cyan at (3,10)
diff: 
   (112.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,18) and color black and layers
  _0: point with color grey at (5,3)
  _01: point with color cyan at (5,16)
diff: 
! 34 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,18) and color black and layers
  _0: point with color cyan at (5,16)
  _01: point with color grey at (5,3)
diff: 
! 34 wrong pixels (generated / expected)

TRAIN b7249182.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,9) and color black and layers
  _0: point with color orange at (1,3)
  _01: point with color pink at (16,3)
diff: 
! 36 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (19,9) and color black and layers
  _0: point with color pink at (16,3)
  _01: point with color orange at (1,3)
diff: 
! 36 wrong pixels (generated / expected)

TEST b7249182.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.3 sec (3.3 sec/task)
bits-train-error = 3090.1 bits (3090.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-116] Checking task b775ac94.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 631133.6 = 631135.9
DL output with Mo: L = 2.3 + 631133.6 = 631135.9
DL input+output M: L = 4.6 + 1262267.2 = 1262271.9

# learning a model for train pairs
2.000	
1.036	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.126	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.113	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.098	OUT ADD ^.layer_0 = ^.layer_0
0.085	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.072	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.060	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.055	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.050	OUT ADD ^.layer_010 = ^.layer_01
0.044	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.041	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.039	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.023	
0.023	IN  DEL ^.layer_011
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: ^.layer_0
  _010: ^.layer_01
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 9592.8 = 9690.9
DL output with Mo: L = 164.9 + 14483.4 = 14648.3
DL input+output M: L = 263.0 + 24076.3 = 24339.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: ^.layer_0
  _010: ^.layer_01
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 164.9 + 14483.4 = 14648.3
DL input+output M: L = 235.1 + 14483.4 = 14718.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (30,30) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 0 0 
0 0 . 0 
. . . 0 
. . 0 . 
 with color blue at (12,3)
  _01: rectangle with size (3,3) with mask 
. 0 0 
. 0 . 
0 . 0 
 with color orange at (10,14)
  + 12 delta pixels
diff: 
   (0.0 bits)
data: a background with size (30,30) and color black and layers
  _0: 
. 1 1 1 
1 1 . 1 
. . . 1 
. . 1 . 
 at (12,3)
  _010: 
. 7#7#
. 7#. 
7#. 7#
 at (10,14)
  _01: rectangle with size (4,4) with mask 
. . 0 . 
. . . 0 
0 0 . 0 
. 0 0 0 
 with color green at (8,3)
  _011: rectangle with size (4,4) with mask 
. 0 . . 
0 . . . 
0 . 0 0 
0 0 0 . 
 with color yellow at (8,7)
  _0111: rectangle with size (4,4) with mask 
0 0 0 . 
0 . 0 0 
0 . . . 
. 0 . . 
 with color red at (12,7)
  _01111: rectangle with size (3,3) with mask 
0 . 0 
. 0 . 
. 0 0 
 with color red at (7,14)
  _011111: rectangle with size (3,3) with mask 
0 . 0 
. 0 . 
0 0 . 
 with color blue at (7,17)
  + 17 delta pixels
diff: 
   (1009.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 0 0 
0 0 . 0 
. . . 0 
. . 0 . 
 with color blue at (12,3)
  _01: rectangle with size (3,3) with mask 
. 0 0 
. 0 . 
0 . 0 
 with color orange at (10,14)
  + 12 delta pixels
diff: 
! size mismatch, 10x10 instead of 30x30

TRAIN b775ac94.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (3,5) with mask 
. 0 . 0 . 
0 0 0 0 0 
. . . 0 0 
 with color red at (6,3)
  _01: rectangle with size (1,1) with model Full with color cyan at (8,8)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _0: 
. 2 . 2 . 
2 2 2 2 2 
. . . 2 2 
 at (6,3)
  _010: 
8 
 at (8,8)
  _01: rectangle with size (3,5) with mask 
. . . 0 0 
0 0 0 0 0 
. 0 . 0 . 
 with color yellow at (9,3)
  _011: rectangle with size (3,5) with mask 
0 0 . . . 
0 0 0 0 0 
. 0 . 0 . 
 with color green at (9,8)
  _0111: rectangle with size (1,5) with model Full with color cyan at (7,8)
  _01111: rectangle with size (3,1) with model Full with color cyan at (6,9)
  _011111: rectangle with size (2,1) with model Full with color cyan at (6,11)
diff: 
   (221.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (3,5) with mask 
. 0 . 0 . 
0 0 0 0 0 
. . . 0 0 
 with color red at (6,3)
  _01: rectangle with size (1,1) with model Full with color cyan at (8,8)
  + 2 delta pixels
diff: 
! size mismatch, 10x10 instead of 20x20
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (3,5) with mask 
. 0 . 0 . 
0 0 0 0 0 
. . . 0 0 
 with color red at (6,3)
  _01: rectangle with size (1,1) with model Full with color yellow at (9,7)
  + 2 delta pixels
diff: 
! size mismatch, 10x10 instead of 20x20
>> Trial 3
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (3,5) with mask 
. 0 . 0 . 
0 0 0 0 0 
. . . 0 0 
 with color red at (6,3)
  _01: rectangle with size (1,1) with model Full with color green at (9,8)
  + 2 delta pixels
diff: 
! size mismatch, 10x10 instead of 20x20

TRAIN b775ac94.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (14,14) and color black and layers
  _0: rectangle with size (3,4) with mask 
. . . 0 
0 0 0 0 
. . 0 . 
 with color red at (8,1)
  _01: rectangle with size (3,3) with mask 
0 0 . 
0 0 . 
. . 0 
 with color cyan at (1,7)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (14,14) and color black and layers
  _0: 
. . . 2 
2 2 2 2 
. . 2 . 
 at (8,1)
  _010: 
8 8 . 
8 8 . 
. . 8 
 at (1,7)
  _01: rectangle with size (3,4) with mask 
. 0 . . 
0 0 0 0 
0 . . . 
 with color blue at (5,5)
  _011: rectangle with size (3,4) with mask 
0 . . . 
0 0 0 0 
. 0 . . 
 with color yellow at (8,5)
  _0111: rectangle with size (3,3) with mask 
. 0 0 
. 0 0 
0 . . 
 with color yellow at (1,10)
  _01111: rectangle with size (2,2) with model Full with color pink at (5,11)
  _011111: rectangle with size (1,1) with model Full with color pink at (4,10)
diff: 
   (216.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (3,4) with mask 
. . . 0 
0 0 0 0 
. . 0 . 
 with color red at (8,1)
  _01: rectangle with size (3,3) with mask 
0 0 . 
0 0 . 
. . 0 
 with color cyan at (1,7)
  + 4 delta pixels
diff: 
! size mismatch, 10x10 instead of 14x14
>> Trial 2
data: a background with size (14,14) and color black and layers
  _0: rectangle with size (3,4) with mask 
. . . 0 
0 0 0 0 
. . 0 . 
 with color red at (8,1)
  _01: rectangle with size (2,2) with model Full with color cyan at (1,7)
  + 5 delta pixels
diff: 
! size mismatch, 10x10 instead of 14x14

TRAIN b775ac94.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (24,24) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 . . 
0 0 0 . 
. 0 . 0 
. . 0 0 
 with color cyan at (3,4)
  _01: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
0 . . 
 with color red at (17,11)
  + 12 delta pixels
diff: 
! size mismatch, 10x10 instead of 24x24

TEST b775ac94.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.7 sec (59.7 sec/task)
bits-train-error = 14483.4 bits (14483.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-115] Checking task b782dc8a.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 182434.2 = 182436.5
DL output with Mo: L = 2.3 + 182434.2 = 182436.5
DL input+output M: L = 4.6 + 364868.4 = 364873.1

# learning a model for train pairs
2.000	
1.495	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.991	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.837	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.678	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.588	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.501	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.433	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.380	OUT ADD ^.layer_00 = ^.layer_0
0.337	OUT ADD ^.layer_010 = ^.layer_01
0.311	OUT ADD ^.layer_001 = ^.layer_011
0.290	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.277	OUT ADD ^.layer_0101 = ^.layer_0111
0.266	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.258	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.246	OUT ADD ^.layer_000 = ^.layer_01111
0.241	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.238	IN  ADD ^.layer_0111110 = point with color ? at (?,?)
0.236	OUT SPE ^.size = ^.size
0.234	OUT SPE ^.layer_011.pos = ^.layer_0111110.pos + (0, 1)
0.234	IN  SPE ^.layer_0.shape.color = cyan
0.233	IN  SPE ^.layer_01.shape.color = cyan
0.233	OUT SPE ^.layer_01.shape.mask.size.i = ^.layer_011.shape.mask.size.j - 2
0.176	
0.176	IN  GEN ^.layer_01.shape.color = ?
0.176	IN  GEN ^.layer_0.shape.color = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _000: ^.layer_01111
  _00: ^.layer_0
  _001: ^.layer_011
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _0101: ^.layer_0111
  _01: rectangle with size (^.layer_011.shape.mask.size.j - 2,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at ^.layer_0111110.pos + (0, 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color cyan at (?,?)
  _01: rectangle with size (?,?) with model ? with color cyan at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111110: point with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 205.1 + 10420.4 = 10625.5
DL output with Mo: L = 220.3 + 31580.0 = 31800.3
DL input+output M: L = 425.5 + 42000.4 = 42425.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _000: ^.layer_01111
  _00: ^.layer_0
  _001: ^.layer_011
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _0101: ^.layer_0111
  _01: rectangle with size (^.layer_011.shape.mask.size.j - 2,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at ^.layer_0111110.pos + (0, 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111110: point with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 198.5 + 31.7 = 230.2
DL output with Mo: L = 220.3 + 31580.0 = 31800.3
DL input+output M: L = 418.8 + 31611.7 = 32030.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (11,24) and color black and layers
  _0: rectangle with size (10,10) with mask 
. . 0 0 0 . . . . . 
0 0 0 . 0 . 0 0 0 0 
0 . . . 0 . 0 . . 0 
0 . 0 0 0 . 0 0 . 0 
0 . 0 . . . . 0 . 0 
0 . 0 0 0 0 0 0 . 0 
0 . . . . . . . . 0 
0 0 . 0 0 0 . 0 0 0 
. 0 . 0 . 0 . 0 . . 
. 0 0 0 . 0 0 0 . . 
 with color cyan at (1,0)
  _01: rectangle with size (11,14) with mask 
. . . . . . . . 0 0 . 0 0 0 
. . . . . . . . 0 . . 0 . 0 
. . . . . . . . 0 0 0 0 . 0 
. . . . . . . . . . . . . 0 
. . . . . . . . . 0 0 0 0 0 
. . . . . . . . . 0 . . . . 
. . . . . . . . . 0 0 0 0 0 
. . . . . . . . . . . . . 0 
. . 0 0 0 0 0 0 . 0 0 0 . 0 
. . 0 . . . . 0 . 0 . 0 . 0 
0 0 0 . . . . 0 0 0 . 0 0 0 
 with color cyan at (0,9)
  _011: rectangle with size (7,11) with mask 
0 0 0 0 0 0 . 0 0 0 . 
. . . . . 0 . . . 0 . 
. . . . . 0 0 0 . 0 . 
. . . . . . . 0 . 0 . 
. . . . . 0 0 0 . 0 0 
. . . . . 0 . . . . 0 
. . . . . 0 0 0 0 0 0 
 with color cyan at (0,6)
  _0111: rectangle with size (3,3) with model Border with color green at (6,16)
  _01111: rectangle with size (1,2) with model Full with color cyan at (10,13)
  _0111110: point with color cyan at (0,0)
  _011111: rectangle with size (1,1) with model Full with color red at (7,17)
diff: 
   (0.0 bits)
data: a background with size (11,24) and color black and layers
  _000: 
8 8 
 at (10,13)
  _00: 
. . 8 8 8 . . . . . 
8 8 8 . 8 . 8 8 8 8 
8 . . . 8 . 8 . . 8 
8 . 8 8 8 . 8 8 . 8 
8 . 8 . . . . 8 . 8 
8 . 8 8 8 8 8 8 . 8 
8 . . . . . . . . 8 
8 8 . 8 8 8 . 8 8 8 
. 8 . 8 . 8 . 8 . . 
. 8 8 8 . 8 8 8 . . 
 at (1,0)
  _001: 
8 8 8 8 8 8 . 8 8 8 . 
. . . . . 8 . . . 8 . 
. . . . . 8 8 8 . 8 . 
. . . . . . . 8 . 8 . 
. . . . . 8 8 8 . 8 8 
. . . . . 8 . . . . 8 
. . . . . 8 8 8 8 8 8 
 at (0,6)
  _0: rectangle with size (1,11) with model Full with color red at (7,11)
  _010: 
. . . . . . . . 8 8 . 8 8 8 
. . . . . . . . 8 . . 8 . 8 
. . . . . . . . 8 8 8 8 . 8 
. . . . . . . . . . . . . 8 
. . . . . . . . . 8 8 8 8 8 
. . . . . . . . . 8 . . . . 
. . . . . . . . . 8 8 8 8 8 
. . . . . . . . . . . . . 8 
. . 8 8 8 8 8 8 . 8 8 8 . 8 
. . 8 . . . . 8 . 8 . 8 . 8 
8 8 8 . . . . 8 8 8 . 8 8 8 
 at (0,9)
  _0101: 
3 3 3 
3 . 3 
3 3 3 
 at (6,16)
  _01: rectangle with size (9,1) with model Full with color green at (1,10)
  _011: rectangle with size (2,5) with model Full with color red at (0,1)
  + 46 delta pixels
diff: 
   (1976.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,24) and color black and layers
  _0: rectangle with size (10,10) with mask 
. . 0 0 0 . . . . . 
0 0 0 . 0 . 0 0 0 0 
0 . . . 0 . 0 . . 0 
0 . 0 0 0 . 0 0 . 0 
0 . 0 . . . . 0 . 0 
0 . 0 0 0 0 0 0 . 0 
0 . . . . . . . . 0 
0 0 . 0 0 0 . 0 0 0 
. 0 . 0 . 0 . 0 . . 
. 0 0 0 . 0 0 0 . . 
 with color cyan at (1,0)
  _01: rectangle with size (11,14) with mask 
. . . . . . . . 0 0 . 0 0 0 
. . . . . . . . 0 . . 0 . 0 
. . . . . . . . 0 0 0 0 . 0 
. . . . . . . . . . . . . 0 
. . . . . . . . . 0 0 0 0 0 
. . . . . . . . . 0 . . . . 
. . . . . . . . . 0 0 0 0 0 
. . . . . . . . . . . . . 0 
. . 0 0 0 0 0 0 . 0 0 0 . 0 
. . 0 . . . . 0 . 0 . 0 . 0 
0 0 0 . . . . 0 0 0 . 0 0 0 
 with color cyan at (0,9)
  _011: rectangle with size (7,11) with mask 
0 0 0 0 0 0 . 0 0 0 . 
. . . . . 0 . . . 0 . 
. . . . . 0 0 0 . 0 . 
. . . . . . . 0 . 0 . 
. . . . . 0 0 0 . 0 0 
. . . . . 0 . . . . 0 
. . . . . 0 0 0 0 0 0 
 with color cyan at (0,6)
  _0111: rectangle with size (3,3) with model Border with color green at (6,16)
  _01111: rectangle with size (1,2) with model Full with color cyan at (10,13)
  _0111110: point with color cyan at (0,0)
  _011111: rectangle with size (1,1) with model Full with color red at (7,17)
diff: 
! 64 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,24) and color black and layers
  _0: rectangle with size (10,10) with mask 
. . 0 0 0 . . . . . 
0 0 0 . 0 . 0 0 0 0 
0 . . . 0 . 0 . . 0 
0 . 0 0 0 . 0 0 . 0 
0 . 0 . . . . 0 . 0 
0 . 0 0 0 0 0 0 . 0 
0 . . . . . . . . 0 
0 0 . 0 0 0 . 0 0 0 
. 0 . 0 . 0 . 0 . . 
. 0 0 0 . 0 0 0 . . 
 with color cyan at (1,0)
  _01: rectangle with size (11,14) with mask 
. . . . . . . . 0 0 . 0 0 0 
. . . . . . . . 0 . . 0 . 0 
. . . . . . . . 0 0 0 0 . 0 
. . . . . . . . . . . . . 0 
. . . . . . . . . 0 0 0 0 0 
. . . . . . . . . 0 . . . . 
. . . . . . . . . 0 0 0 0 0 
. . . . . . . . . . . . . 0 
. . 0 0 0 0 0 0 . 0 0 0 . 0 
. . 0 . . . . 0 . 0 . 0 . 0 
0 0 0 . . . . 0 0 0 . 0 0 0 
 with color cyan at (0,9)
  _011: rectangle with size (7,11) with mask 
0 0 0 0 0 0 . 0 0 0 . 
. . . . . 0 . . . 0 . 
. . . . . 0 0 0 . 0 . 
. . . . . . . 0 . 0 . 
. . . . . 0 0 0 . 0 0 
. . . . . 0 . . . . 0 
. . . . . 0 0 0 0 0 0 
 with color cyan at (0,6)
  _0111: rectangle with size (3,3) with model Border with color green at (6,16)
  _01111: rectangle with size (1,2) with model Full with color cyan at (10,13)
  _0111110: point with color red at (7,17)
  _011111: rectangle with size (1,1) with model Full with color cyan at (0,0)
diff: 
! 64 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (11,24) and color black and layers
  _0: rectangle with size (10,10) with mask 
. . 0 0 0 . . . . . 
0 0 0 . 0 . 0 0 0 0 
0 . . . 0 . 0 . . 0 
0 . 0 0 0 . 0 0 . 0 
0 . 0 . . . . 0 . 0 
0 . 0 0 0 0 0 0 . 0 
0 . . . . . . . . 0 
0 0 . 0 0 0 . 0 0 0 
. 0 . 0 . 0 . 0 . . 
. 0 0 0 . 0 0 0 . . 
 with color cyan at (1,0)
  _01: rectangle with size (11,14) with mask 
. . . . . . . . 0 0 . 0 0 0 
. . . . . . . . 0 . . 0 . 0 
. . . . . . . . 0 0 0 0 . 0 
. . . . . . . . . . . . . 0 
. . . . . . . . . 0 0 0 0 0 
. . . . . . . . . 0 . . . . 
. . . . . . . . . 0 0 0 0 0 
. . . . . . . . . . . . . 0 
. . 0 0 0 0 0 0 . 0 0 0 . 0 
. . 0 . . . . 0 . 0 . 0 . 0 
0 0 0 . . . . 0 0 0 . 0 0 0 
 with color cyan at (0,9)
  _011: rectangle with size (7,11) with mask 
0 0 0 0 0 0 . 0 0 0 . 
. . . . . 0 . . . 0 . 
. . . . . 0 0 0 . 0 . 
. . . . . . . 0 . 0 . 
. . . . . 0 0 0 . 0 0 
. . . . . 0 . . . . 0 
. . . . . 0 0 0 0 0 0 
 with color cyan at (0,6)
  _0111: rectangle with size (3,3) with model Border with color green at (6,16)
  _01111: rectangle with size (1,1) with model Full with color cyan at (0,0)
  _0111110: point with color red at (7,17)
  _011111: rectangle with size (1,2) with model Full with color cyan at (10,13)
diff: 
! 65 wrong pixels (generated / expected)

TRAIN b782dc8a.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (13,14) and color black and layers
  _0: rectangle with size (12,10) with mask 
. . . . . . . 0 . . 
. . . . . . . 0 . . 
. . . . . . . 0 . . 
. . . . . . . 0 . . 
. . . . . . . 0 . . 
0 0 0 0 0 0 . 0 . . 
0 . . . . 0 . 0 0 0 
0 0 0 0 . 0 . . . 0 
. . . 0 . 0 0 0 0 0 
0 0 . 0 . . . . . . 
. 0 . 0 . . . . . . 
. 0 0 0 . . . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (4,6) with mask 
. . . 0 . . 
0 0 . 0 0 0 
. 0 . . . 0 
. 0 0 0 0 0 
 with color cyan at (0,0)
  _011: rectangle with size (13,9) with mask 
. . . . . . . . 0 
. . . . 0 0 0 . 0 
. . . . 0 . 0 0 0 
. . . . 0 . . . . 
. . . . 0 0 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 0 . 
. . . . . . . 0 . 
0 0 0 0 0 0 0 0 . 
0 . . . . . . . . 
0 . . . . . . . . 
 with color cyan at (0,5)
  _0111: rectangle with size (1,7) with model Full with color cyan at (12,7)
  _01111: rectangle with size (3,1) with model Full with color cyan at (4,13)
  _0111110: point with color yellow at (9,4)
  _011111: rectangle with size (3,2) with model Full with color blue at (8,4)
diff: 
   (3.2 bits)
data: a background with size (13,14) and color black and layers
  _000: 
8 
8 
8 
 at (4,13)
  _00: 
. . . . . . . 8 . . 
. . . . . . . 8 . . 
. . . . . . . 8 . . 
. . . . . . . 8 . . 
. . . . . . . 8 . . 
8 8 8 8 8 8 . 8 . . 
8 . . . . 8 . 8 8 8 
8 8 8 8 . 8 . . . 8 
. . . 8 . 8 8 8 8 8 
8 8 . 8 . . . . . . 
. 8 . 8 . . . . . . 
. 8 8 8 . . . . . . 
 at (0,0)
  _001: 
. . . . . . . . 8 
. . . . 8 8 8 . 8 
. . . . 8 . 8 8 8 
. . . . 8 . . . . 
. . . . 8 8 8 . . 
. . . . . . 8 . . 
. . . . . . 8 . . 
. . . . . . 8 . . 
. . . . . . 8 8 . 
. . . . . . . 8 . 
8 8 8 8 8 8 8 8 . 
8 . . . . . . . . 
8 . . . . . . . . 
 at (0,5)
  _0: rectangle with size (2,5) with model Full with color yellow at (0,8)
  _010: 
. . . 8 . . 
8 8 . 8 8 8 
. 8 . . . 8 
. 8 8 8 8 8 
 at (0,0)
  _0101: 
8 8 8 8 8 8 8 
 at (12,7)
  _01: rectangle with size (7,1) with model Full with color blue at (6,4)
  _011: rectangle with size (1,7) with model Full with color blue at (9,5)
  + 27 delta pixels
diff: 
   (1181.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,14) and color black and layers
  _0: rectangle with size (12,10) with mask 
. . . . . . . 0 . . 
. . . . . . . 0 . . 
. . . . . . . 0 . . 
. . . . . . . 0 . . 
. . . . . . . 0 . . 
0 0 0 0 0 0 . 0 . . 
0 . . . . 0 . 0 0 0 
0 0 0 0 . 0 . . . 0 
. . . 0 . 0 0 0 0 0 
0 0 . 0 . . . . . . 
. 0 . 0 . . . . . . 
. 0 0 0 . . . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (13,9) with mask 
. . . . . . . . 0 
. . . . 0 0 0 . 0 
. . . . 0 . 0 0 0 
. . . . 0 . . . . 
. . . . 0 0 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 0 . 
. . . . . . . 0 . 
0 0 0 0 0 0 0 0 . 
0 . . . . . . . . 
0 . . . . . . . . 
 with color cyan at (0,5)
  _011: rectangle with size (4,6) with mask 
. . . 0 . . 
0 0 . 0 0 0 
. 0 . . . 0 
. 0 0 0 0 0 
 with color cyan at (0,0)
  _0111: rectangle with size (1,7) with model Full with color cyan at (12,7)
  _01111: rectangle with size (3,1) with model Full with color cyan at (4,13)
  _0111110: point with color yellow at (9,4)
  _011111: rectangle with size (3,2) with model Full with color blue at (8,4)
diff: 
! 43 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,14) and color black and layers
  _0: rectangle with size (12,10) with mask 
. . . . . . . 0 . . 
. . . . . . . 0 . . 
. . . . . . . 0 . . 
. . . . . . . 0 . . 
. . . . . . . 0 . . 
0 0 0 0 0 0 . 0 . . 
0 . . . . 0 . 0 0 0 
0 0 0 0 . 0 . . . 0 
. . . 0 . 0 0 0 0 0 
0 0 . 0 . . . . . . 
. 0 . 0 . . . . . . 
. 0 0 0 . . . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (4,6) with mask 
. . . 0 . . 
0 0 . 0 0 0 
. 0 . . . 0 
. 0 0 0 0 0 
 with color cyan at (0,0)
  _011: rectangle with size (13,9) with mask 
. . . . . . . . 0 
. . . . 0 0 0 . 0 
. . . . 0 . 0 0 0 
. . . . 0 . . . . 
. . . . 0 0 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 . . 
. . . . . . 0 0 . 
. . . . . . . 0 . 
0 0 0 0 0 0 0 0 . 
0 . . . . . . . . 
0 . . . . . . . . 
 with color cyan at (0,5)
  _0111: rectangle with size (1,7) with model Full with color cyan at (12,7)
  _01111: rectangle with size (3,1) with model Full with color cyan at (4,13)
  _0111110: point with color yellow at (9,4)
  _011111: rectangle with size (3,2) with model Full with color blue at (8,4)
diff: 
! 47 wrong pixels (generated / expected)

TRAIN b782dc8a.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (14,9) with mask 
. . 0 0 0 0 0 0 0 
. . 0 . . . . . 0 
. . 0 0 0 . 0 0 0 
. . . . 0 . 0 . . 
. . . . 0 . 0 . 0 
. . . . 0 . 0 . 0 
. . . . 0 . 0 0 0 
. . . . 0 . . . . 
. . . . 0 0 0 . . 
. . . . . . 0 . . 
0 0 0 0 0 0 0 . . 
0 . . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
 with color cyan at (1,6)
  _01: rectangle with size (10,9) with mask 
0 0 . . . . . . . 
. 0 . . . . . . . 
. 0 . . . . . . . 
. 0 0 0 0 0 0 . . 
. . . . . . 0 . . 
0 0 0 0 0 . 0 0 0 
. . . . 0 . . . 0 
. . . . 0 0 0 . 0 
. . . . . . 0 . 0 
. . . . . . 0 0 0 
 with color cyan at (0,0)
  _011: rectangle with size (7,5) with mask 
0 0 0 . . 
. . 0 . . 
0 . 0 0 0 
0 . . . 0 
0 0 0 . 0 
. . 0 . 0 
. . 0 0 0 
 with color cyan at (7,0)
  _0111: rectangle with size (6,7) with mask 
. . . . . . 0 
. . . . . . 0 
. . . . . . 0 
. . . . . . 0 
0 0 0 0 0 0 0 
0 . . . . . . 
 with color cyan at (9,8)
  _01111: rectangle with size (2,4) with mask 
0 . . 0 
0 0 0 0 
 with color cyan at (0,3)
  _0111110: point with color green at (2,7)
  _011111: rectangle with size (3,2) with model Full with color yellow at (1,6)
  + 2 delta pixels
diff: 
! 61 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (10,9) with mask 
0 0 . . . . . . . 
. 0 . . . . . . . 
. 0 . . . . . . . 
. 0 0 0 0 0 0 . . 
. . . . . . 0 . . 
0 0 0 0 0 . 0 0 0 
. . . . 0 . . . 0 
. . . . 0 0 0 . 0 
. . . . . . 0 . 0 
. . . . . . 0 0 0 
 with color cyan at (0,0)
  _01: rectangle with size (14,9) with mask 
. . 0 0 0 0 0 0 0 
. . 0 . . . . . 0 
. . 0 0 0 . 0 0 0 
. . . . 0 . 0 . . 
. . . . 0 . 0 . 0 
. . . . 0 . 0 . 0 
. . . . 0 . 0 0 0 
. . . . 0 . . . . 
. . . . 0 0 0 . . 
. . . . . . 0 . . 
0 0 0 0 0 0 0 . . 
0 . . . . . . . . 
0 . . . . . . . . 
0 . . . . . . . . 
 with color cyan at (1,6)
  _011: rectangle with size (7,5) with mask 
0 0 0 . . 
. . 0 . . 
0 . 0 0 0 
0 . . . 0 
0 0 0 . 0 
. . 0 . 0 
. . 0 0 0 
 with color cyan at (7,0)
  _0111: rectangle with size (6,7) with mask 
. . . . . . 0 
. . . . . . 0 
. . . . . . 0 
. . . . . . 0 
0 0 0 0 0 0 0 
0 . . . . . . 
 with color cyan at (9,8)
  _01111: rectangle with size (2,4) with mask 
0 . . 0 
0 0 0 0 
 with color cyan at (0,3)
  _0111110: point with color yellow at (1,7)
  _011111: rectangle with size (2,1) with model Full with color cyan at (13,0)
  + 3 delta pixels
diff: 
! 58 wrong pixels (generated / expected)

TEST b782dc8a.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 60.0 sec (60.0 sec/task)
bits-train-error = 31580.0 bits (31580.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-114] Checking task b8825c91.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 420420.3 = 420422.6
DL output with Mo: L = 2.3 + 420420.3 = 420422.6
DL input+output M: L = 4.6 + 840840.5 = 840845.2

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = closeSym(flipHeight; rotate90; rotate180; , yellow, ^)
0.759	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.661	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.608	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.571	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.543	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.516	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.487	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.463	IN  ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.454	IN  ADD ^.layer_01111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.452	IN  SPE ^.layer_011111.shape.mask.model = Full
0.447	IN  SPE ^.layer_01111111.shape.mask.model = Full
0.447	IN  SPE ^.layer_0111.shape.mask.model = Full
0.447	IN  SPE ^.layer_01111.shape.mask.model = Full
0.446	IN  SPE ^.layer_0111111.shape.mask.model = Full
0.001	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
closeSym(flipHeight; rotate90; rotate180; , yellow, ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 238.3 + 187383.0 = 187621.3
DL output with Mo: L = 18.1 + 0.0 = 18.1
DL input+output M: L = 256.4 + 187383.0 = 187639.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
closeSym(flipHeight; rotate90; rotate180; , yellow, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 18.1 + 0.0 = 18.1
DL input+output M: L = 20.4 + 0.0 = 20.4

# train input/output grids

## instance 1

> Input and output best reading:

data: 
9#9#6 5#9#6 7#7#7#7#6 9#5#6 9#9#
9#1 5#5#6 1 7#9#9#7#1 6 5#5#1 9#
6 5#1 9#7#7#3 3 3 3 7#7#9#1 5#6 
5#5#9#3 7#9#3 3 3 3 9#7#3 9#5#5#
9#6 7#7#3 8 9#1 1 9#8 3 7#7#6 9#
6 1 7#9#8 3 1 1 1 1 4 4 4 4 1 6 
7#7#3 3 9#1 6 6 6 6 4 4 4 4 7#7#
7#9#3 3 1 1 6 1 1 6 4 4 4 4 9#7#
7#9#3 3 1 1 6 1 1 6 1 1 3 3 9#7#
7#7#3 3 9#1 6 6 6 6 1 9#3 3 7#7#
6 1 7#9#8 3 1 1 1 1 4 4 4 7#1 6 
9#6 7#7#3 8 9#1 1 9#4 4 4 7#6 9#
5#5#9#3 7#9#3 3 3 3 4 4 4 9#5#5#
6 5#1 9#7#7#3 3 3 3 4 4 4 1 5#6 
9#1 5#5#6 1 7#9#9#7#1 6 5#5#1 9#
9#9#6 5#9#6 7#7#7#7#6 9#5#6 9#9#

diff: 
   (0.0 bits)
data: 
9#9#6 5#9#6 7#7#7#7#6 9#5#6 9#9#
9#1 5#5#6 1 7#9#9#7#1 6 5#5#1 9#
6 5#1 9#7#7#3 3 3 3 7#7#9#1 5#6 
5#5#9#3 7#9#3 3 3 3 9#7#3 9#5#5#
9#6 7#7#3 8 9#1 1 9#8 3 7#7#6 9#
6 1 7#9#8 3 1 1 1 1 3 8 9#7#1 6 
7#7#3 3 9#1 6 6 6 6 1 9#3 3 7#7#
7#9#3 3 1 1 6 1 1 6 1 1 3 3 9#7#
7#9#3 3 1 1 6 1 1 6 1 1 3 3 9#7#
7#7#3 3 9#1 6 6 6 6 1 9#3 3 7#7#
6 1 7#9#8 3 1 1 1 1 3 8 9#7#1 6 
9#6 7#7#3 8 9#1 1 9#8 3 7#7#6 9#
5#5#9#3 7#9#3 3 3 3 9#7#3 9#5#5#
6 5#1 9#7#7#3 3 3 3 7#7#9#1 5#6 
9#1 5#5#6 1 7#9#9#7#1 6 5#5#1 9#
9#9#6 5#9#6 7#7#7#7#6 9#5#6 9#9#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
9#9#6 5#9#6 7#7#7#7#6 9#5#6 9#9#
9#1 5#5#6 1 7#9#9#7#1 6 5#5#1 9#
6 5#1 9#7#7#3 3 3 3 7#7#9#1 5#6 
5#5#9#3 7#9#3 3 3 3 9#7#3 9#5#5#
9#6 7#7#3 8 9#1 1 9#8 3 7#7#6 9#
6 1 7#9#8 3 1 1 1 1 4 4 4 4 1 6 
7#7#3 3 9#1 6 6 6 6 4 4 4 4 7#7#
7#9#3 3 1 1 6 1 1 6 4 4 4 4 9#7#
7#9#3 3 1 1 6 1 1 6 1 1 3 3 9#7#
7#7#3 3 9#1 6 6 6 6 1 9#3 3 7#7#
6 1 7#9#8 3 1 1 1 1 4 4 4 7#1 6 
9#6 7#7#3 8 9#1 1 9#4 4 4 7#6 9#
5#5#9#3 7#9#3 3 3 3 4 4 4 9#5#5#
6 5#1 9#7#7#3 3 3 3 4 4 4 1 5#6 
9#1 5#5#6 1 7#9#9#7#1 6 5#5#1 9#
9#9#6 5#9#6 7#7#7#7#6 9#5#6 9#9#

diff: 
correct output grid

TRAIN b8825c91.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
9#9#6 1 8 9#6 6 6 6 9#8 1 6 9#9#
9#6 1 3 9#6 6 1 1 6 6 9#3 1 6 9#
6 4 4 2 6 6 8 8 8 8 6 6 2 5#1 6 
1 4 4 8 6 1 8 2 2 8 1 6 8 2 3 1 
8 4 4 6 7#1 5#5#5#5#1 7#6 6 9#8 
9#6 6 1 1 1 5#5#5#5#1 1 1 6 6 9#
6 6 8 8 5#5#9#5#5#9#5#5#8 8 6 6 
6 1 8 2 5#5#5#8 8 5#5#5#2 8 1 6 
6 1 8 2 5#5#5#8 8 5#5#4 4 4 1 6 
6 6 8 8 5#5#9#5#5#9#5#4 4 4 6 6 
9#6 6 1 1 1 5#5#5#5#1 1 1 6 6 9#
8 9#6 6 7#1 5#5#5#5#1 7#6 6 9#8 
1 3 2 8 6 1 8 2 2 8 1 6 8 2 3 1 
6 1 5#2 6 6 8 8 8 8 6 6 2 5#1 6 
9#6 1 3 9#6 6 1 1 6 6 9#3 1 6 9#
9#9#6 1 8 9#6 6 6 6 9#8 1 6 9#9#

diff: 
   (0.0 bits)
data: 
9#9#6 1 8 9#6 6 6 6 9#8 1 6 9#9#
9#6 1 3 9#6 6 1 1 6 6 9#3 1 6 9#
6 1 5#2 6 6 8 8 8 8 6 6 2 5#1 6 
1 3 2 8 6 1 8 2 2 8 1 6 8 2 3 1 
8 9#6 6 7#1 5#5#5#5#1 7#6 6 9#8 
9#6 6 1 1 1 5#5#5#5#1 1 1 6 6 9#
6 6 8 8 5#5#9#5#5#9#5#5#8 8 6 6 
6 1 8 2 5#5#5#8 8 5#5#5#2 8 1 6 
6 1 8 2 5#5#5#8 8 5#5#5#2 8 1 6 
6 6 8 8 5#5#9#5#5#9#5#5#8 8 6 6 
9#6 6 1 1 1 5#5#5#5#1 1 1 6 6 9#
8 9#6 6 7#1 5#5#5#5#1 7#6 6 9#8 
1 3 2 8 6 1 8 2 2 8 1 6 8 2 3 1 
6 1 5#2 6 6 8 8 8 8 6 6 2 5#1 6 
9#6 1 3 9#6 6 1 1 6 6 9#3 1 6 9#
9#9#6 1 8 9#6 6 6 6 9#8 1 6 9#9#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
9#9#6 1 8 9#6 6 6 6 9#8 1 6 9#9#
9#6 1 3 9#6 6 1 1 6 6 9#3 1 6 9#
6 4 4 2 6 6 8 8 8 8 6 6 2 5#1 6 
1 4 4 8 6 1 8 2 2 8 1 6 8 2 3 1 
8 4 4 6 7#1 5#5#5#5#1 7#6 6 9#8 
9#6 6 1 1 1 5#5#5#5#1 1 1 6 6 9#
6 6 8 8 5#5#9#5#5#9#5#5#8 8 6 6 
6 1 8 2 5#5#5#8 8 5#5#5#2 8 1 6 
6 1 8 2 5#5#5#8 8 5#5#4 4 4 1 6 
6 6 8 8 5#5#9#5#5#9#5#4 4 4 6 6 
9#6 6 1 1 1 5#5#5#5#1 1 1 6 6 9#
8 9#6 6 7#1 5#5#5#5#1 7#6 6 9#8 
1 3 2 8 6 1 8 2 2 8 1 6 8 2 3 1 
6 1 5#2 6 6 8 8 8 8 6 6 2 5#1 6 
9#6 1 3 9#6 6 1 1 6 6 9#3 1 6 9#
9#9#6 1 8 9#6 6 6 6 9#8 1 6 9#9#

diff: 
correct output grid

TRAIN b8825c91.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
9#3 9#9#2 8 7#8 8 7#8 2 9#9#3 9#
3 9#9#3 8 8 8 5#5#8 8 8 3 9#9#3 
9#9#2 8 7#8 2 2 2 2 8 7#8 2 9#9#
9#3 8 8 8 5#2 1 1 2 5#8 8 8 3 9#
2 8 7#8 2 5#9#7#7#9#5#2 8 7#8 2 
8 8 8 5#5#5#7#6 6 7#5#5#5#8 8 8 
7#8 2 2 9#7#1 1 1 1 7#9#4 4 8 7#
8 5#2 1 7#6 1 3 3 1 6 7#4 4 5#8 
8 5#2 1 7#6 1 3 3 1 6 7#4 4 5#8 
7#8 2 2 9#7#1 1 1 1 7#9#4 4 8 7#
8 8 8 5#5#5#7#6 6 7#5#5#5#8 8 8 
2 8 4 4 4 4 9#7#7#9#5#2 8 7#8 2 
9#3 4 4 4 4 2 1 1 2 5#8 8 8 3 9#
9#9#4 4 4 4 2 2 2 2 8 7#8 2 9#9#
3 9#4 4 4 4 8 5#5#8 8 8 3 9#9#3 
9#3 9#9#2 8 7#8 8 7#8 2 9#9#3 9#

diff: 
   (0.0 bits)
data: 
9#3 9#9#2 8 7#8 8 7#8 2 9#9#3 9#
3 9#9#3 8 8 8 5#5#8 8 8 3 9#9#3 
9#9#2 8 7#8 2 2 2 2 8 7#8 2 9#9#
9#3 8 8 8 5#2 1 1 2 5#8 8 8 3 9#
2 8 7#8 2 5#9#7#7#9#5#2 8 7#8 2 
8 8 8 5#5#5#7#6 6 7#5#5#5#8 8 8 
7#8 2 2 9#7#1 1 1 1 7#9#2 2 8 7#
8 5#2 1 7#6 1 3 3 1 6 7#1 2 5#8 
8 5#2 1 7#6 1 3 3 1 6 7#1 2 5#8 
7#8 2 2 9#7#1 1 1 1 7#9#2 2 8 7#
8 8 8 5#5#5#7#6 6 7#5#5#5#8 8 8 
2 8 7#8 2 5#9#7#7#9#5#2 8 7#8 2 
9#3 8 8 8 5#2 1 1 2 5#8 8 8 3 9#
9#9#2 8 7#8 2 2 2 2 8 7#8 2 9#9#
3 9#9#3 8 8 8 5#5#8 8 8 3 9#9#3 
9#3 9#9#2 8 7#8 8 7#8 2 9#9#3 9#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
9#3 9#9#2 8 7#8 8 7#8 2 9#9#3 9#
3 9#9#3 8 8 8 5#5#8 8 8 3 9#9#3 
9#9#2 8 7#8 2 2 2 2 8 7#8 2 9#9#
9#3 8 8 8 5#2 1 1 2 5#8 8 8 3 9#
2 8 7#8 2 5#9#7#7#9#5#2 8 7#8 2 
8 8 8 5#5#5#7#6 6 7#5#5#5#8 8 8 
7#8 2 2 9#7#1 1 1 1 7#9#4 4 8 7#
8 5#2 1 7#6 1 3 3 1 6 7#4 4 5#8 
8 5#2 1 7#6 1 3 3 1 6 7#4 4 5#8 
7#8 2 2 9#7#1 1 1 1 7#9#4 4 8 7#
8 8 8 5#5#5#7#6 6 7#5#5#5#8 8 8 
2 8 4 4 4 4 9#7#7#9#5#2 8 7#8 2 
9#3 4 4 4 4 2 1 1 2 5#8 8 8 3 9#
9#9#4 4 4 4 2 2 2 2 8 7#8 2 9#9#
3 9#4 4 4 4 8 5#5#8 8 8 3 9#9#3 
9#3 9#9#2 8 7#8 8 7#8 2 9#9#3 9#

diff: 
correct output grid

TRAIN b8825c91.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: 
2 2 7#6 8 9#9#1 1 9#9#8 6 7#2 2 
2 1 6 2 9#5#1 1 1 1 4 4 4 4 1 2 
7#6 3 3 9#1 6 6 6 6 4 4 4 4 6 7#
6 2 3 8 1 1 6 6 6 6 4 4 4 4 2 6 
8 9#9#1 1 7#1 1 1 1 7#1 1 9#9#8 
9#5#1 1 7#7#1 3 3 1 7#7#1 1 5#9#
9#1 6 6 1 1 3 3 3 3 1 1 6 6 1 9#
1 1 6 6 1 3 3 2 2 3 3 1 6 6 1 1 
1 1 6 4 4 3 3 2 2 3 3 1 6 6 1 1 
9#1 6 4 4 1 3 3 3 3 1 1 6 6 1 9#
9#5#1 4 4 7#1 3 3 1 7#7#1 1 5#9#
8 9#9#1 1 7#1 1 1 1 7#1 1 9#9#8 
6 2 3 8 1 1 6 6 6 6 1 1 8 3 2 6 
7#6 3 3 9#1 6 6 6 6 1 9#3 3 6 7#
2 1 6 2 9#5#1 1 1 1 5#9#2 6 1 2 
2 2 7#6 8 9#9#1 1 9#9#8 6 7#2 2 

diff: 
   (0.0 bits)
data: 
2 2 7#6 8 9#9#1 1 9#9#8 6 7#2 2 
2 1 6 2 9#5#1 1 1 1 5#9#2 6 1 2 
7#6 3 3 9#1 6 6 6 6 1 9#3 3 6 7#
6 2 3 8 1 1 6 6 6 6 1 1 8 3 2 6 
8 9#9#1 1 7#1 1 1 1 7#1 1 9#9#8 
9#5#1 1 7#7#1 3 3 1 7#7#1 1 5#9#
9#1 6 6 1 1 3 3 3 3 1 1 6 6 1 9#
1 1 6 6 1 3 3 2 2 3 3 1 6 6 1 1 
1 1 6 6 1 3 3 2 2 3 3 1 6 6 1 1 
9#1 6 6 1 1 3 3 3 3 1 1 6 6 1 9#
9#5#1 1 7#7#1 3 3 1 7#7#1 1 5#9#
8 9#9#1 1 7#1 1 1 1 7#1 1 9#9#8 
6 2 3 8 1 1 6 6 6 6 1 1 8 3 2 6 
7#6 3 3 9#1 6 6 6 6 1 9#3 3 6 7#
2 1 6 2 9#5#1 1 1 1 5#9#2 6 1 2 
2 2 7#6 8 9#9#1 1 9#9#8 6 7#2 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 2 7#6 8 9#9#1 1 9#9#8 6 7#2 2 
2 1 6 2 9#5#1 1 1 1 4 4 4 4 1 2 
7#6 3 3 9#1 6 6 6 6 4 4 4 4 6 7#
6 2 3 8 1 1 6 6 6 6 4 4 4 4 2 6 
8 9#9#1 1 7#1 1 1 1 7#1 1 9#9#8 
9#5#1 1 7#7#1 3 3 1 7#7#1 1 5#9#
9#1 6 6 1 1 3 3 3 3 1 1 6 6 1 9#
1 1 6 6 1 3 3 2 2 3 3 1 6 6 1 1 
1 1 6 4 4 3 3 2 2 3 3 1 6 6 1 1 
9#1 6 4 4 1 3 3 3 3 1 1 6 6 1 9#
9#5#1 4 4 7#1 3 3 1 7#7#1 1 5#9#
8 9#9#1 1 7#1 1 1 1 7#1 1 9#9#8 
6 2 3 8 1 1 6 6 6 6 1 1 8 3 2 6 
7#6 3 3 9#1 6 6 6 6 1 9#3 3 6 7#
2 1 6 2 9#5#1 1 1 1 5#9#2 6 1 2 
2 2 7#6 8 9#9#1 1 9#9#8 6 7#2 2 

diff: 
correct output grid

TRAIN b8825c91.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
7#7#8 1 9#8 2 6 6 2 8 9#1 8 7#7#
7#1 1 8 8 8 6 6 6 6 8 8 8 1 1 7#
8 1 6 9#2 6 4 4 4 6 6 2 9#6 1 8 
1 8 9#1 6 6 4 4 4 1 6 6 1 9#8 1 
9#8 2 6 8 7#4 4 4 6 4 4 4 4 8 9#
8 8 6 6 7#7#6 5#5#6 4 4 4 4 8 8 
2 6 6 1 6 6 5#5#5#5#4 4 4 4 6 2 
6 6 1 1 6 5#5#7#7#5#4 4 4 4 6 6 
6 6 1 1 6 5#5#7#7#5#5#6 1 1 6 6 
2 6 6 1 6 6 5#5#5#5#6 6 1 6 6 2 
8 8 6 6 7#7#6 5#5#6 7#7#6 6 8 8 
9#8 2 6 8 7#6 6 6 6 7#8 6 2 8 9#
1 8 9#1 6 6 1 1 1 1 6 6 1 9#8 1 
8 1 6 9#2 6 6 1 1 6 6 2 9#6 1 8 
7#1 1 8 8 8 6 6 6 6 8 8 8 1 1 7#
7#7#8 1 9#8 2 6 6 2 8 9#1 8 7#7#

diff: 
correct output grid

TEST b8825c91.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 6.4 sec (6.4 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-113] Checking task b8cdaf2b.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 42145.2 = 42147.5
DL output with Mo: L = 2.3 + 42145.2 = 42147.5
DL input+output M: L = 4.6 + 84290.4 = 84295.0

# learning a model for train pairs
2.000	
1.273	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.654	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.512	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.331	OUT ADD ^.layer_0 = ^.layer_0
0.277	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.228	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.182	OUT ADD ^.layer_011 = ^.layer_01
0.154	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.139	OUT SPE ^.size = ^.size
0.131	OUT SPE ^.layer_01.pos = projI(^.layer_01.pos) - (2, 0)
0.127	OUT SPE ^.layer_01.shape.mask.size.i = ^.layer_01.shape.mask.size.i
0.123	OUT SPE ^.layer_0111.pos.j = ^.layer_01.pos.i
0.119	OUT SPE ^.layer_01.shape.mask.size.j = ^.layer_01.shape.mask.size.i
0.115	OUT SPE ^.layer_0111.pos.i = ^.layer_01.pos.i - 2
0.112	OUT SPE ^.layer_0111.shape.mask.size.i = ^.layer_01.shape.mask.size.i
0.108	OUT SPE ^.layer_0111.shape.mask.size.j = ^.layer_01.shape.mask.size.i
0.106	IN  SPE ^.color = black
0.103	OUT SPE ^.color = black
0.026	
0.026	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (^.layer_01.shape.mask.size.i,^.layer_01.shape.mask.size.i) with model ? with color ? at projI(^.layer_01.pos) - (2, 0)
  _011: ^.layer_01
  _0111: rectangle with size (^.layer_01.shape.mask.size.i,^.layer_01.shape.mask.size.i) with model ? with color ? at (^.layer_01.pos.i - 2,^.layer_01.pos.i)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.3 + 3289.1 = 3359.4
DL output with Mo: L = 165.8 + 829.6 = 995.3
DL input+output M: L = 236.1 + 4118.6 = 4354.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (^.layer_01.shape.mask.size.i,^.layer_01.shape.mask.size.i) with model ? with color ? at projI(^.layer_01.pos) - (2, 0)
  _011: ^.layer_01
  _0111: rectangle with size (^.layer_01.shape.mask.size.i,^.layer_01.shape.mask.size.i) with model ? with color ? at (^.layer_01.pos.i - 2,^.layer_01.pos.i)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 40.0 = 110.2
DL output with Mo: L = 165.8 + 829.6 = 995.3
DL input+output M: L = 236.0 + 869.6 = 1105.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,3) with model Odd Checkboard with color red at (1,0)
  _01: rectangle with size (1,1) with model Full with color yellow at (2,1)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
. 2 . 
2 . 2 
 at (1,0)
  _01: rectangle with size (1,1) with model Full with color yellow at (0,0)
  _011: 
4 
 at (2,1)
  _0111: rectangle with size (1,1) with model Full with color yellow at (0,2)
diff: 
   (16.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,3) with model Odd Checkboard with color red at (1,0)
  _01: rectangle with size (1,1) with model Full with color yellow at (2,1)
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color yellow at (2,1)
  _01: rectangle with size (2,3) with model Odd Checkboard with color red at (1,0)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,3) and color red and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color black at (0,0)
  _01: rectangle with size (1,1) with model Full with color yellow at (2,1)
diff: 
! 5 wrong pixels (generated / expected)

TRAIN b8cdaf2b.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (5,5) and color black and layers
  _0: rectangle with size (1,1) with model Full with color green at (4,2)
  _01: rectangle with size (2,5) with mask 
. . 0 . . 
0 0 . 0 0 
 with color cyan at (3,0)
diff: 
   (2.0 bits)
data: a background with size (5,5) and color black and layers
  _0: 
3 
 at (4,2)
  _01: rectangle with size (2,2) with model Even Checkboard with color green at (1,0)
  _011: 
. . 8 . . 
8 8 . 8 8 
 at (3,0)
  _0111: rectangle with size (2,2) with model Odd Checkboard with color green at (1,3)
diff: 
   (24.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,5) with mask 
. . 0 . . 
0 0 . 0 0 
 with color cyan at (3,0)
  _01: rectangle with size (1,1) with model Full with color green at (4,2)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (1,1) with model Full with color green at (4,2)
  _01: rectangle with size (2,5) with mask 
. . 0 . . 
0 0 . 0 0 
 with color cyan at (3,0)
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (1,5) with model Full with color cyan at (4,0)
  _01: rectangle with size (1,1) with model Full with color cyan at (3,2)
  + 1 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TRAIN b8cdaf2b.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,5) with mask 
. 0 0 0 . 
0 . . . 0 
 with color pink at (3,0)
  _01: rectangle with size (1,3) with model Full with color blue at (4,1)
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: 
. 6 6 6 . 
6 . . . 6 
 at (3,0)
  _01: rectangle with size (1,1) with model Full with color blue at (2,0)
  _011: 
1 1 1 
 at (4,1)
  _0111: rectangle with size (1,1) with model Full with color blue at (2,4)
diff: 
   (16.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (2,5) with mask 
. 0 0 0 . 
0 . . . 0 
 with color pink at (3,0)
  _01: rectangle with size (1,3) with model Full with color blue at (4,1)
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (1,3) with model Full with color blue at (4,1)
  _01: rectangle with size (2,5) with mask 
. 0 0 0 . 
0 . . . 0 
 with color pink at (3,0)
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (1,3) with model Full with color pink at (3,1)
  _01: rectangle with size (1,3) with model Full with color blue at (4,1)
  + 2 delta pixels
diff: 
! 4 wrong pixels (generated / expected)

TRAIN b8cdaf2b.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (7,7) and color black and layers
  _0: rectangle with size (1,3) with model Full with color yellow at (6,2)
  _01: rectangle with size (2,7) with mask 
. . 0 0 0 . . 
0 0 . . . 0 0 
 with color red at (5,0)
diff: 
   (2.0 bits)
data: a background with size (7,7) and color black and layers
  _0: 
4 4 4 
 at (6,2)
  _01: rectangle with size (2,2) with model Even Checkboard with color yellow at (3,0)
  _011: 
. . 2 2 2 . . 
2 2 . . . 2 2 
 at (5,0)
  _0111: rectangle with size (2,2) with model Odd Checkboard with color yellow at (3,5)
diff: 
   (24.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (2,7) with mask 
. . 0 0 0 . . 
0 0 . . . 0 0 
 with color red at (5,0)
  _01: rectangle with size (1,3) with model Full with color yellow at (6,2)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (1,3) with model Full with color yellow at (6,2)
  _01: rectangle with size (2,7) with mask 
. . 0 0 0 . . 
0 0 . . . 0 0 
 with color red at (5,0)
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (5,2)
  _01: rectangle with size (1,7) with model Full with color red at (6,0)
  + 3 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN b8cdaf2b.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (2,9) with mask 
. . . 0 0 0 . . . 
0 0 0 . . . 0 0 0 
 with color cyan at (7,0)
  _01: rectangle with size (1,3) with model Full with color red at (8,3)
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (8,3)
  _01: rectangle with size (2,9) with mask 
. . . 0 0 0 . . . 
0 0 0 . . . 0 0 0 
 with color cyan at (7,0)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (1,3) with model Full with color cyan at (7,3)
  _01: rectangle with size (1,9) with model Full with color cyan at (8,0)
  + 3 delta pixels
diff: 
! 11 wrong pixels (generated / expected)

TEST b8cdaf2b.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 5.8 sec (5.8 sec/task)
bits-train-error = 829.6 bits (829.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-112] Checking task b91ae062.json: 5 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 17558.0 = 17560.3
DL output with Mo: L = 2.3 + 150493.5 = 150495.8
DL input+output M: L = 4.6 + 168051.5 = 168056.2

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = ^ * colorCount(^)
0.510	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.380	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.310	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.271	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.263	IN  SPE ^.layer_01.shape.mask.model = Full
0.256	IN  SPE ^.color = black
0.005	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
^ * colorCount(^)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 88.9 + 4402.6 = 4491.6
DL output with Mo: L = 17.5 + 0.0 = 17.5
DL input+output M: L = 106.4 + 4402.6 = 4509.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
^ * colorCount(^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 17.5 + 0.0 = 17.5
DL input+output M: L = 19.8 + 0.0 = 19.8

# train input/output grids

## instance 1

> Input and output best reading:

data: 
6 7#0 
0 6 6 
0 0 0 

diff: 
   (0.0 bits)
data: 
6 6 7#7#0 0 
6 6 7#7#0 0 
0 0 6 6 6 6 
0 0 6 6 6 6 
0 0 0 0 0 0 
0 0 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
6 7#0 
0 6 6 
0 0 0 

diff: 
correct output grid

TRAIN b91ae062.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
1 0 4 
0 4 0 
0 1 0 

diff: 
   (0.0 bits)
data: 
1 1 0 0 4 4 
1 1 0 0 4 4 
0 0 4 4 0 0 
0 0 4 4 0 0 
0 0 1 1 0 0 
0 0 1 1 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 0 4 
0 4 0 
0 1 0 

diff: 
correct output grid

TRAIN b91ae062.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
3 2 0 
0 7#3 
0 0 0 

diff: 
   (0.0 bits)
data: 
3 3 3 2 2 2 0 0 0 
3 3 3 2 2 2 0 0 0 
3 3 3 2 2 2 0 0 0 
0 0 0 7#7#7#3 3 3 
0 0 0 7#7#7#3 3 3 
0 0 0 7#7#7#3 3 3 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 2 0 
0 7#3 
0 0 0 

diff: 
correct output grid

TRAIN b91ae062.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: 
0 8 0 
0 6 6 
9#8 0 

diff: 
   (0.0 bits)
data: 
0 0 0 8 8 8 0 0 0 
0 0 0 8 8 8 0 0 0 
0 0 0 8 8 8 0 0 0 
0 0 0 6 6 6 6 6 6 
0 0 0 6 6 6 6 6 6 
0 0 0 6 6 6 6 6 6 
9#9#9#8 8 8 0 0 0 
9#9#9#8 8 8 0 0 0 
9#9#9#8 8 8 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 8 0 
0 6 6 
9#8 0 

diff: 
correct output grid

TRAIN b91ae062.json/4: 1 1st (SUCCESS)

## instance 5

> Input and output best reading:

data: 
4 0 3 
2 2 0 
0 0 8 

diff: 
   (0.0 bits)
data: 
4 4 4 4 0 0 0 0 3 3 3 3 
4 4 4 4 0 0 0 0 3 3 3 3 
4 4 4 4 0 0 0 0 3 3 3 3 
4 4 4 4 0 0 0 0 3 3 3 3 
2 2 2 2 2 2 2 2 0 0 0 0 
2 2 2 2 2 2 2 2 0 0 0 0 
2 2 2 2 2 2 2 2 0 0 0 0 
2 2 2 2 2 2 2 2 0 0 0 0 
0 0 0 0 0 0 0 0 8 8 8 8 
0 0 0 0 0 0 0 0 8 8 8 8 
0 0 0 0 0 0 0 0 8 8 8 8 
0 0 0 0 0 0 0 0 8 8 8 8 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 0 3 
2 2 0 
0 0 8 

diff: 
correct output grid

TRAIN b91ae062.json/5: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 1 0 
0 8 7#
9#9#0 

diff: 
correct output grid

TEST b91ae062.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.2 sec (1.2 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-111] Checking task b94a9452.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 179284.6 = 179286.9
DL output with Mo: L = 2.3 + 19416.1 = 19418.4
DL input+output M: L = 4.6 + 198700.7 = 198705.3

# learning a model for train pairs
2.000	
1.117	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.272	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.179	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.101	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.079	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.070	IN  ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.045	OUT SPE ^.layer_0.shape = coloring(^.layer_00.shape, ^.layer_0.shape.color)
0.032	OUT SPE ^.color = ^.layer_00.shape.color
0.020	OUT SPE ^.layer_0.pos = '(0, 0) + ^.layer_00.pos - ^.layer_0.pos
0.019	IN  SPE ^.layer_00.shape.mask.model = Full
0.019	IN  SPE ^.layer_0.shape.mask.model = Full
0.019	IN  SPE ^.color = black
0.005	
0.005	IN  GEN ^.layer_0.shape.mask.model = ?
0.005	IN  GEN ^.layer_00.shape.mask.model = ?
0.005	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color ^.layer_00.shape.color and layers
  _0: coloring(^.layer_00.shape, ^.layer_0.shape.color) at '(0, 0) + ^.layer_00.pos - ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 71.4 + 2355.2 = 2426.6
DL output with Mo: L = 97.3 + 0.0 = 97.3
DL input+output M: L = 168.7 + 2355.2 = 2523.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color ^.layer_00.shape.color and layers
  _0: coloring(^.layer_00.shape, ^.layer_0.shape.color) at '(0, 0) + ^.layer_00.pos - ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 97.3 + 0.0 = 97.3
DL input+output M: L = 167.5 + 0.0 = 167.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (12,13) and color black and layers
  _00: rectangle with size (2,2) with model Full with color yellow at (2,4)
  _0: rectangle with size (4,4) with model Full with color red at (1,3)
diff: 
   (0.0 bits)
data: a background with size (4,4) and color yellow and layers
  _0: 
2 2 
2 2 
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,13) and color black and layers
  _00: rectangle with size (2,2) with model Full with color yellow at (2,4)
  _0: rectangle with size (4,4) with model Full with color red at (1,3)
diff: 
correct output grid

TRAIN b94a9452.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (12,11) and color black and layers
  _00: rectangle with size (1,1) with model Full with color green at (3,5)
  _0: rectangle with size (3,3) with model Full with color blue at (2,4)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color green and layers
  _0: 
1 
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,11) and color black and layers
  _00: rectangle with size (1,1) with model Full with color green at (3,5)
  _0: rectangle with size (3,3) with model Full with color blue at (2,4)
diff: 
correct output grid

TRAIN b94a9452.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (12,13) and color black and layers
  _00: rectangle with size (1,1) with model Full with color pink at (8,4)
  _0: rectangle with size (5,5) with model Full with color yellow at (6,2)
diff: 
   (0.0 bits)
data: a background with size (5,5) and color pink and layers
  _0: 
4 
 at (2,2)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,13) and color black and layers
  _00: rectangle with size (1,1) with model Full with color pink at (8,4)
  _0: rectangle with size (5,5) with model Full with color yellow at (6,2)
diff: 
correct output grid

TRAIN b94a9452.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,13) and color black and layers
  _00: rectangle with size (2,2) with model Full with color cyan at (3,4)
  _0: rectangle with size (6,6) with model Full with color green at (1,2)
diff: 
correct output grid

TEST b94a9452.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 3.8 sec (3.8 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-110] Checking task b9b7f026.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 295956.7 = 295959.1
DL output with Mo: L = 2.3 + 1458.7 = 1461.0
DL input+output M: L = 4.6 + 297415.4 = 297420.1

# learning a model for train pairs
2.000	
1.329	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.713	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.580	OUT SPE ^.size = '(1, 1)
0.488	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.402	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.325	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.149	OUT SPE ^.color = ^.layer_01.shape.color
0.088	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.087	IN  SPE ^.layer_011.shape.mask.model = Full
0.087	IN  SPE ^.layer_0111.shape.mask.model = Full
0.087	IN  SPE ^.layer_0.shape.mask.model = Full
0.065	IN  ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.064	IN  SPE ^.layer_00.shape.mask.model = Full
0.064	IN  SPE ^.color = black
0.022	
0.022	IN  DEL ^.layer_0111
0.021	IN  DEL ^.layer_011
0.021	IN  GEN ^.layer_00.shape.mask.model = ?
0.021	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(1, 1) and color ^.layer_01.shape.color and layers
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 155.6 + 12557.8 = 12713.3
DL output with Mo: L = 30.8 + 0.0 = 30.8
DL input+output M: L = 186.4 + 12557.8 = 12744.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(1, 1) and color ^.layer_01.shape.color and layers
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.6 + 0.0 = 98.6
DL output with Mo: L = 30.8 + 0.0 = 30.8
DL input+output M: L = 129.5 + 0.0 = 129.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (15,13) and color black and layers
  _00: rectangle with size (3,5) with model Full with color red at (7,3)
  _0: rectangle with size (3,4) with model Full with color cyan at (11,8)
  _01: rectangle with size (4,3) with model Border with color pink at (1,1)
  + 28 delta pixels
diff: 
   (0.0 bits)
data: a background with size (1,1) and color pink and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,13) and color black and layers
  _00: rectangle with size (3,5) with model Full with color red at (7,3)
  _0: rectangle with size (3,4) with model Full with color cyan at (11,8)
  _01: rectangle with size (4,3) with model Border with color pink at (1,1)
  + 28 delta pixels
diff: 
correct output grid

TRAIN b9b7f026.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (15,17) and color black and layers
  _00: rectangle with size (6,4) with model Full with color orange at (0,13)
  _0: rectangle with size (4,5) with model Full with color yellow at (11,10)
  _01: rectangle with size (7,4) with mask 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 . . 0 
0 . . 0 
0 0 0 0 
0 0 0 0 
 with color grey at (3,7)
  + 33 delta pixels
diff: 
   (0.0 bits)
data: a background with size (1,1) and color grey and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,17) and color black and layers
  _00: rectangle with size (6,4) with model Full with color orange at (0,13)
  _0: rectangle with size (4,5) with model Full with color yellow at (11,10)
  _01: rectangle with size (7,4) with mask 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 . . 0 
0 . . 0 
0 0 0 0 
0 0 0 0 
 with color grey at (3,7)
  + 33 delta pixels
diff: 
correct output grid

TRAIN b9b7f026.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (16,17) and color black and layers
  _00: rectangle with size (5,6) with model Full with color blue at (1,2)
  _0: rectangle with size (6,5) with model Full with color green at (2,10)
  _01: rectangle with size (5,7) with mask 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 . . . 0 0 0 
0 . . . 0 0 0 
0 0 0 0 0 0 0 
 with color red at (9,2)
  + 20 delta pixels
diff: 
   (0.0 bits)
data: a background with size (1,1) and color red and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,17) and color black and layers
  _00: rectangle with size (5,6) with model Full with color blue at (1,2)
  _0: rectangle with size (6,5) with model Full with color green at (2,10)
  _01: rectangle with size (5,7) with mask 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 
0 . . . 0 0 0 
0 . . . 0 0 0 
0 0 0 0 0 0 0 
 with color red at (9,2)
  + 20 delta pixels
diff: 
correct output grid

TRAIN b9b7f026.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,15) and color black and layers
  _00: rectangle with size (6,8) with model Full with color red at (1,0)
  _0: rectangle with size (5,4) with model Full with color green at (0,10)
  _01: rectangle with size (4,4) with model Full with color yellow at (6,9)
  + 35 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,15) and color black and layers
  _00: rectangle with size (6,8) with model Full with color red at (1,0)
  _0: rectangle with size (5,4) with model Full with color green at (0,10)
  _01: rectangle with size (4,4) with model Full with color cyan at (9,4)
  + 35 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (14,15) and color black and layers
  _00: rectangle with size (6,8) with model Full with color red at (1,0)
  _0: rectangle with size (4,4) with model Full with color yellow at (6,9)
  _01: rectangle with size (5,4) with model Full with color green at (0,10)
  + 35 delta pixels
diff: 
! 1 wrong pixels (generated / expected)

TEST b9b7f026.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 4.7 sec (4.7 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-109] Checking task ba26e723.json: 5 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 69039.7 = 69042.0
DL output with Mo: L = 2.3 + 69039.7 = 69042.0
DL input+output M: L = 4.6 + 138079.4 = 138084.0

# learning a model for train pairs
2.000	
1.349	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.942	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.656	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.570	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.539	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.478	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.458	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.418	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.391	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.328	
0.327	IN  GEN ^ = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 4355.2 = 4397.2
DL output with Mo: L = 180.9 + 22402.9 = 22583.8
DL input+output M: L = 222.9 + 26758.1 = 26981.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 180.9 + 22402.9 = 22583.8
DL input+output M: L = 183.2 + 22402.9 = 22586.1

# train input/output grids

## instance 1

> Input and output best reading:

data: 
4 0 4 0 4 0 4 0 4 0 
4 4 4 4 4 4 4 4 4 4 
0 4 0 4 0 4 0 4 0 4 

diff: 
   (0.0 bits)
data: a background with size (3,10) and color black and layers
  _0: rectangle with size (3,2) with mask 
. 0 
0 0 
0 . 
 with color yellow at (0,1)
  _01: rectangle with size (3,2) with mask 
0 . 
0 0 
. 0 
 with color yellow at (0,4)
  _011: rectangle with size (2,7) with model Full with color pink at (0,0)
  _0111: rectangle with size (3,2) with mask 
. 0 
0 0 
0 . 
 with color yellow at (0,7)
  _01111: rectangle with size (2,1) with model Full with color pink at (1,9)
  _011111: rectangle with size (2,1) with model Full with color pink at (1,3)
  + 4 delta pixels
diff: 
   (362.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 0 4 0 4 0 4 0 4 0 
4 4 4 4 4 4 4 4 4 4 
0 4 0 4 0 4 0 4 0 4 

diff: 
! size mismatch, 10x10 instead of 3x10

TRAIN ba26e723.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
0 4 0 4 0 4 0 4 0 4 0 
4 4 4 4 4 4 4 4 4 4 4 
4 0 4 0 4 0 4 0 4 0 4 

diff: 
   (0.0 bits)
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 . 
0 0 
. 0 
 with color yellow at (0,1)
  _01: rectangle with size (3,2) with mask 
. 0 
0 0 
0 . 
 with color yellow at (0,4)
  _011: rectangle with size (3,2) with mask 
0 . 
0 0 
. 0 
 with color yellow at (0,7)
  _0111: rectangle with size (2,7) with model Full with color pink at (0,3)
  _01111: rectangle with size (2,1) with model Full with color pink at (1,0)
  _011111: rectangle with size (2,1) with model Full with color yellow at (1,10)
  + 5 delta pixels
diff: 
   (403.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 4 0 4 0 4 0 4 0 4 0 
4 4 4 4 4 4 4 4 4 4 4 
4 0 4 0 4 0 4 0 4 0 4 

diff: 
! size mismatch, 10x10 instead of 3x11

TRAIN ba26e723.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
4 0 4 0 4 0 4 0 4 0 4 
4 4 4 4 4 4 4 4 4 4 4 
0 4 0 4 0 4 0 4 0 4 0 

diff: 
   (0.0 bits)
data: a background with size (3,11) and color black and layers
  _0: rectangle with size (3,2) with mask 
. 0 
0 0 
0 . 
 with color yellow at (0,1)
  _01: rectangle with size (3,2) with mask 
0 . 
0 0 
. 0 
 with color yellow at (0,4)
  _011: rectangle with size (2,7) with model Full with color pink at (0,0)
  _0111: rectangle with size (3,2) with mask 
. 0 
0 0 
0 . 
 with color yellow at (0,7)
  _01111: rectangle with size (2,1) with model Full with color pink at (1,9)
  _011111: rectangle with size (2,1) with model Full with color yellow at (0,10)
  + 5 delta pixels
diff: 
   (403.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 0 4 0 4 0 4 0 4 0 4 
4 4 4 4 4 4 4 4 4 4 4 
0 4 0 4 0 4 0 4 0 4 0 

diff: 
! size mismatch, 10x10 instead of 3x11

TRAIN ba26e723.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: 
4 0 4 0 4 0 4 0 4 0 4 0 4 
4 4 4 4 4 4 4 4 4 4 4 4 4 
0 4 0 4 0 4 0 4 0 4 0 4 0 

diff: 
   (0.0 bits)
data: a background with size (3,13) and color black and layers
  _0: rectangle with size (3,2) with mask 
. 0 
0 0 
0 . 
 with color yellow at (0,1)
  _01: rectangle with size (3,2) with mask 
0 . 
0 0 
. 0 
 with color yellow at (0,4)
  _011: rectangle with size (3,5) with model Full with color yellow at (0,7)
  _0111: rectangle with size (2,1) with model Full with color pink at (0,0)
  _01111: rectangle with size (2,7) with model Full with color pink at (0,6)
  _011111: rectangle with size (2,1) with model Full with color pink at (1,3)
  + 7 delta pixels
diff: 
   (481.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 0 4 0 4 0 4 0 4 0 4 0 4 
4 4 4 4 4 4 4 4 4 4 4 4 4 
0 4 0 4 0 4 0 4 0 4 0 4 0 

diff: 
! size mismatch, 10x10 instead of 3x13

TRAIN ba26e723.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: 
0 4 0 4 0 4 0 4 0 4 0 4 0 4 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 0 4 0 4 0 4 0 4 0 4 0 4 0 

diff: 
   (0.0 bits)
data: a background with size (3,14) and color yellow and layers
  _0: rectangle with size (2,1) with model Full with color pink at (0,3)
  _01: rectangle with size (1,13) with model Full with color black at (0,0)
  _011: rectangle with size (2,1) with model Full with color pink at (1,0)
  _0111: rectangle with size (2,1) with model Full with color pink at (1,6)
  _01111: rectangle with size (2,1) with model Full with color pink at (1,12)
  _011111: rectangle with size (1,13) with model Full with color black at (2,1)
  + 10 delta pixels
diff: 
   (590.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 4 0 4 0 4 0 4 0 4 0 4 0 4 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 0 4 0 4 0 4 0 4 0 4 0 4 0 

diff: 
! size mismatch, 10x10 instead of 3x14

TRAIN ba26e723.json/5: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 4 0 4 0 4 0 4 0 4 0 4 0 4 0 4 0 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
4 0 4 0 4 0 4 0 4 0 4 0 4 0 4 0 4 

diff: 
! size mismatch, 10x10 instead of 3x17

TEST ba26e723.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.8 sec (59.8 sec/task)
bits-train-error = 22402.9 bits (22402.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-108] Checking task ba97ae07.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 134218.3 = 134220.6
DL output with Mo: L = 2.3 + 134218.3 = 134220.6
DL input+output M: L = 4.6 + 268436.6 = 268441.2

# learning a model for train pairs
2.000	
1.325	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.649	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.458	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.291	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.160	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.043	OUT ADD ^.layer_00 = ^.layer_01
0.033	OUT SPE ^.layer_0 = ^.layer_0
0.028	OUT SPE ^.size = ^.size
0.027	IN  SPE ^.layer_0.shape.mask.model = Full
0.026	IN  SPE ^.layer_01.shape.mask.model = Full
0.025	IN  SPE ^.color = black
0.024	OUT SPE ^.color = black
0.001	
0.001	IN  GEN ^.layer_01.shape.mask.model = ?
0.001	IN  GEN ^.layer_0.shape.mask.model = ?
0.001	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_01
  _0: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 71.4 + 3177.1 = 3248.4
DL output with Mo: L = 30.8 + 0.0 = 30.8
DL input+output M: L = 102.2 + 3177.1 = 3279.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_01
  _0: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 30.8 + 0.0 = 30.8
DL input+output M: L = 101.0 + 0.0 = 101.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: rectangle with size (13,2) with model Full with color cyan at (0,3)
  _01: rectangle with size (3,13) with model Full with color green at (3,0)
diff: 
   (0.0 bits)
data: a background with size (13,13) and color black and layers
  _00: 
3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 
 at (3,0)
  _0: 
8 8 
8 8 
8 8 
8 8 
8 8 
8 8 
8 8 
8 8 
8 8 
8 8 
8 8 
8 8 
8 8 
 at (0,3)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (13,2) with model Full with color cyan at (0,3)
  _01: rectangle with size (3,13) with model Full with color green at (3,0)
diff: 
correct output grid

TRAIN ba97ae07.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (7,9) and color black and layers
  _0: rectangle with size (1,9) with model Full with color blue at (3,0)
  _01: rectangle with size (7,2) with model Full with color pink at (0,2)
diff: 
   (0.0 bits)
data: a background with size (7,9) and color black and layers
  _00: 
6 6 
6 6 
6 6 
6 6 
6 6 
6 6 
6 6 
 at (0,2)
  _0: 
1 1 1 1 1 1 1 1 1 
 at (3,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,9) and color black and layers
  _0: rectangle with size (1,9) with model Full with color blue at (3,0)
  _01: rectangle with size (7,2) with model Full with color pink at (0,2)
diff: 
correct output grid

TRAIN ba97ae07.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (8,7) and color black and layers
  _0: rectangle with size (1,7) with model Full with color orange at (3,0)
  _01: rectangle with size (8,1) with model Full with color blue at (0,2)
diff: 
   (0.0 bits)
data: a background with size (8,7) and color black and layers
  _00: 
1 
1 
1 
1 
1 
1 
1 
1 
 at (0,2)
  _0: 
7#7#7#7#7#7#7#
 at (3,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,7) and color black and layers
  _0: rectangle with size (1,7) with model Full with color orange at (3,0)
  _01: rectangle with size (8,1) with model Full with color blue at (0,2)
diff: 
correct output grid

TRAIN ba97ae07.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: a background with size (8,6) and color black and layers
  _0: rectangle with size (8,1) with model Full with color green at (0,1)
  _01: rectangle with size (1,6) with model Full with color red at (4,0)
diff: 
   (0.0 bits)
data: a background with size (8,6) and color black and layers
  _00: 
2 2 2 2 2 2 
 at (4,0)
  _0: 
3 
3 
3 
3 
3 
3 
3 
3 
 at (0,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,6) and color black and layers
  _0: rectangle with size (8,1) with model Full with color green at (0,1)
  _01: rectangle with size (1,6) with model Full with color red at (4,0)
diff: 
correct output grid

TRAIN ba97ae07.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,6) and color black and layers
  _0: rectangle with size (11,2) with model Full with color yellow at (0,2)
  _01: rectangle with size (2,6) with model Full with color grey at (2,0)
diff: 
correct output grid

TEST ba97ae07.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 3.6 sec (3.6 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-107] Checking task bb43febb.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79850.6 = 79852.9
DL output with Mo: L = 2.3 + 79850.6 = 79852.9
DL input+output M: L = 4.6 + 159701.1 = 159705.8

# learning a model for train pairs
2.000	
1.414	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.829	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.565	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.396	OUT ADD ^.layer_0 = ^.layer_0
0.270	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.160	OUT ADD ^.layer_01 = ^.layer_01
0.064	OUT ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.046	OUT ADD ^.layer_010 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.041	OUT SPE ^.size = ^.size
0.038	OUT SPE ^.layer_010.pos = ^.layer_01.pos + (1, 1)
0.036	OUT SPE ^.layer_00.pos = ^.layer_0.pos + (1, 1)
0.034	OUT SPE ^.layer_00.shape.mask.size.i = 3
0.030	OUT SPE ^.layer_010.shape = scaleTo(coloring(^.layer_01.shape, red), ^.layer_01.shape.mask.size - (2, 2))
0.027	OUT SPE ^.layer_00.shape = scaleTo(coloring(^.layer_01.shape, red), ^.layer_0.shape.mask.size - (2, 2))
0.026	IN  SPE ^.layer_0.shape.color = grey
0.024	IN  SPE ^.layer_01.shape.color = grey
0.023	IN  SPE ^.layer_0.shape.mask.model = Full
0.023	IN  SPE ^.layer_01.shape.mask.model = Full
0.022	IN  SPE ^.color = black
0.022	OUT SPE ^.color = black
0.003	
0.003	IN  GEN ^.layer_01.shape.color = ?
0.003	IN  GEN ^.layer_0.shape.color = ?
0.003	IN  GEN ^.layer_01.shape.mask.model = ?
0.003	IN  GEN ^.layer_0.shape.mask.model = ?
0.003	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: scaleTo(coloring(^.layer_01.shape, red), ^.layer_0.shape.mask.size - (2, 2)) at ^.layer_0.pos + (1, 1)
  _0: ^.layer_0
  _010: scaleTo(coloring(^.layer_01.shape, red), ^.layer_01.shape.mask.size - (2, 2)) at ^.layer_01.pos + (1, 1)
  _01: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color grey at (?,?)
  _01: rectangle with size (?,?) with model Full with color grey at (?,?)

DL input  with Mi: L = 78.0 + 1456.7 = 1534.7
DL output with Mo: L = 185.8 + 0.0 = 185.8
DL input+output M: L = 263.8 + 1456.7 = 1720.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: scaleTo(coloring(^.layer_01.shape, red), ^.layer_0.shape.mask.size - (2, 2)) at ^.layer_0.pos + (1, 1)
  _0: ^.layer_0
  _010: scaleTo(coloring(^.layer_01.shape, red), ^.layer_01.shape.mask.size - (2, 2)) at ^.layer_01.pos + (1, 1)
  _01: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 185.8 + 0.0 = 185.8
DL input+output M: L = 256.0 + 0.0 = 256.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with model Full with color grey at (2,0)
  _01: rectangle with size (4,3) with model Full with color grey at (3,6)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
2 2 2 
2 2 2 
2 2 2 
 at (3,1)
  _0: 
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
 at (2,0)
  _010: 
2 
2 
 at (4,7)
  _01: 
5#5#5#
5#5#5#
5#5#5#
5#5#5#
 at (3,6)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with model Full with color grey at (2,0)
  _01: rectangle with size (4,3) with model Full with color grey at (3,6)
diff: 
correct output grid

TRAIN bb43febb.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,6) with model Full with color grey at (1,1)
  _01: rectangle with size (3,5) with model Full with color grey at (7,4)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
2 2 2 2 
2 2 2 2 
2 2 2 2 
 at (2,2)
  _0: 
5#5#5#5#5#5#
5#5#5#5#5#5#
5#5#5#5#5#5#
5#5#5#5#5#5#
5#5#5#5#5#5#
 at (1,1)
  _010: 
2 2 2 
 at (8,5)
  _01: 
5#5#5#5#5#
5#5#5#5#5#
5#5#5#5#5#
 at (7,4)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,6) with model Full with color grey at (1,1)
  _01: rectangle with size (3,5) with model Full with color grey at (7,4)
diff: 
correct output grid

TRAIN bb43febb.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,7) with model Full with color grey at (4,3)
  _01: rectangle with size (3,6) with model Full with color grey at (0,0)
diff: 
correct output grid

TEST bb43febb.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 5.7 sec (5.7 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-106] Checking task bbc9ae5d.json: 5 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 14143.4 = 14145.7
DL output with Mo: L = 2.3 + 53007.2 = 53009.6
DL input+output M: L = 4.6 + 67150.6 = 67155.3

# learning a model for train pairs
2.000	
1.295	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.699	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.356	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.202	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.192	IN  SPE ^.layer_0.shape.mask.model = Full
0.184	IN  SPE ^.color = black
0.175	OUT SPE ^.size.j = ^.size.j
0.168	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.162	OUT SPE ^.size.i = ^.size.j / '2
0.156	OUT SPE ^.layer_0.shape.mask.size.i = ^.size.j / '2
0.150	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.148	OUT SPE ^.color = black
0.028	
0.028	IN  GEN ^.layer_0.shape.mask.model = ?
0.028	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (^.size.j / '2,^.size.j) and color black and layers
  _0: rectangle with size (^.size.j / '2,?) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 42.6 + 1692.1 = 1734.7
DL output with Mo: L = 91.0 + 1255.5 = 1346.5
DL input+output M: L = 133.7 + 2947.5 = 3081.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (^.size.j / '2,^.size.j) and color black and layers
  _0: rectangle with size (^.size.j / '2,?) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 91.0 + 1255.5 = 1346.5
DL input+output M: L = 133.0 + 1255.5 = 1388.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (1,6) and color black and layers
  _0: rectangle with size (1,2) with model Full with color blue at (0,0)
diff: 
   (0.0 bits)
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (3,4) with mask 
0 0 . . 
0 0 0 . 
0 0 0 0 
 with color blue at (0,0)
diff: 
   (19.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (1,6) and color black and layers
  _0: rectangle with size (1,2) with model Full with color blue at (0,0)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (1,6) and color blue and layers
  _0: rectangle with size (1,4) with model Full with color black at (0,2)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN bbc9ae5d.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (1,8) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,0)
diff: 
   (0.0 bits)
data: a background with size (4,8) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . . . 
0 0 . . 
0 0 0 . 
0 0 0 0 
 with color red at (0,0)
diff: 
   (24.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (1,8) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,0)
diff: 
! 4 wrong pixels (generated / expected)

TRAIN bbc9ae5d.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (1,10) and color black and layers
  _0: rectangle with size (1,3) with model Full with color grey at (0,0)
diff: 
   (0.0 bits)
data: a background with size (5,10) and color black and layers
  _0: rectangle with size (5,7) with mask 
0 0 0 . . . . 
0 0 0 0 . . . 
0 0 0 0 0 . . 
0 0 0 0 0 0 . 
0 0 0 0 0 0 0 
 with color grey at (0,0)
diff: 
   (42.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (1,10) and color black and layers
  _0: rectangle with size (1,3) with model Full with color grey at (0,0)
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (1,10) and color grey and layers
  _0: rectangle with size (1,7) with model Full with color black at (0,3)
diff: 
! 25 wrong pixels (generated / expected)

TRAIN bbc9ae5d.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (1,6) and color black and layers
  _0: rectangle with size (1,4) with model Full with color cyan at (0,0)
diff: 
   (0.0 bits)
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (3,6) with mask 
0 0 0 0 . . 
0 0 0 0 0 . 
0 0 0 0 0 0 
 with color cyan at (0,0)
diff: 
   (22.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (1,6) and color black and layers
  _0: rectangle with size (1,4) with model Full with color cyan at (0,0)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (1,6) and color cyan and layers
  _0: rectangle with size (1,2) with model Full with color black at (0,4)
diff: 
! 15 wrong pixels (generated / expected)

TRAIN bbc9ae5d.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: a background with size (1,6) and color black and layers
  _0: rectangle with size (1,1) with model Full with color orange at (0,0)
diff: 
   (0.0 bits)
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
0 0 . 
0 0 0 
 with color orange at (0,0)
diff: 
   (16.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (1,6) and color black and layers
  _0: rectangle with size (1,1) with model Full with color orange at (0,0)
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (1,6) and color orange and layers
  _0: rectangle with size (1,5) with model Full with color black at (0,1)
diff: 
! 6 wrong pixels (generated / expected)

TRAIN bbc9ae5d.json/5: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (1,12) and color black and layers
  _0: rectangle with size (1,3) with model Full with color blue at (0,0)
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (1,12) and color blue and layers
  _0: rectangle with size (1,9) with model Full with color black at (0,3)
diff: 
! 33 wrong pixels (generated / expected)

TEST bbc9ae5d.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.1 sec (3.1 sec/task)
bits-train-error = 1255.5 bits (1255.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-105] Checking task bc1d5164.json: 5 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 68229.8 = 68232.1
DL output with Mo: L = 2.3 + 17558.0 = 17560.3
DL input+output M: L = 4.6 + 85787.8 = 85792.5

# learning a model for train pairs
2.000	
1.231	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.651	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.380	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.329	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.293	OUT SPE ^.size = '(3, 3)
0.257	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.224	OUT SPE ^.layer_0.shape.mask.size = projI(^.layer_01.shape.mask.size) + (1, 3)
0.202	OUT SPE ^.layer_0.pos = '(0, 0)
0.200	IN  SPE ^.color = black
0.059	
0.058	IN  DEL ^.layer_0
0.058	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color ? and layers
  _0: rectangle with size projI(^.layer_01.shape.mask.size) + (1, 3) with model ? with color ? at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.3 + 9730.0 = 9800.4
DL output with Mo: L = 85.8 + 908.6 = 994.4
DL input+output M: L = 156.1 + 10638.6 = 10794.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color ? and layers
  _0: rectangle with size projI(^.layer_01.shape.mask.size) + (1, 3) with model ? with color ? at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 31.7 = 73.7
DL output with Mo: L = 85.8 + 908.6 = 994.4
DL input+output M: L = 127.7 + 940.3 = 1068.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (5,7) and color black and layers
  _01: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color cyan at (0,0)
  + 9 delta pixels
diff: 
   (3.2 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with model +-cross with color cyan at (0,0)
diff: 
   (14.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,7) and color black and layers
  _01: rectangle with size (5,1) with model Full with color cyan at (0,1)
  + 9 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN bc1d5164.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (5,7) and color black and layers
  _01: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color red at (0,5)
  + 6 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. 0 0 
0 . 0 
 with color red at (0,0)
diff: 
   (16.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,7) and color black and layers
  _01: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color red at (0,5)
  + 6 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,7) and color black and layers
  _01: rectangle with size (1,2) with model Full with color red at (0,0)
  + 7 delta pixels
diff: 
! 8 wrong pixels (generated / expected)

TRAIN bc1d5164.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (5,7) and color black and layers
  _01: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color yellow at (0,5)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
0 . 0 
 with color yellow at (0,0)
diff: 
   (18.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,7) and color black and layers
  _01: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color yellow at (0,5)
  + 4 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,7) and color black and layers
  _01: rectangle with size (1,2) with model Full with color yellow at (0,0)
  + 5 delta pixels
diff: 
! 8 wrong pixels (generated / expected)

TRAIN bc1d5164.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (5,7) and color black and layers
  _01: rectangle with size (1,2) with model Full with color yellow at (4,5)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color yellow and layers
  _0: rectangle with size (2,3) with mask 
. 0 . 
0 0 0 
 with color black at (0,0)
diff: 
   (21.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,7) and color black and layers
  _01: rectangle with size (1,2) with model Full with color yellow at (4,5)
  + 3 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN bc1d5164.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: a background with size (5,7) and color black and layers
  _01: rectangle with size (2,2) with model Odd Checkboard with color green at (0,0)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 . 0 
. . 0 
 with color green at (0,0)
diff: 
   (19.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,7) and color black and layers
  _01: rectangle with size (2,2) with model Odd Checkboard with color green at (0,0)
  + 3 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,7) and color black and layers
  _01: rectangle with size (1,1) with model Full with color green at (0,1)
  + 4 delta pixels
diff: 
! 7 wrong pixels (generated / expected)

TRAIN bc1d5164.json/5: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,7) and color black and layers
  _01: rectangle with size (1,2) with model Full with color blue at (0,5)
  + 3 delta pixels
diff: 
! 8 wrong pixels (generated / expected)

TEST bc1d5164.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.3 sec (3.3 sec/task)
bits-train-error = 908.6 bits (908.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-104] Checking task bd4472b8.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 29602.8 = 29605.2
DL output with Mo: L = 2.3 + 29602.8 = 29605.2
DL input+output M: L = 4.6 + 59205.7 = 59210.3

# learning a model for train pairs
2.000	
1.253	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.988	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.901	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.786	OUT ADD ^.layer_0 = ^.layer_0
0.700	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.613	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.538	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.488	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.436	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.397	OUT ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.374	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.350	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.234	
0.234	IN  DEL ^.layer_011
0.233	IN  DEL ^.layer_01
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 78.5 + 3438.7 = 3517.2
DL output with Mo: L = 185.0 + 6671.0 = 6856.0
DL input+output M: L = 263.5 + 10109.7 = 10373.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 185.0 + 6671.0 = 6856.0
DL input+output M: L = 227.0 + 6671.0 = 6898.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (8,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color grey at (1,0)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (8,3) and color blue and layers
  _0: 
5#5#5#
 at (1,0)
  _01: rectangle with size (1,3) with model Full with color red at (2,0)
  _011: rectangle with size (1,3) with model Full with color yellow at (4,0)
  _0111: rectangle with size (1,3) with model Full with color red at (5,0)
  _01111: rectangle with size (1,3) with model Full with color yellow at (7,0)
  _011111: rectangle with size (1,1) with model Full with color red at (0,0)
  _0111111: rectangle with size (1,1) with model Full with color yellow at (0,2)
diff: 
   (183.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color grey at (1,0)
  + 3 delta pixels
diff: 
! size mismatch, 10x10 instead of 8x3
>> Trial 2
data: a background with size (8,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,0)
  + 5 delta pixels
diff: 
! size mismatch, 10x10 instead of 8x3
>> Trial 3
data: a background with size (8,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color blue at (0,1)
  + 5 delta pixels
diff: 
! size mismatch, 10x10 instead of 8x3

TRAIN bd4472b8.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,4) and color black and layers
  _0: rectangle with size (1,4) with model Full with color grey at (1,0)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,4) and color blue and layers
  _0: 
5#5#5#5#
 at (1,0)
  _01: rectangle with size (1,4) with model Full with color green at (2,0)
  _011: rectangle with size (1,4) with model Full with color red at (3,0)
  _0111: rectangle with size (1,4) with model Full with color yellow at (5,0)
  _01111: rectangle with size (1,4) with model Full with color green at (6,0)
  _011111: rectangle with size (1,4) with model Full with color red at (7,0)
  _0111111: rectangle with size (1,4) with model Full with color yellow at (9,0)
  + 3 delta pixels
diff: 
   (319.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,4) and color black and layers
  _0: rectangle with size (1,4) with model Full with color grey at (1,0)
  + 4 delta pixels
diff: 
! size mismatch, 10x10 instead of 10x4
>> Trial 2
data: a background with size (10,4) and color black and layers
  _0: rectangle with size (1,1) with model Full with color green at (0,0)
  + 7 delta pixels
diff: 
! size mismatch, 10x10 instead of 10x4
>> Trial 3
data: a background with size (10,4) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,1)
  + 7 delta pixels
diff: 
! size mismatch, 10x10 instead of 10x4

TRAIN bd4472b8.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (6,2) and color black and layers
  _0: rectangle with size (1,2) with model Full with color grey at (1,0)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,2) and color black and layers
  _0: 
5#5#
 at (1,0)
  _01: rectangle with size (1,2) with model Full with color cyan at (2,0)
  _011: rectangle with size (1,2) with model Full with color green at (3,0)
  _0111: rectangle with size (1,2) with model Full with color cyan at (4,0)
  _01111: rectangle with size (1,2) with model Full with color green at (5,0)
  _011111: rectangle with size (1,1) with model Full with color cyan at (0,0)
  _0111111: rectangle with size (1,1) with model Full with color green at (0,1)
diff: 
   (164.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,2) and color black and layers
  _0: rectangle with size (1,2) with model Full with color grey at (1,0)
  + 2 delta pixels
diff: 
! size mismatch, 10x10 instead of 6x2
>> Trial 2
data: a background with size (6,2) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (0,0)
  + 3 delta pixels
diff: 
! size mismatch, 10x10 instead of 6x2
>> Trial 3
data: a background with size (6,2) and color black and layers
  _0: rectangle with size (1,1) with model Full with color green at (0,1)
  + 3 delta pixels
diff: 
! size mismatch, 10x10 instead of 6x2

TRAIN bd4472b8.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,5) and color black and layers
  _0: rectangle with size (1,5) with model Full with color grey at (1,0)
  + 5 delta pixels
diff: 
! size mismatch, 10x10 instead of 12x5
>> Trial 2
data: a background with size (12,5) and color black and layers
  _0: rectangle with size (1,1) with model Full with color blue at (0,0)
  + 9 delta pixels
diff: 
! size mismatch, 10x10 instead of 12x5
>> Trial 3
data: a background with size (12,5) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,1)
  + 9 delta pixels
diff: 
! size mismatch, 10x10 instead of 12x5

TEST bd4472b8.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.7 sec (59.7 sec/task)
bits-train-error = 6671.0 bits (6671.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-103] Checking task bda2d7a6.json: 3 train, 2 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 53344.3 = 53346.6
DL output with Mo: L = 2.3 + 53344.3 = 53346.6
DL input+output M: L = 4.6 + 106688.6 = 106693.3

# learning a model for train pairs
2.000	
1.480	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.961	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.662	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.363	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.234	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.104	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.085	OUT SPE ^.layer_01 = coloring(^.layer_01, ^.color)
0.067	OUT SPE ^.layer_0 = coloring(^.layer_0, ^.layer_01.shape.color)
0.057	OUT SPE ^.size = ^.size
0.054	OUT SPE ^.color = ^.layer_0.shape.color
0.053	IN  SPE ^.layer_0.shape.mask.model = Border
0.004	
0.003	IN  GEN ^.layer_0.shape.mask.model = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.layer_0.shape.color and layers
  _0: coloring(^.layer_0, ^.layer_01.shape.color)
  _01: coloring(^.layer_01, ^.color)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model Border with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 73.5 + 2671.4 = 2744.9
DL output with Mo: L = 56.5 + 0.0 = 56.5
DL input+output M: L = 130.0 + 2671.4 = 2801.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.layer_0.shape.color and layers
  _0: coloring(^.layer_0, ^.layer_01.shape.color)
  _01: coloring(^.layer_01, ^.color)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 20.0 = 90.2
DL output with Mo: L = 56.5 + 0.0 = 56.5
DL input+output M: L = 126.7 + 20.0 = 146.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (6,6) and color green and layers
  _0: rectangle with size (2,2) with model Full with color black at (2,2)
  _01: rectangle with size (4,4) with model Full with color red at (1,1)
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _0: 
2 2 
2 2 
 at (2,2)
  _01: 
3 3 3 3 
3 3 3 3 
3 3 3 3 
3 3 3 3 
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color green and layers
  _0: rectangle with size (2,2) with model Full with color black at (2,2)
  _01: rectangle with size (4,4) with model Full with color red at (1,1)
diff: 
correct output grid

TRAIN bda2d7a6.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _0: rectangle with size (2,2) with model Full with color pink at (2,2)
  _01: rectangle with size (4,4) with model Full with color orange at (1,1)
diff: 
   (0.0 bits)
data: a background with size (6,6) and color pink and layers
  _0: 
7#7#
7#7#
 at (2,2)
  _01: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (2,2) with model Full with color pink at (2,2)
  _01: rectangle with size (4,4) with model Full with color orange at (1,1)
diff: 
correct output grid

TRAIN bda2d7a6.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (8,8) and color cyan and layers
  _0: rectangle with size (4,4) with model Border with color grey at (2,2)
  _01: rectangle with size (6,6) with model Border with color black at (1,1)
diff: 
   (2.0 bits)
data: a background with size (8,8) and color grey and layers
  _0: 
0 0 0 0 
0 . . 0 
0 . . 0 
0 0 0 0 
 at (2,2)
  _01: 
8 8 8 8 8 8 
8 . . . . 8 
8 . . . . 8 
8 . . . . 8 
8 . . . . 8 
8 8 8 8 8 8 
 at (1,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color cyan and layers
  _0: rectangle with size (6,6) with model Border with color black at (1,1)
  _01: rectangle with size (4,4) with model Border with color grey at (2,2)
diff: 
! 64 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color cyan and layers
  _0: rectangle with size (4,4) with model Border with color grey at (2,2)
  _01: rectangle with size (6,6) with model Border with color black at (1,1)
diff: 
correct output grid

TRAIN bda2d7a6.json/3: 1 2nd (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (6,6) with model Border with color brown at (0,0)
  _01: rectangle with size (2,2) with model Full with color blue at (2,2)
diff: 
correct output grid

TEST bda2d7a6.json/1: 1 1st (SUCCESS)

## instance 2

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color green and layers
  _0: rectangle with size (6,6) with model Border with color orange at (1,1)
  _01: rectangle with size (4,4) with model Border with color pink at (2,2)
diff: 
! 64 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color green and layers
  _0: rectangle with size (4,4) with model Border with color pink at (2,2)
  _01: rectangle with size (6,6) with model Border with color orange at (1,1)
diff: 
correct output grid

TEST bda2d7a6.json/2: 1 2nd (SUCCESS)

# Performance measures on task
runtime-learning = 5.1 sec (5.1 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 0.83
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 0.75

=====================================
[-102] Checking task bdad9b1f.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 28084.5 = 28086.9
DL output with Mo: L = 2.3 + 28084.5 = 28086.9
DL input+output M: L = 4.6 + 56169.1 = 56173.7

# learning a model for train pairs
2.000	
1.126	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.443	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.329	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.214	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.179	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.142	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.126	OUT ADD ^.layer_00 = point with color ? at (?,?)
0.111	OUT SPE ^.layer_01.shape = tiling(^.layer_01.shape, 1, 3)
0.096	OUT SPE ^.layer_0.shape = tiling(^.layer_0.shape, 3, 1)
0.084	OUT SPE ^.size = ^.size
0.076	IN  SPE ^.layer_0.shape.mask = 
0 
0 

0.067	IN  SPE ^.layer_01.shape.mask = 
0 0 

0.060	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.053	OUT SPE ^.layer_01.pos = projI(^.layer_01.pos)
0.047	OUT SPE ^.layer_00.pos = corner(^.layer_01.pos, ^.layer_0.pos)
0.043	IN  SPE ^.layer_0.shape.color = cyan
0.040	IN  SPE ^.layer_01.shape.color = red
0.036	OUT SPE ^.layer_00.shape.color = yellow
0.034	IN  SPE ^.color = black
0.032	OUT SPE ^.color = black
0.006	
0.006	IN  GEN ^.layer_01.shape.color = ?
0.006	IN  GEN ^.layer_0.shape.color = ?
0.006	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: point with color yellow at corner(^.layer_01.pos, ^.layer_0.pos)
  _0: tiling(^.layer_0.shape, 3, 1) at ^.layer_0.pos
  _01: tiling(^.layer_01.shape, 1, 3) at projI(^.layer_01.pos)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
0 
0 
 with color cyan at (?,?)
  _01: 
0 0 
 with color red at (?,?)

DL input  with Mi: L = 66.2 + 732.2 = 798.4
DL output with Mo: L = 104.3 + 0.0 = 104.3
DL input+output M: L = 170.5 + 732.2 = 902.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: point with color yellow at corner(^.layer_01.pos, ^.layer_0.pos)
  _0: tiling(^.layer_0.shape, 3, 1) at ^.layer_0.pos
  _01: tiling(^.layer_01.shape, 1, 3) at projI(^.layer_01.pos)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 
0 
 with color ? at (?,?)
  _01: 
0 0 
 with color ? at (?,?)

DL input  with Mi: L = 59.4 + 0.0 = 59.4
DL output with Mo: L = 104.3 + 0.0 = 104.3
DL input+output M: L = 163.7 + 0.0 = 163.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _0: 
0 
0 
 with color cyan at (0,4)
  _01: 
0 0 
 with color red at (2,0)
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _00: point with color yellow at (2,4)
  _0: 
8 
8 
8 
8 
8 
8 
 at (0,4)
  _01: 
2 2 2 2 2 2 
 at (2,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: 
0 
0 
 with color cyan at (0,4)
  _01: 
0 0 
 with color red at (2,0)
diff: 
correct output grid

TRAIN bdad9b1f.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _0: 
0 
0 
 with color cyan at (0,1)
  _01: 
0 0 
 with color red at (3,4)
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _00: point with color yellow at (3,1)
  _0: 
8 
8 
8 
8 
8 
8 
 at (0,1)
  _01: 
2 2 2 2 2 2 
 at (3,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: 
0 
0 
 with color cyan at (0,1)
  _01: 
0 0 
 with color red at (3,4)
diff: 
correct output grid

TRAIN bdad9b1f.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: 
0 
0 
 with color cyan at (0,3)
  _01: 
0 0 
 with color red at (4,0)
diff: 
correct output grid

TEST bdad9b1f.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 3.6 sec (3.6 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-101] Checking task be94b721.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 106787.9 = 106790.3
DL output with Mo: L = 2.3 + 15202.1 = 15204.4
DL input+output M: L = 4.6 + 121990.1 = 121994.7

# learning a model for train pairs
2.000	
1.241	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.547	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.380	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.288	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.213	OUT SPE ^.layer_0.shape = ^.layer_0.shape
0.153	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.113	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.080	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.059	OUT SPE ^.layer_0.pos = '(0, 0)
0.052	OUT SPE ^.color = black
0.052	IN  SPE ^.color = black
0.003	
0.003	IN  DEL ^.layer_011
0.003	IN  DEL ^.layer_01
0.003	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: ^.layer_0.shape at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.2 + 5138.1 = 5236.3
DL output with Mo: L = 37.8 + 0.0 = 37.8
DL input+output M: L = 136.1 + 5138.1 = 5274.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: ^.layer_0.shape at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 37.8 + 0.0 = 37.8
DL input+output M: L = 79.8 + 0.0 = 79.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (7,13) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 0 . 
. 0 . 
. 0 0 
0 0 0 
 with color red at (1,1)
  + 9 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,3) and color black and layers
  _0: 
2 2 . 
. 2 . 
. 2 2 
2 2 2 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,13) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 0 . 
. 0 . 
. 0 0 
0 0 0 
 with color red at (1,1)
  + 9 delta pixels
diff: 
correct output grid

TRAIN be94b721.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (5,10) and color black and layers
  _0: rectangle with size (3,2) with model Full with color yellow at (1,4)
  + 8 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,2) and color black and layers
  _0: 
4 4 
4 4 
4 4 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,10) and color black and layers
  _0: rectangle with size (3,2) with model Full with color yellow at (1,4)
  + 8 delta pixels
diff: 
correct output grid

TRAIN be94b721.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (6,11) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 0 0 
. 0 . 
0 0 . 
0 0 . 
 with color cyan at (1,1)
  + 9 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,3) and color black and layers
  _0: 
8 8 8 
. 8 . 
8 8 . 
8 8 . 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,11) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 0 0 
. 0 . 
0 0 . 
0 0 . 
 with color cyan at (1,1)
  + 9 delta pixels
diff: 
correct output grid

TRAIN be94b721.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: a background with size (7,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. 0 . 
0 0 0 
 with color red at (1,6)
  + 8 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
2 2 2 
. 2 . 
2 2 2 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,9) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. 0 . 
0 0 0 
 with color red at (1,6)
  + 8 delta pixels
diff: 
correct output grid

TRAIN be94b721.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 0 0 
0 0 0 
0 . 0 
0 . 0 
 with color green at (2,3)
  + 16 delta pixels
diff: 
correct output grid

TEST be94b721.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 2.4 sec (2.4 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-100] Checking task beb8660c.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 42082.3 = 42084.7
DL output with Mo: L = 2.3 + 42082.3 = 42084.7
DL input+output M: L = 4.6 + 84164.7 = 84169.3

# learning a model for train pairs
2.000	
1.419	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.839	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.732	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.605	OUT ADD ^.layer_0 = ^.layer_0
0.525	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.431	OUT ADD ^.layer_01 = ^.layer_01.shape at (?,?)
0.377	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.310	OUT ADD ^.layer_011 = ^.layer_011.shape at (?,?)
0.299	OUT SPE ^.size = ^.size
0.295	IN  SPE ^.layer_0.shape.color = cyan
0.291	OUT SPE ^.layer_01.pos.i = ^.layer_0.pos.i - 1
0.288	OUT SPE ^.layer_01.pos.j = 1
0.285	OUT SPE ^.layer_011.pos.j = 2
0.282	OUT SPE ^.layer_011.pos.i = ^.layer_0.pos.i - 2
0.280	IN  SPE ^.layer_0.shape.mask.model = Full
0.278	IN  SPE ^.layer_01.shape.mask.model = Full
0.276	IN  SPE ^.layer_011.shape.mask.model = Full
0.275	IN  SPE ^.color = black
0.273	OUT SPE ^.color = black
0.108	
0.108	IN  GEN ^.layer_0.shape.color = ?
0.108	IN  GEN ^.layer_011.shape.mask.model = ?
0.108	IN  GEN ^.layer_01.shape.mask.model = ?
0.108	IN  GEN ^.layer_0.shape.mask.model = ?
0.108	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_01.shape at (^.layer_0.pos.i - 1,1)
  _011: ^.layer_011.shape at (^.layer_0.pos.i - 2,2)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color cyan at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 103.1 + 6922.8 = 7025.8
DL output with Mo: L = 88.4 + 4366.8 = 4455.1
DL input+output M: L = 191.5 + 11289.5 = 11481.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_01.shape at (^.layer_0.pos.i - 1,1)
  _011: ^.layer_011.shape at (^.layer_0.pos.i - 2,2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 0.0 = 98.1
DL output with Mo: L = 88.4 + 4366.8 = 4455.1
DL input+output M: L = 186.5 + 4366.8 = 4553.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,7) and color black and layers
  _0: rectangle with size (1,7) with model Full with color cyan at (9,0)
  _01: rectangle with size (1,6) with model Full with color grey at (4,1)
  _011: rectangle with size (1,5) with model Full with color pink at (6,0)
  + 10 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,7) and color black and layers
  _0: 
8 8 8 8 8 8 8 
 at (9,0)
  _01: 
5#5#5#5#5#5#
 at (8,1)
  _011: 
6 6 6 6 6 
 at (7,2)
  + 10 delta pixels
diff: 
   (397.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,7) and color black and layers
  _0: rectangle with size (1,7) with model Full with color cyan at (9,0)
  _01: rectangle with size (1,6) with model Full with color grey at (4,1)
  _011: rectangle with size (1,5) with model Full with color pink at (6,0)
  + 10 delta pixels
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,7) and color black and layers
  _0: rectangle with size (1,7) with model Full with color cyan at (9,0)
  _01: rectangle with size (1,5) with model Full with color pink at (6,0)
  _011: rectangle with size (1,6) with model Full with color grey at (4,1)
  + 10 delta pixels
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,7) and color black and layers
  _0: rectangle with size (1,6) with model Full with color grey at (4,1)
  _01: rectangle with size (1,7) with model Full with color cyan at (9,0)
  _011: rectangle with size (1,5) with model Full with color pink at (6,0)
  + 10 delta pixels
diff: 
! 42 wrong pixels (generated / expected)

TRAIN beb8660c.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (7,4) and color black and layers
  _0: rectangle with size (1,4) with model Full with color cyan at (6,0)
  _01: rectangle with size (1,3) with model Full with color red at (2,0)
  _011: rectangle with size (1,2) with model Full with color green at (4,1)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (7,4) and color black and layers
  _0: 
8 8 8 8 
 at (6,0)
  _01: 
2 2 2 
 at (5,1)
  _011: 
3 3 
 at (4,2)
  + 1 delta pixels
diff: 
   (39.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,4) and color black and layers
  _0: rectangle with size (1,4) with model Full with color cyan at (6,0)
  _01: rectangle with size (1,3) with model Full with color red at (2,0)
  _011: rectangle with size (1,2) with model Full with color green at (4,1)
  + 1 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,4) and color black and layers
  _0: rectangle with size (1,4) with model Full with color cyan at (6,0)
  _01: rectangle with size (1,2) with model Full with color green at (4,1)
  _011: rectangle with size (1,3) with model Full with color red at (2,0)
  + 1 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (7,4) and color black and layers
  _0: rectangle with size (1,3) with model Full with color red at (2,0)
  _01: rectangle with size (1,4) with model Full with color cyan at (6,0)
  _011: rectangle with size (1,2) with model Full with color green at (4,1)
  + 1 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TRAIN beb8660c.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color cyan at (2,0)
  _01: rectangle with size (1,2) with model Full with color red at (0,0)
  _011: rectangle with size (1,1) with model Full with color yellow at (1,1)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
8 8 8 
 at (2,0)
  _01: 
2 2 
 at (1,1)
  _011: 
4 
 at (0,2)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color cyan at (2,0)
  _01: rectangle with size (1,2) with model Full with color red at (0,0)
  _011: rectangle with size (1,1) with model Full with color yellow at (1,1)
diff: 
correct output grid

TRAIN beb8660c.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,8) and color black and layers
  _0: rectangle with size (1,8) with model Full with color cyan at (10,0)
  _01: rectangle with size (1,7) with model Full with color red at (6,0)
  _011: rectangle with size (1,6) with model Full with color green at (7,2)
  + 15 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,8) and color black and layers
  _0: rectangle with size (1,8) with model Full with color cyan at (10,0)
  _01: rectangle with size (1,6) with model Full with color green at (7,2)
  _011: rectangle with size (1,7) with model Full with color red at (6,0)
  + 15 delta pixels
diff: 
! 28 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (11,8) and color black and layers
  _0: rectangle with size (1,7) with model Full with color red at (6,0)
  _01: rectangle with size (1,8) with model Full with color cyan at (10,0)
  _011: rectangle with size (1,6) with model Full with color green at (7,2)
  + 15 delta pixels
diff: 
! 48 wrong pixels (generated / expected)

TEST beb8660c.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.8 sec (3.8 sec/task)
bits-train-error = 4366.8 bits (4366.8 bits/task)
acc-train-micro = 0.33 tasks (33.33%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.33
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-99] Checking task c0f76784.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 174280.1 = 174282.4
DL output with Mo: L = 2.3 + 174280.1 = 174282.4
DL input+output M: L = 4.6 + 348560.2 = 348564.8

# learning a model for train pairs
2.000	
1.236	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.566	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.462	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.358	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.275	OUT ADD ^.layer_01 = ^.layer_0
0.198	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.135	OUT ADD ^.layer_011 = ^.layer_01
0.095	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.086	OUT ADD ^.layer_0110 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.064	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.054	OUT ADD ^.layer_01110 = ^.layer_011
0.050	OUT SPE ^.size = ^.size
0.046	IN  SPE ^.layer_0.shape.mask = 
0 0 0 0 0 
0 . . . 0 
0 . . . 0 
0 . . . 0 
0 0 0 0 0 

0.044	OUT SPE ^.layer_0.shape.mask = 
0 0 0 
0 0 0 
0 0 0 

0.041	OUT SPE ^.layer_0110.shape.mask = 
0 0 
0 0 

0.039	OUT SPE ^.layer_0.pos = ^.layer_0.pos + (1, 1)
0.037	OUT SPE ^.layer_0110.pos = ^.layer_01.pos + (1, 1)
0.037	IN  SPE ^.layer_0.shape.color = grey
0.036	IN  SPE ^.layer_01.shape.color = grey
0.035	IN  SPE ^.layer_011.shape.color = grey
0.034	OUT SPE ^.layer_0.shape.color = cyan
0.033	OUT SPE ^.layer_0110.shape.color = orange
0.032	OUT SPE ^.layer_0111.pos.j = average(^.layer_0.pos.i, ^.layer_01.pos.i)
0.031	OUT SPE ^.layer_0111.shape.mask.model = Full
0.031	IN  SPE ^.color = black
0.031	OUT SPE ^.color = black
0.005	
0.005	IN  GEN ^.layer_0.shape.mask = rectangle with size (?,?) with model ?
0.005	IN  GEN ^.layer_011.shape.color = ?
0.005	IN  GEN ^.layer_01.shape.color = ?
0.005	IN  GEN ^.layer_0.shape.color = ?
0.005	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color cyan at ^.layer_0.pos + (1, 1)
  _01: ^.layer_0
  _0110: 
0 0 
0 0 
 with color orange at ^.layer_01.pos + (1, 1)
  _011: ^.layer_01
  _01110: ^.layer_011
  _0111: rectangle with size (?,?) with model Full with color ? at (?,average(^.layer_0.pos.i, ^.layer_01.pos.i))
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
0 0 0 0 0 
0 . . . 0 
0 . . . 0 
0 . . . 0 
0 0 0 0 0 
 with color grey at (?,?)
  _01: rectangle with size (?,?) with model ? with color grey at (?,?)
  _011: rectangle with size (?,?) with model ? with color grey at (?,?)

DL input  with Mi: L = 134.9 + 4389.0 = 4523.9
DL output with Mo: L = 179.6 + 625.4 = 805.1
DL input+output M: L = 314.5 + 5014.4 = 5328.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color cyan at ^.layer_0.pos + (1, 1)
  _01: ^.layer_0
  _0110: 
0 0 
0 0 
 with color orange at ^.layer_01.pos + (1, 1)
  _011: ^.layer_01
  _01110: ^.layer_011
  _0111: rectangle with size (?,?) with model Full with color ? at (?,average(^.layer_0.pos.i, ^.layer_01.pos.i))
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 0.0 = 98.1
DL output with Mo: L = 179.6 + 625.4 = 805.1
DL input+output M: L = 277.7 + 625.4 = 903.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (5,5) with model Border with color grey at (0,7)
  _01: rectangle with size (4,4) with model Border with color grey at (6,6)
  _011: rectangle with size (3,3) with model Border with color grey at (2,2)
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color cyan at (1,8)
  _01: 
5#5#5#5#5#
5#. . . 5#
5#. . . 5#
5#. . . 5#
5#5#5#5#5#
 at (0,7)
  _0110: 
0 0 
0 0 
 with color orange at (7,7)
  _011: 
5#5#5#5#
5#. . 5#
5#. . 5#
5#5#5#5#
 at (6,6)
  _01110: 
5#5#5#
5#. 5#
5#5#5#
 at (2,2)
  _0111: rectangle with size (1,1) with model Full with color pink at (3,3)
diff: 
   (18.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (5,5) with model Border with color grey at (0,7)
  _01: rectangle with size (4,4) with model Border with color grey at (6,6)
  _011: rectangle with size (3,3) with model Border with color grey at (2,2)
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (5,5) with model Border with color grey at (0,7)
  _01: rectangle with size (3,3) with model Border with color grey at (2,2)
  _011: rectangle with size (4,4) with model Border with color grey at (6,6)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (4,4) with model Border with color grey at (6,6)
  _01: rectangle with size (5,5) with model Border with color grey at (0,7)
  _011: rectangle with size (3,3) with model Border with color grey at (2,2)
diff: 
! 23 wrong pixels (generated / expected)

TRAIN c0f76784.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (5,5) with model Border with color grey at (4,6)
  _01: rectangle with size (4,4) with model Border with color grey at (0,1)
  _011: rectangle with size (3,3) with model Border with color grey at (7,1)
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color cyan at (5,7)
  _01: 
5#5#5#5#5#
5#. . . 5#
5#. . . 5#
5#. . . 5#
5#5#5#5#5#
 at (4,6)
  _0110: 
0 0 
0 0 
 with color orange at (1,2)
  _011: 
5#5#5#5#
5#. . 5#
5#. . 5#
5#5#5#5#
 at (0,1)
  _01110: 
5#5#5#
5#. 5#
5#5#5#
 at (7,1)
  _0111: rectangle with size (1,1) with model Full with color pink at (8,2)
diff: 
   (18.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (5,5) with model Border with color grey at (4,6)
  _01: rectangle with size (4,4) with model Border with color grey at (0,1)
  _011: rectangle with size (3,3) with model Border with color grey at (7,1)
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (4,4) with model Border with color grey at (0,1)
  _01: rectangle with size (5,5) with model Border with color grey at (4,6)
  _011: rectangle with size (3,3) with model Border with color grey at (7,1)
diff: 
! 19 wrong pixels (generated / expected)

TRAIN c0f76784.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (5,5) with model Border with color grey at (1,1)
  _01: rectangle with size (1,4) with model Full with color grey at (7,4)
  _011: rectangle with size (1,4) with model Full with color grey at (10,4)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _0: 
0 0 0 
0 0 0 
0 0 0 
 with color cyan at (2,2)
  _01: 
5#5#5#5#5#
5#. . . 5#
5#. . . 5#
5#. . . 5#
5#5#5#5#5#
 at (1,1)
  _0110: 
0 0 
0 0 
 with color orange at (8,5)
  _011: 
5#5#5#5#
 at (7,4)
  _01110: 
5#5#5#5#
 at (10,4)
  _0111: rectangle with size (4,4) with model Full with color grey at (7,4)
diff: 
   (26.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (5,5) with model Border with color grey at (1,1)
  _01: rectangle with size (1,4) with model Full with color grey at (7,4)
  _011: rectangle with size (1,4) with model Full with color grey at (10,4)
  + 4 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (5,5) with model Border with color grey at (1,1)
  _01: rectangle with size (4,1) with model Full with color grey at (7,4)
  _011: rectangle with size (4,1) with model Full with color grey at (7,7)
  + 4 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (5,5) with model Border with color grey at (1,1)
  _01: rectangle with size (4,1) with model Full with color grey at (7,7)
  _011: rectangle with size (4,1) with model Full with color grey at (7,4)
  + 4 delta pixels
diff: 
! 14 wrong pixels (generated / expected)

TRAIN c0f76784.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
undefined expression: Average: not an integer

TEST c0f76784.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 28.1 sec (28.1 sec/task)
bits-train-error = 625.4 bits (625.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-98] Checking task c1d99e64.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 266040.6 = 266042.9
DL output with Mo: L = 2.3 + 266040.6 = 266042.9
DL input+output M: L = 4.6 + 532081.1 = 532085.8

# learning a model for train pairs
2.000	
1.412	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.823	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.505	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.387	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.345	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.280	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.222	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.190	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.172	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.097	
0.097	IN  GEN ^ = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 19880.9 = 19951.1
DL output with Mo: L = 153.4 + 25654.8 = 25808.2
DL input+output M: L = 223.6 + 45535.7 = 45759.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 153.4 + 25654.8 = 25808.2
DL input+output M: L = 155.7 + 25654.8 = 25810.5

# train input/output grids

## instance 1

> Input and output best reading:

data: 
1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 
1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 
1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 
1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 
1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 
1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 1 
1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 0 
1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 
1 1 0 0 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 
1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 

diff: 
   (0.0 bits)
data: a background with size (12,19) and color black and layers
  _0: rectangle with size (8,10) with mask 
0 0 . 0 . 0 . 0 0 0 
. 0 0 0 0 0 0 . 0 0 
0 . . . 0 . 0 . 0 . 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
. . 0 . 0 0 . . . 0 
0 0 0 0 0 0 0 . 0 . 
0 . 0 0 0 . 0 0 0 0 
 with color blue at (0,9)
  _01: rectangle with size (8,8) with mask 
0 . . . 0 0 0 0 
0 . 0 . 0 0 0 0 
0 0 0 0 . . 0 0 
0 . 0 0 0 0 0 0 
0 . 0 0 . 0 0 0 
0 0 . 0 . 0 0 . 
0 . . 0 0 . 0 . 
0 0 . . 0 0 0 0 
 with color blue at (0,0)
  _011: rectangle with size (12,19) with mask 
. . . . . . . . 0 . . . . . . . . . . 
. . . . . . . . 0 . . . . . . . . . . 
. . . . . . . . 0 . . . . . . . . . . 
. . . . . . . . 0 . . . . . . . . . . 
. . . . . . . . 0 . . . . . . . . . . 
. . . . . . . . 0 . . . . . . . . . . 
. . . . . . . . 0 . . . . . . . . . . 
. . . . . . . . 0 . . . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . 0 . . . . . . . . . . 
. . . . . . . . 0 . . . . . . . . . . 
. . . . . . . . 0 . . . . . . . . . . 
 with color red at (0,0)
  _0111: rectangle with size (3,7) with mask 
0 0 0 0 0 0 0 
. . 0 . 0 . 0 
. . . 0 0 0 0 
 with color blue at (9,12)
  _01111: rectangle with size (3,3) with mask 
0 0 0 
0 0 . 
0 . 0 
 with color blue at (9,0)
  + 14 delta pixels
diff: 
   (1074.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 
1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 
1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 
1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 
1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 
1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 1 
1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 0 
1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 
1 1 0 0 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 
1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 

diff: 
! size mismatch, 10x10 instead of 12x19

TRAIN c1d99e64.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
8 8 8 8 0 8 8 8 8 8 0 0 8 8 
0 8 0 0 0 0 8 8 8 8 0 8 8 8 
8 8 0 8 0 8 8 8 8 8 0 0 8 8 
8 0 8 8 0 8 8 0 0 8 0 8 8 0 
8 8 8 8 0 8 8 0 0 0 0 8 8 8 
8 8 8 0 0 8 8 0 8 0 0 8 8 8 
8 0 8 8 0 8 8 8 8 8 0 0 0 8 
8 8 0 0 0 8 0 0 8 8 0 0 8 8 
8 0 0 8 0 8 8 8 0 8 0 8 8 8 
8 8 0 8 0 8 8 8 8 8 0 0 8 0 
0 8 0 8 0 0 0 0 0 0 0 8 0 8 
8 8 8 8 0 8 8 8 8 8 0 0 8 0 

diff: 
   (0.0 bits)
data: a background with size (12,14) and color black and layers
  _0: rectangle with size (10,5) with mask 
0 0 0 0 0 
. 0 0 0 0 
0 0 0 0 0 
0 0 . . 0 
0 0 . . . 
0 0 . 0 . 
0 0 0 0 0 
0 . . 0 0 
0 0 0 . 0 
0 0 0 0 0 
 with color cyan at (0,5)
  _01: rectangle with size (12,4) with mask 
0 0 0 0 
. 0 . . 
0 0 . 0 
0 . 0 0 
0 0 0 0 
0 0 0 . 
0 . 0 0 
0 0 . . 
0 . . 0 
0 0 . 0 
. 0 . 0 
0 0 0 0 
 with color cyan at (0,0)
  _011: rectangle with size (12,3) with mask 
. 0 0 
0 0 0 
. 0 0 
0 0 . 
0 0 0 
0 0 0 
. . 0 
. 0 0 
0 0 0 
. 0 . 
0 . 0 
. 0 . 
 with color cyan at (0,11)
  _0111: rectangle with size (12,1) with model Full with color red at (0,4)
  _01111: rectangle with size (12,1) with model Full with color red at (0,10)
  + 5 delta pixels
diff: 
   (525.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 8 8 8 0 8 8 8 8 8 0 0 8 8 
0 8 0 0 0 0 8 8 8 8 0 8 8 8 
8 8 0 8 0 8 8 8 8 8 0 0 8 8 
8 0 8 8 0 8 8 0 0 8 0 8 8 0 
8 8 8 8 0 8 8 0 0 0 0 8 8 8 
8 8 8 0 0 8 8 0 8 0 0 8 8 8 
8 0 8 8 0 8 8 8 8 8 0 0 0 8 
8 8 0 0 0 8 0 0 8 8 0 0 8 8 
8 0 0 8 0 8 8 8 0 8 0 8 8 8 
8 8 0 8 0 8 8 8 8 8 0 0 8 0 
0 8 0 8 0 0 0 0 0 0 0 8 0 8 
8 8 8 8 0 8 8 8 8 8 0 0 8 0 

diff: 
! size mismatch, 10x10 instead of 12x14

TRAIN c1d99e64.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
3 0 3 3 3 3 3 0 3 3 3 0 3 0 3 
3 0 3 0 3 3 3 0 3 0 3 0 0 3 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
3 0 0 3 0 0 3 3 0 3 0 3 3 0 0 
3 0 3 3 3 3 3 3 3 3 0 3 3 3 3 
3 0 3 3 3 3 3 3 0 0 3 3 0 3 3 
0 0 3 0 3 0 3 0 3 0 0 3 3 3 0 
3 0 0 3 3 3 0 0 3 0 3 3 0 0 3 
3 0 3 3 3 3 3 0 3 3 3 3 3 0 3 
3 0 0 3 3 0 3 3 3 3 3 3 3 3 0 
3 0 3 3 3 3 3 3 0 3 3 3 0 3 3 
3 0 3 3 3 0 3 0 0 3 0 3 3 3 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
3 0 3 0 0 3 0 3 3 0 3 3 3 3 0 
3 0 0 3 0 3 3 0 3 0 3 3 0 0 3 
3 0 0 3 3 3 3 3 0 3 3 0 0 3 3 
0 0 3 3 0 3 3 0 0 3 0 3 0 3 0 

diff: 
   (0.0 bits)
data: a background with size (17,15) and color black and layers
  _0: rectangle with size (9,13) with mask 
. 0 . . 0 0 . 0 . 0 0 . . 
0 0 0 0 0 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 . . 0 0 . 0 0 
0 . 0 . 0 . 0 . . 0 0 0 . 
. 0 0 0 . . 0 . 0 0 . . 0 
0 0 0 0 0 . 0 0 0 0 0 . 0 
. 0 0 . 0 0 0 0 0 0 0 0 . 
0 0 0 0 0 0 . 0 0 0 . 0 0 
0 0 0 . 0 . . 0 . 0 0 0 . 
 with color green at (3,2)
  _01: rectangle with size (17,15) with mask 
. 0 . . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. 0 . . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. 0 . . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . . 
 with color red at (0,0)
  _011: rectangle with size (4,13) with mask 
0 . . 0 . 0 0 . 0 0 0 0 . 
. 0 . 0 0 . 0 . 0 0 . . 0 
. 0 0 0 0 0 . 0 0 . . 0 0 
0 0 . 0 0 . . 0 . 0 . 0 . 
 with color green at (13,2)
  _0111: rectangle with size (2,15) with model Full with color green at (0,0)
  _01111: rectangle with size (13,1) with model Full with color green at (3,0)
  + 10 delta pixels
diff: 
   (965.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 0 3 3 3 3 3 0 3 3 3 0 3 0 3 
3 0 3 0 3 3 3 0 3 0 3 0 0 3 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
3 0 0 3 0 0 3 3 0 3 0 3 3 0 0 
3 0 3 3 3 3 3 3 3 3 0 3 3 3 3 
3 0 3 3 3 3 3 3 0 0 3 3 0 3 3 
0 0 3 0 3 0 3 0 3 0 0 3 3 3 0 
3 0 0 3 3 3 0 0 3 0 3 3 0 0 3 
3 0 3 3 3 3 3 0 3 3 3 3 3 0 3 
3 0 0 3 3 0 3 3 3 3 3 3 3 3 0 
3 0 3 3 3 3 3 3 0 3 3 3 0 3 3 
3 0 3 3 3 0 3 0 0 3 0 3 3 3 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
3 0 3 0 0 3 0 3 3 0 3 3 3 3 0 
3 0 0 3 0 3 3 0 3 0 3 3 0 0 3 
3 0 0 3 3 3 3 3 0 3 3 0 0 3 3 
0 0 3 3 0 3 3 0 0 3 0 3 0 3 0 

diff: 
! size mismatch, 10x10 instead of 17x15

TRAIN c1d99e64.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 0 4 0 4 4 0 0 4 4 4 4 0 4 4 4 4 4 0 4 4 0 4 0 0 
4 4 4 0 0 4 0 4 4 0 4 4 4 4 4 4 0 4 4 4 4 0 4 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
4 0 4 4 4 0 0 4 4 4 4 4 0 4 4 4 4 4 4 4 4 0 4 4 0 
4 4 0 4 4 4 0 0 0 0 4 4 4 4 0 4 4 4 0 4 4 0 4 4 4 
4 4 4 0 4 4 0 4 4 4 4 4 4 4 4 4 4 0 4 0 4 0 4 0 4 
4 0 0 4 0 4 0 4 4 4 4 4 4 0 4 0 4 4 4 0 4 0 4 4 4 
4 4 4 4 4 0 0 4 0 4 0 0 4 4 0 0 4 4 4 0 0 0 0 4 0 
0 4 4 0 4 4 0 4 4 0 4 4 0 4 4 0 0 4 0 4 0 0 4 0 4 
4 4 4 0 4 4 0 0 4 4 4 4 4 0 0 4 0 4 4 4 0 0 4 4 4 
4 0 4 4 4 0 0 4 0 4 4 0 4 4 0 4 4 0 4 4 0 0 0 0 4 
4 4 0 4 0 0 0 4 4 4 0 4 4 4 4 4 4 0 4 4 4 0 4 4 4 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 4 4 0 0 0 0 0 4 4 4 4 0 4 4 0 0 4 4 4 4 0 0 4 4 
4 4 4 4 4 4 0 4 4 4 4 0 4 0 4 4 0 4 4 4 4 0 4 4 4 
4 4 4 4 4 0 0 4 0 4 0 0 4 4 4 4 4 4 4 4 0 0 4 0 4 
0 4 4 4 4 4 0 4 4 4 4 4 0 4 0 4 4 0 4 4 4 0 4 4 0 
0 4 4 4 4 0 0 4 4 4 0 4 0 4 0 4 4 4 4 4 4 0 0 4 4 
4 4 4 0 4 4 0 0 4 0 4 4 4 4 4 4 4 4 4 4 4 0 0 0 0 
4 4 0 4 4 4 0 4 4 0 4 4 4 0 4 4 4 0 4 4 0 0 0 4 4 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
4 4 4 4 0 4 0 4 0 4 4 4 0 0 0 0 4 0 4 4 4 0 4 4 4 
0 4 4 4 4 4 0 4 0 4 0 4 4 0 4 4 0 4 4 0 4 0 4 4 4 
4 4 4 4 4 4 0 4 4 0 0 0 0 4 4 4 0 0 4 4 4 0 4 4 0 
4 0 4 0 4 4 0 4 0 0 0 4 4 4 4 4 0 4 0 4 4 0 0 4 0 
4 4 0 4 0 4 0 0 4 0 4 4 0 4 4 0 0 0 4 0 4 0 4 4 4 
4 0 0 4 4 4 0 4 0 4 4 4 4 4 0 4 4 4 4 0 0 0 4 4 4 

diff: 
! size mismatch, 10x10 instead of 27x25

TEST c1d99e64.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.8 sec (59.8 sec/task)
bits-train-error = 25654.8 bits (25654.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-97] Checking task c3e719e8.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 10534.8 = 10537.1
DL output with Mo: L = 2.3 + 96473.4 = 96475.7
DL input+output M: L = 4.6 + 107008.2 = 107012.9

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = compose(majorityColor(^), ^, ^)
0.557	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.427	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.333	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.314	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.298	IN  SPE ^.layer_0.shape.color = cyan
0.287	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.011	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
compose(majorityColor(^), ^, ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color cyan at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 109.5 + 2911.2 = 3020.7
DL output with Mo: L = 17.1 + 0.0 = 17.1
DL input+output M: L = 126.6 + 2911.2 = 3037.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
compose(majorityColor(^), ^, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 17.1 + 0.0 = 17.1
DL input+output M: L = 19.4 + 0.0 = 19.4

# train input/output grids

## instance 1

> Input and output best reading:

data: 
3 8 7#
9#3 8 
7#9#3 

diff: 
   (0.0 bits)
data: 
3 8 7#0 0 0 0 0 0 
9#3 8 0 0 0 0 0 0 
7#9#3 0 0 0 0 0 0 
0 0 0 3 8 7#0 0 0 
0 0 0 9#3 8 0 0 0 
0 0 0 7#9#3 0 0 0 
0 0 0 0 0 0 3 8 7#
0 0 0 0 0 0 9#3 8 
0 0 0 0 0 0 7#9#3 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 8 7#
9#3 8 
7#9#3 

diff: 
correct output grid

TRAIN c3e719e8.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
8 6 8 
3 3 8 
8 8 8 

diff: 
   (0.0 bits)
data: 
8 6 8 0 0 0 8 6 8 
3 3 8 0 0 0 3 3 8 
8 8 8 0 0 0 8 8 8 
0 0 0 0 0 0 8 6 8 
0 0 0 0 0 0 3 3 8 
0 0 0 0 0 0 8 8 8 
8 6 8 8 6 8 8 6 8 
3 3 8 3 3 8 3 3 8 
8 8 8 8 8 8 8 8 8 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 6 8 
3 3 8 
8 8 8 

diff: 
correct output grid

TRAIN c3e719e8.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
6 9#9#
4 6 8 
9#9#8 

diff: 
   (0.0 bits)
data: 
0 0 0 6 9#9#6 9#9#
0 0 0 4 6 8 4 6 8 
0 0 0 9#9#8 9#9#8 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
6 9#9#6 9#9#0 0 0 
4 6 8 4 6 8 0 0 0 
9#9#8 9#9#8 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
6 9#9#
4 6 8 
9#9#8 

diff: 
correct output grid

TRAIN c3e719e8.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 7#
7#4 1 
5#1 7#

diff: 
correct output grid

TEST c3e719e8.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.1 sec (1.1 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-96] Checking task c3f564a4.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 315315.2 = 315317.5
DL output with Mo: L = 2.3 + 315315.2 = 315317.5
DL input+output M: L = 4.6 + 630630.4 = 630635.0

# learning a model for train pairs
2.000	
1.826	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.667	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.840	OUT SPE ^ = fillResizeAlike(black, ^.size, ^)
0.781	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.740	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.700	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.662	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.627	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.593	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.563	IN  ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.535	IN  ADD ^.layer_01111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.001	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
fillResizeAlike(black, ^.size, ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 235.7 + 168566.4 = 168802.1
DL output with Mo: L = 20.8 + 0.0 = 20.8
DL input+output M: L = 256.6 + 168566.4 = 168822.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
fillResizeAlike(black, ^.size, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 20.8 + 0.0 = 20.8
DL input+output M: L = 23.2 + 0.0 = 23.2

# train input/output grids

## instance 1

> Input and output best reading:

data: 
1 2 3 4 5#1 2 3 4 5#1 2 3 4 5#1 
2 0 0 0 1 2 3 4 5#1 2 3 4 5#1 2 
3 0 0 0 2 3 4 5#1 2 3 4 5#1 2 3 
4 0 0 0 3 4 5#1 2 3 4 5#1 2 3 4 
5#0 0 0 4 5#1 2 3 4 5#1 2 3 4 5#
1 2 3 4 5#1 2 3 4 5#1 2 0 0 5#1 
2 3 4 5#1 2 3 4 5#1 2 3 0 0 1 2 
3 4 5#1 2 3 4 5#1 2 3 4 5#1 2 3 
4 5#1 2 3 4 5#1 2 3 4 5#1 2 3 4 
5#1 2 3 4 5#1 2 3 4 0 0 0 0 4 5#
1 2 3 4 5#1 2 3 4 5#0 0 0 0 5#1 
2 3 4 5#1 2 0 0 0 1 0 0 0 0 1 2 
3 4 5#1 2 3 0 0 0 0 3 4 5#1 2 3 
4 5#1 2 3 4 0 0 0 0 4 5#1 2 3 4 
5#1 2 3 4 5#0 0 0 0 5#1 2 3 4 5#
1 2 3 4 5#1 2 3 4 5#1 2 3 4 5#1 

diff: 
   (0.0 bits)
data: 
1 2 3 4 5#1 2 3 4 5#1 2 3 4 5#1 
2 3 4 5#1 2 3 4 5#1 2 3 4 5#1 2 
3 4 5#1 2 3 4 5#1 2 3 4 5#1 2 3 
4 5#1 2 3 4 5#1 2 3 4 5#1 2 3 4 
5#1 2 3 4 5#1 2 3 4 5#1 2 3 4 5#
1 2 3 4 5#1 2 3 4 5#1 2 3 4 5#1 
2 3 4 5#1 2 3 4 5#1 2 3 4 5#1 2 
3 4 5#1 2 3 4 5#1 2 3 4 5#1 2 3 
4 5#1 2 3 4 5#1 2 3 4 5#1 2 3 4 
5#1 2 3 4 5#1 2 3 4 5#1 2 3 4 5#
1 2 3 4 5#1 2 3 4 5#1 2 3 4 5#1 
2 3 4 5#1 2 3 4 5#1 2 3 4 5#1 2 
3 4 5#1 2 3 4 5#1 2 3 4 5#1 2 3 
4 5#1 2 3 4 5#1 2 3 4 5#1 2 3 4 
5#1 2 3 4 5#1 2 3 4 5#1 2 3 4 5#
1 2 3 4 5#1 2 3 4 5#1 2 3 4 5#1 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 2 3 4 5#1 2 3 4 5#1 2 3 4 5#1 
2 0 0 0 1 2 3 4 5#1 2 3 4 5#1 2 
3 0 0 0 2 3 4 5#1 2 3 4 5#1 2 3 
4 0 0 0 3 4 5#1 2 3 4 5#1 2 3 4 
5#0 0 0 4 5#1 2 3 4 5#1 2 3 4 5#
1 2 3 4 5#1 2 3 4 5#1 2 0 0 5#1 
2 3 4 5#1 2 3 4 5#1 2 3 0 0 1 2 
3 4 5#1 2 3 4 5#1 2 3 4 5#1 2 3 
4 5#1 2 3 4 5#1 2 3 4 5#1 2 3 4 
5#1 2 3 4 5#1 2 3 4 0 0 0 0 4 5#
1 2 3 4 5#1 2 3 4 5#0 0 0 0 5#1 
2 3 4 5#1 2 0 0 0 1 0 0 0 0 1 2 
3 4 5#1 2 3 0 0 0 0 3 4 5#1 2 3 
4 5#1 2 3 4 0 0 0 0 4 5#1 2 3 4 
5#1 2 3 4 5#0 0 0 0 5#1 2 3 4 5#
1 2 3 4 5#1 2 3 4 5#1 2 3 4 5#1 

diff: 
correct output grid

TRAIN c3f564a4.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
1 2 3 4 5#6 1 2 3 4 5#6 1 2 3 4 
2 3 4 5#6 1 2 3 4 5#6 1 2 3 4 5#
3 4 5#6 1 2 0 0 5#6 1 2 3 4 5#6 
4 5#6 1 2 0 0 0 6 1 2 3 4 5#6 1 
5#6 1 2 3 0 0 0 1 2 3 4 5#6 1 2 
6 1 2 3 4 5#6 1 2 3 4 5#6 1 2 3 
1 2 3 4 5#6 1 2 0 0 0 6 1 2 3 4 
2 3 4 5#6 1 2 3 0 0 0 0 2 3 4 5#
3 4 5#6 1 2 3 4 0 0 0 0 3 4 5#6 
0 0 0 0 2 3 4 5#0 0 0 0 4 5#6 1 
0 0 0 0 3 4 5#6 1 2 3 4 5#6 1 2 
0 0 0 0 4 5#6 1 2 3 4 5#6 1 2 3 
0 0 0 0 5#6 1 2 3 4 5#6 1 2 3 4 
2 3 4 5#6 1 2 3 4 5#6 1 2 3 4 5#
3 4 5#6 1 2 3 4 5#6 1 2 3 4 5#6 
4 5#6 1 2 3 4 5#6 1 2 3 4 5#6 1 

diff: 
   (0.0 bits)
data: 
1 2 3 4 5#6 1 2 3 4 5#6 1 2 3 4 
2 3 4 5#6 1 2 3 4 5#6 1 2 3 4 5#
3 4 5#6 1 2 3 4 5#6 1 2 3 4 5#6 
4 5#6 1 2 3 4 5#6 1 2 3 4 5#6 1 
5#6 1 2 3 4 5#6 1 2 3 4 5#6 1 2 
6 1 2 3 4 5#6 1 2 3 4 5#6 1 2 3 
1 2 3 4 5#6 1 2 3 4 5#6 1 2 3 4 
2 3 4 5#6 1 2 3 4 5#6 1 2 3 4 5#
3 4 5#6 1 2 3 4 5#6 1 2 3 4 5#6 
4 5#6 1 2 3 4 5#6 1 2 3 4 5#6 1 
5#6 1 2 3 4 5#6 1 2 3 4 5#6 1 2 
6 1 2 3 4 5#6 1 2 3 4 5#6 1 2 3 
1 2 3 4 5#6 1 2 3 4 5#6 1 2 3 4 
2 3 4 5#6 1 2 3 4 5#6 1 2 3 4 5#
3 4 5#6 1 2 3 4 5#6 1 2 3 4 5#6 
4 5#6 1 2 3 4 5#6 1 2 3 4 5#6 1 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 2 3 4 5#6 1 2 3 4 5#6 1 2 3 4 
2 3 4 5#6 1 2 3 4 5#6 1 2 3 4 5#
3 4 5#6 1 2 0 0 5#6 1 2 3 4 5#6 
4 5#6 1 2 0 0 0 6 1 2 3 4 5#6 1 
5#6 1 2 3 0 0 0 1 2 3 4 5#6 1 2 
6 1 2 3 4 5#6 1 2 3 4 5#6 1 2 3 
1 2 3 4 5#6 1 2 0 0 0 6 1 2 3 4 
2 3 4 5#6 1 2 3 0 0 0 0 2 3 4 5#
3 4 5#6 1 2 3 4 0 0 0 0 3 4 5#6 
0 0 0 0 2 3 4 5#0 0 0 0 4 5#6 1 
0 0 0 0 3 4 5#6 1 2 3 4 5#6 1 2 
0 0 0 0 4 5#6 1 2 3 4 5#6 1 2 3 
0 0 0 0 5#6 1 2 3 4 5#6 1 2 3 4 
2 3 4 5#6 1 2 3 4 5#6 1 2 3 4 5#
3 4 5#6 1 2 3 4 5#6 1 2 3 4 5#6 
4 5#6 1 2 3 4 5#6 1 2 3 4 5#6 1 

diff: 
correct output grid

TRAIN c3f564a4.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 
2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 3 
3 0 0 0 0 1 2 3 4 5#6 7#1 2 3 4 
4 0 0 0 0 2 3 4 5#6 7#1 2 3 4 5#
5#0 0 0 0 3 4 5#6 7#1 2 3 4 5#6 
6 0 0 0 0 4 5#6 7#1 2 3 4 5#6 7#
7#1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 
1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 
2 0 0 0 0 7#1 2 3 4 5#6 7#1 2 3 
3 0 0 0 0 1 2 3 4 5#6 7#1 2 3 4 
4 5#6 7#1 2 3 4 5#6 7#1 0 0 4 5#
5#6 7#1 2 3 4 5#6 7#1 2 0 0 5#6 
6 7#1 2 3 4 5#6 7#1 2 0 0 0 0 7#
7#1 2 3 4 5#6 7#1 2 3 0 0 0 0 1 
1 2 3 4 5#6 7#1 2 3 4 0 0 0 0 2 
2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 3 

diff: 
   (0.0 bits)
data: 
1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 
2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 3 
3 4 5#6 7#1 2 3 4 5#6 7#1 2 3 4 
4 5#6 7#1 2 3 4 5#6 7#1 2 3 4 5#
5#6 7#1 2 3 4 5#6 7#1 2 3 4 5#6 
6 7#1 2 3 4 5#6 7#1 2 3 4 5#6 7#
7#1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 
1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 
2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 3 
3 4 5#6 7#1 2 3 4 5#6 7#1 2 3 4 
4 5#6 7#1 2 3 4 5#6 7#1 2 3 4 5#
5#6 7#1 2 3 4 5#6 7#1 2 3 4 5#6 
6 7#1 2 3 4 5#6 7#1 2 3 4 5#6 7#
7#1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 
1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 
2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 3 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 
2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 3 
3 0 0 0 0 1 2 3 4 5#6 7#1 2 3 4 
4 0 0 0 0 2 3 4 5#6 7#1 2 3 4 5#
5#0 0 0 0 3 4 5#6 7#1 2 3 4 5#6 
6 0 0 0 0 4 5#6 7#1 2 3 4 5#6 7#
7#1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 
1 2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 
2 0 0 0 0 7#1 2 3 4 5#6 7#1 2 3 
3 0 0 0 0 1 2 3 4 5#6 7#1 2 3 4 
4 5#6 7#1 2 3 4 5#6 7#1 0 0 4 5#
5#6 7#1 2 3 4 5#6 7#1 2 0 0 5#6 
6 7#1 2 3 4 5#6 7#1 2 0 0 0 0 7#
7#1 2 3 4 5#6 7#1 2 3 0 0 0 0 1 
1 2 3 4 5#6 7#1 2 3 4 0 0 0 0 2 
2 3 4 5#6 7#1 2 3 4 5#6 7#1 2 3 

diff: 
correct output grid

TRAIN c3f564a4.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 2 3 4 5#6 7#0 0 0 3 4 5#6 7#8 
2 3 4 5#6 7#8 0 0 0 4 5#6 7#8 1 
3 4 5#6 7#8 1 2 3 4 5#6 7#8 1 2 
4 5#6 7#8 1 2 3 4 5#6 7#8 1 2 3 
5#6 0 0 0 0 3 4 5#6 7#8 1 2 3 4 
6 7#0 0 0 0 0 0 0 7#8 1 2 3 4 5#
7#8 0 0 0 0 0 0 0 8 1 2 3 4 5#6 
8 1 0 0 0 0 0 0 0 1 2 3 4 5#6 7#
1 2 3 4 5#0 0 0 0 2 3 4 5#6 7#8 
2 3 4 5#6 7#8 1 2 3 4 5#6 7#8 1 
3 4 5#6 7#8 1 2 3 4 5#6 7#8 1 2 
4 5#6 7#8 1 2 3 4 5#6 7#8 1 2 3 
5#6 7#8 1 2 3 0 0 6 7#8 1 2 3 4 
6 7#8 1 2 3 4 0 0 7#8 1 2 3 4 5#
7#8 1 2 3 4 5#6 7#8 1 2 3 4 5#6 
8 1 2 3 4 5#6 7#8 1 2 3 4 5#6 7#

diff: 
correct output grid

TEST c3f564a4.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 6.7 sec (6.7 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-95] Checking task c444b776.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 219176.9 = 219179.2
DL output with Mo: L = 2.3 + 219176.9 = 219179.2
DL input+output M: L = 4.6 + 438353.7 = 438358.3

# learning a model for train pairs
2.000	
1.127	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.329	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.246	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.160	OUT ADD ^.layer_0 = ^.layer_0
0.155	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.148	OUT ADD ^.layer_01 = ^.layer_01
0.142	OUT ADD ^.layer_011 = ^.layer_01.shape at (?,?)
0.137	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.130	OUT ADD ^.layer_0111 = ^.layer_011
0.124	OUT ADD ^.layer_0110 = ^.layer_011.shape at (?,?)
0.121	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.119	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.116	OUT ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.114	OUT SPE ^.size = ^.size
0.112	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.110	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.108	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.106	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.104	IN  ADD ^.layer_01111111 = point with color ? at (?,?)
0.102	IN  SPE ^.layer_01.shape.mask = 
. 0 
0 . 

0.101	OUT SPE ^.layer_0111111.pos.i = ^.layer_0111111.pos.i
0.101	OUT SPE ^.layer_0111111 = ^.layer_0111111
0.100	OUT SPE ^.layer_011111.pos.i = middle(^.layer_0111)
0.100	OUT SPE ^.layer_01111.pos.i = ^.layer_01.pos.j
0.099	OUT SPE ^.layer_0110.pos.j = ^.layer_011.pos.j
0.099	OUT SPE ^.layer_011.pos.j = ^.layer_01.pos.j
0.098	IN  SPE ^.layer_0.shape.color = yellow
0.098	IN  SPE ^.layer_01.shape.color = red
0.097	OUT SPE ^.layer_01111.shape.color = red
0.097	OUT SPE ^.layer_011111.pos.j = middle(^.layer_0111)
0.096	OUT SPE ^.layer_01111.pos.j = center(^.layer_0) + 2
0.096	OUT SPE ^.layer_011111.shape.mask.size = span(^.layer_0111111.pos, ^.layer_01111111.pos) - (1, 2)
0.095	OUT SPE ^.layer_01111.shape.mask.size = span(^.layer_0111111.pos, ^.layer_01111111.pos) - (1, 2)
0.095	IN  SPE ^.color = black
0.095	OUT SPE ^.color = black
0.073	
0.073	IN  GEN ^.layer_01.shape.color = ?
0.073	IN  GEN ^.layer_0.shape.color = ?
0.073	IN  GEN ^.layer_01.shape.mask = rectangle with size (?,?) with model ?
0.073	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_01
  _0110: ^.layer_011.shape at (?,^.layer_011.pos.j)
  _011: ^.layer_01.shape at (?,^.layer_01.pos.j)
  _0111: ^.layer_011
  _01111: rectangle with size span(^.layer_0111111.pos, ^.layer_01111111.pos) - (1, 2) with model ? with color red at (^.layer_01.pos.j,center(^.layer_0) + 2)
  _011111: rectangle with size span(^.layer_0111111.pos, ^.layer_01111111.pos) - (1, 2) with model ? with color ? at (middle(^.layer_0111),middle(^.layer_0111))
  _0111111: ^.layer_0111111
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color yellow at (?,?)
  _01: 
. 0 
0 . 
 with color red at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)

DL input  with Mi: L = 194.1 + 4768.2 = 4962.2
DL output with Mo: L = 312.5 + 15525.1 = 15837.6
DL input+output M: L = 506.6 + 20293.3 = 20799.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_01
  _0110: ^.layer_011.shape at (?,^.layer_011.pos.j)
  _011: ^.layer_01.shape at (?,^.layer_01.pos.j)
  _0111: ^.layer_011
  _01111: rectangle with size span(^.layer_0111111.pos, ^.layer_01111111.pos) - (1, 2) with model ? with color red at (^.layer_01.pos.j,center(^.layer_0) + 2)
  _011111: rectangle with size span(^.layer_0111111.pos, ^.layer_01111111.pos) - (1, 2) with model ? with color ? at (middle(^.layer_0111),middle(^.layer_0111))
  _0111111: ^.layer_0111111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)

DL input  with Mi: L = 186.7 + 20.0 = 206.7
DL output with Mo: L = 312.5 + 15525.1 = 15837.6
DL input+output M: L = 499.2 + 15545.1 = 16044.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (19,19) and color black and layers
  _0: rectangle with size (19,19) with model +-cross with color yellow at (0,0)
  _01: rectangle with size (2,2) with model Odd Checkboard with color red at (12,2)
  _011: rectangle with size (2,2) with model Even Checkboard with color cyan at (16,3)
  _0111: point with color orange at (11,5)
  _01111: point with color green at (14,1)
  _011111: point with color green at (14,5)
  _0111111: point with color orange at (16,4)
  _01111111: point with color orange at (18,1)
  + 1 delta pixels
diff: 
   (2.0 bits)
data: a background with size (19,19) and color black and layers
  _0: 
. . . . . . . . . 4 . . . . . . . . . 
. . . . . . . . . 4 . . . . . . . . . 
. . . . . . . . . 4 . . . . . . . . . 
. . . . . . . . . 4 . . . . . . . . . 
. . . . . . . . . 4 . . . . . . . . . 
. . . . . . . . . 4 . . . . . . . . . 
. . . . . . . . . 4 . . . . . . . . . 
. . . . . . . . . 4 . . . . . . . . . 
. . . . . . . . . 4 . . . . . . . . . 
4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 
. . . . . . . . . 4 . . . . . . . . . 
. . . . . . . . . 4 . . . . . . . . . 
. . . . . . . . . 4 . . . . . . . . . 
. . . . . . . . . 4 . . . . . . . . . 
. . . . . . . . . 4 . . . . . . . . . 
. . . . . . . . . 4 . . . . . . . . . 
. . . . . . . . . 4 . . . . . . . . . 
. . . . . . . . . 4 . . . . . . . . . 
. . . . . . . . . 4 . . . . . . . . . 
 at (0,0)
  _01: 
. 2 
2 . 
 at (12,2)
  _0110: 
8 . 
. 8 
 at (6,3)
  _011: 
. 2 
2 . 
 at (2,2)
  _0111: 
8 . 
. 8 
 at (16,3)
  _01111: rectangle with size (2,2) with model Odd Checkboard with color red at (2,12)
  _011111: rectangle with size (2,2) with model Odd Checkboard with color red at (12,12)
  _0111111: 
7#
 at (16,4)
  + 27 delta pixels
diff: 
   (1158.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,19) and color black and layers
  _0: rectangle with size (19,19) with model +-cross with color yellow at (0,0)
  _01: rectangle with size (2,2) with model Odd Checkboard with color red at (12,2)
  _011: rectangle with size (2,2) with model Even Checkboard with color cyan at (16,3)
  _0111: point with color orange at (11,5)
  _01111: point with color green at (14,1)
  _011111: point with color green at (14,5)
  _0111111: point with color orange at (16,4)
  _01111111: point with color green at (17,7)
  + 1 delta pixels
diff: 
! 39 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (19,19) and color black and layers
  _0: rectangle with size (19,19) with model +-cross with color yellow at (0,0)
  _01: rectangle with size (2,2) with model Odd Checkboard with color red at (12,2)
  _011: rectangle with size (2,2) with model Even Checkboard with color cyan at (16,3)
  _0111: point with color orange at (11,5)
  _01111: point with color green at (14,1)
  _011111: point with color green at (14,5)
  _0111111: point with color orange at (16,4)
  _01111111: point with color orange at (18,1)
  + 1 delta pixels
diff: 
! 40 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (19,19) and color black and layers
  _0: rectangle with size (19,19) with model +-cross with color yellow at (0,0)
  _01: rectangle with size (2,2) with model Odd Checkboard with color red at (12,2)
  _011: rectangle with size (2,2) with model Even Checkboard with color cyan at (16,3)
  _0111: point with color orange at (11,5)
  _01111: point with color green at (14,1)
  _011111: point with color green at (14,5)
  _0111111: point with color green at (17,7)
  _01111111: point with color orange at (16,4)
  + 1 delta pixels
diff: 
! 39 wrong pixels (generated / expected)

TRAIN c444b776.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (19,9) and color black and layers
  _0: rectangle with size (1,9) with model Full with color yellow at (9,0)
  _01: rectangle with size (2,2) with model Odd Checkboard with color red at (6,1)
  _011: rectangle with size (1,2) with model Full with color grey at (7,5)
  _0111: point with color grey at (1,5)
  _01111: point with color red at (1,7)
  _011111: point with color blue at (2,2)
  _0111111: point with color blue at (4,4)
  _01111111: point with color blue at (5,2)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (19,9) and color black and layers
  _0: 
4 4 4 4 4 4 4 4 4 
 at (9,0)
  _01: 
. 2 
2 . 
 at (6,1)
  _0110: 
5#5#
 at (17,5)
  _011: 
. 2 
2 . 
 at (16,1)
  _0111: 
5#5#
 at (7,5)
  _01111: rectangle with size (1,1) with model Full with color red at (1,7)
  _011111: rectangle with size (1,1) with model Full with color blue at (2,2)
  _0111111: 
1 
 at (4,4)
  + 9 delta pixels
diff: 
   (393.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,9) and color black and layers
  _0: rectangle with size (1,9) with model Full with color yellow at (9,0)
  _01: rectangle with size (2,2) with model Odd Checkboard with color red at (6,1)
  _011: rectangle with size (1,2) with model Full with color grey at (7,5)
  _0111: point with color grey at (1,5)
  _01111: point with color red at (1,7)
  _011111: point with color blue at (2,2)
  _0111111: point with color blue at (4,4)
  _01111111: point with color blue at (5,2)
  + 1 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (19,9) and color black and layers
  _0: rectangle with size (1,9) with model Full with color yellow at (9,0)
  _01: rectangle with size (2,2) with model Odd Checkboard with color red at (6,1)
  _011: rectangle with size (1,2) with model Full with color grey at (7,5)
  _0111: point with color grey at (1,5)
  _01111: point with color red at (1,7)
  _011111: point with color blue at (2,2)
  _0111111: point with color blue at (4,4)
  _01111111: point with color red at (6,7)
  + 1 delta pixels
diff: 
! 24 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (19,9) and color black and layers
  _0: rectangle with size (1,9) with model Full with color yellow at (9,0)
  _01: rectangle with size (2,2) with model Odd Checkboard with color red at (6,1)
  _011: rectangle with size (1,2) with model Full with color grey at (7,5)
  _0111: point with color grey at (1,5)
  _01111: point with color red at (1,7)
  _011111: point with color blue at (2,2)
  _0111111: point with color blue at (5,2)
  _01111111: point with color blue at (4,4)
  + 1 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TRAIN c444b776.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,29) and color black and layers
  _0: rectangle with size (1,29) with model Full with color yellow at (9,0)
  _01: rectangle with size (19,1) with model Full with color yellow at (0,9)
  _011: rectangle with size (19,1) with model Full with color yellow at (0,19)
  _0111: point with color green at (1,14)
  _01111: point with color red at (2,11)
  _011111: point with color red at (2,17)
  _0111111: point with color green at (3,11)
  _01111111: point with color red at (4,14)
  + 3 delta pixels
diff: 
! 49 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (19,29) and color black and layers
  _0: rectangle with size (1,29) with model Full with color yellow at (9,0)
  _01: rectangle with size (19,1) with model Full with color yellow at (0,9)
  _011: rectangle with size (19,1) with model Full with color yellow at (0,19)
  _0111: point with color green at (1,14)
  _01111: point with color red at (2,11)
  _011111: point with color red at (2,17)
  _0111111: point with color red at (4,14)
  _01111111: point with color green at (3,11)
  + 3 delta pixels
diff: 
! 49 wrong pixels (generated / expected)

TEST c444b776.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 43.7 sec (43.7 sec/task)
bits-train-error = 15525.1 bits (15525.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-94] Checking task c59eb873.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 11330.3 = 11332.6
DL output with Mo: L = 2.3 + 45501.7 = 45504.0
DL input+output M: L = 4.6 + 56832.0 = 56836.7

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = ^ * '2
0.548	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.364	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.297	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.263	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.248	IN  SPE ^.layer_01.shape.color = red
0.240	IN  SPE ^.layer_01.shape.mask.model = Full
0.234	IN  SPE ^.color = black
0.009	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
^ * '2
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color red at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 92.3 + 2554.2 = 2646.5
DL output with Mo: L = 18.9 + 0.0 = 18.9
DL input+output M: L = 111.1 + 2554.2 = 2665.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
^ * '2
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 18.9 + 0.0 = 18.9
DL input+output M: L = 21.2 + 0.0 = 21.2

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 5#1 
5#5#5#
2 5#0 

diff: 
   (0.0 bits)
data: 
0 0 5#5#1 1 
0 0 5#5#1 1 
5#5#5#5#5#5#
5#5#5#5#5#5#
2 2 5#5#0 0 
2 2 5#5#0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 5#1 
5#5#5#
2 5#0 

diff: 
correct output grid

TRAIN c59eb873.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
2 1 
3 1 

diff: 
   (0.0 bits)
data: 
2 2 1 1 
2 2 1 1 
3 3 1 1 
3 3 1 1 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 1 
3 1 

diff: 
correct output grid

TRAIN c59eb873.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
2 0 3 0 
2 1 3 0 
0 0 3 3 
0 0 3 5#

diff: 
   (0.0 bits)
data: 
2 2 0 0 3 3 0 0 
2 2 0 0 3 3 0 0 
2 2 1 1 3 3 0 0 
2 2 1 1 3 3 0 0 
0 0 0 0 3 3 3 3 
0 0 0 0 3 3 3 3 
0 0 0 0 3 3 5#5#
0 0 0 0 3 3 5#5#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 0 3 0 
2 1 3 0 
0 0 3 3 
0 0 3 5#

diff: 
correct output grid

TRAIN c59eb873.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 0 0 7#8 
2 1 1 0 0 
0 5#6 6 0 
3 5#6 0 0 
0 5#0 0 0 

diff: 
correct output grid

TEST c59eb873.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.1 sec (1.1 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-93] Checking task c8cbb738.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 152954.8 = 152957.1
DL output with Mo: L = 2.3 + 22921.2 = 22923.5
DL input+output M: L = 4.6 + 175876.0 = 175880.6

# learning a model for train pairs
2.000	
1.091	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.602	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.527	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.495	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.485	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.477	OUT ADD ^.layer_00 = ^.layer_0.shape at (?,?)
0.444	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.412	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.393	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.370	OUT ADD ^.layer_010 = ^.layer_01.shape at (?,?)
0.358	OUT SPE ^.layer_0.pos = '(0, 0)
0.348	OUT SPE ^.layer_011.pos = projI(^.layer_01.pos) - (1, 0)
0.342	OUT SPE ^.layer_01.pos.j = ^.layer_01.pos.j
0.337	OUT SPE ^.layer_00.pos.i = '0
0.332	IN  ADD ^.layer_00 = point with color ? at (?,?)
0.328	IN  ADD ^.layer_010 = point with color ? at (?,?)
0.324	OUT SPE ^.layer_01.shape.mask.size.j = 1
0.319	OUT SPE ^.layer_010.pos.i = ^.layer_0.pos.i / '2
0.314	OUT SPE ^.layer_01.pos.i = ^.layer_0.pos.i - area(^.layer_0.shape)
0.310	OUT SPE ^.layer_0111.shape.mask.size.i = 1
0.299	OUT SPE ^.layer_0.shape.mask.size = span(^.layer_00.pos, ^.layer_010.pos) - translationSym(flipWidth, ^.layer_010, ^.layer_0)
0.295	OUT SPE ^.layer_0111.pos.j = ^.layer_0.pos.i - ^.layer_0.shape.mask.size.j
0.291	OUT SPE ^.layer_00.pos.j = ^.layer_01.pos.i - ^.layer_0.shape.mask.size.i
0.287	OUT SPE ^.layer_011.shape.mask.size.j = ^.layer_0.shape.mask.size.j + ^.layer_01.pos.i - ^.layer_0.pos.i
0.283	OUT SPE ^.layer_01.shape.mask.model = Full
0.280	OUT SPE ^.layer_011.shape.mask.model = Full
0.276	OUT SPE ^.layer_0111.shape.mask.model = Full
0.273	OUT SPE ^.layer_011.shape.mask.size.i = area(^.layer_01.shape) - ^.layer_0.pos.j - ^.layer_010.pos.j
0.270	OUT SPE ^.layer_0111.pos.i = center(^.layer_01) - average(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i)
0.269	IN  SPE ^.layer_01.shape.mask = 
0 

0.201	
0.201	IN  GEN ^.layer_01.shape.mask = rectangle with size (?,?) with model ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _00: ^.layer_0.shape at ('0,^.layer_01.pos.i - ^.layer_0.shape.mask.size.i)
  _0: rectangle with size span(^.layer_00.pos, ^.layer_010.pos) - translationSym(flipWidth, ^.layer_010, ^.layer_0) with model ? with color ? at '(0, 0)
  _010: ^.layer_01.shape at (^.layer_0.pos.i / '2,?)
  _01: rectangle with size (?,1) with model Full with color ? at (^.layer_0.pos.i - area(^.layer_0.shape),^.layer_01.pos.j)
  _011: rectangle with size (area(^.layer_01.shape) - ^.layer_0.pos.j - ^.layer_010.pos.j,^.layer_0.shape.mask.size.j + ^.layer_01.pos.i - ^.layer_0.pos.i) with model Full with color ? at projI(^.layer_01.pos) - (1, 0)
  _0111: rectangle with size (1,?) with model Full with color ? at (center(^.layer_01) - average(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i),^.layer_0.pos.i - ^.layer_0.shape.mask.size.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: point with color ? at (?,?)
  _01: 
0 
 with color ? at (?,?)

DL input  with Mi: L = 98.4 + 10349.8 = 10448.2
DL output with Mo: L = 602.5 + 3987.6 = 4590.1
DL input+output M: L = 700.8 + 14337.4 = 15038.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _00: ^.layer_0.shape at ('0,^.layer_01.pos.i - ^.layer_0.shape.mask.size.i)
  _0: rectangle with size span(^.layer_00.pos, ^.layer_010.pos) - translationSym(flipWidth, ^.layer_010, ^.layer_0) with model ? with color ? at '(0, 0)
  _010: ^.layer_01.shape at (^.layer_0.pos.i / '2,?)
  _01: rectangle with size (?,1) with model Full with color ? at (^.layer_0.pos.i - area(^.layer_0.shape),^.layer_01.pos.j)
  _011: rectangle with size (area(^.layer_01.shape) - ^.layer_0.pos.j - ^.layer_010.pos.j,^.layer_0.shape.mask.size.j + ^.layer_01.pos.i - ^.layer_0.pos.i) with model Full with color ? at projI(^.layer_01.pos) - (1, 0)
  _0111: rectangle with size (1,?) with model Full with color ? at (center(^.layer_01) - average(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i),^.layer_0.pos.i - ^.layer_0.shape.mask.size.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: point with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: point with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 106.2 + 31.7 = 137.9
DL output with Mo: L = 602.5 + 3987.6 = 4590.1
DL input+output M: L = 708.6 + 4019.3 = 4728.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (12,11) and color green and layers
  _00: point with color yellow at (0,7)
  _0: rectangle with size (1,3) with model Full with color yellow at (4,7)
  _010: point with color yellow at (0,9)
  _01: rectangle with size (1,1) with model Full with color blue at (2,4)
  + 12 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,5) and color green and layers
  _00: 
4 4 4 
 at (0,1)
  _0: rectangle with size (1,5) with model Full with color red at (0,0)
  _010: 
1 
 at (2,0)
  _01: rectangle with size (3,1) with model Full with color cyan at (1,4)
  _011: rectangle with size (3,1) with model Full with color cyan at (1,0)
  _0111: rectangle with size (1,3) with model Full with color yellow at (4,1)
  + 5 delta pixels
diff: 
   (260.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,11) and color green and layers
  _00: point with color yellow at (0,7)
  _0: rectangle with size (1,3) with model Full with color yellow at (4,7)
  _010: point with color yellow at (0,9)
  _01: rectangle with size (1,1) with model Full with color blue at (2,4)
  + 12 delta pixels
diff: 
! size mismatch, 10x10 instead of 5x5
>> Trial 2
data: a background with size (12,11) and color green and layers
  _00: point with color yellow at (0,7)
  _0: rectangle with size (1,3) with model Full with color yellow at (4,7)
  _010: point with color yellow at (0,9)
  _01: rectangle with size (1,1) with model Full with color blue at (4,2)
  + 12 delta pixels
diff: 
! size mismatch, 10x10 instead of 5x5

TRAIN c8cbb738.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,8) and color blue and layers
  _00: point with color cyan at (1,1)
  _0: rectangle with size (3,3) with model Odd Checkboard with color green at (5,3)
  _010: point with color cyan at (1,3)
  _01: rectangle with size (1,1) with model Full with color cyan at (3,1)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _00: 
. 3 . 
3 . 3 
. 3 . 
 at (0,0)
  _0: rectangle with size (1,1) with model Full with color cyan at (0,0)
  _010: 
8 
 at (2,2)
  _01: rectangle with size (1,1) with model Full with color blue at (1,1)
  _011: rectangle with size (1,1) with model Full with color cyan at (2,0)
  _0111: rectangle with size (1,1) with model Full with color cyan at (0,2)
diff: 
   (51.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,8) and color blue and layers
  _00: point with color cyan at (1,1)
  _0: rectangle with size (3,3) with model Odd Checkboard with color green at (5,3)
  _010: point with color cyan at (1,3)
  _01: rectangle with size (1,1) with model Full with color cyan at (3,1)
  + 1 delta pixels
diff: 
! size mismatch, 10x10 instead of 3x3
>> Trial 2
data: a background with size (10,8) and color blue and layers
  _00: point with color cyan at (1,1)
  _0: rectangle with size (3,3) with model Odd Checkboard with color green at (5,3)
  _010: point with color cyan at (1,3)
  _01: rectangle with size (1,1) with model Full with color cyan at (3,3)
  + 1 delta pixels
diff: 
! size mismatch, 10x10 instead of 3x3

TRAIN c8cbb738.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (12,14) and color yellow and layers
  _00: point with color blue at (1,2)
  _0: rectangle with size (1,1) with model Full with color blue at (1,6)
  _010: point with color blue at (5,6)
  _01: rectangle with size (1,1) with model Full with color blue at (5,2)
  + 4 delta pixels
diff: 
   (3.2 bits)
data: a background with size (5,5) and color black and layers
  _00: 
1 
 at (0,4)
  _0: rectangle with size (5,5) with mask 
. 0 . 0 . 
0 0 0 0 0 
. 0 0 0 . 
0 0 0 0 0 
. 0 . 0 . 
 with color yellow at (0,0)
  _010: 
1 
 at (0,0)
  _01: rectangle with size (5,1) with model Full with color orange at (0,2)
  _011: rectangle with size (1,5) with model Full with color blue at (4,0)
  _0111: rectangle with size (1,5) with model Full with color orange at (2,0)
diff: 
   (86.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,14) and color yellow and layers
  _00: point with color blue at (1,2)
  _0: rectangle with size (1,1) with model Full with color blue at (1,6)
  _010: point with color blue at (5,6)
  _01: rectangle with size (1,1) with model Full with color blue at (5,2)
  + 4 delta pixels
diff: 
! size mismatch, 10x10 instead of 5x5

TRAIN c8cbb738.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
Invalid_argument("Model2.mask_rectangle: negative or null mask size")

TEST c8cbb738.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 50.7 sec (50.7 sec/task)
bits-train-error = 3987.6 bits (3987.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-92] Checking task c8f0f002.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 17446.5 = 17448.8
DL output with Mo: L = 2.3 + 17446.5 = 17448.8
DL input+output M: L = 4.6 + 34892.9 = 34897.6

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = swapColor(^, orange, grey)
0.602	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.351	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.266	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.244	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.217	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.202	IN  SPE ^.color = blue
0.193	IN  SPE ^.layer_0111.shape.color = orange
0.183	IN  SPE ^.layer_01.shape.color = orange
0.174	IN  SPE ^.layer_0.shape.color = cyan
0.169	IN  SPE ^.layer_011.shape.mask.model = Full
0.009	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
swapColor(^, orange, grey)
WHERE (Mi)
a background with size (?,?) and color blue and layers
  _0: rectangle with size (?,?) with model ? with color cyan at (?,?)
  _01: rectangle with size (?,?) with model ? with color orange at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: point with color orange at (?,?)

DL input  with Mi: L = 133.1 + 2797.7 = 2930.7
DL output with Mo: L = 20.6 + 0.0 = 20.6
DL input+output M: L = 153.7 + 2797.7 = 2951.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
swapColor(^, orange, grey)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 20.6 + 0.0 = 20.6
DL input+output M: L = 22.9 + 0.0 = 22.9

# train input/output grids

## instance 1

> Input and output best reading:

data: 
1 8 8 7#7#8 
1 1 7#7#1 8 
7#1 1 7#7#8 

diff: 
   (0.0 bits)
data: 
1 8 8 5#5#8 
1 1 5#5#1 8 
5#1 1 5#5#8 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 8 8 7#7#8 
1 1 7#7#1 8 
7#1 1 7#7#8 

diff: 
correct output grid

TRAIN c8f0f002.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
7#7#7#1 
1 8 1 7#
7#1 1 7#

diff: 
   (0.0 bits)
data: 
5#5#5#1 
1 8 1 5#
5#1 1 5#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
7#7#7#1 
1 8 1 7#
7#1 1 7#

diff: 
correct output grid

TRAIN c8f0f002.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
1 8 1 7#1 
7#8 8 1 1 
7#1 8 8 7#

diff: 
   (0.0 bits)
data: 
1 8 1 5#1 
5#8 8 1 1 
5#1 8 8 5#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 8 1 7#1 
7#8 8 1 1 
7#1 8 8 7#

diff: 
correct output grid

TRAIN c8f0f002.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 7#7#1 7#
8 1 7#7#7#
8 7#1 7#8 

diff: 
correct output grid

TEST c8f0f002.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 2.0 sec (2.0 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-91] Checking task c909285e.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 862682.6 = 862684.9
DL output with Mo: L = 2.3 + 57672.1 = 57674.4
DL input+output M: L = 4.6 + 920354.6 = 920359.3

# learning a model for train pairs
2.000	
1.520	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.179	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.998	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.821	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.701	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.656	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.622	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.574	OUT ADD ^.layer_010 = ^.layer_01.shape at (?,?)
0.547	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.527	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.506	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.486	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.466	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.102	
0.102	IN  DEL ^.layer_011111
0.102	IN  DEL ^.layer_01111
0.102	IN  DEL ^.layer_0111
0.102	IN  DEL ^.layer_011
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01.shape at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 180.9 + 314014.2 = 314195.1
DL output with Mo: L = 145.7 + 5729.1 = 5874.8
DL input+output M: L = 326.6 + 319743.3 = 320069.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01.shape at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 145.7 + 5729.1 = 5874.8
DL input+output M: L = 215.9 + 5729.1 = 5945.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (24,24) and color yellow and layers
  _0: rectangle with size (24,24) with mask 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 
0 0 0 0 0 . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (7,7) with model Border with color green at (5,5)
  + 266 delta pixels
diff: 
   (0.0 bits)
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (5,5) with mask 
. 0 . . . 
0 0 0 0 0 
. 0 . . . 
. 0 . . . 
. 0 . . . 
 with color yellow at (1,1)
  _010: 
3 3 3 3 3 3 3 
3 . . . . . 3 
3 . . . . . 3 
3 . . . . . 3 
3 . . . . . 3 
3 . . . . . 3 
3 3 3 3 3 3 3 
 at (0,0)
  _01: rectangle with size (5,1) with model Full with color red at (1,3)
  _011: rectangle with size (1,5) with model Full with color red at (3,1)
  _0111: rectangle with size (5,1) with model Full with color cyan at (1,4)
  + 2 delta pixels
diff: 
   (258.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (24,24) and color yellow and layers
  _0: rectangle with size (24,24) with mask 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 
0 0 0 0 0 . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (7,7) with model Border with color green at (5,5)
  + 266 delta pixels
diff: 
! size mismatch, 10x10 instead of 7x7
>> Trial 2
data: a background with size (24,24) and color yellow and layers
  _0: rectangle with size (7,7) with model Border with color green at (5,5)
  _01: rectangle with size (24,24) with mask 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 
0 0 0 0 0 . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color grey at (0,0)
  + 266 delta pixels
diff: 
! size mismatch, 10x10 instead of 7x7

TRAIN c909285e.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (26,26) and color black and layers
  _0: rectangle with size (26,26) with mask 
. . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . . . . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . . . . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color cyan at (0,0)
  _01: rectangle with size (7,7) with model Border with color red at (2,2)
  + 220 delta pixels
diff: 
   (0.0 bits)
data: a background with size (7,7) and color green and layers
  _0: rectangle with size (5,5) with model +-cross with color cyan at (1,1)
  _010: 
2 2 2 2 2 2 2 
2 . . . . . 2 
2 . . . . . 2 
2 . . . . . 2 
2 . . . . . 2 
2 . . . . . 2 
2 2 2 2 2 2 2 
 at (0,0)
  _01: rectangle with size (1,3) with model Full with color blue at (2,2)
  _011: rectangle with size (1,1) with model Full with color blue at (4,2)
  _0111: rectangle with size (1,1) with model Full with color black at (4,4)
diff: 
   (155.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (26,26) and color black and layers
  _0: rectangle with size (26,26) with mask 
. . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . . . . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . . . . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color cyan at (0,0)
  _01: rectangle with size (7,7) with model Border with color red at (2,2)
  + 220 delta pixels
diff: 
! size mismatch, 10x10 instead of 7x7
>> Trial 2
data: a background with size (26,26) and color black and layers
  _0: rectangle with size (26,26) with mask 
. . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . . . . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . . . . . . . . . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
. . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 0 . . 
 with color cyan at (0,0)
  _01: rectangle with size (26,1) with model Full with color green at (0,3)
  + 226 delta pixels
diff: 
! size mismatch, 10x10 instead of 7x7

TRAIN c909285e.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (28,28) and color green and layers
  _0: rectangle with size (28,28) with mask 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
0 0 0 0 0 . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
 with color grey at (0,0)
  _01: rectangle with size (7,7) with model Border with color pink at (17,5)
  + 370 delta pixels
diff: 
   (0.0 bits)
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (5,5) with model +-cross with color green at (1,1)
  _010: 
6 6 6 6 6 6 6 
6 . . . . . 6 
6 . . . . . 6 
6 . . . . . 6 
6 . . . . . 6 
6 . . . . . 6 
6 6 6 6 6 6 6 
 at (0,0)
  _01: rectangle with size (5,1) with model Full with color cyan at (1,4)
  _011: rectangle with size (1,5) with model Full with color cyan at (2,1)
  _0111: rectangle with size (5,1) with model Full with color blue at (1,2)
diff: 
   (159.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (28,28) and color green and layers
  _0: rectangle with size (28,28) with mask 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
0 0 0 0 0 . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
 with color grey at (0,0)
  _01: rectangle with size (7,7) with model Border with color pink at (17,5)
  + 370 delta pixels
diff: 
! size mismatch, 10x10 instead of 7x7
>> Trial 2
data: a background with size (28,28) and color green and layers
  _0: rectangle with size (7,7) with model Border with color pink at (17,5)
  _01: rectangle with size (28,28) with mask 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
0 0 0 0 0 . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
 with color grey at (0,0)
  + 370 delta pixels
diff: 
! size mismatch, 10x10 instead of 7x7
>> Trial 3
data: a background with size (28,28) and color green and layers
  _0: rectangle with size (28,28) with mask 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
0 0 0 0 0 . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
. . . . . . . . . . . 0 . . . . . 0 . . . . . 0 . . . . 
 with color grey at (0,0)
  _01: rectangle with size (2,26) with model Full with color black at (0,0)
  + 380 delta pixels
diff: 
! size mismatch, 10x10 instead of 7x7

TRAIN c909285e.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (24,24) and color black and layers
  _0: rectangle with size (24,24) with mask 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . . . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . . . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . . . . . 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . . . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . . . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color yellow at (0,0)
  _01: rectangle with size (23,1) with model Full with color green at (0,4)
  + 291 delta pixels
diff: 
! size mismatch, 10x10 instead of 6x6
>> Trial 2
data: a background with size (24,24) and color black and layers
  _0: rectangle with size (24,24) with mask 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . . . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . . . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . . . . . 0 0 0 0 
. . . . . 0 . . . . . 0 . . . . . . . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . . . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
. . . . . 0 . . . . . 0 . . . . . 0 . . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color yellow at (0,0)
  _01: rectangle with size (1,23) with model Full with color green at (4,0)
  + 291 delta pixels
diff: 
! size mismatch, 10x10 instead of 6x6

TEST c909285e.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 60.1 sec (60.1 sec/task)
bits-train-error = 5729.1 bits (5729.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-90] Checking task c9e6f938.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 10534.8 = 10537.1
DL output with Mo: L = 2.3 + 20923.3 = 20925.6
DL input+output M: L = 4.6 + 31458.1 = 31462.7

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = unfoldSym( [ id flipWidth ], ^)
0.295	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.125	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.109	IN  SPE ^.layer_0.shape.color = orange
0.102	IN  SPE ^.color = black
0.005	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
unfoldSym( [ id flipWidth ], ^)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color orange at (?,?)

DL input  with Mi: L = 45.4 + 1023.6 = 1069.0
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 56.7 + 1023.6 = 1080.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
unfoldSym( [ id flipWidth ], ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 11.3 + 0.0 = 11.3
DL input+output M: L = 13.6 + 0.0 = 13.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 7#0 
0 0 7#
0 7#7#

diff: 
   (0.0 bits)
data: 
0 7#0 0 7#0 
0 0 7#7#0 0 
0 7#7#7#7#0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 7#0 
0 0 7#
0 7#7#

diff: 
correct output grid

TRAIN c9e6f938.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 0 0 
0 7#7#
0 0 0 

diff: 
   (0.0 bits)
data: 
0 0 0 0 0 0 
0 7#7#7#7#0 
0 0 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 
0 7#7#
0 0 0 

diff: 
correct output grid

TRAIN c9e6f938.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 0 0 
7#0 0 
0 0 0 

diff: 
   (0.0 bits)
data: 
0 0 0 0 0 0 
7#0 0 0 0 7#
0 0 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 
7#0 0 
0 0 0 

diff: 
correct output grid

TRAIN c9e6f938.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
7#7#0 
0 7#0 
0 0 7#

diff: 
correct output grid

TEST c9e6f938.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 0.9 sec (0.9 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-89] Checking task c9f8e694.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 116186.7 = 116189.0
DL output with Mo: L = 2.3 + 116186.7 = 116189.0
DL input+output M: L = 4.6 + 232373.4 = 232378.1

# learning a model for train pairs
2.000	
1.413	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.878	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.679	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.539	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.449	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.365	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.313	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.267	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.221	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.185	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.159	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.145	OUT ADD ^.layer_010 = ^.layer_011
0.140	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.136	OUT SPE ^.size = ^.size
0.078	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_011
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 6821.6 = 6947.4
DL output with Mo: L = 192.1 + 8684.7 = 8876.8
DL input+output M: L = 317.9 + 15506.2 = 15824.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_011
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 51.7 = 177.5
DL output with Mo: L = 192.1 + 8684.7 = 8876.8
DL input+output M: L = 317.9 + 8736.4 = 9054.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (7,2) with model Full with color grey at (1,2)
  _01: rectangle with size (7,2) with model Full with color grey at (5,8)
  _011: rectangle with size (10,1) with model Full with color blue at (1,0)
  _0111: rectangle with size (3,3) with model Full with color grey at (9,4)
  + 4 delta pixels
diff: 
   (2.0 bits)
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (5,2) with model Full with color blue at (1,2)
  _010: 
1 
1 
1 
1 
1 
1 
1 
1 
1 
1 
 at (1,0)
  _01: rectangle with size (3,2) with model Full with color blue at (8,8)
  _011: rectangle with size (6,2) with model Full with color red at (6,8)
  _0111: rectangle with size (2,3) with model Full with color blue at (9,4)
  _01111: rectangle with size (2,2) with model Full with color red at (6,2)
  _011111: rectangle with size (1,3) with model Full with color red at (11,4)
  + 8 delta pixels
diff: 
   (522.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (7,2) with model Full with color grey at (1,2)
  _01: rectangle with size (7,2) with model Full with color grey at (5,8)
  _011: rectangle with size (3,3) with model Full with color grey at (9,4)
  _0111: rectangle with size (10,1) with model Full with color blue at (1,0)
  + 4 delta pixels
diff: 
! 51 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (7,2) with model Full with color grey at (1,2)
  _01: rectangle with size (7,2) with model Full with color grey at (5,8)
  _011: rectangle with size (10,1) with model Full with color blue at (1,0)
  _0111: rectangle with size (3,3) with model Full with color grey at (9,4)
  + 4 delta pixels
diff: 
! 45 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (7,2) with model Full with color grey at (1,2)
  _01: rectangle with size (3,3) with model Full with color grey at (9,4)
  _011: rectangle with size (7,2) with model Full with color grey at (5,8)
  _0111: rectangle with size (10,1) with model Full with color blue at (1,0)
  + 4 delta pixels
diff: 
! 51 wrong pixels (generated / expected)

TRAIN c9f8e694.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (10,8) with mask 
. . . 0 0 0 0 0 
. . . 0 0 0 0 0 
. . . 0 0 0 0 0 
. . . 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 . . . . . 
0 0 0 . . . . . 
 with color grey at (2,4)
  _01: rectangle with size (9,1) with model Full with color green at (1,0)
  _011: rectangle with size (2,1) with model Full with color yellow at (10,0)
  _0111: rectangle with size (4,4) with model Full with color grey at (1,1)
  + 3 delta pixels
diff: 
   (3.2 bits)
data: a background with size (12,12) and color green and layers
  _0: rectangle with size (12,12) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 
. . . . . 0 0 0 0 0 0 0 
. . . . . 0 0 . . . . . 
. . . . . 0 0 . . . . . 
. . . . . 0 0 . . . . . 
. 0 0 0 0 0 0 . . . . . 
. 0 0 0 . . . . . . . . 
. 0 0 0 . . . . . . . . 
. 0 0 0 . . . . . . . . 
. 0 0 0 . . . . . . . . 
. 0 0 0 . . . . . . . . 
. 0 0 0 . . . . . . . . 
 with color black at (0,0)
  _010: 
4 
4 
 at (10,0)
  _01: rectangle with size (2,12) with model Full with color yellow at (3,0)
  _011: rectangle with size (2,5) with model Full with color black at (10,7)
  _0111: rectangle with size (1,8) with model Full with color yellow at (6,4)
  _01111: rectangle with size (2,3) with model Full with color yellow at (10,4)
  _011111: rectangle with size (1,1) with model Full with color yellow at (6,0)
diff: 
   (346.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (10,8) with mask 
. . . 0 0 0 0 0 
. . . 0 0 0 0 0 
. . . 0 0 0 0 0 
. . . 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 . . . . . 
0 0 0 . . . . . 
 with color grey at (2,4)
  _01: rectangle with size (4,4) with model Full with color grey at (1,1)
  _011: rectangle with size (9,1) with model Full with color green at (1,0)
  _0111: rectangle with size (2,1) with model Full with color yellow at (10,0)
  + 3 delta pixels
diff: 
! 82 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (10,8) with mask 
. . . 0 0 0 0 0 
. . . 0 0 0 0 0 
. . . 0 0 0 0 0 
. . . 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 . . . . . 
0 0 0 . . . . . 
 with color grey at (2,4)
  _01: rectangle with size (9,1) with model Full with color green at (1,0)
  _011: rectangle with size (4,4) with model Full with color grey at (1,1)
  _0111: rectangle with size (2,1) with model Full with color yellow at (10,0)
  + 3 delta pixels
diff: 
! 87 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (10,8) with mask 
. . . 0 0 0 0 0 
. . . 0 0 0 0 0 
. . . 0 0 0 0 0 
. . . 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 . . . . . 
0 0 0 . . . . . 
 with color grey at (2,4)
  _01: rectangle with size (9,1) with model Full with color green at (1,0)
  _011: rectangle with size (2,1) with model Full with color yellow at (10,0)
  _0111: rectangle with size (4,4) with model Full with color grey at (1,1)
  + 3 delta pixels
diff: 
! 85 wrong pixels (generated / expected)

TRAIN c9f8e694.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (12,10) with mask 
0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 . 0 0 0 
0 0 0 0 0 0 . 0 0 0 
0 0 0 0 0 0 . 0 0 0 
. . . . 0 0 0 0 0 0 
. . . . 0 0 0 . . . 
. . . . 0 0 0 . . . 
. . . . 0 0 0 . . . 
. . . . 0 0 0 . . . 
. . . . 0 0 0 . . . 
 with color grey at (0,2)
  _01: rectangle with size (3,3) with model Full with color grey at (9,2)
  _011: rectangle with size (4,1) with model Full with color orange at (4,0)
  _0111: rectangle with size (11,1) with model Full with color cyan at (1,0)
  + 3 delta pixels
diff: 
! 85 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (12,10) with mask 
0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 . 0 0 0 
0 0 0 0 0 0 . 0 0 0 
0 0 0 0 0 0 . 0 0 0 
. . . . 0 0 0 0 0 0 
. . . . 0 0 0 . . . 
. . . . 0 0 0 . . . 
. . . . 0 0 0 . . . 
. . . . 0 0 0 . . . 
. . . . 0 0 0 . . . 
 with color grey at (0,2)
  _01: rectangle with size (4,1) with model Full with color orange at (4,0)
  _011: rectangle with size (3,3) with model Full with color grey at (9,2)
  _0111: rectangle with size (11,1) with model Full with color cyan at (1,0)
  + 3 delta pixels
diff: 
! 89 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (12,10) with mask 
0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 . . . . 
0 0 0 0 0 0 . 0 0 0 
0 0 0 0 0 0 . 0 0 0 
0 0 0 0 0 0 . 0 0 0 
. . . . 0 0 0 0 0 0 
. . . . 0 0 0 . . . 
. . . . 0 0 0 . . . 
. . . . 0 0 0 . . . 
. . . . 0 0 0 . . . 
. . . . 0 0 0 . . . 
 with color grey at (0,2)
  _01: rectangle with size (4,1) with model Full with color orange at (4,0)
  _011: rectangle with size (11,1) with model Full with color cyan at (1,0)
  _0111: rectangle with size (3,3) with model Full with color grey at (9,2)
  + 3 delta pixels
diff: 
! 85 wrong pixels (generated / expected)

TEST c9f8e694.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.6 sec (59.6 sec/task)
bits-train-error = 8684.7 bits (8684.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-88] Checking task caa06a1f.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 87870.6 = 87872.9
DL output with Mo: L = 2.3 + 87870.6 = 87872.9
DL input+output M: L = 4.6 + 175741.2 = 175745.9

# learning a model for train pairs
2.000	
1.504	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.011	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.531	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.273	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.070	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.062	OUT SPE ^.layer_0.shape.mask = fillResizeAlike(transparent, ^.size, ^.layer_0.shape.mask)
0.055	OUT SPE ^.size = ^.size
0.052	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.049	OUT SPE ^.color = ^.layer_0.shape.color
0.046	IN  SPE ^.layer_0.shape.mask.model = Odd Checkboard
0.003	
0.003	IN  DEL ^.layer_01

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.layer_0.shape.color and layers
  _0: fillResizeAlike(transparent, ^.size, ^.layer_0.shape.mask) with color ? at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model Odd Checkboard with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 74.5 + 3773.4 = 3847.9
DL output with Mo: L = 56.0 + 168.9 = 224.9
DL input+output M: L = 130.5 + 3942.3 = 4072.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.layer_0.shape.color and layers
  _0: fillResizeAlike(transparent, ^.size, ^.layer_0.shape.mask) with color ? at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model Odd Checkboard with color ? at (?,?)

DL input  with Mi: L = 46.3 + 0.0 = 46.3
DL output with Mo: L = 56.0 + 168.9 = 224.9
DL input+output M: L = 102.3 + 168.9 = 271.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (11,11) and color green and layers
  _0: rectangle with size (7,7) with model Odd Checkboard with color orange at (0,0)
  + 25 delta pixels
diff: 
   (0.0 bits)
data: a background with size (11,11) and color orange and layers
  _0: 
. 0 . 0 . 0 . 0 . 0 . 
0 . 0 . 0 . 0 . 0 . 0 
. 0 . 0 . 0 . 0 . 0 . 
0 . 0 . 0 . 0 . 0 . 0 
. 0 . 0 . 0 . 0 . 0 . 
0 . 0 . 0 . 0 . 0 . 0 
. 0 . 0 . 0 . 0 . 0 . 
0 . 0 . 0 . 0 . 0 . 0 
. 0 . 0 . 0 . 0 . 0 . 
0 . 0 . 0 . 0 . 0 . 0 
. 0 . 0 . 0 . 0 . 0 . 
 with color pink at (0,0)
diff: 
   (5.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color green and layers
  _0: rectangle with size (7,7) with model Full with color pink at (0,0)
  + 24 delta pixels
diff:   ^.layer_0.shape.mask.model
! 121 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,11) and color green and layers
  _0: rectangle with size (7,7) with model Even Checkboard with color pink at (0,0)
  + 24 delta pixels
diff:   ^.layer_0.shape.mask.model
! 61 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (11,11) and color green and layers
  _0: rectangle with size (7,7) with model Odd Checkboard with color orange at (0,0)
  + 25 delta pixels
diff: 
! 60 wrong pixels (generated / expected)

TRAIN caa06a1f.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (8,8) and color pink and layers
  _0: rectangle with size (7,7) with model Odd Checkboard with color green at (0,0)
  + 15 delta pixels
diff: 
   (0.0 bits)
data: a background with size (8,8) and color green and layers
  _0: 
. 0 . 0 . 0 . 0 
0 . 0 . 0 . 0 . 
. 0 . 0 . 0 . 0 
0 . 0 . 0 . 0 . 
. 0 . 0 . 0 . 0 
0 . 0 . 0 . 0 . 
. 0 . 0 . 0 . 0 
0 . 0 . 0 . 0 . 
 with color pink at (0,0)
diff: 
   (5.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color pink and layers
  _0: rectangle with size (7,7) with model Odd Checkboard with color green at (0,0)
  + 15 delta pixels
diff: 
! 32 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color green and layers
  _0: rectangle with size (7,7) with model Even Checkboard with color pink at (0,0)
  + 15 delta pixels
diff:   ^.layer_0.shape.mask.model
! 32 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (8,8) and color pink and layers
  _0: rectangle with size (8,1) with model Full with color blue at (0,7)
  + 31 delta pixels
diff:   ^.layer_0.shape.mask.model
! 64 wrong pixels (generated / expected)

TRAIN caa06a1f.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (6,6) and color grey and layers
  _0: rectangle with size (5,5) with model Odd Checkboard with color yellow at (0,0)
  + 11 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,6) and color yellow and layers
  _0: 
. 0 . 0 . 0 
0 . 0 . 0 . 
. 0 . 0 . 0 
0 . 0 . 0 . 
. 0 . 0 . 0 
0 . 0 . 0 . 
 with color grey at (0,0)
diff: 
   (5.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color grey and layers
  _0: rectangle with size (5,5) with model Odd Checkboard with color yellow at (0,0)
  + 11 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,6) and color yellow and layers
  _0: rectangle with size (5,5) with model Even Checkboard with color grey at (0,0)
  + 11 delta pixels
diff:   ^.layer_0.shape.mask.model
! 18 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (6,6) and color grey and layers
  _0: rectangle with size (6,1) with model Full with color pink at (0,5)
  + 17 delta pixels
diff:   ^.layer_0.shape.mask.model
! 36 wrong pixels (generated / expected)

TRAIN caa06a1f.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,18) and color green and layers
  _0: rectangle with size (12,2) with model Odd Checkboard with color grey at (0,0)
  + 132 delta pixels
diff: 
! 270 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (18,18) and color green and layers
  _0: rectangle with size (12,2) with model Odd Checkboard with color orange at (0,1)
  + 132 delta pixels
diff: 
! 270 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (18,18) and color green and layers
  _0: rectangle with size (12,2) with model Odd Checkboard with color cyan at (0,2)
  + 132 delta pixels
diff: 
! 270 wrong pixels (generated / expected)

TEST caa06a1f.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 4.9 sec (4.9 sec/task)
bits-train-error = 168.9 bits (168.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-87] Checking task cbded52d.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 75779.3 = 75781.7
DL output with Mo: L = 2.3 + 75779.3 = 75781.7
DL input+output M: L = 4.6 + 151558.7 = 151563.3

# learning a model for train pairs
2.000	
1.508	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.049	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.657	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.226	OUT ADD ^.layer_0 = ^.layer_0
0.193	IN  SPE ^.layer_0.shape.mask = 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 

0.184	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.169	OUT ADD ^.layer_01 = ^.layer_01
0.157	OUT ADD ^.layer_011 = ^.layer_01.shape at (?,?)
0.146	OUT ADD ^.layer_010 = ^.layer_01.shape at (?,?)
0.137	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.130	OUT SPE ^.size = ^.size
0.126	OUT SPE ^.layer_010.pos = ^.layer_01.pos + (0, 3)
0.122	OUT SPE ^.color = ^.color
0.119	IN  SPE ^.color = blue
0.117	IN  SPE ^.layer_0.shape.color = black
0.115	OUT SPE ^.layer_011.pos.i = ^.layer_01.pos.i
0.058	
0.057	IN  GEN ^.layer_0.shape.mask = rectangle with size (?,?) with model ?
0.057	IN  DEL ^.layer_011
0.057	IN  GEN ^.color = ?
0.057	IN  GEN ^.layer_0.shape.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.color and layers
  _0: ^.layer_0
  _010: ^.layer_01.shape at ^.layer_01.pos + (0, 3)
  _01: ^.layer_01
  _011: ^.layer_01.shape at (^.layer_01.pos.i,?)
WHERE (Mi)
a background with size (?,?) and color blue and layers
  _0: 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 with color black at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 158.4 + 4299.4 = 4457.8
DL output with Mo: L = 86.1 + 4150.8 = 4237.0
DL input+output M: L = 244.5 + 8450.3 = 8694.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.color and layers
  _0: ^.layer_0
  _010: ^.layer_01.shape at ^.layer_01.pos + (0, 3)
  _01: ^.layer_01
  _011: ^.layer_01.shape at (^.layer_01.pos.i,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 60.4 + 20.0 = 80.4
DL output with Mo: L = 86.1 + 4150.8 = 4237.0
DL input+output M: L = 146.6 + 4170.8 = 4317.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (8,8) and color blue and layers
  _0: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 with color black at (0,0)
  _01: point with color yellow at (0,1)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (8,8) and color blue and layers
  _0: 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 at (0,0)
  _010: 
4 
 at (0,4)
  _01: 
4 
 at (0,1)
  _011: 
4 
 at (0,7)
  + 5 delta pixels
diff: 
   (204.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color blue and layers
  _0: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 with color black at (0,0)
  _01: point with color yellow at (0,1)
  + 4 delta pixels
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color blue and layers
  _0: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 with color black at (0,0)
  _01: point with color yellow at (0,7)
  + 4 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (8,8) and color blue and layers
  _0: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 with color black at (0,0)
  _01: point with color red at (4,0)
  + 4 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TRAIN cbded52d.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (8,8) and color blue and layers
  _0: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 with color black at (0,0)
  _01: point with color green at (1,1)
  + 4 delta pixels
diff: 
   (2.0 bits)
data: a background with size (8,8) and color blue and layers
  _0: 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 at (0,0)
  _010: 
3 
 at (1,4)
  _01: 
3 
 at (1,1)
  _011: 
3 
 at (1,7)
  + 5 delta pixels
diff: 
   (204.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color blue and layers
  _0: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 with color black at (0,0)
  _01: point with color orange at (0,3)
  + 4 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color blue and layers
  _0: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 with color black at (0,0)
  _01: point with color green at (1,1)
  + 4 delta pixels
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (8,8) and color blue and layers
  _0: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 with color black at (0,0)
  _01: point with color green at (1,7)
  + 4 delta pixels
diff: 
! 8 wrong pixels (generated / expected)

TRAIN cbded52d.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (8,8) and color blue and layers
  _0: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 with color black at (0,0)
  _01: point with color green at (4,0)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (8,8) and color blue and layers
  _0: 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 at (0,0)
  _010: 
3 
 at (4,3)
  _01: 
3 
 at (4,0)
  _011: 
3 
 at (4,6)
diff: 
   (5.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color blue and layers
  _0: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 with color black at (0,0)
  _01: point with color green at (4,0)
  + 1 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color blue and layers
  _0: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 with color black at (0,0)
  _01: point with color green at (4,6)
  + 1 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (8,8) and color blue and layers
  _0: rectangle with size (8,1) with model Full with color black at (0,2)
  _01: point with color green at (4,0)
  + 21 delta pixels
diff: 
! 21 wrong pixels (generated / expected)

TRAIN cbded52d.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color blue and layers
  _0: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 with color black at (0,0)
  _01: point with color cyan at (1,1)
  + 4 delta pixels
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color blue and layers
  _0: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 with color black at (0,0)
  _01: point with color cyan at (1,7)
  + 4 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (8,8) and color blue and layers
  _0: rectangle with size (8,8) with mask 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
0 0 0 0 0 0 0 0 
. . 0 . . 0 . . 
. . 0 . . 0 . . 
 with color black at (0,0)
  _01: point with color pink at (6,0)
  + 4 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TEST cbded52d.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 7.1 sec (7.1 sec/task)
bits-train-error = 4150.8 bits (4150.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-86] Checking task cce03e0d.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 10534.8 = 10537.1
DL output with Mo: L = 2.3 + 96473.4 = 96475.7
DL input+output M: L = 4.6 + 107008.2 = 107012.9

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = compose(red, ^, ^)
0.545	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.326	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.258	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.242	IN  SPE ^.layer_0.shape.color = blue
0.227	IN  SPE ^.layer_01.shape.color = red
0.220	IN  SPE ^.color = black
0.007	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
compose(red, ^, ^)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color blue at (?,?)
  _01: rectangle with size (?,?) with model ? with color red at (?,?)

DL input  with Mi: L = 77.0 + 2236.8 = 2313.8
DL output with Mo: L = 17.7 + 0.0 = 17.7
DL input+output M: L = 94.7 + 2236.8 = 2331.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
compose(red, ^, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 17.7 + 0.0 = 17.7
DL input+output M: L = 20.0 + 0.0 = 20.0

# train input/output grids

## instance 1

> Input and output best reading:

data: 
1 0 0 
2 1 0 
0 0 1 

diff: 
   (0.0 bits)
data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
1 0 0 0 0 0 0 0 0 
2 1 0 0 0 0 0 0 0 
0 0 1 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 0 0 
2 1 0 
0 0 1 

diff: 
correct output grid

TRAIN cce03e0d.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 1 2 
1 1 0 
2 0 0 

diff: 
   (0.0 bits)
data: 
0 0 0 0 0 0 0 1 2 
0 0 0 0 0 0 1 1 0 
0 0 0 0 0 0 2 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 1 2 0 0 0 0 0 0 
1 1 0 0 0 0 0 0 0 
2 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 1 2 
1 1 0 
2 0 0 

diff: 
correct output grid

TRAIN cce03e0d.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
2 1 2 
0 2 1 
2 1 0 

diff: 
   (0.0 bits)
data: 
2 1 2 0 0 0 2 1 2 
0 2 1 0 0 0 0 2 1 
2 1 0 0 0 0 2 1 0 
0 0 0 2 1 2 0 0 0 
0 0 0 0 2 1 0 0 0 
0 0 0 2 1 0 0 0 0 
2 1 2 0 0 0 0 0 0 
0 2 1 0 0 0 0 0 0 
2 1 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 1 2 
0 2 1 
2 1 0 

diff: 
correct output grid

TRAIN cce03e0d.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 2 2 
2 0 1 
1 2 0 

diff: 
correct output grid

TEST cce03e0d.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.1 sec (1.1 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-85] Checking task cdecee7f.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 10534.8 = 10537.1
DL input+output M: L = 4.6 + 130310.7 = 130315.3

# learning a model for train pairs
2.000	
1.080	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.832	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.764	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.700	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.635	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.570	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.505	OUT ADD ^.layer_01111 = point with color ? at (?,?)
0.437	OUT ADD ^.layer_011111 = point with color ? at (?,?)
0.401	OUT SPE ^.size = '(3, 3)
0.379	OUT SPE ^.layer_01111.pos = '(1, 1)
0.357	OUT SPE ^.layer_01.pos = '(0, 1)
0.336	OUT SPE ^.layer_011.pos = '(0, 2)
0.325	OUT SPE ^.layer_0111.pos.j = '0
0.314	OUT SPE ^.layer_011111.pos.j = '0
0.303	OUT SPE ^.layer_0111.pos = '(0, 0)
0.281	OUT SPE ^.layer_0.pos = '(1, 2)
0.272	OUT SPE ^.layer_0.shape.mask.size.j = 1
0.264	OUT SPE ^.layer_0.shape.mask.model = Full
0.258	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.249	OUT SPE ^.layer_011111.pos.i = ^.layer_0.pos.j
0.243	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.237	OUT SPE ^.layer_0.shape.mask.size.i = area(^.layer_0.shape.mask) - ^.layer_01.pos.i - ^.layer_0.pos.i
0.236	IN  SPE ^.color = black
0.169	
0.169	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color ? and layers
  _0: rectangle with size (area(^.layer_0.shape.mask) - ^.layer_01.pos.i - ^.layer_0.pos.i,1) with model Full with color ? at '(1, 2)
  _01: point with color ? at '(0, 1)
  _011: point with color ? at '(0, 2)
  _0111: point with color ? at '(0, 0)
  _01111: point with color ? at '(1, 1)
  _011111: point with color ? at (^.layer_0.pos.j,'0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.7 + 8126.3 = 8177.0
DL output with Mo: L = 237.9 + 1532.6 = 1770.5
DL input+output M: L = 288.7 + 9658.9 = 9947.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color ? and layers
  _0: rectangle with size (area(^.layer_0.shape.mask) - ^.layer_01.pos.i - ^.layer_0.pos.i,1) with model Full with color ? at '(1, 2)
  _01: point with color ? at '(0, 1)
  _011: point with color ? at '(0, 2)
  _0111: point with color ? at '(0, 0)
  _01111: point with color ? at '(1, 1)
  _011111: point with color ? at (^.layer_0.pos.j,'0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.6 + 31.7 = 82.3
DL output with Mo: L = 237.9 + 1532.6 = 1770.5
DL input+output M: L = 288.5 + 1564.3 = 1852.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color blue at (2,1)
  _01: point with color pink at (2,4)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color pink at (1,2)
  _01: point with color blue at (0,1)
  _011: point with color cyan at (0,2)
  _0111: point with color green at (0,0)
  _01111: point with color orange at (1,1)
  _011111: point with color brown at (1,0)
diff: 
   (36.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (2,1)
  _01: point with color pink at (2,4)
  + 4 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color pink at (2,4)
  _01: point with color blue at (2,1)
  + 4 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TRAIN cdecee7f.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (1,2)
  _01: point with color red at (1,9)
  + 5 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color pink at (1,2)
  _01: point with color green at (0,1)
  _011: point with color yellow at (0,2)
  _0111: point with color brown at (0,0)
  _01111: point with color cyan at (1,1)
  _011111: point with color red at (2,0)
  + 1 delta pixels
diff: 
   (74.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color yellow at (1,2)
  _01: point with color red at (1,9)
  + 5 delta pixels
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color red at (1,9)
  _01: point with color yellow at (1,2)
  + 5 delta pixels
diff: 
! 7 wrong pixels (generated / expected)

TRAIN cdecee7f.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color grey at (1,2)
  _01: point with color green at (0,9)
  + 7 delta pixels
diff: 
   (3.2 bits)
data: a background with size (3,3) and color blue and layers
  _0: rectangle with size (2,1) with model Full with color green at (1,2)
  _01: point with color yellow at (0,1)
  _011: point with color grey at (0,2)
  _0111: point with color red at (0,0)
  _01111: point with color brown at (1,1)
  _011111: point with color grey at (2,0)
diff: 
   (42.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color grey at (1,2)
  _01: point with color green at (0,9)
  + 7 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN cdecee7f.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color grey at (1,4)
  _01: point with color brown at (1,6)
  + 7 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TEST cdecee7f.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 32.5 sec (32.5 sec/task)
bits-train-error = 1532.6 bits (1532.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-84] Checking task ce22a75a.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 64315.6 = 64317.9
DL output with Mo: L = 2.3 + 64315.6 = 64317.9
DL input+output M: L = 4.6 + 128631.2 = 128635.9

# learning a model for train pairs
2.000	
1.051	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.445	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.090	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.083	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.076	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.068	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.062	OUT SPE ^.size = ^.size
0.059	OUT SPE ^.layer_0.pos = ^.layer_0.pos - (1, 1)
0.054	OUT SPE ^.layer_0.shape.mask.size = span(^.layer_0.pos, ^.layer_011.pos) + (2, 2)
0.053	IN  SPE ^.layer_0.shape.color = grey
0.051	IN  SPE ^.layer_01.shape.color = grey
0.049	IN  SPE ^.layer_011.shape.color = grey
0.048	OUT SPE ^.layer_0.shape.color = blue
0.047	IN  SPE ^.color = black
0.046	OUT SPE ^.color = black
0.023	
0.023	IN  GEN ^.layer_011.shape.color = ?
0.023	IN  GEN ^.layer_01.shape.color = ?
0.023	IN  GEN ^.layer_0.shape.color = ?
0.023	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size span(^.layer_0.pos, ^.layer_011.pos) + (2, 2) with model ? with color blue at ^.layer_0.pos - (1, 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color grey at (?,?)
  _01: point with color grey at (?,?)
  _011: point with color grey at (?,?)

DL input  with Mi: L = 78.8 + 1477.7 = 1556.4
DL output with Mo: L = 96.2 + 1306.8 = 1403.0
DL input+output M: L = 174.9 + 2784.5 = 2959.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size span(^.layer_0.pos, ^.layer_011.pos) + (2, 2) with model ? with color blue at ^.layer_0.pos - (1, 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 68.7 + 20.0 = 88.7
DL output with Mo: L = 96.2 + 1306.8 = 1403.0
DL input+output M: L = 164.9 + 1326.8 = 1491.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,1)
  _01: point with color grey at (4,4)
  _011: point with color grey at (7,7)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,9) with mask 
0 0 0 . . . . . . 
0 0 0 . . . . . . 
0 0 0 . . . . . . 
. . . 0 0 0 . . . 
. . . 0 0 0 . . . 
. . . 0 0 0 . . . 
. . . . . . 0 0 0 
. . . . . . 0 0 0 
. . . . . . 0 0 0 
 with color blue at (0,0)
diff: 
   (77.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,1)
  _01: point with color grey at (4,4)
  _011: point with color grey at (7,7)
diff: 
! 54 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,1)
  _01: point with color grey at (7,7)
  _011: point with color grey at (4,4)
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (4,4)
  _01: point with color grey at (1,1)
  _011: point with color grey at (7,7)
diff: 
! 27 wrong pixels (generated / expected)

TRAIN ce22a75a.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,4)
  _01: point with color grey at (4,4)
  _011: point with color grey at (7,7)
  + 1 delta pixels
diff: 
   (2.0 bits)
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (9,6) with mask 
0 0 0 . . . 
0 0 0 . . . 
0 0 0 . . . 
0 0 0 . . . 
0 0 0 . . . 
0 0 0 . . . 
0 0 0 0 0 0 
0 0 0 0 0 0 
0 0 0 0 0 0 
 with color blue at (0,3)
diff: 
   (52.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,4)
  _01: point with color grey at (4,4)
  _011: point with color grey at (7,4)
  + 1 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,4)
  _01: point with color grey at (4,4)
  _011: point with color grey at (7,7)
  + 1 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,4)
  _01: point with color grey at (7,4)
  _011: point with color grey at (4,4)
  + 1 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TRAIN ce22a75a.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,7)
  _01: point with color grey at (4,1)
  _011: point with color grey at (4,7)
  + 1 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: point with color grey at (1,7)
  _01: point with color grey at (4,1)
  _011: point with color grey at (7,1)
  + 1 delta pixels
diff: 
! 27 wrong pixels (generated / expected)

TEST ce22a75a.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 2.1 sec (2.1 sec/task)
bits-train-error = 1306.8 bits (1306.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-83] Checking task ce4f8723.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 56169.1 = 56171.4
DL output with Mo: L = 2.3 + 24798.7 = 24801.0
DL input+output M: L = 4.6 + 80967.8 = 80972.4

# learning a model for train pairs
2.000	
1.239	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.842	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.597	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.439	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.297	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.206	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.183	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.161	OUT SPE ^.layer_0.shape.mask.size = ^.layer_0.shape.mask.size
0.147	OUT SPE ^.layer_0.pos = '(0, 0)
0.137	IN  SPE ^.layer_011.shape.mask = 
0 0 0 0 

0.128	OUT SPE ^.layer_0.shape.color = green
0.124	OUT SPE ^.color = black
0.121	IN  SPE ^.layer_011.shape.color = yellow
0.119	IN  SPE ^.color = black
0.026	
0.026	IN  DEL ^.layer_011
0.025	IN  DEL ^.layer_01
0.025	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: rectangle with size ^.layer_0.shape.mask.size with model ? with color green at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: 
0 0 0 0 
 with color yellow at (?,?)

DL input  with Mi: L = 98.6 + 5204.5 = 5303.2
DL output with Mo: L = 51.9 + 552.3 = 604.2
DL input+output M: L = 150.6 + 5756.8 = 5907.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color black and layers
  _0: rectangle with size ^.layer_0.shape.mask.size with model ? with color green at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 51.9 + 552.3 = 604.2
DL input+output M: L = 93.9 + 552.3 = 646.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 0 
. . 0 0 
0 0 . . 
. . 0 0 
 with color red at (5,0)
  + 11 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 0 
. 0 0 0 
0 0 . . 
0 . 0 0 
 with color green at (0,0)
diff: 
   (15.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 0 
. . 0 0 
0 0 . . 
. . 0 0 
 with color red at (5,0)
  + 11 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 0 . 
. 0 . 
. 0 . 
0 . 0 
 with color blue at (0,0)
  + 15 delta pixels
diff: 
! size mismatch, 4x3 instead of 4x4
>> Trial 3
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (1,4) with model Full with color yellow at (4,0)
  + 17 delta pixels
diff: 
! size mismatch, 1x4 instead of 4x4

TRAIN ce4f8723.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 . 
. 0 . 0 
. . 0 0 
0 0 . 0 
 with color blue at (0,0)
  + 13 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 0 
. 0 . 0 
0 0 0 0 
0 0 . 0 
 with color green at (0,0)
diff: 
   (13.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 . 
. 0 . 0 
. . 0 0 
0 0 . 0 
 with color blue at (0,0)
  + 13 delta pixels
diff: 
! 3 wrong pixels (generated / expected)

TRAIN ce4f8723.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 . . 
0 . 0 . 
0 0 . 0 
0 0 0 0 
 with color blue at (0,0)
  + 11 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 . 0 
0 . 0 . 
0 0 . 0 
0 0 0 0 
 with color green at (0,0)
diff: 
   (15.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 . . 
0 . 0 . 
0 0 . 0 
0 0 0 0 
 with color blue at (0,0)
  + 11 delta pixels
diff: 
! 4 wrong pixels (generated / expected)

TRAIN ce4f8723.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . 0 . 
0 0 . 0 
0 . 0 0 
. 0 . 0 
 with color blue at (0,0)
  + 10 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 . 
0 0 0 0 
0 0 0 0 
. 0 0 0 
 with color green at (0,0)
diff: 
   (11.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . 0 . 
0 0 . 0 
0 . 0 0 
. 0 . 0 
 with color blue at (0,0)
  + 10 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 0 . 
. . 0 
0 0 . 
. . 0 
 with color red at (5,0)
  + 14 delta pixels
diff: 
! size mismatch, 4x3 instead of 4x4
>> Trial 3
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (1,4) with model Full with color yellow at (4,0)
  + 16 delta pixels
diff: 
! size mismatch, 1x4 instead of 4x4

TRAIN ce4f8723.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 . . 
. . 0 . 
. 0 . 0 
0 0 0 . 
 with color red at (5,0)
  + 11 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 . 0 
0 . 0 
. 0 . 
0 . 0 
 with color blue at (0,0)
  + 12 delta pixels
diff: 
! size mismatch, 4x3 instead of 4x4
>> Trial 3
data: a background with size (9,4) and color black and layers
  _0: rectangle with size (1,4) with model Full with color yellow at (4,0)
  + 15 delta pixels
diff: 
! size mismatch, 1x4 instead of 4x4

TEST ce4f8723.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 20.8 sec (20.8 sec/task)
bits-train-error = 552.3 bits (552.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-82] Checking task ce602527.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 491395.7 = 491398.0
DL output with Mo: L = 2.3 + 27144.7 = 27147.1
DL input+output M: L = 4.6 + 518540.4 = 518545.1

# learning a model for train pairs
2.000	
1.184	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.541	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.285	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.201	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.166	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.115	OUT SPE ^.layer_0.shape = ^.layer_01.shape
0.094	OUT SPE ^.size = ^.layer_01.shape.mask.size
0.081	OUT SPE ^.color = ^.color
0.068	OUT SPE ^.layer_0.pos = '(0, 0)
0.002	

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_01.shape.mask.size and color ^.color and layers
  _0: ^.layer_01.shape at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 32426.9 = 32497.1
DL output with Mo: L = 53.0 + 0.0 = 53.0
DL input+output M: L = 123.2 + 32426.9 = 32550.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_01.shape.mask.size and color ^.color and layers
  _0: ^.layer_01.shape at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 91.7 = 161.9
DL output with Mo: L = 53.0 + 0.0 = 53.0
DL input+output M: L = 123.2 + 91.7 = 214.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (17,17) and color blue and layers
  _0: rectangle with size (8,10) with mask 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 . . 0 0 . . 0 0 
0 0 . . 0 0 . . 0 0 
. . . . . . . . 0 0 
. . . . . . . . 0 0 
. . . . . . . . 0 0 
. . . . . . . . 0 0 
 with color cyan at (9,3)
  _01: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 . 0 . 0 
. . . . 0 
0 . 0 . 0 
0 0 0 0 0 
 with color red at (3,3)
  + 25 delta pixels
diff: 
   (2.0 bits)
data: a background with size (5,5) and color blue and layers
  _0: 
2 2 2 2 2 
2 . 2 . 2 
. . . . 2 
2 . 2 . 2 
2 2 2 2 2 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,17) and color blue and layers
  _0: rectangle with size (8,10) with mask 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 . . 0 0 . . 0 0 
0 0 . . 0 0 . . 0 0 
. . . . . . . . 0 0 
. . . . . . . . 0 0 
. . . . . . . . 0 0 
. . . . . . . . 0 0 
 with color cyan at (9,3)
  _01: rectangle with size (5,5) with mask 
0 0 . 0 0 
0 . . . 0 
0 0 0 0 0 
. . 0 . . 
0 0 0 0 0 
 with color green at (2,11)
  + 25 delta pixels
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,17) and color blue and layers
  _0: rectangle with size (8,10) with mask 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 . . 0 0 . . 0 0 
0 0 . . 0 0 . . 0 0 
. . . . . . . . 0 0 
. . . . . . . . 0 0 
. . . . . . . . 0 0 
. . . . . . . . 0 0 
 with color cyan at (9,3)
  _01: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 . 0 . 0 
. . . . 0 
0 . 0 . 0 
0 0 0 0 0 
 with color red at (3,3)
  + 25 delta pixels
diff: 
correct output grid

TRAIN ce602527.json/1: 1 2nd (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (18,18) and color cyan and layers
  _0: rectangle with size (8,5) with mask 
. 0 0 . . 
. 0 0 . . 
0 0 0 0 0 
0 0 0 0 0 
. 0 0 . . 
. 0 0 . . 
0 0 0 0 0 
0 0 0 0 0 
 with color pink at (10,0)
  _01: rectangle with size (5,3) with mask 
. 0 . 
0 0 0 
. 0 . 
0 0 0 
. 0 . 
 with color yellow at (8,11)
  + 9 delta pixels
diff: 
   (2.0 bits)
data: a background with size (5,3) and color cyan and layers
  _0: 
. 4 . 
4 4 4 
. 4 . 
4 4 4 
. 4 . 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,18) and color cyan and layers
  _0: rectangle with size (8,5) with mask 
. 0 0 . . 
. 0 0 . . 
0 0 0 0 0 
0 0 0 0 0 
. 0 0 . . 
. 0 0 . . 
0 0 0 0 0 
0 0 0 0 0 
 with color pink at (10,0)
  _01: rectangle with size (3,5) with mask 
. 0 . 0 . 
0 0 0 0 0 
. 0 . 0 . 
 with color green at (4,3)
  + 9 delta pixels
diff: 
! size mismatch, 3x5 instead of 5x3
>> Trial 2
data: a background with size (18,18) and color cyan and layers
  _0: rectangle with size (8,5) with mask 
. 0 0 . . 
. 0 0 . . 
0 0 0 0 0 
0 0 0 0 0 
. 0 0 . . 
. 0 0 . . 
0 0 0 0 0 
0 0 0 0 0 
 with color pink at (10,0)
  _01: rectangle with size (5,3) with mask 
. 0 . 
0 0 0 
. 0 . 
0 0 0 
. 0 . 
 with color yellow at (8,11)
  + 9 delta pixels
diff: 
correct output grid

TRAIN ce602527.json/2: 1 2nd (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (19,17) and color red and layers
  _0: rectangle with size (3,5) with mask 
0 . 0 . 0 
0 0 0 0 0 
. . 0 . . 
 with color green at (10,8)
  _01: rectangle with size (5,3) with mask 
0 0 0 
0 . . 
0 0 0 
. . 0 
0 0 0 
 with color cyan at (2,4)
  + 16 delta pixels
diff: 
   (2.0 bits)
data: a background with size (5,3) and color red and layers
  _0: 
8 8 8 
8 . . 
8 8 8 
. . 8 
8 8 8 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,17) and color red and layers
  _0: rectangle with size (5,3) with mask 
0 0 0 
0 . . 
0 0 0 
. . 0 
0 0 0 
 with color cyan at (2,4)
  _01: rectangle with size (3,5) with mask 
0 . 0 . 0 
0 0 0 0 0 
. . 0 . . 
 with color green at (10,8)
  + 16 delta pixels
diff: 
! size mismatch, 3x5 instead of 5x3
>> Trial 2
data: a background with size (19,17) and color red and layers
  _0: rectangle with size (3,5) with mask 
0 . 0 . 0 
0 0 0 0 0 
. . 0 . . 
 with color green at (10,8)
  _01: rectangle with size (5,3) with mask 
0 0 0 
0 . . 
0 0 0 
. . 0 
0 0 0 
 with color cyan at (2,4)
  + 16 delta pixels
diff: 
correct output grid

TRAIN ce602527.json/3: 1 2nd (SUCCESS)

## instance 4

> Input and output best reading:

data: a background with size (15,17) and color blue and layers
  _0: rectangle with size (6,7) with mask 
0 0 0 0 0 . . 
0 0 0 0 0 . . 
0 . . 0 0 0 0 
0 . . 0 0 0 0 
0 0 0 0 0 . . 
0 0 0 0 0 . . 
 with color red at (9,0)
  _01: rectangle with size (3,5) with mask 
. 0 0 0 . 
0 0 . 0 0 
. 0 0 0 . 
 with color green at (9,8)
  + 12 delta pixels
diff: 
   (3.2 bits)
data: a background with size (3,5) and color blue and layers
  _0: 
. 3 3 3 . 
3 3 . 3 3 
. 3 3 3 . 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,17) and color blue and layers
  _0: rectangle with size (6,7) with mask 
0 0 0 0 0 . . 
0 0 0 0 0 . . 
0 . . 0 0 0 0 
0 . . 0 0 0 0 
0 0 0 0 0 . . 
0 0 0 0 0 . . 
 with color red at (9,0)
  _01: rectangle with size (4,4) with mask 
0 . . 0 
0 0 0 0 
0 . . 0 
0 0 0 0 
 with color cyan at (2,5)
  + 10 delta pixels
diff: 
! size mismatch, 4x4 instead of 3x5
>> Trial 2
data: a background with size (15,17) and color blue and layers
  _0: rectangle with size (4,4) with mask 
0 . . 0 
0 0 0 0 
0 . . 0 
0 0 0 0 
 with color cyan at (2,5)
  _01: rectangle with size (6,7) with mask 
0 0 0 0 0 . . 
0 0 0 0 0 . . 
0 . . 0 0 0 0 
0 . . 0 0 0 0 
0 0 0 0 0 . . 
0 0 0 0 0 . . 
 with color red at (9,0)
  + 10 delta pixels
diff: 
! size mismatch, 6x7 instead of 3x5
>> Trial 3
data: a background with size (15,17) and color blue and layers
  _0: rectangle with size (6,7) with mask 
0 0 0 0 0 . . 
0 0 0 0 0 . . 
0 . . 0 0 0 0 
0 . . 0 0 0 0 
0 0 0 0 0 . . 
0 0 0 0 0 . . 
 with color red at (9,0)
  _01: rectangle with size (3,5) with mask 
. 0 0 0 . 
0 0 . 0 0 
. 0 0 0 . 
 with color green at (9,8)
  + 12 delta pixels
diff: 
correct output grid

TRAIN ce602527.json/4: 1 3rd (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,18) and color green and layers
  _0: rectangle with size (6,6) with model +-cross with color cyan at (12,6)
  _01: rectangle with size (3,4) with mask 
0 . 0 0 
0 0 . 0 
0 . 0 0 
 with color blue at (2,9)
  + 8 delta pixels
diff: 
! size mismatch, 3x4 instead of 4x3
>> Trial 2
data: a background with size (18,18) and color green and layers
  _0: rectangle with size (3,4) with mask 
0 . 0 0 
0 0 . 0 
0 . 0 0 
 with color blue at (2,9)
  _01: rectangle with size (6,6) with model +-cross with color cyan at (12,6)
  + 8 delta pixels
diff: 
! size mismatch, 6x6 instead of 4x3
>> Trial 3
data: a background with size (18,18) and color green and layers
  _0: rectangle with size (6,6) with model +-cross with color cyan at (12,6)
  _01: rectangle with size (4,3) with mask 
. 0 . 
0 0 0 
. 0 . 
0 0 0 
 with color pink at (5,2)
  + 9 delta pixels
diff: 
correct output grid

TEST ce602527.json/1: 1 3rd (SUCCESS)

# Performance measures on task
runtime-learning = 4.1 sec (4.1 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 0.46
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 0.33

=====================================
[-81] Checking task ce9e57f2.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 85512.7 = 85515.0
DL output with Mo: L = 2.3 + 85512.7 = 85515.0
DL input+output M: L = 4.6 + 171025.4 = 171030.0

# learning a model for train pairs
2.000	
1.289	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.579	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.494	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.422	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.373	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.333	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.298	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.266	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.224	OUT ADD ^.layer_011 = ^.layer_0111.shape at (?,?)
0.191	OUT ADD ^.layer_0111 = ^.layer_0111.shape at (?,?)
0.170	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.152	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.138	OUT ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.125	OUT ADD ^.layer_01111111 = point with color ? at (?,?)
0.115	OUT SPE ^.layer_01111 = applySym(flipDiag1, periodicFactor(transparent, ^.layer_0111))
0.109	OUT SPE ^.size = ^.size
0.104	OUT SPE ^.layer_01.shape.mask = 
0 
0 
0 

0.100	OUT SPE ^.layer_0111111.shape.mask = 
0 
0 

0.096	OUT SPE ^.layer_0111.pos = ^.layer_01.pos
0.094	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.092	IN  SPE ^.layer_0.shape.color = red
0.091	IN  SPE ^.layer_01.shape.color = red
0.089	IN  SPE ^.layer_011.shape.color = red
0.087	IN  SPE ^.layer_0111.shape.color = red
0.085	OUT SPE ^.layer_01.shape.color = cyan
0.083	OUT SPE ^.layer_011111.shape.color = cyan
0.080	OUT SPE ^.layer_011111.shape.mask.size = ^.layer_01.shape.mask.size - (3, 0)
0.078	OUT SPE ^.layer_0111111.shape.color = cyan
0.076	OUT SPE ^.layer_01111111.shape.color = cyan
0.074	OUT SPE ^.layer_01.pos.j = 1
0.072	OUT SPE ^.layer_01111111.pos.i = bottom(^.layer_0111)
0.069	OUT SPE ^.layer_011111.pos = max(^.layer_0.pos, ^.layer_01.pos) + (3, 0)
0.067	OUT SPE ^.layer_01.pos.i = bottom(^.layer_01) - 2
0.066	OUT SPE ^.layer_0111111.pos.i = bottom(^.layer_0111) - 1
0.064	OUT SPE ^.layer_0.shape.mask.size.j = 1
0.063	IN  SPE ^.layer_0.shape.mask.model = Full
0.062	IN  SPE ^.layer_01.shape.mask.model = Full
0.061	OUT SPE ^.layer_0111111.pos.j = span(^.layer_01.pos.j, ^.layer_0111.pos.j)
0.059	OUT SPE ^.layer_01111111.pos.j = span(^.layer_0.pos.j, ^.layer_0111.pos.j)
0.058	OUT SPE ^.layer_011.pos.i = span(^.layer_01.pos.j, ^.layer_011.pos.j) - 2
0.057	IN  SPE ^.layer_011.shape.mask.model = Full
0.056	IN  SPE ^.layer_0111.shape.mask.model = Full
0.055	OUT SPE ^.layer_0.shape.mask.model = Full
0.054	OUT SPE ^.layer_011111.shape.mask.model = Full
0.053	OUT SPE ^.layer_011.pos.j = max(^.layer_01.pos.j, ^.layer_0111.pos.j) - ^.layer_0111.pos.j - ^.layer_0.pos.j
0.052	OUT SPE ^.layer_0.pos.j = min(^.layer_01.pos.j, ^.layer_0111.pos.j) + ^.layer_011.pos.j - ^.layer_01.pos.j
0.051	IN  SPE ^.color = black
0.050	OUT SPE ^.color = black
0.013	
0.013	IN  GEN ^.layer_0111.shape.color = ?
0.012	IN  GEN ^.layer_011.shape.color = ?
0.012	IN  GEN ^.layer_01.shape.color = ?
0.012	IN  GEN ^.layer_0.shape.color = ?
0.012	IN  GEN ^.layer_0111.shape.mask.model = ?
0.012	IN  GEN ^.layer_011.shape.mask.model = ?
0.012	IN  GEN ^.layer_01.shape.mask.model = ?
0.012	IN  GEN ^.layer_0.shape.mask.model = ?
0.012	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,1) with model Full with color ^.layer_0.shape.color at (?,min(^.layer_01.pos.j, ^.layer_0111.pos.j) + ^.layer_011.pos.j - ^.layer_01.pos.j)
  _01: 
0 
0 
0 
 with color cyan at (bottom(^.layer_01) - 2,1)
  _011: ^.layer_0111.shape at (span(^.layer_01.pos.j, ^.layer_011.pos.j) - 2,max(^.layer_01.pos.j, ^.layer_0111.pos.j) - ^.layer_0111.pos.j - ^.layer_0.pos.j)
  _0111: ^.layer_0111.shape at ^.layer_01.pos
  _01111: applySym(flipDiag1, periodicFactor(transparent, ^.layer_0111))
  _011111: rectangle with size ^.layer_01.shape.mask.size - (3, 0) with model Full with color cyan at max(^.layer_0.pos, ^.layer_01.pos) + (3, 0)
  _0111111: 
0 
0 
 with color cyan at (bottom(^.layer_0111) - 1,span(^.layer_01.pos.j, ^.layer_0111.pos.j))
  _01111111: point with color cyan at (bottom(^.layer_0111),span(^.layer_0.pos.j, ^.layer_0111.pos.j))
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color red at (?,?)
  _01: rectangle with size (?,?) with model Full with color red at (?,?)
  _011: rectangle with size (?,?) with model Full with color red at (?,?)
  _0111: rectangle with size (?,?) with model Full with color red at (?,?)

DL input  with Mi: L = 141.2 + 3226.7 = 3368.0
DL output with Mo: L = 574.0 + 339.1 = 913.1
DL input+output M: L = 715.2 + 3565.8 = 4281.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,1) with model Full with color ^.layer_0.shape.color at (?,min(^.layer_01.pos.j, ^.layer_0111.pos.j) + ^.layer_011.pos.j - ^.layer_01.pos.j)
  _01: 
0 
0 
0 
 with color cyan at (bottom(^.layer_01) - 2,1)
  _011: ^.layer_0111.shape at (span(^.layer_01.pos.j, ^.layer_011.pos.j) - 2,max(^.layer_01.pos.j, ^.layer_0111.pos.j) - ^.layer_0111.pos.j - ^.layer_0.pos.j)
  _0111: ^.layer_0111.shape at ^.layer_01.pos
  _01111: applySym(flipDiag1, periodicFactor(transparent, ^.layer_0111))
  _011111: rectangle with size ^.layer_01.shape.mask.size - (3, 0) with model Full with color cyan at max(^.layer_0.pos, ^.layer_01.pos) + (3, 0)
  _0111111: 
0 
0 
 with color cyan at (bottom(^.layer_0111) - 1,span(^.layer_01.pos.j, ^.layer_0111.pos.j))
  _01111111: point with color cyan at (bottom(^.layer_0111),span(^.layer_0.pos.j, ^.layer_0111.pos.j))
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 20.0 = 145.8
DL output with Mo: L = 574.0 + 339.1 = 913.1
DL input+output M: L = 699.8 + 359.1 = 1058.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (7,9) and color black and layers
  _0: rectangle with size (6,1) with model Full with color red at (1,1)
  _01: rectangle with size (5,1) with model Full with color red at (2,3)
  _011: rectangle with size (4,1) with model Full with color red at (3,5)
  _0111: rectangle with size (3,1) with model Full with color red at (4,7)
diff: 
   (0.0 bits)
data: a background with size (7,9) and color black and layers
  _0: rectangle with size (2,1) with model Full with color red at (3,5)
  _01: 
0 
0 
0 
 with color cyan at (4,1)
  _011: 
2 
2 
2 
 at (1,1)
  _0111: 
2 
2 
2 
 at (2,3)
  _01111: 
2 
2 
 at (4,7)
  _011111: rectangle with size (2,1) with model Full with color cyan at (5,3)
  _0111111: 
0 
0 
 with color cyan at (5,5)
  _01111111: point with color cyan at (6,7)
diff: 
   (10.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,9) and color black and layers
  _0: rectangle with size (6,1) with model Full with color red at (1,1)
  _01: rectangle with size (5,1) with model Full with color red at (2,3)
  _011: rectangle with size (4,1) with model Full with color red at (3,5)
  _0111: rectangle with size (3,1) with model Full with color red at (4,7)
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,9) and color black and layers
  _0: rectangle with size (6,1) with model Full with color red at (1,1)
  _01: rectangle with size (5,1) with model Full with color red at (2,3)
  _011: rectangle with size (3,1) with model Full with color red at (4,7)
  _0111: rectangle with size (4,1) with model Full with color red at (3,5)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (7,9) and color black and layers
  _0: rectangle with size (6,1) with model Full with color red at (1,1)
  _01: rectangle with size (4,1) with model Full with color red at (3,5)
  _011: rectangle with size (5,1) with model Full with color red at (2,3)
  _0111: rectangle with size (3,1) with model Full with color red at (4,7)
diff: 
! 6 wrong pixels (generated / expected)

TRAIN ce9e57f2.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (8,9) and color black and layers
  _0: rectangle with size (7,1) with model Full with color red at (1,1)
  _01: rectangle with size (6,1) with model Full with color red at (2,7)
  _011: rectangle with size (5,1) with model Full with color red at (3,3)
  _0111: rectangle with size (3,1) with model Full with color red at (5,5)
diff: 
   (0.0 bits)
data: a background with size (8,9) and color black and layers
  _0: rectangle with size (4,1) with model Full with color red at (1,1)
  _01: 
0 
0 
0 
 with color cyan at (5,1)
  _011: 
2 
2 
2 
 at (3,3)
  _0111: 
2 
2 
2 
 at (2,7)
  _01111: 
2 
2 
 at (5,5)
  _011111: rectangle with size (3,1) with model Full with color cyan at (5,7)
  _0111111: 
0 
0 
 with color cyan at (6,3)
  _01111111: point with color cyan at (7,5)
diff: 
   (12.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,9) and color black and layers
  _0: rectangle with size (7,1) with model Full with color red at (1,1)
  _01: rectangle with size (6,1) with model Full with color red at (2,7)
  _011: rectangle with size (5,1) with model Full with color red at (3,3)
  _0111: rectangle with size (3,1) with model Full with color red at (5,5)
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,9) and color black and layers
  _0: rectangle with size (7,1) with model Full with color red at (1,1)
  _01: rectangle with size (6,1) with model Full with color red at (2,7)
  _011: rectangle with size (3,1) with model Full with color red at (5,5)
  _0111: rectangle with size (5,1) with model Full with color red at (3,3)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (8,9) and color black and layers
  _0: rectangle with size (7,1) with model Full with color red at (1,1)
  _01: rectangle with size (5,1) with model Full with color red at (3,3)
  _011: rectangle with size (6,1) with model Full with color red at (2,7)
  _0111: rectangle with size (3,1) with model Full with color red at (5,5)
diff: 
! 10 wrong pixels (generated / expected)

TRAIN ce9e57f2.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: rectangle with size (8,1) with model Full with color red at (1,7)
  _01: rectangle with size (7,1) with model Full with color red at (2,1)
  _011: rectangle with size (3,1) with model Full with color red at (6,3)
  _0111: rectangle with size (4,1) with model Full with color red at (5,5)
diff: 
   (2.0 bits)
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (2,1) with model Full with color red at (6,3)
  _01: 
0 
0 
0 
 with color cyan at (6,1)
  _011: 
2 
2 
2 
2 
 at (1,7)
  _0111: 
2 
2 
2 
2 
 at (2,1)
  _01111: 
2 
2 
 at (5,5)
  _011111: rectangle with size (4,1) with model Full with color cyan at (5,7)
  _0111111: 
0 
0 
 with color cyan at (7,5)
  _01111111: point with color cyan at (8,3)
diff: 
   (10.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (8,1) with model Full with color red at (1,7)
  _01: rectangle with size (7,1) with model Full with color red at (2,1)
  _011: rectangle with size (4,1) with model Full with color red at (5,5)
  _0111: rectangle with size (3,1) with model Full with color red at (6,3)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (8,1) with model Full with color red at (1,7)
  _01: rectangle with size (7,1) with model Full with color red at (2,1)
  _011: rectangle with size (3,1) with model Full with color red at (6,3)
  _0111: rectangle with size (4,1) with model Full with color red at (5,5)
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (8,1) with model Full with color red at (1,7)
  _01: rectangle with size (4,1) with model Full with color red at (5,5)
  _011: rectangle with size (7,1) with model Full with color red at (2,1)
  _0111: rectangle with size (3,1) with model Full with color red at (6,3)
diff: 
! 12 wrong pixels (generated / expected)

TRAIN ce9e57f2.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,9) and color black and layers
  _0: rectangle with size (10,1) with model Full with color red at (1,1)
  _01: rectangle with size (9,1) with model Full with color red at (2,3)
  _011: rectangle with size (5,1) with model Full with color red at (6,7)
  _0111: rectangle with size (2,1) with model Full with color red at (9,5)
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,9) and color black and layers
  _0: rectangle with size (10,1) with model Full with color red at (1,1)
  _01: rectangle with size (9,1) with model Full with color red at (2,3)
  _011: rectangle with size (2,1) with model Full with color red at (9,5)
  _0111: rectangle with size (5,1) with model Full with color red at (6,7)
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (11,9) and color black and layers
  _0: rectangle with size (10,1) with model Full with color red at (1,1)
  _01: rectangle with size (5,1) with model Full with color red at (6,7)
  _011: rectangle with size (9,1) with model Full with color red at (2,3)
  _0111: rectangle with size (2,1) with model Full with color red at (9,5)
diff: 
! 14 wrong pixels (generated / expected)

TEST ce9e57f2.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 43.0 sec (43.0 sec/task)
bits-train-error = 339.1 bits (339.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-80] Checking task cf98881b.json: 5 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 110170.1 = 110172.4
DL output with Mo: L = 2.3 + 30998.4 = 31000.7
DL input+output M: L = 4.6 + 141168.5 = 141173.1

# learning a model for train pairs
2.000	
1.428	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.980	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.835	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.647	OUT ADD ^.layer_0 = ^.layer_0
0.549	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.484	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.422	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.365	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.314	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.275	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.252	OUT SPE ^.size = ^.size - translationSym(flipWidth, ^.layer_0, ^)
0.245	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.235	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.226	OUT SPE ^.layer_01.shape.color = ^.layer_0111111.shape.color
0.220	IN  SPE ^.layer_011.shape.mask = 
0 
0 
0 
0 

0.214	IN  SPE ^.layer_01111.shape.mask = 
0 
0 
0 
0 

0.208	OUT SPE ^.layer_01.shape.mask.size.j = ^.size.i - ^.layer_0111.shape.mask.size.i
0.202	OUT SPE ^.layer_011.pos.i = ^.layer_01.pos.i + ^.layer_011111.shape.mask.size.j
0.197	OUT SPE ^.layer_01.shape.mask.model = ^.layer_011111.shape.mask.model
0.195	IN  SPE ^.layer_0.shape.color = yellow
0.192	IN  SPE ^.layer_011.shape.color = red
0.190	IN  SPE ^.layer_01111.shape.color = red
0.188	IN  SPE ^.color = black
0.090	
0.090	IN  GEN ^.layer_01111.shape.color = ?
0.090	IN  GEN ^.layer_011.shape.color = ?
0.090	IN  GEN ^.layer_0.shape.color = ?
0.090	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size - translationSym(flipWidth, ^.layer_0, ^) and color ? and layers
  _0: ^.layer_0
  _01: rectangle with size (?,^.size.i - ^.layer_0111.shape.mask.size.i) with model ^.layer_011111.shape.mask.model with color ^.layer_0111111.shape.color at (?,?)
  _011: point with color ? at (^.layer_01.pos.i + ^.layer_011111.shape.mask.size.j,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color yellow at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: 
0 
0 
0 
0 
 with color red at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: 
0 
0 
0 
0 
 with color red at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: point with color ? at (?,?)

DL input  with Mi: L = 202.7 + 10875.5 = 11078.2
DL output with Mo: L = 213.2 + 2511.7 = 2724.9
DL input+output M: L = 415.9 + 13387.2 = 13803.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size - translationSym(flipWidth, ^.layer_0, ^) and color ? and layers
  _0: ^.layer_0
  _01: rectangle with size (?,^.size.i - ^.layer_0111.shape.mask.size.i) with model ^.layer_011111.shape.mask.model with color ^.layer_0111111.shape.color at (?,?)
  _011: point with color ? at (^.layer_01.pos.i + ^.layer_011111.shape.mask.size.j,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: 
0 
0 
0 
0 
 with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: 
0 
0 
0 
0 
 with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: point with color ? at (?,?)

DL input  with Mi: L = 192.7 + 0.0 = 192.7
DL output with Mo: L = 213.2 + 2511.7 = 2724.9
DL input+output M: L = 405.8 + 2511.7 = 2917.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 . . 
. 0 . . 
0 . . . 
0 0 0 0 
 with color yellow at (0,0)
  _01: rectangle with size (3,4) with mask 
. 0 . . 
0 0 0 . 
0 0 . 0 
 with color blue at (1,10)
  _011: 
0 
0 
0 
0 
 with color red at (0,4)
  _0111: rectangle with size (2,4) with mask 
0 0 . . 
. . 0 0 
 with color brown at (0,5)
  _01111: 
0 
0 
0 
0 
 with color red at (0,9)
  _011111: rectangle with size (1,1) with model Full with color yellow at (0,3)
  _0111111: point with color brown at (3,5)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: 
. 4 . . 
. 4 . . 
4 . . . 
4 4 4 4 
 at (0,0)
  _01: rectangle with size (1,2) with model Full with color brown at (1,2)
  _011: point with color blue at (2,1)
  + 3 delta pixels
diff: 
   (139.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 . . 
. 0 . . 
0 . . . 
0 0 0 0 
 with color yellow at (0,0)
  _01: rectangle with size (3,4) with mask 
. 0 . . 
0 0 0 . 
0 0 . 0 
 with color blue at (1,10)
  _011: 
0 
0 
0 
0 
 with color red at (0,4)
  _0111: rectangle with size (2,4) with mask 
0 0 . . 
. . 0 0 
 with color brown at (0,5)
  _01111: 
0 
0 
0 
0 
 with color red at (0,9)
  _011111: rectangle with size (1,1) with model Full with color yellow at (0,3)
  _0111111: point with color brown at (3,5)
  + 1 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 . . 
. 0 . . 
0 . . . 
0 0 0 0 
 with color yellow at (0,0)
  _01: rectangle with size (3,4) with mask 
. 0 . . 
0 0 0 . 
0 0 . 0 
 with color blue at (1,10)
  _011: 
0 
0 
0 
0 
 with color red at (0,4)
  _0111: rectangle with size (2,4) with mask 
0 0 . . 
. . 0 0 
 with color brown at (0,5)
  _01111: 
0 
0 
0 
0 
 with color red at (0,9)
  _011111: rectangle with size (1,1) with model Full with color brown at (3,5)
  _0111111: point with color yellow at (0,3)
  + 1 delta pixels
diff: 
! 7 wrong pixels (generated / expected)

TRAIN cf98881b.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (4,14) and color black and layers
  _0: rectangle with size (3,4) with mask 
0 0 0 0 
0 0 . . 
0 . 0 0 
 with color yellow at (0,0)
  _01: rectangle with size (3,4) with mask 
0 . . . 
. 0 . 0 
0 . 0 . 
 with color blue at (1,10)
  _011: 
0 
0 
0 
0 
 with color red at (0,4)
  _0111: rectangle with size (2,3) with mask 
0 . 0 
0 0 . 
 with color brown at (0,5)
  _01111: 
0 
0 
0 
0 
 with color red at (0,9)
  _011111: rectangle with size (2,2) with model Odd Checkboard with color brown at (2,7)
  _0111111: point with color blue at (0,13)
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: 
4 4 4 4 
4 4 . . 
4 . 4 4 
 at (0,0)
  _01: rectangle with size (2,2) with model Odd Checkboard with color blue at (2,0)
  _011: point with color brown at (3,2)
diff: 
   (26.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,14) and color black and layers
  _0: rectangle with size (3,4) with mask 
0 0 0 0 
0 0 . . 
0 . 0 0 
 with color yellow at (0,0)
  _01: rectangle with size (3,4) with mask 
0 . . . 
. 0 . 0 
0 . 0 . 
 with color blue at (1,10)
  _011: 
0 
0 
0 
0 
 with color red at (0,4)
  _0111: rectangle with size (2,3) with mask 
0 . 0 
0 0 . 
 with color brown at (0,5)
  _01111: 
0 
0 
0 
0 
 with color red at (0,9)
  _011111: rectangle with size (2,2) with model Odd Checkboard with color brown at (2,7)
  _0111111: point with color blue at (0,13)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,14) and color black and layers
  _0: rectangle with size (3,4) with mask 
0 0 0 0 
0 0 . . 
0 . 0 0 
 with color yellow at (0,0)
  _01: rectangle with size (2,3) with mask 
0 . 0 
0 0 . 
 with color brown at (0,5)
  _011: 
0 
0 
0 
0 
 with color red at (0,4)
  _0111: rectangle with size (3,4) with mask 
0 . . . 
. 0 . 0 
0 . 0 . 
 with color blue at (1,10)
  _01111: 
0 
0 
0 
0 
 with color red at (0,9)
  _011111: rectangle with size (2,2) with model Odd Checkboard with color brown at (2,7)
  _0111111: point with color blue at (0,13)
diff: 
! 3 wrong pixels (generated / expected)

TRAIN cf98881b.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 . 
. 0 . 0 
. 0 . 0 
0 . 0 0 
 with color yellow at (0,0)
  _01: rectangle with size (4,4) with mask 
0 0 . 0 
. . 0 . 
. . 0 0 
0 0 0 . 
 with color brown at (0,5)
  _011: 
0 
0 
0 
0 
 with color red at (0,4)
  _0111: rectangle with size (3,2) with mask 
. 0 
. 0 
0 . 
 with color blue at (0,10)
  _01111: 
0 
0 
0 
0 
 with color red at (0,9)
  _011111: rectangle with size (2,1) with model Full with color blue at (2,13)
  _0111111: point with color blue at (0,13)
diff: 
   (0.0 bits)
data: a background with size (4,4) and color brown and layers
  _0: 
4 4 4 . 
. 4 . 4 
. 4 . 4 
4 . 4 4 
 at (0,0)
  _01: rectangle with size (1,1) with model Full with color blue at (2,0)
  _011: point with color black at (1,0)
diff: 
   (31.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 . 
. 0 . 0 
. 0 . 0 
0 . 0 0 
 with color yellow at (0,0)
  _01: rectangle with size (4,4) with mask 
0 0 . 0 
. . 0 . 
. . 0 0 
0 0 0 . 
 with color brown at (0,5)
  _011: 
0 
0 
0 
0 
 with color red at (0,4)
  _0111: rectangle with size (3,2) with mask 
. 0 
. 0 
0 . 
 with color blue at (0,10)
  _01111: 
0 
0 
0 
0 
 with color red at (0,9)
  _011111: rectangle with size (2,1) with model Full with color blue at (2,13)
  _0111111: point with color blue at (0,13)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 . 0 
. . 0 . 
. . 0 0 
0 0 0 . 
 with color brown at (0,5)
  _01: rectangle with size (4,4) with mask 
0 0 0 . 
. 0 . 0 
. 0 . 0 
0 . 0 0 
 with color yellow at (0,0)
  _011: 
0 
0 
0 
0 
 with color red at (0,4)
  _0111: rectangle with size (3,2) with mask 
. 0 
. 0 
0 . 
 with color blue at (0,10)
  _01111: 
0 
0 
0 
0 
 with color red at (0,9)
  _011111: rectangle with size (2,1) with model Full with color blue at (2,13)
  _0111111: point with color blue at (0,13)
diff: 
! size mismatch, 4x14 instead of 4x4

TRAIN cf98881b.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
0 0 . 0 
0 . 0 0 
. 0 0 0 
 with color yellow at (0,0)
  _01: rectangle with size (2,4) with mask 
0 0 . 0 
0 0 0 0 
 with color blue at (2,10)
  _011: 
0 
0 
0 
0 
 with color red at (0,4)
  _0111: rectangle with size (2,1) with model Full with color brown at (1,7)
  _01111: 
0 
0 
0 
0 
 with color red at (0,9)
  _011111: rectangle with size (2,1) with model Full with color brown at (2,6)
  _0111111: point with color brown at (0,8)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: 
. . . 4 
4 4 . 4 
4 . 4 4 
. 4 4 4 
 at (0,0)
  _01: rectangle with size (2,2) with model Full with color brown at (1,1)
  _011: point with color blue at (3,0)
diff: 
   (26.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
0 0 . 0 
0 . 0 0 
. 0 0 0 
 with color yellow at (0,0)
  _01: rectangle with size (2,4) with mask 
0 0 . 0 
0 0 0 0 
 with color blue at (2,10)
  _011: 
0 
0 
0 
0 
 with color red at (0,4)
  _0111: rectangle with size (2,1) with model Full with color brown at (1,7)
  _01111: 
0 
0 
0 
0 
 with color red at (0,9)
  _011111: rectangle with size (2,1) with model Full with color brown at (2,6)
  _0111111: point with color brown at (0,8)
  + 1 delta pixels
diff: 
! 5 wrong pixels (generated / expected)

TRAIN cf98881b.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . 0 . 
0 0 0 0 
. 0 0 0 
. 0 0 . 
 with color yellow at (0,0)
  _01: rectangle with size (3,2) with mask 
0 0 
0 0 
. 0 
 with color blue at (1,10)
  _011: 
0 
0 
0 
0 
 with color red at (0,4)
  _0111: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
. 0 . 
 with color brown at (1,6)
  _01111: 
0 
0 
0 
0 
 with color red at (0,9)
  _011111: rectangle with size (2,1) with model Full with color blue at (2,13)
  _0111111: point with color blue at (0,13)
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: 
4 . 4 . 
4 4 4 4 
. 4 4 4 
. 4 4 . 
 at (0,0)
  _01: rectangle with size (4,1) with model Full with color blue at (0,3)
  _011: point with color blue at (2,0)
diff: 
   (28.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . 0 . 
0 0 0 0 
. 0 0 0 
. 0 0 . 
 with color yellow at (0,0)
  _01: rectangle with size (3,2) with mask 
0 0 
0 0 
. 0 
 with color blue at (1,10)
  _011: 
0 
0 
0 
0 
 with color red at (0,4)
  _0111: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
. 0 . 
 with color brown at (1,6)
  _01111: 
0 
0 
0 
0 
 with color red at (0,9)
  _011111: rectangle with size (2,1) with model Full with color blue at (2,13)
  _0111111: point with color blue at (0,13)
diff: 
! 3 wrong pixels (generated / expected)

TRAIN cf98881b.json/5: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,14) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . 0 . 
0 0 0 . 
. 0 0 0 
0 . 0 0 
 with color brown at (0,5)
  _01: rectangle with size (4,4) with mask 
0 0 . . 
0 0 0 . 
0 0 . 0 
0 . . . 
 with color blue at (0,10)
  _011: 
0 
0 
0 
0 
 with color red at (0,4)
  _0111: rectangle with size (1,2) with model Full with color yellow at (1,0)
  _01111: 
0 
0 
0 
0 
 with color red at (0,9)
  _011111: rectangle with size (1,2) with model Full with color yellow at (3,1)
  _0111111: point with color yellow at (0,2)
  + 1 delta pixels
diff: 
! size mismatch, 4x14 instead of 4x4

TEST cf98881b.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 28.2 sec (28.2 sec/task)
bits-train-error = 2511.7 bits (2511.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-79] Checking task d037b0a7.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 10534.8 = 10537.1
DL output with Mo: L = 2.3 + 10534.8 = 10537.1
DL input+output M: L = 4.6 + 21069.6 = 21074.2

# learning a model for train pairs
2.000	
1.329	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.978	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.771	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.633	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.568	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.501	OUT SPE ^.layer_0 = unfoldSym( [ id ] [ flipHeight ], ^.layer_0)
0.428	IN  ADD ^.layer_00 = point with color ? at (?,?)
0.377	OUT SPE ^.layer_01.shape = tiling(^.layer_00.shape, 3, 1)
0.340	OUT SPE ^.size = ^.size
0.318	OUT SPE ^.layer_01.pos = ^.layer_00.pos
0.311	IN  SPE ^.color = black
0.305	OUT SPE ^.color = black
0.119	
0.119	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: unfoldSym( [ id ] [ flipHeight ], ^.layer_0)
  _01: tiling(^.layer_00.shape, 3, 1) at ^.layer_00.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: point with color ? at (?,?)
  _0: point with color ? at (?,?)

DL input  with Mi: L = 50.7 + 1957.1 = 2007.8
DL output with Mo: L = 67.7 + 1133.1 = 1200.8
DL input+output M: L = 118.4 + 3090.2 = 3208.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: unfoldSym( [ id ] [ flipHeight ], ^.layer_0)
  _01: tiling(^.layer_00.shape, 3, 1) at ^.layer_00.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: point with color ? at (?,?)
  _0: point with color ? at (?,?)

DL input  with Mi: L = 50.6 + 0.0 = 50.6
DL output with Mo: L = 67.7 + 1133.1 = 1200.8
DL input+output M: L = 118.3 + 1133.1 = 1251.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _00: point with color pink at (0,2)
  _0: point with color yellow at (1,1)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
4 
4 
 at (1,1)
  _01: 
6 
6 
6 
 at (0,2)
  + 1 delta pixels
diff: 
   (38.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _00: point with color pink at (0,2)
  _0: point with color yellow at (1,1)
  + 1 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color black and layers
  _00: point with color pink at (0,2)
  _0: point with color green at (2,0)
  + 1 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,3) and color black and layers
  _00: point with color yellow at (1,1)
  _0: point with color pink at (0,2)
  + 1 delta pixels
diff: 
! 2 wrong pixels (generated / expected)

TRAIN d037b0a7.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _00: point with color red at (0,1)
  _0: point with color orange at (1,0)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
7#
7#
 at (1,0)
  _01: 
2 
2 
2 
 at (0,1)
  + 2 delta pixels
diff: 
   (75.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _00: point with color red at (0,1)
  _0: point with color orange at (1,0)
  + 1 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color black and layers
  _00: point with color red at (0,1)
  _0: point with color cyan at (1,2)
  + 1 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,3) and color black and layers
  _00: point with color orange at (1,0)
  _0: point with color red at (0,1)
  + 1 delta pixels
diff: 
! 3 wrong pixels (generated / expected)

TRAIN d037b0a7.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _00: point with color yellow at (0,0)
  _0: point with color red at (1,1)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
2 
2 
 at (1,1)
  _01: 
4 
4 
4 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _00: point with color yellow at (0,0)
  _0: point with color red at (1,1)
diff: 
correct output grid

TRAIN d037b0a7.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _00: point with color yellow at (0,0)
  _0: point with color cyan at (0,2)
  + 1 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color black and layers
  _00: point with color yellow at (0,0)
  _0: point with color orange at (2,1)
  + 1 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,3) and color black and layers
  _00: point with color cyan at (0,2)
  _0: point with color yellow at (0,0)
  + 1 delta pixels
diff: 
! 2 wrong pixels (generated / expected)

TEST d037b0a7.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 1.7 sec (1.7 sec/task)
bits-train-error = 1133.1 bits (1133.1 bits/task)
acc-train-micro = 0.33 tasks (33.33%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.33
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-78] Checking task d06dbe63.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 137009.7 = 137012.0
DL output with Mo: L = 2.3 + 137009.7 = 137012.0
DL input+output M: L = 4.6 + 274019.4 = 274024.0

# learning a model for train pairs
2.000	
1.010	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.129	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.072	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.038	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.034	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.031	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.028	OUT SPE ^.size = ^.size
0.025	OUT SPE ^.layer_011 = ^.layer_0
0.023	OUT SPE ^.layer_0.pos = projJ(^.layer_0.pos)
0.023	IN  SPE ^.layer_0.shape.color = cyan
0.022	OUT SPE ^.layer_0.shape.color = grey
0.021	OUT SPE ^.layer_01.shape.color = grey
0.020	OUT SPE ^.layer_01.pos.i = middle(^.layer_0)
0.020	IN  SPE ^.color = black
0.019	OUT SPE ^.color = black
0.015	
0.015	IN  GEN ^.layer_0.shape.color = ?
0.015	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color grey at projJ(^.layer_0.pos)
  _01: rectangle with size (?,?) with model ? with color grey at (middle(^.layer_0),?)
  _011: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color cyan at (?,?)

DL input  with Mi: L = 35.6 + 669.8 = 705.4
DL output with Mo: L = 96.0 + 1867.7 = 1963.8
DL input+output M: L = 131.7 + 2537.5 = 2669.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color grey at projJ(^.layer_0.pos)
  _01: rectangle with size (?,?) with model ? with color grey at (middle(^.layer_0),?)
  _011: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 0.0 = 32.2
DL output with Mo: L = 96.0 + 1867.7 = 1963.8
DL input+output M: L = 128.2 + 1867.7 = 1995.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: point with color cyan at (3,4)
diff: 
   (0.0 bits)
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
0 . . 
 with color grey at (0,4)
  _01: rectangle with size (6,5) with mask 
. . . . 0 
. . 0 0 0 
. . 0 . . 
0 0 0 . . 
0 . . . . 
0 . . . . 
 with color grey at (4,0)
  _011: 
8 
 at (3,4)
diff: 
   (76.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: point with color cyan at (3,4)
diff: 
! 19 wrong pixels (generated / expected)

TRAIN d06dbe63.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: point with color cyan at (7,6)
diff: 
   (0.0 bits)
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (7,7) with mask 
. . . . . . 0 
. . . . 0 0 0 
. . . . 0 . . 
. . 0 0 0 . . 
. . 0 . . . . 
0 0 0 . . . . 
0 . . . . . . 
 with color grey at (0,6)
  _01: rectangle with size (5,5) with mask 
. . . . 0 
. . 0 0 0 
. . 0 . . 
0 0 0 . . 
0 . . . . 
 with color grey at (8,2)
  _011: 
8 
 at (7,6)
diff: 
   (110.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: point with color cyan at (7,6)
diff: 
! 30 wrong pixels (generated / expected)

TRAIN d06dbe63.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: point with color cyan at (5,5)
diff: 
! 28 wrong pixels (generated / expected)

TEST d06dbe63.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.7 sec (3.7 sec/task)
bits-train-error = 1867.7 bits (1867.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-77] Checking task d07ae81c.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 253365.4 = 253367.7
DL output with Mo: L = 2.3 + 253365.4 = 253367.7
DL input+output M: L = 4.6 + 506730.8 = 506735.4

# learning a model for train pairs
2.000	
1.425	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.936	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.596	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.307	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.235	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.187	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.158	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.136	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.121	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.085	
0.085	IN  GEN ^ = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 9134.8 = 9205.0
DL output with Mo: L = 153.4 + 21257.2 = 21410.6
DL input+output M: L = 223.6 + 30392.0 = 30615.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 153.4 + 21257.2 = 21410.6
DL input+output M: L = 155.7 + 21257.2 = 21412.9

# train input/output grids

## instance 1

> Input and output best reading:

data: 
8 8 8 2 2 2 2 8 8 8 8 8 
8 8 8 2 2 2 2 8 8 8 8 8 
2 2 2 2 2 2 2 2 2 2 2 2 
2 2 2 2 2 2 2 2 2 2 2 2 
2 2 2 2 2 2 2 2 2 2 2 2 
8 8 8 2 4 2 2 8 8 8 8 8 
8 8 8 2 2 2 2 8 8 8 8 8 
8 8 8 2 2 2 2 8 8 8 8 8 
8 1 8 2 2 2 2 8 8 8 8 8 
8 8 8 2 2 2 2 8 8 8 8 8 
8 8 8 2 2 2 2 8 8 8 8 8 
8 8 8 2 2 2 2 8 8 8 8 8 
2 2 2 2 2 2 2 2 2 2 2 2 
2 2 2 2 2 2 2 2 2 2 2 2 
2 2 2 2 2 2 2 2 2 2 2 2 
2 2 2 2 2 2 2 2 2 2 2 2 
8 8 8 2 2 2 2 8 8 8 8 8 
8 8 8 2 2 2 2 8 8 8 8 8 
8 8 8 2 2 2 2 8 8 8 8 8 

diff: 
   (0.0 bits)
data: a background with size (19,12) and color cyan and layers
  _0: rectangle with size (19,12) with mask 
. . . 0 0 0 0 . . . . . 
. . . 0 0 0 0 . . . . . 
0 . 0 0 0 0 0 . 0 0 0 0 
0 0 . 0 0 0 . 0 0 0 0 0 
0 0 0 . 0 . 0 0 0 0 0 0 
. . . 0 . 0 0 . . . . . 
. . . . 0 . 0 . . . . . 
. . . 0 0 0 . . . . . . 
. . . 0 0 0 0 . . . . . 
. . . 0 0 0 0 . . . . . 
. . . . 0 0 0 . . . . . 
. . . 0 . 0 0 . . . . . 
0 0 0 0 0 . 0 0 0 0 0 . 
0 0 0 0 0 0 . 0 0 0 0 0 
0 0 0 0 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 . 0 0 0 
. . . 0 0 0 0 . . . . . 
. . . 0 0 0 0 . . . . . 
. . . 0 0 0 0 . . . . . 
 with color red at (0,0)
  _01: rectangle with size (6,7) with mask 
0 . . . . . 0 
. 0 . . . 0 . 
. . 0 . 0 . . 
. . . 0 . . . 
. . 0 . 0 . . 
. . . . . 0 . 
 with color yellow at (2,1)
  _011: rectangle with size (6,6) with mask 
0 . . . . . 
. 0 . . . . 
. . 0 . . . 
. . . 0 . . 
. . . . 0 . 
. . . . . 0 
 with color yellow at (10,3)
  _0111: rectangle with size (3,3) with model Even Checkboard with color blue at (7,0)
  _01111: rectangle with size (4,4) with mask 
0 . . . 
. 0 . . 
. . 0 . 
. . . 0 
 with color blue at (8,7)
  + 7 delta pixels
diff: 
   (814.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 8 8 2 2 2 2 8 8 8 8 8 
8 8 8 2 2 2 2 8 8 8 8 8 
2 2 2 2 2 2 2 2 2 2 2 2 
2 2 2 2 2 2 2 2 2 2 2 2 
2 2 2 2 2 2 2 2 2 2 2 2 
8 8 8 2 4 2 2 8 8 8 8 8 
8 8 8 2 2 2 2 8 8 8 8 8 
8 8 8 2 2 2 2 8 8 8 8 8 
8 1 8 2 2 2 2 8 8 8 8 8 
8 8 8 2 2 2 2 8 8 8 8 8 
8 8 8 2 2 2 2 8 8 8 8 8 
8 8 8 2 2 2 2 8 8 8 8 8 
2 2 2 2 2 2 2 2 2 2 2 2 
2 2 2 2 2 2 2 2 2 2 2 2 
2 2 2 2 2 2 2 2 2 2 2 2 
2 2 2 2 2 2 2 2 2 2 2 2 
8 8 8 2 2 2 2 8 8 8 8 8 
8 8 8 2 2 2 2 8 8 8 8 8 
8 8 8 2 2 2 2 8 8 8 8 8 

diff: 
! size mismatch, 10x10 instead of 19x12

TRAIN d07ae81c.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
3 3 3 1 1 1 1 1 1 3 3 3 3 3 
3 3 3 1 1 1 1 1 1 3 3 3 3 3 
3 3 3 1 1 1 1 1 1 3 3 3 3 3 
3 3 3 1 1 1 2 1 1 3 3 3 3 3 
3 3 3 1 1 1 1 1 1 3 3 3 3 3 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 
3 3 3 1 1 1 1 1 1 3 3 8 3 3 
3 3 3 1 1 1 1 1 1 3 3 3 3 3 
3 3 3 1 1 1 1 1 1 3 3 3 3 3 
3 3 3 1 1 1 1 1 1 3 3 3 3 3 

diff: 
   (0.0 bits)
data: a background with size (12,14) and color green and layers
  _0: rectangle with size (12,14) with mask 
. . . . 0 0 0 0 0 . . . . . 
. . . 0 . 0 0 0 . . . . . . 
. . . 0 0 . 0 . 0 . . . . . 
. . . 0 0 0 . 0 0 . . . . . 
. . . 0 0 . 0 . 0 . . . . . 
0 0 0 0 . 0 0 0 . 0 0 0 0 0 
0 0 0 . 0 0 0 0 0 . 0 0 0 . 
0 0 . 0 0 0 0 0 0 0 . 0 . 0 
. . . 0 0 0 0 0 0 . . . . . 
. . . 0 0 0 0 0 0 . . . . . 
. . . 0 0 0 0 0 0 . . . . . 
. . . 0 0 0 0 0 . . . . . . 
 with color blue at (0,0)
  _01: rectangle with size (8,9) with mask 
. 0 . . . . . . . 
. . 0 . . . 0 . . 
. . . 0 . 0 . . . 
. . . . 0 . . . . 
. . . 0 . 0 . . . 
. . 0 . . . 0 . . 
. 0 . . . . . 0 . 
0 . . . . . . . 0 
 with color red at (0,2)
  _011: rectangle with size (3,5) with mask 
. . 0 . . 
. 0 . 0 . 
0 . . . 0 
 with color cyan at (8,9)
  _0111: rectangle with size (2,2) with model Full with color red at (6,12)
  _01111: rectangle with size (2,2) with model Odd Checkboard with color cyan at (8,0)
  + 2 delta pixels
diff: 
   (530.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 3 3 1 1 1 1 1 1 3 3 3 3 3 
3 3 3 1 1 1 1 1 1 3 3 3 3 3 
3 3 3 1 1 1 1 1 1 3 3 3 3 3 
3 3 3 1 1 1 2 1 1 3 3 3 3 3 
3 3 3 1 1 1 1 1 1 3 3 3 3 3 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 
3 3 3 1 1 1 1 1 1 3 3 8 3 3 
3 3 3 1 1 1 1 1 1 3 3 3 3 3 
3 3 3 1 1 1 1 1 1 3 3 3 3 3 
3 3 3 1 1 1 1 1 1 3 3 3 3 3 

diff: 
! size mismatch, 10x10 instead of 12x14

TRAIN d07ae81c.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 8 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 3 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 3 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 

diff: 
   (0.0 bits)
data: a background with size (15,15) and color pink and layers
  _0: rectangle with size (15,4) with mask 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 . 
. 0 . 0 
0 . 0 0 
. 0 . 0 
0 0 0 . 
0 0 0 0 
0 0 0 0 
. 0 0 0 
0 . 0 0 
0 0 . 0 
0 0 0 . 
0 0 . 0 
 with color blue at (0,6)
  _01: rectangle with size (15,2) with model Full with color blue at (0,0)
  _011: rectangle with size (12,4) with model Full with color cyan at (3,6)
  _0111: rectangle with size (5,5) with model x-cross with color green at (8,10)
  _01111: rectangle with size (5,4) with mask 
0 . . . 
. 0 . 0 
. . 0 . 
. 0 . 0 
0 . . . 
 with color green at (6,2)
  + 12 delta pixels
diff: 
   (781.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 8 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 3 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 3 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 
1 1 6 6 6 6 1 1 1 1 6 6 6 6 6 

diff: 
! size mismatch, 10x10 instead of 15x15

TRAIN d07ae81c.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 8 8 3 3 3 3 3 3 8 4 8 8 8 8 8 8 8 8 
8 8 8 3 3 3 3 3 3 8 8 8 8 8 8 8 8 8 8 
8 8 8 3 3 3 3 3 3 8 8 8 8 8 8 8 8 8 8 
8 8 8 3 3 3 3 3 3 8 8 8 8 8 8 8 8 8 8 
3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
8 8 8 3 3 3 3 3 3 8 8 8 8 8 8 8 8 8 8 
8 8 8 3 3 3 3 3 3 8 8 8 8 8 8 8 8 8 8 
8 8 8 3 3 3 3 3 3 8 8 8 8 8 8 8 8 8 8 
8 8 8 3 3 3 3 3 3 8 8 8 8 8 8 8 8 8 8 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
8 8 8 3 3 3 3 3 3 8 8 8 8 8 8 8 8 8 8 
8 8 8 3 3 3 3 3 3 8 8 8 8 8 8 8 8 8 8 

diff: 
! size mismatch, 10x10 instead of 17x19

TEST d07ae81c.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.6 sec (59.6 sec/task)
bits-train-error = 21257.2 bits (21257.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-76] Checking task d0f5fe59.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 161129.2 = 161131.5
DL output with Mo: L = 2.3 + 11330.3 = 11332.6
DL input+output M: L = 4.6 + 172459.5 = 172464.1

# learning a model for train pairs
2.000	
1.135	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.474	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.276	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.230	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.197	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.177	OUT SPE ^.layer_0.pos = '(0, 0)
0.158	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.127	OUT SPE ^.layer_0.shape.mask.size = max(^.layer_0.shape.mask.size, ^.layer_011.shape.mask.size)
0.096	OUT SPE ^.size = max(^.layer_0.shape.mask.size, ^.layer_011.shape.mask.size)
0.081	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.075	OUT SPE ^.color = black
0.074	IN  SPE ^.layer_0.shape.color = cyan
0.073	IN  SPE ^.layer_01.shape.color = cyan
0.072	IN  SPE ^.layer_011.shape.color = cyan
0.071	IN  SPE ^.color = black
0.039	
0.039	IN  GEN ^.layer_011.shape.color = ?
0.039	IN  GEN ^.layer_01.shape.color = ?
0.039	IN  GEN ^.layer_0.shape.color = ?
0.039	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size max(^.layer_0.shape.mask.size, ^.layer_011.shape.mask.size) and color black and layers
  _0: rectangle with size max(^.layer_0.shape.mask.size, ^.layer_011.shape.mask.size) with model ? with color ^.layer_0.shape.color at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color cyan at (?,?)
  _01: rectangle with size (?,?) with model ? with color cyan at (?,?)
  _011: rectangle with size (?,?) with model ? with color cyan at (?,?)

DL input  with Mi: L = 108.2 + 5262.4 = 5370.6
DL output with Mo: L = 108.5 + 322.0 = 430.5
DL input+output M: L = 216.7 + 5584.4 = 5801.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size max(^.layer_0.shape.mask.size, ^.layer_011.shape.mask.size) and color black and layers
  _0: rectangle with size max(^.layer_0.shape.mask.size, ^.layer_011.shape.mask.size) with model ? with color ^.layer_0.shape.color at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 51.7 = 149.8
DL output with Mo: L = 108.5 + 322.0 = 430.5
DL input+output M: L = 206.6 + 373.7 = 580.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (16,10) and color black and layers
  _0: rectangle with size (4,3) with mask 
. 0 0 
. 0 0 
0 0 0 
. 0 . 
 with color cyan at (1,1)
  _01: rectangle with size (3,3) with mask 
. 0 0 
0 0 0 
. . 0 
 with color cyan at (6,4)
  _011: rectangle with size (3,4) with mask 
. . 0 0 
0 0 0 . 
. . 0 . 
 with color cyan at (10,1)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,4) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . . . 
. 0 . . 
. . 0 . 
. . . 0 
 with color cyan at (0,0)
diff: 
   (15.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,10) and color black and layers
  _0: rectangle with size (4,3) with mask 
. 0 0 
. 0 0 
0 0 0 
. 0 . 
 with color cyan at (1,1)
  _01: rectangle with size (3,3) with mask 
. 0 0 
0 0 0 
. . 0 
 with color cyan at (6,4)
  _011: rectangle with size (3,4) with mask 
. . 0 0 
0 0 0 . 
. . 0 . 
 with color cyan at (10,1)
  + 4 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (16,10) and color black and layers
  _0: rectangle with size (4,3) with mask 
. 0 0 
. 0 0 
0 0 0 
. 0 . 
 with color cyan at (1,1)
  _01: rectangle with size (3,4) with mask 
. . 0 0 
0 0 0 . 
. . 0 . 
 with color cyan at (10,1)
  _011: rectangle with size (3,3) with mask 
. 0 0 
0 0 0 
. . 0 
 with color cyan at (6,4)
  + 4 delta pixels
diff: 
! size mismatch, 4x3 instead of 4x4
>> Trial 3
data: a background with size (16,10) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
0 0 0 
. . 0 
 with color cyan at (6,4)
  _01: rectangle with size (4,3) with mask 
. 0 0 
. 0 0 
0 0 0 
. 0 . 
 with color cyan at (1,1)
  _011: rectangle with size (3,4) with mask 
. . 0 0 
0 0 0 . 
. . 0 . 
 with color cyan at (10,1)
  + 4 delta pixels
diff: 
! size mismatch, 3x4 instead of 4x4

TRAIN d0f5fe59.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
0 0 . 
 with color cyan at (1,1)
  _01: rectangle with size (3,4) with mask 
. . 0 . 
0 0 0 0 
0 . 0 . 
 with color cyan at (3,5)
  _011: rectangle with size (2,2) with model Full with color cyan at (8,3)
diff: 
   (2.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
. 0 . 
. . 0 
 with color cyan at (0,0)
diff: 
   (10.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (3,4) with mask 
. . 0 . 
0 0 0 0 
0 . 0 . 
 with color cyan at (3,5)
  _01: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
0 0 . 
 with color cyan at (1,1)
  _011: rectangle with size (2,2) with model Full with color cyan at (8,3)
diff: 
! size mismatch, 3x4 instead of 3x3
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
0 0 . 
 with color cyan at (1,1)
  _01: rectangle with size (3,4) with mask 
. . 0 . 
0 0 0 0 
0 . 0 . 
 with color cyan at (3,5)
  _011: rectangle with size (2,2) with model Full with color cyan at (8,3)
diff: 
! 6 wrong pixels (generated / expected)

TRAIN d0f5fe59.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (8,12) and color black and layers
  _0: rectangle with size (2,2) with model Full with color cyan at (2,2)
  _01: rectangle with size (3,2) with mask 
0 . 
0 0 
0 . 
 with color cyan at (3,8)
  _011: rectangle with size (2,2) with model Full with color cyan at (3,3)
diff: 
   (3.2 bits)
data: a background with size (2,2) and color black and layers
  _0: rectangle with size (2,2) with model Even Checkboard with color cyan at (0,0)
diff: 
   (6.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,12) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 . 
0 0 0 
. 0 0 
 with color cyan at (2,2)
  _01: rectangle with size (3,1) with model Full with color cyan at (3,8)
  _011: rectangle with size (1,2) with model Full with color cyan at (4,8)
diff: 
! size mismatch, 3x3 instead of 2x2
>> Trial 2
data: a background with size (8,12) and color black and layers
  _0: rectangle with size (2,2) with model Full with color cyan at (2,2)
  _01: rectangle with size (3,2) with mask 
0 . 
0 0 
0 . 
 with color cyan at (3,8)
  _011: rectangle with size (2,2) with model Full with color cyan at (3,3)
diff: 
! 2 wrong pixels (generated / expected)

TRAIN d0f5fe59.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,12) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. 0 0 
 with color cyan at (2,3)
  _01: rectangle with size (3,2) with mask 
. 0 
0 0 
0 0 
 with color cyan at (1,8)
  _011: rectangle with size (2,3) with mask 
0 0 . 
0 0 0 
 with color cyan at (9,8)
  + 7 delta pixels
diff: 
! size mismatch, 3x3 instead of 5x5

TEST d0f5fe59.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 4.2 sec (4.2 sec/task)
bits-train-error = 322.0 bits (322.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-75] Checking task d10ecb37.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 67801.2 = 67803.5
DL output with Mo: L = 2.3 + 4857.0 = 4859.4
DL input+output M: L = 4.6 + 72658.2 = 72662.8

# learning a model for train pairs
2.000	
1.006	OUT SPE ^ = fillResizeAlike(majorityColor(^), '(2, 2), ^)
0.668	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.589	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.534	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.502	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.487	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.472	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.451	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.434	IN  ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.419	IN  ADD ^.layer_01111110 = point with color ? at (?,?)
0.414	IN  SPE ^.layer_011111.shape.mask = 
0 0 

0.412	IN  SPE ^.layer_01.shape.mask.model = Full
0.411	IN  SPE ^.layer_0111.shape.mask.model = Full
0.410	IN  SPE ^.layer_01111.shape.mask.model = Full
0.409	IN  SPE ^.layer_0111111.shape.mask.model = Full
0.009	
0.006	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
fillResizeAlike(majorityColor(^), '(2, 2), ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011111: 
0 0 
 with color ? at (?,?)
  _01111110: point with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 222.6 + 27069.6 = 27292.2
DL output with Mo: L = 29.2 + 0.0 = 29.2
DL input+output M: L = 251.8 + 27069.6 = 27321.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
fillResizeAlike(majorityColor(^), '(2, 2), ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 29.2 + 0.0 = 29.2
DL input+output M: L = 31.5 + 0.0 = 31.5

# train input/output grids

## instance 1

> Input and output best reading:

data: 
4 3 6 4 0 6 
6 0 0 3 3 4 
6 4 4 3 3 0 
0 3 6 0 4 6 
0 6 3 0 4 3 
3 4 4 6 6 0 

diff: 
   (0.0 bits)
data: 
4 3 
6 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 3 6 4 0 6 
6 0 0 3 3 4 
6 4 4 3 3 0 
0 3 6 0 4 6 
0 6 3 0 4 3 
3 4 4 6 6 0 

diff: 
correct output grid

TRAIN d10ecb37.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
2 4 2 2 5#2 4 5#
2 5#5#4 4 2 2 2 
4 5#5#2 2 2 2 4 
2 2 4 2 5#4 2 5#
2 4 2 2 5#2 4 5#
2 5#5#4 4 2 2 2 
4 5#5#2 2 2 2 4 
2 2 4 2 5#4 2 5#

diff: 
   (0.0 bits)
data: 
2 4 
2 5#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 4 2 2 5#2 4 5#
2 5#5#4 4 2 2 2 
4 5#5#2 2 2 2 4 
2 2 4 2 5#4 2 5#
2 4 2 2 5#2 4 5#
2 5#5#4 4 2 2 2 
4 5#5#2 2 2 2 4 
2 2 4 2 5#4 2 5#

diff: 
correct output grid

TRAIN d10ecb37.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
3 2 1 3 4 1 
1 4 4 2 2 3 
1 3 3 2 2 4 
4 2 1 4 3 1 
4 1 2 4 3 2 
2 3 3 1 1 4 
2 4 4 1 1 3 
3 1 2 3 4 2 
3 2 1 3 4 1 
1 4 4 2 2 3 
1 3 3 2 2 4 
4 2 1 4 3 1 

diff: 
   (0.0 bits)
data: 
3 2 
1 4 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 2 1 3 4 1 
1 4 4 2 2 3 
1 3 3 2 2 4 
4 2 1 4 3 1 
4 1 2 4 3 2 
2 3 3 1 1 4 
2 4 4 1 1 3 
3 1 2 3 4 2 
3 2 1 3 4 1 
1 4 4 2 2 3 
1 3 3 2 2 4 
4 2 1 4 3 1 

diff: 
correct output grid

TRAIN d10ecb37.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
9#6 2 9#9#2 6 9#
2 9#9#6 6 9#9#2 
6 9#9#2 2 9#9#6 
9#2 6 9#9#6 2 9#

diff: 
correct output grid

TEST d10ecb37.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 2.9 sec (2.9 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-74] Checking task d13f3404.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 10534.8 = 10537.1
DL output with Mo: L = 2.3 + 42126.8 = 42129.1
DL input+output M: L = 4.6 + 52661.6 = 52666.3

# learning a model for train pairs
2.000	
1.364	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.782	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.676	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.577	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.490	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.425	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.360	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.291	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.266	OUT SPE ^.layer_01.shape.mask = 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 

0.240	OUT SPE ^.layer_0.shape.mask = 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 

0.228	OUT SPE ^.size = tiling(^.size, 2, 2)
0.221	OUT SPE ^.layer_01.pos = ^.layer_01.pos
0.214	IN  SPE ^.color = black
0.210	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.207	OUT SPE ^.layer_011.pos = min(^.layer_0.pos, ^.layer_011.pos) * '2
0.203	OUT SPE ^.layer_0.pos.i = 1
0.201	OUT SPE ^.layer_0.pos.j = center(^.layer_0) / '2
0.199	OUT SPE ^.color = black
0.047	
0.047	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size tiling(^.size, 2, 2) and color black and layers
  _0: 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color ? at (1,center(^.layer_0) / '2)
  _01: 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color ^.layer_01.shape.color at ^.layer_01.pos
  _011: rectangle with size (?,?) with model ? with color ? at min(^.layer_0.pos, ^.layer_011.pos) * '2
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 68.8 + 1631.1 = 1699.9
DL output with Mo: L = 206.8 + 1370.4 = 1577.3
DL input+output M: L = 275.7 + 3001.5 = 3277.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size tiling(^.size, 2, 2) and color black and layers
  _0: 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color ? at (1,center(^.layer_0) / '2)
  _01: 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color ^.layer_01.shape.color at ^.layer_01.pos
  _011: rectangle with size (?,?) with model ? with color ? at min(^.layer_0.pos, ^.layer_011.pos) * '2
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 68.7 + 31.7 = 100.4
DL output with Mo: L = 206.8 + 1370.4 = 1577.3
DL input+output M: L = 275.5 + 1402.1 = 1677.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: point with color pink at (0,0)
  _01: point with color blue at (0,1)
  _011: point with color green at (1,0)
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _0: 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color green at (1,0)
  _01: 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color blue at (0,1)
  _011: rectangle with size (6,6) with mask 
0 . . . . . 
. 0 . . . . 
. . 0 . . . 
. . . 0 . . 
. . . . 0 . 
. . . . . 0 
 with color pink at (0,0)
diff: 
   (54.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: point with color pink at (0,0)
  _01: point with color blue at (0,1)
  _011: point with color green at (1,0)
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color black and layers
  _0: point with color pink at (0,0)
  _01: point with color green at (1,0)
  _011: point with color blue at (0,1)
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,3) and color black and layers
  _0: point with color blue at (0,1)
  _01: point with color pink at (0,0)
  _011: point with color green at (1,0)
diff: 
! 15 wrong pixels (generated / expected)

TRAIN d13f3404.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: point with color cyan at (1,1)
  _01: point with color yellow at (0,1)
  _011: point with color red at (2,0)
diff: 
   (3.2 bits)
data: a background with size (6,6) and color black and layers
  _0: 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color cyan at (1,1)
  _01: 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color yellow at (0,1)
  _011: rectangle with size (4,4) with mask 
0 . . . 
. 0 . . 
. . 0 . 
. . . 0 
 with color red at (2,0)
diff: 
   (41.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: point with color yellow at (0,1)
  _01: point with color cyan at (1,1)
  _011: point with color red at (2,0)
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color black and layers
  _0: point with color yellow at (0,1)
  _01: point with color red at (2,0)
  _011: point with color cyan at (1,1)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,3) and color black and layers
  _0: point with color cyan at (1,1)
  _01: point with color yellow at (0,1)
  _011: point with color red at (2,0)
diff: 
! 11 wrong pixels (generated / expected)

TRAIN d13f3404.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: point with color pink at (0,2)
  _01: point with color blue at (1,0)
  _011: point with color green at (1,1)
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _0: 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color green at (1,1)
  _01: 
0 . . . . 
. 0 . . . 
. . 0 . . 
. . . 0 . 
. . . . 0 
 with color blue at (1,0)
  _011: rectangle with size (4,4) with mask 
0 . . . 
. 0 . . 
. . 0 . 
. . . 0 
 with color pink at (0,2)
diff: 
   (41.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: point with color pink at (0,2)
  _01: point with color blue at (1,0)
  _011: point with color green at (1,1)
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color black and layers
  _0: point with color pink at (0,2)
  _01: point with color green at (1,1)
  _011: point with color blue at (1,0)
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,3) and color black and layers
  _0: point with color blue at (1,0)
  _01: point with color pink at (0,2)
  _011: point with color green at (1,1)
diff: 
! 13 wrong pixels (generated / expected)

TRAIN d13f3404.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: point with color green at (0,2)
  _01: point with color yellow at (2,1)
  _011: point with color brown at (2,2)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color black and layers
  _0: point with color green at (0,2)
  _01: point with color brown at (2,2)
  _011: point with color yellow at (2,1)
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,3) and color black and layers
  _0: point with color yellow at (2,1)
  _01: point with color green at (0,2)
  _011: point with color brown at (2,2)
diff: 
! 12 wrong pixels (generated / expected)

TEST d13f3404.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 9.8 sec (9.8 sec/task)
bits-train-error = 1370.4 bits (1370.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-73] Checking task d22278a0.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 185747.5 = 185749.8
DL output with Mo: L = 2.3 + 185747.5 = 185749.8
DL input+output M: L = 4.6 + 371495.0 = 371499.7

# learning a model for train pairs
2.000	
1.025	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.496	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.439	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.382	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.345	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.313	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.283	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.259	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.247	OUT ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.232	OUT ADD ^.layer_01111110 = point with color ? at (?,?)
0.222	OUT SPE ^.layer_0.shape.color = majorityColor(^)
0.217	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.212	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.208	OUT SPE ^.size = ^.size
0.204	OUT SPE ^.layer_01.shape.color = ^.layer_0.shape.color
0.200	OUT SPE ^.layer_011.pos.j = '0
0.198	OUT SPE ^.layer_01.pos.i = '0
0.197	OUT SPE ^.layer_0.pos.i = ^.layer_0.pos.i
0.196	OUT SPE ^.layer_01111110.pos.i = '0
0.195	OUT SPE ^.layer_01111.shape.color = ^.layer_01.shape.color
0.194	OUT SPE ^.layer_0111111.shape.color = ^.layer_01.shape.color
0.179	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (?,?) with model ? with color majorityColor(^) at (^.layer_0.pos.i,?)
  _01: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at ('0,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,'0)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111110: point with color ? at ('0,?)
  _0111111: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.6 + 2664.0 = 2714.7
DL output with Mo: L = 278.4 + 32988.3 = 33266.7
DL input+output M: L = 329.0 + 35652.3 = 35981.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (?,?) with model ? with color majorityColor(^) at (^.layer_0.pos.i,?)
  _01: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at ('0,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,'0)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111110: point with color ? at ('0,?)
  _0111111: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.6 + 0.0 = 50.6
DL output with Mo: L = 278.4 + 32988.3 = 33266.7
DL input+output M: L = 329.0 + 32988.3 = 33317.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color blue at (0,0)
  _01: point with color red at (0,9)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with mask 
. . . . 0 
. . . . 0 
. . . . 0 
. . . . 0 
0 0 0 0 0 
 with color blue at (0,0)
  _01: rectangle with size (3,3) with mask 
. . 0 
. . 0 
0 0 0 
 with color blue at (0,0)
  _011: rectangle with size (1,5) with model Full with color blue at (6,0)
  _0111: rectangle with size (5,5) with mask 
0 . . . . 
0 . . . . 
0 . . . . 
0 . . . . 
0 0 0 0 0 
 with color red at (0,5)
  _01111: rectangle with size (3,3) with mask 
0 . . 
0 . . 
0 0 0 
 with color red at (0,7)
  _011111: rectangle with size (1,5) with model Full with color red at (6,5)
  _01111110: point with color blue at (0,0)
  _0111111: rectangle with size (1,5) with model Full with color red at (8,5)
  + 6 delta pixels
diff: 
   (509.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (0,0)
  _01: point with color red at (0,9)
diff: 
! 52 wrong pixels (generated / expected)

TRAIN d22278a0.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: point with color green at (0,11)
  _01: point with color cyan at (11,0)
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 . . . . 
0 . . . . 
0 . . . . 
0 . . . . 
0 0 0 0 0 
 with color green at (0,7)
  _01: rectangle with size (5,1) with model Full with color green at (0,5)
  _011: rectangle with size (5,5) with mask 
0 0 0 0 0 
. . . . 0 
. . . . 0 
. . . . 0 
. . . . 0 
 with color cyan at (7,0)
  _0111: rectangle with size (3,3) with mask 
0 . . 
0 . . 
0 0 0 
 with color green at (0,9)
  _01111: rectangle with size (1,5) with model Full with color cyan at (5,0)
  _011111: rectangle with size (1,5) with model Full with color green at (6,7)
  _01111110: point with color green at (0,1)
  _0111111: rectangle with size (5,1) with model Full with color cyan at (7,6)
  + 22 delta pixels
diff: 
   (1150.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: point with color green at (0,11)
  _01: point with color cyan at (11,0)
diff: 
! 67 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: point with color cyan at (11,0)
  _01: point with color green at (0,11)
diff: 
! 68 wrong pixels (generated / expected)

TRAIN d22278a0.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: point with color red at (0,0)
  _01: point with color yellow at (12,0)
diff: 
   (0.0 bits)
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (6,7) with model Full with color red at (0,6)
  _01: rectangle with size (5,5) with mask 
. . . . 0 
. . . . 0 
. . . . 0 
. . . . 0 
0 0 0 0 0 
 with color red at (0,0)
  _011: rectangle with size (5,5) with mask 
0 0 0 0 0 
. . . . 0 
. . . . 0 
. . . . 0 
. . . . 0 
 with color yellow at (8,0)
  _0111: rectangle with size (6,1) with model Full with color yellow at (7,6)
  _01111: rectangle with size (6,1) with model Full with color yellow at (7,8)
  _011111: rectangle with size (6,1) with model Full with color yellow at (7,10)
  _01111110: point with color red at (0,0)
  _0111111: rectangle with size (6,1) with model Full with color yellow at (7,12)
  + 29 delta pixels
diff: 
   (1438.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: point with color red at (0,0)
  _01: point with color yellow at (12,0)
diff: 
! 80 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,13) and color black and layers
  _0: point with color yellow at (12,0)
  _01: point with color red at (0,0)
diff: 
! 82 wrong pixels (generated / expected)

TRAIN d22278a0.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (7,7) and color black and layers
  _0: point with color blue at (0,0)
  _01: point with color red at (0,6)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (7,7) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
. . 0 
0 0 0 
 with color blue at (0,0)
  _01: rectangle with size (1,1) with model Full with color blue at (0,0)
  _011: rectangle with size (1,1) with model Full with color cyan at (6,0)
  _0111: rectangle with size (3,3) with mask 
0 0 0 
. . 0 
. . 0 
 with color cyan at (4,0)
  _01111: rectangle with size (3,3) with mask 
0 . . 
0 . . 
0 0 0 
 with color red at (0,4)
  _011111: rectangle with size (2,1) with model Full with color cyan at (5,4)
  _01111110: point with color red at (0,6)
  _0111111: rectangle with size (1,2) with model Full with color red at (4,5)
diff: 
   (200.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: point with color blue at (0,0)
  _01: point with color red at (0,6)
  + 1 delta pixels
diff: 
! 24 wrong pixels (generated / expected)

TRAIN d22278a0.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,17) and color black and layers
  _0: point with color yellow at (0,0)
  _01: point with color cyan at (16,0)
  + 1 delta pixels
diff: 
! 127 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,17) and color black and layers
  _0: point with color cyan at (16,0)
  _01: point with color yellow at (0,0)
  + 1 delta pixels
diff: 
! 128 wrong pixels (generated / expected)

TEST d22278a0.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.5 sec (59.5 sec/task)
bits-train-error = 32988.3 bits (32988.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-72] Checking task d23f8c26.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 22921.2 = 22923.5
DL output with Mo: L = 2.3 + 22921.2 = 22923.5
DL input+output M: L = 4.6 + 45842.4 = 45847.0

# learning a model for train pairs
2.000	
1.175	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.678	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.630	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.582	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.533	OUT ADD ^.layer_01 = ^.layer_0
0.484	IN  ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.434	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.404	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.373	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.354	OUT SPE ^.size = ^.size
0.341	OUT SPE ^.layer_0.shape.mask = 
0 

0.330	OUT SPE ^.layer_0.pos = corner(^.layer_011.pos, ^.layer_0.pos)
0.326	IN  SPE ^.layer_00.shape.mask.model = Full
0.323	IN  SPE ^.layer_0.shape.mask.model = Full
0.319	IN  SPE ^.layer_0111.shape.mask.model = Full
0.316	IN  SPE ^.color = black
0.313	OUT SPE ^.color = black
0.034	
0.034	IN  GEN ^.layer_0111.shape.mask.model = ?
0.034	IN  GEN ^.layer_0.shape.mask.model = ?
0.034	IN  GEN ^.layer_00.shape.mask.model = ?
0.034	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 
 with color ? at corner(^.layer_011.pos, ^.layer_0.pos)
  _01: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 155.1 + 6390.0 = 6545.0
DL output with Mo: L = 56.5 + 564.1 = 620.7
DL input+output M: L = 211.6 + 6954.1 = 7165.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
0 
 with color ? at corner(^.layer_011.pos, ^.layer_0.pos)
  _01: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 153.4 + 0.0 = 153.4
DL output with Mo: L = 56.5 + 564.1 = 620.7
DL input+output M: L = 209.9 + 564.1 = 774.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _00: rectangle with size (1,1) with model Full with color pink at (0,0)
  _0: rectangle with size (1,1) with model Full with color yellow at (0,1)
  _01: rectangle with size (1,1) with model Full with color green at (1,1)
  _011: rectangle with size (1,1) with model Full with color brown at (1,2)
  _0111: rectangle with size (1,1) with model Full with color blue at (2,0)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
0 
 with color green at (1,1)
  _01: 
4 
 at (0,1)
diff: 
   (5.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _00: rectangle with size (1,1) with model Full with color pink at (0,0)
  _0: rectangle with size (1,1) with model Full with color yellow at (0,1)
  _01: rectangle with size (1,1) with model Full with color green at (1,1)
  _011: rectangle with size (1,1) with model Full with color brown at (1,2)
  _0111: rectangle with size (1,1) with model Full with color blue at (2,0)
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color black and layers
  _00: rectangle with size (1,1) with model Full with color pink at (0,0)
  _0: rectangle with size (1,1) with model Full with color yellow at (0,1)
  _01: rectangle with size (1,1) with model Full with color green at (1,1)
  _011: rectangle with size (1,1) with model Full with color blue at (2,0)
  _0111: rectangle with size (1,1) with model Full with color brown at (1,2)
diff: 
! 2 wrong pixels (generated / expected)

TRAIN d23f8c26.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (5,5) and color black and layers
  _00: rectangle with size (2,1) with model Full with color cyan at (0,0)
  _0: rectangle with size (3,1) with model Full with color green at (0,2)
  _01: rectangle with size (2,1) with model Full with color pink at (1,1)
  _011: rectangle with size (1,1) with model Full with color pink at (1,3)
  _0111: rectangle with size (1,1) with model Full with color green at (2,0)
  + 5 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: 
0 
 with color grey at (1,2)
  _01: 
3 
3 
3 
 at (0,2)
  + 1 delta pixels
diff: 
   (45.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color black and layers
  _00: rectangle with size (2,1) with model Full with color cyan at (0,0)
  _0: rectangle with size (3,1) with model Full with color green at (0,2)
  _01: rectangle with size (2,1) with model Full with color pink at (1,1)
  _011: rectangle with size (1,1) with model Full with color pink at (1,3)
  _0111: rectangle with size (1,1) with model Full with color green at (2,0)
  + 5 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,5) and color black and layers
  _00: rectangle with size (2,1) with model Full with color cyan at (0,0)
  _0: rectangle with size (3,1) with model Full with color green at (0,2)
  _01: rectangle with size (2,1) with model Full with color pink at (1,1)
  _011: rectangle with size (1,1) with model Full with color green at (2,0)
  _0111: rectangle with size (1,1) with model Full with color pink at (1,3)
  + 5 delta pixels
diff: 
! 3 wrong pixels (generated / expected)

TRAIN d23f8c26.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (5,5) and color black and layers
  _00: rectangle with size (2,1) with model Full with color green at (0,0)
  _0: rectangle with size (2,1) with model Full with color yellow at (0,2)
  _01: rectangle with size (2,2) with model Even Checkboard with color orange at (1,3)
  _011: rectangle with size (2,2) with model Odd Checkboard with color cyan at (3,1)
  _0111: rectangle with size (1,2) with model Full with color red at (4,3)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: 
0 
 with color cyan at (3,2)
  _01: 
4 
4 
 at (0,2)
diff: 
   (5.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color black and layers
  _00: rectangle with size (2,1) with model Full with color green at (0,0)
  _0: rectangle with size (2,1) with model Full with color yellow at (0,2)
  _01: rectangle with size (2,2) with model Even Checkboard with color orange at (1,3)
  _011: rectangle with size (2,2) with model Odd Checkboard with color cyan at (3,1)
  _0111: rectangle with size (1,2) with model Full with color red at (4,3)
  + 1 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,5) and color black and layers
  _00: rectangle with size (2,1) with model Full with color green at (0,0)
  _0: rectangle with size (2,1) with model Full with color yellow at (0,2)
  _01: rectangle with size (2,2) with model Even Checkboard with color orange at (1,3)
  _011: rectangle with size (1,2) with model Full with color red at (4,3)
  _0111: rectangle with size (2,2) with model Odd Checkboard with color cyan at (3,1)
  + 1 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (5,5) and color black and layers
  _00: rectangle with size (2,1) with model Full with color green at (0,0)
  _0: rectangle with size (2,1) with model Full with color yellow at (0,2)
  _01: rectangle with size (2,2) with model Odd Checkboard with color cyan at (3,1)
  _011: rectangle with size (2,2) with model Even Checkboard with color orange at (1,3)
  _0111: rectangle with size (1,2) with model Full with color red at (4,3)
  + 1 delta pixels
diff: 
! 2 wrong pixels (generated / expected)

TRAIN d23f8c26.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _00: rectangle with size (3,1) with model Full with color green at (0,2)
  _0: rectangle with size (1,4) with model Full with color cyan at (1,0)
  _01: rectangle with size (2,2) with model Odd Checkboard with color cyan at (5,1)
  _011: rectangle with size (2,1) with model Full with color pink at (5,3)
  _0111: rectangle with size (1,1) with model Full with color orange at (0,6)
  + 9 delta pixels
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,7) and color black and layers
  _00: rectangle with size (3,1) with model Full with color green at (0,2)
  _0: rectangle with size (1,4) with model Full with color cyan at (1,0)
  _01: rectangle with size (2,2) with model Odd Checkboard with color cyan at (5,1)
  _011: rectangle with size (1,1) with model Full with color orange at (0,6)
  _0111: rectangle with size (2,1) with model Full with color pink at (5,3)
  + 9 delta pixels
diff: 
! 7 wrong pixels (generated / expected)

TEST d23f8c26.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 5.0 sec (5.0 sec/task)
bits-train-error = 564.1 bits (564.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-71] Checking task d2abd087.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.269	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.537	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.484	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.430	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.378	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.325	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.282	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.238	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.213	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.189	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.169	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.150	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.140	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.131	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.123	OUT SPE ^.layer_01111 = coloring(^.layer_01111, blue)
0.118	OUT SPE ^.layer_011.shape.mask = ^.layer_011.shape.mask
0.112	OUT SPE ^.layer_0.shape.mask = ^.layer_0.shape.mask
0.107	OUT SPE ^.size = ^.size
0.102	OUT SPE ^.layer_01.shape.mask = ^.layer_01.shape.mask
0.039	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: ^.layer_0.shape.mask with color ? at (?,?)
  _01: ^.layer_01.shape.mask with color ? at (?,?)
  _011: ^.layer_011.shape.mask with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: coloring(^.layer_01111, blue)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 180.9 + 7661.5 = 7842.4
DL output with Mo: L = 135.7 + 4294.6 = 4430.3
DL input+output M: L = 316.6 + 11956.1 = 12272.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: ^.layer_0.shape.mask with color ? at (?,?)
  _01: ^.layer_01.shape.mask with color ? at (?,?)
  _011: ^.layer_011.shape.mask with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: coloring(^.layer_01111, blue)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 180.9 + 20.0 = 200.9
DL output with Mo: L = 135.7 + 4294.6 = 4430.3
DL input+output M: L = 316.6 + 4314.6 = 4631.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with model Full with color grey at (2,2)
  _01: rectangle with size (2,2) with model Full with color grey at (5,6)
  _011: rectangle with size (2,2) with model Full with color grey at (7,1)
  _0111: rectangle with size (3,1) with model Full with color grey at (5,6)
  _01111: rectangle with size (1,3) with model Full with color grey at (8,1)
  _011111: rectangle with size (1,3) with model Full with color grey at (6,5)
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
0 0 0 
0 0 0 
 with color red at (2,2)
  _01: 
0 0 
0 0 
 with color red at (5,6)
  _011: 
0 0 
0 0 
 with color blue at (7,1)
  _0111: rectangle with size (3,1) with model Full with color red at (5,6)
  _01111: 
1 1 1 
 at (8,1)
  _011111: rectangle with size (1,3) with model Full with color red at (6,5)
diff: 
   (112.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with model Full with color grey at (2,2)
  _01: rectangle with size (2,2) with model Full with color grey at (5,6)
  _011: rectangle with size (2,2) with model Full with color grey at (7,1)
  _0111: rectangle with size (3,1) with model Full with color grey at (5,6)
  _01111: rectangle with size (1,3) with model Full with color grey at (6,5)
  _011111: rectangle with size (1,3) with model Full with color grey at (8,1)
diff: 
! 23 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with model Full with color grey at (2,2)
  _01: rectangle with size (2,2) with model Full with color grey at (5,6)
  _011: rectangle with size (2,2) with model Full with color grey at (7,1)
  _0111: rectangle with size (3,1) with model Full with color grey at (5,6)
  _01111: rectangle with size (1,3) with model Full with color grey at (8,1)
  _011111: rectangle with size (1,3) with model Full with color grey at (6,5)
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,3) with model Full with color grey at (2,2)
  _01: rectangle with size (2,2) with model Full with color grey at (5,6)
  _011: rectangle with size (2,2) with model Full with color grey at (7,1)
  _0111: rectangle with size (1,3) with model Full with color grey at (6,5)
  _01111: rectangle with size (3,1) with model Full with color grey at (5,6)
  _011111: rectangle with size (1,3) with model Full with color grey at (8,1)
diff: 
! 23 wrong pixels (generated / expected)

TRAIN d2abd087.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,4) with mask 
. 0 0 . 
0 0 0 0 
 with color grey at (1,0)
  _01: rectangle with size (3,2) with model Full with color grey at (6,5)
  _011: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. . 0 
 with color grey at (0,6)
  _0111: rectangle with size (1,4) with model Full with color grey at (4,2)
  _01111: rectangle with size (2,2) with model Full with color grey at (7,1)
  _011111: rectangle with size (2,1) with model Full with color grey at (4,8)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
. 0 0 . 
0 0 0 0 
 with color red at (1,0)
  _01: 
0 0 
0 0 
0 0 
 with color red at (6,5)
  _011: 
. . 0 
0 0 0 
. . 0 
 with color blue at (0,6)
  _0111: rectangle with size (1,4) with model Full with color blue at (4,2)
  _01111: 
1 1 
1 1 
 at (7,1)
  _011111: rectangle with size (2,1) with model Full with color blue at (4,8)
diff: 
   (112.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,4) with mask 
. 0 0 . 
0 0 0 0 
 with color grey at (1,0)
  _01: rectangle with size (3,2) with model Full with color grey at (6,5)
  _011: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. . 0 
 with color grey at (0,6)
  _0111: rectangle with size (1,4) with model Full with color grey at (4,2)
  _01111: rectangle with size (2,2) with model Full with color grey at (7,1)
  _011111: rectangle with size (2,1) with model Full with color grey at (4,8)
diff: 
! 28 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,4) with mask 
. 0 0 . 
0 0 0 0 
 with color grey at (1,0)
  _01: rectangle with size (3,2) with model Full with color grey at (6,5)
  _011: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. . 0 
 with color grey at (0,6)
  _0111: rectangle with size (2,2) with model Full with color grey at (7,1)
  _01111: rectangle with size (1,4) with model Full with color grey at (4,2)
  _011111: rectangle with size (2,1) with model Full with color grey at (4,8)
diff: 
! 28 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,4) with mask 
. 0 0 . 
0 0 0 0 
 with color grey at (1,0)
  _01: rectangle with size (3,2) with model Full with color grey at (6,5)
  _011: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. . 0 
 with color grey at (0,6)
  _0111: rectangle with size (1,4) with model Full with color grey at (4,2)
  _01111: rectangle with size (2,1) with model Full with color grey at (4,8)
  _011111: rectangle with size (2,2) with model Full with color grey at (7,1)
diff: 
! 30 wrong pixels (generated / expected)

TRAIN d2abd087.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 0 0 
. 0 0 
. . 0 
. . 0 
 with color grey at (0,0)
  _01: rectangle with size (3,4) with mask 
. 0 . . 
0 0 0 0 
. 0 0 . 
 with color grey at (7,1)
  _011: rectangle with size (4,3) with mask 
0 0 0 
0 . . 
0 . . 
0 . . 
 with color grey at (0,7)
  _0111: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
. 0 0 
 with color grey at (4,4)
  _01111: rectangle with size (2,2) with model Full with color grey at (1,4)
  _011111: rectangle with size (3,1) with model Full with color grey at (4,9)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
0 0 0 
. 0 0 
. . 0 
. . 0 
 with color blue at (0,0)
  _01: 
. 0 . . 
0 0 0 0 
. 0 0 . 
 with color blue at (7,1)
  _011: 
0 0 0 
0 . . 
0 . . 
0 . . 
 with color red at (0,7)
  _0111: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
. 0 0 
 with color red at (4,4)
  _01111: 
1 1 
1 1 
 at (1,4)
  _011111: rectangle with size (3,1) with model Full with color blue at (4,9)
  + 2 delta pixels
diff: 
   (205.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 0 0 
. 0 0 
. . 0 
. . 0 
 with color grey at (0,0)
  _01: rectangle with size (3,4) with mask 
. 0 . . 
0 0 0 0 
. 0 0 . 
 with color grey at (7,1)
  _011: rectangle with size (4,3) with mask 
0 0 0 
0 . . 
0 . . 
0 . . 
 with color grey at (0,7)
  _0111: rectangle with size (3,3) with mask 
0 0 . 
. 0 0 
. 0 0 
 with color grey at (4,4)
  _01111: rectangle with size (2,2) with model Full with color grey at (1,4)
  _011111: rectangle with size (3,1) with model Full with color grey at (4,9)
  + 2 delta pixels
diff: 
! 36 wrong pixels (generated / expected)

TRAIN d2abd087.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,2) with model Full with color grey at (0,1)
  _01: rectangle with size (3,3) with mask 
. 0 0 
. 0 0 
0 0 . 
 with color grey at (0,5)
  _011: rectangle with size (1,5) with model Full with color grey at (8,1)
  _0111: rectangle with size (4,1) with model Full with color grey at (4,7)
  _01111: rectangle with size (1,4) with model Full with color grey at (2,0)
  _011111: rectangle with size (2,4) with mask 
0 0 . . 
0 0 0 0 
 with color grey at (4,1)
  + 2 delta pixels
diff: 
! 35 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,2) with model Full with color grey at (0,1)
  _01: rectangle with size (3,3) with mask 
. 0 0 
. 0 0 
0 0 . 
 with color grey at (0,5)
  _011: rectangle with size (4,1) with model Full with color grey at (4,7)
  _0111: rectangle with size (1,5) with model Full with color grey at (8,1)
  _01111: rectangle with size (1,4) with model Full with color grey at (2,0)
  _011111: rectangle with size (2,4) with mask 
0 0 . . 
0 0 0 0 
 with color grey at (4,1)
  + 2 delta pixels
diff: 
! 33 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,2) with model Full with color grey at (0,1)
  _01: rectangle with size (3,3) with mask 
. 0 0 
. 0 0 
0 0 . 
 with color grey at (0,5)
  _011: rectangle with size (1,5) with model Full with color grey at (8,1)
  _0111: rectangle with size (1,4) with model Full with color grey at (2,0)
  _01111: rectangle with size (4,1) with model Full with color grey at (4,7)
  _011111: rectangle with size (2,4) with mask 
0 0 . . 
0 0 0 0 
 with color grey at (4,1)
  + 2 delta pixels
diff: 
! 33 wrong pixels (generated / expected)

TEST d2abd087.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.6 sec (59.6 sec/task)
bits-train-error = 4294.6 bits (4294.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-70] Checking task d364b489.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79850.6 = 79852.9
DL output with Mo: L = 2.3 + 79850.6 = 79852.9
DL input+output M: L = 4.6 + 159701.1 = 159705.8

# learning a model for train pairs
2.000	
1.062	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.307	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.302	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.292	OUT ADD ^.layer_0 = ^.layer_0
0.285	OUT ADD ^.layer_01 = ^.layer_0.shape at (?,?)
0.278	OUT ADD ^.layer_00 = ^.layer_0.shape at (?,?)
0.271	OUT ADD ^.layer_011 = ^.layer_0.shape at (?,?)
0.264	OUT ADD ^.layer_010 = ^.layer_0.shape at (?,?)
0.259	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.253	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.248	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.242	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.236	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.231	OUT ADD ^.layer_01111 = point with color ? at (?,?)
0.225	OUT ADD ^.layer_011111 = point with color ? at (?,?)
0.193	
0.193	IN  DEL ^.layer_01111
0.193	IN  DEL ^.layer_0111
0.193	IN  DEL ^.layer_011
0.192	IN  DEL ^.layer_01
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _00: ^.layer_0.shape at (?,?)
  _0: ^.layer_0
  _010: ^.layer_0.shape at (?,?)
  _01: ^.layer_0.shape at (?,?)
  _011: ^.layer_0.shape at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 104.4 + 2554.7 = 2659.1
DL output with Mo: L = 153.4 + 15176.2 = 15329.7
DL input+output M: L = 257.8 + 17730.9 = 17988.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _00: ^.layer_0.shape at (?,?)
  _0: ^.layer_0
  _010: ^.layer_0.shape at (?,?)
  _01: ^.layer_0.shape at (?,?)
  _011: ^.layer_0.shape at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 0.0 = 32.2
DL output with Mo: L = 153.4 + 15176.2 = 15329.7
DL input+output M: L = 185.6 + 15176.2 = 15361.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color blue at (1,6)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
1 
 at (3,9)
  _0: 
1 
 at (1,6)
  _010: 
1 
 at (5,3)
  _01: 
1 
 at (7,7)
  _011: 
1 
 at (9,1)
  _0111: point with color red at (0,6)
  _01111: point with color orange at (1,5)
  _011111: point with color pink at (1,7)
  + 15 delta pixels
diff: 
   (719.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (1,6)
  + 4 delta pixels
diff: 
! 23 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (3,9)
  + 4 delta pixels
diff: 
! 23 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (5,3)
  + 4 delta pixels
diff: 
! 23 wrong pixels (generated / expected)

TRAIN d364b489.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color blue at (0,5)
  + 5 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
1 
 at (2,0)
  _0: 
1 
 at (0,5)
  _010: 
1 
 at (3,9)
  _01: 
1 
 at (5,5)
  _011: 
1 
 at (8,2)
  _0111: point with color orange at (0,4)
  _01111: point with color pink at (0,6)
  _011111: point with color red at (1,0)
  + 17 delta pixels
diff: 
   (798.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (0,5)
  + 5 delta pixels
diff: 
! 25 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (2,0)
  + 5 delta pixels
diff: 
! 25 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (3,9)
  + 5 delta pixels
diff: 
! 25 wrong pixels (generated / expected)

TRAIN d364b489.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (0,1)
  + 6 delta pixels
diff: 
! 29 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (0,9)
  + 6 delta pixels
diff: 
! 29 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (2,7)
  + 6 delta pixels
diff: 
! 29 wrong pixels (generated / expected)

TEST d364b489.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.9 sec (59.9 sec/task)
bits-train-error = 15176.2 bits (15176.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-69] Checking task d406998b.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 57373.0 = 57375.4
DL output with Mo: L = 2.3 + 57373.0 = 57375.4
DL input+output M: L = 4.6 + 114746.1 = 114750.7

# learning a model for train pairs
2.000	
1.344	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.689	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.608	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.553	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.511	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.485	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.469	OUT ADD ^.layer_0 = point with color ? at (?,?)
0.454	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.438	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.422	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.407	OUT ADD ^.layer_01111 = point with color ? at (?,?)
0.391	OUT ADD ^.layer_011111 = point with color ? at (?,?)
0.375	OUT ADD ^.layer_0111111 = point with color ? at (?,?)
0.237	
0.235	IN  GEN ^ = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 7935.1 = 8060.9
DL output with Mo: L = 139.7 + 13321.0 = 13460.7
DL input+output M: L = 265.5 + 21256.2 = 21521.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 139.7 + 13321.0 = 13460.7
DL input+output M: L = 142.0 + 13321.0 = 13463.1

# train input/output grids

## instance 1

> Input and output best reading:

data: 
5#0 5#0 0 5#0 0 0 5#
0 5#0 0 5#0 0 5#0 0 
0 0 0 5#0 0 5#0 5#0 

diff: 
   (0.0 bits)
data: a background with size (3,10) and color black and layers
  _0: point with color grey at (0,0)
  _01: point with color grey at (0,2)
  _011: point with color green at (0,5)
  _0111: point with color green at (0,9)
  _01111: point with color green at (1,1)
  _011111: point with color grey at (1,4)
  _0111111: point with color green at (1,7)
  + 3 delta pixels
diff: 
   (242.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
5#0 5#0 0 5#0 0 0 5#
0 5#0 0 5#0 0 5#0 0 
0 0 0 5#0 0 5#0 5#0 

diff: 
! size mismatch, 10x10 instead of 3x10

TRAIN d406998b.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
0 5#0 5#0 0 5#0 5#0 0 0 
5#0 0 0 5#0 0 5#0 0 5#0 
0 0 5#0 0 5#0 0 0 5#0 5#

diff: 
   (0.0 bits)
data: a background with size (3,12) and color black and layers
  _0: point with color green at (0,1)
  _01: point with color green at (0,3)
  _011: point with color grey at (0,6)
  _0111: point with color grey at (0,8)
  _01111: point with color grey at (1,0)
  _011111: point with color grey at (1,4)
  _0111111: point with color green at (1,7)
  + 5 delta pixels
diff: 
   (323.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 5#0 5#0 0 5#0 5#0 0 0 
5#0 0 0 5#0 0 5#0 0 5#0 
0 0 5#0 0 5#0 0 0 5#0 5#

diff: 
! size mismatch, 10x10 instead of 3x12

TRAIN d406998b.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
0 0 5#0 0 5#0 5#0 0 0 5#0 
5#0 0 0 5#0 5#0 0 5#0 0 5#
0 5#0 5#0 0 0 0 5#0 5#0 0 

diff: 
   (0.0 bits)
data: a background with size (3,13) and color black and layers
  _0: point with color green at (0,2)
  _01: point with color grey at (0,5)
  _011: point with color grey at (0,7)
  _0111: point with color grey at (0,11)
  _01111: point with color green at (1,0)
  _011111: point with color green at (1,4)
  _0111111: point with color green at (1,6)
  + 6 delta pixels
diff: 
   (363.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 5#0 0 5#0 5#0 0 0 5#0 
5#0 0 0 5#0 5#0 0 5#0 0 5#
0 5#0 5#0 0 0 0 5#0 5#0 0 

diff: 
! size mismatch, 10x10 instead of 3x13

TRAIN d406998b.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: 
0 0 5#0 0 5#0 5#0 5#0 5#0 0 
5#0 0 0 5#0 0 0 5#0 5#0 0 5#
0 5#0 5#0 0 5#0 0 0 0 0 5#0 

diff: 
   (0.0 bits)
data: a background with size (3,14) and color black and layers
  _0: point with color grey at (0,2)
  _01: point with color green at (0,5)
  _011: point with color green at (0,7)
  _0111: point with color green at (0,9)
  _01111: point with color green at (0,11)
  _011111: point with color grey at (1,0)
  _0111111: point with color grey at (1,4)
  + 7 delta pixels
diff: 
   (403.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 5#0 0 5#0 5#0 5#0 5#0 0 
5#0 0 0 5#0 0 0 5#0 5#0 0 5#
0 5#0 5#0 0 5#0 0 0 0 0 5#0 

diff: 
! size mismatch, 10x10 instead of 3x14

TRAIN d406998b.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 5#0 0 0 5#0 5#0 0 5#0 5#0 0 
5#0 5#0 0 5#0 0 5#0 0 5#0 0 0 5#0 
0 5#0 0 5#0 5#0 0 0 5#0 0 5#0 0 5#

diff: 
! size mismatch, 10x10 instead of 3x17

TEST d406998b.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.6 sec (59.6 sec/task)
bits-train-error = 13321.0 bits (13321.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-68] Checking task d43fd935.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.116	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.299	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.254	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.220	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.188	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.158	OUT ADD ^.layer_00 = ^.layer_0
0.149	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.143	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.132	OUT ADD ^.layer_010 = ^.layer_01
0.127	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.121	OUT SPE ^.size = ^.size
0.118	IN  SPE ^.layer_0.shape.mask = 
0 0 
0 0 

0.116	IN  ADD ^.layer_010 = point with color ? at (?,?)
0.110	IN  ADD ^.layer_0101 = point with color ? at (?,?)
0.103	OUT SPE ^.layer_011 = ^.layer_011
0.102	OUT SPE ^.layer_0.pos.j = ^.layer_0.pos.j
0.100	IN  SPE ^.layer_0.shape.color = green
0.099	OUT SPE ^.layer_0.shape.color = ^.layer_01.shape.color
0.098	OUT SPE ^.layer_01.pos.i = ^.layer_0101.pos.i
0.097	OUT SPE ^.layer_01.shape.color = ^.layer_0101.shape.color
0.096	OUT SPE ^.layer_0.shape.mask.size.j = 1
0.095	OUT SPE ^.layer_0.shape.mask.size.i = area(^.layer_0.shape) - ^.layer_0101.pos.i - ^.layer_0.pos.i
0.093	OUT SPE ^.layer_0.pos = min(^.layer_0.pos, ^.layer_0101.pos) + translationSym(flipHeight, ^.layer_0, ^)
0.093	OUT SPE ^.layer_01.pos.j = min(^.layer_0.pos.j, ^.layer_01.pos.j) - ^.layer_01.pos.j - ^.layer_0101.pos.j
0.092	OUT SPE ^.layer_0.shape.mask.model = Full
0.091	IN  SPE ^.color = black
0.091	OUT SPE ^.color = black
0.036	
0.036	IN  GEN ^.layer_0.shape.color = ?
0.036	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (area(^.layer_0.shape) - ^.layer_0101.pos.i - ^.layer_0.pos.i,1) with model Full with color ^.layer_01.shape.color at min(^.layer_0.pos, ^.layer_0101.pos) + translationSym(flipHeight, ^.layer_0, ^)
  _010: ^.layer_01
  _01: rectangle with size (?,?) with model ? with color ^.layer_0101.shape.color at (^.layer_0101.pos.i,min(^.layer_0.pos.j, ^.layer_01.pos.j) - ^.layer_01.pos.j - ^.layer_0101.pos.j)
  _011: ^.layer_011
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (?,?)
  _010: point with color ? at (?,?)
  _0101: point with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 124.5 + 6662.1 = 6786.6
DL output with Mo: L = 300.4 + 3762.8 = 4063.2
DL input+output M: L = 424.9 + 10425.0 = 10849.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (area(^.layer_0.shape) - ^.layer_0101.pos.i - ^.layer_0.pos.i,1) with model Full with color ^.layer_01.shape.color at min(^.layer_0.pos, ^.layer_0101.pos) + translationSym(flipHeight, ^.layer_0, ^)
  _010: ^.layer_01
  _01: rectangle with size (?,?) with model ? with color ^.layer_0101.shape.color at (^.layer_0101.pos.i,min(^.layer_0.pos.j, ^.layer_01.pos.j) - ^.layer_01.pos.j - ^.layer_0101.pos.j)
  _011: ^.layer_011
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 0 
0 0 
 with color ? at (?,?)
  _010: point with color ? at (?,?)
  _0101: point with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 121.0 + 83.4 = 204.4
DL output with Mo: L = 300.4 + 3762.8 = 4063.2
DL input+output M: L = 421.4 + 3846.2 = 4267.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (3,2)
  _010: point with color blue at (0,0)
  _0101: point with color blue at (3,8)
  _01: rectangle with size (2,2) with model Odd Checkboard with color pink at (6,6)
  _011: point with color pink at (1,8)
  + 2 delta pixels
diff: 
   (3.2 bits)
data: a background with size (10,10) and color black and layers
  _00: 
3 3 
3 3 
 at (3,2)
  _0: rectangle with size (4,1) with model Full with color pink at (5,2)
  _010: 
. 6 
6 . 
 at (6,6)
  _01: rectangle with size (1,5) with model Full with color blue at (3,4)
  _011: 
6 
 at (1,8)
  + 2 delta pixels
diff: 
   (96.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (3,2)
  _010: point with color blue at (0,0)
  _0101: point with color pink at (1,8)
  _01: rectangle with size (2,2) with model Odd Checkboard with color pink at (6,6)
  _011: point with color blue at (3,8)
  + 2 delta pixels
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (3,2)
  _010: point with color blue at (0,0)
  _0101: point with color pink at (1,8)
  _01: rectangle with size (2,2) with model Odd Checkboard with color pink at (6,6)
  _011: point with color pink at (8,2)
  + 2 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (3,2)
  _010: point with color blue at (0,0)
  _0101: point with color blue at (3,8)
  _01: rectangle with size (2,2) with model Odd Checkboard with color pink at (6,6)
  _011: point with color pink at (1,8)
  + 2 delta pixels
diff: 
! 7 wrong pixels (generated / expected)

TRAIN d43fd935.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (2,5)
  _010: point with color orange at (0,1)
  _0101: point with color cyan at (0,6)
  _01: rectangle with size (1,1) with model Full with color orange at (2,3)
  _011: point with color cyan at (5,1)
  + 6 delta pixels
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
3 3 
3 3 
 at (2,5)
  _0: rectangle with size (6,1) with model Full with color orange at (4,5)
  _010: 
7#
 at (2,3)
  _01: rectangle with size (3,4) with mask 
0 . . . 
0 . . . 
. 0 0 0 
 with color cyan at (0,6)
  _011: 
8 
 at (5,1)
  + 6 delta pixels
diff: 
   (270.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (2,5)
  _010: point with color orange at (0,1)
  _0101: point with color cyan at (0,6)
  _01: rectangle with size (1,1) with model Full with color orange at (2,3)
  _011: point with color cyan at (2,9)
  + 6 delta pixels
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (2,5)
  _010: point with color orange at (0,1)
  _0101: point with color cyan at (0,6)
  _01: rectangle with size (1,1) with model Full with color orange at (2,3)
  _011: point with color cyan at (5,1)
  + 6 delta pixels
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (2,5)
  _010: point with color orange at (0,1)
  _0101: point with color cyan at (0,6)
  _01: rectangle with size (1,1) with model Full with color cyan at (2,9)
  _011: point with color orange at (2,3)
  + 6 delta pixels
diff: 
! 21 wrong pixels (generated / expected)

TRAIN d43fd935.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (6,4)
  _010: point with color blue at (1,4)
  _0101: point with color blue at (5,9)
  _01: rectangle with size (1,1) with model Full with color blue at (2,1)
  _011: point with color blue at (9,1)
diff: 
   (3.2 bits)
data: a background with size (10,10) and color black and layers
  _00: 
3 3 
3 3 
 at (6,4)
  _0: rectangle with size (5,1) with model Full with color blue at (1,4)
  _010: 
1 
 at (2,1)
  _01: rectangle with size (1,1) with model Full with color blue at (5,9)
  _011: 
1 
 at (9,1)
diff: 
   (9.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (6,4)
  _010: point with color blue at (1,4)
  _0101: point with color blue at (2,1)
  _01: rectangle with size (1,1) with model Full with color blue at (5,9)
  _011: point with color blue at (9,1)
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (6,4)
  _010: point with color blue at (1,4)
  _0101: point with color blue at (2,1)
  _01: rectangle with size (1,1) with model Full with color blue at (9,1)
  _011: point with color blue at (5,9)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (6,4)
  _010: point with color blue at (1,4)
  _0101: point with color blue at (5,9)
  _01: rectangle with size (1,1) with model Full with color blue at (2,1)
  _011: point with color blue at (9,1)
diff: 
! 1 wrong pixels (generated / expected)

TRAIN d43fd935.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (6,2)
  _010: point with color red at (0,3)
  _0101: point with color red at (1,0)
  _01: rectangle with size (1,1) with model Full with color red at (2,7)
  _011: point with color pink at (3,0)
  + 5 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (6,2)
  _010: point with color red at (0,3)
  _0101: point with color red at (1,0)
  _01: rectangle with size (1,1) with model Full with color red at (2,7)
  _011: point with color pink at (4,7)
  + 5 delta pixels
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color green at (6,2)
  _010: point with color red at (0,3)
  _0101: point with color red at (1,0)
  _01: rectangle with size (1,1) with model Full with color pink at (3,0)
  _011: point with color red at (2,7)
  + 5 delta pixels
diff: 
! 20 wrong pixels (generated / expected)

TEST d43fd935.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 21.5 sec (21.5 sec/task)
bits-train-error = 3762.8 bits (3762.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-67] Checking task d4469b4b.json: 7 train, 2 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 67933.5 = 67935.8
DL output with Mo: L = 2.3 + 24581.2 = 24583.5
DL input+output M: L = 4.6 + 92514.7 = 92519.4

# learning a model for train pairs
2.000	
1.426	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.913	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.571	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.254	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.218	OUT SPE ^.size = '(3, 3)
0.184	OUT SPE ^.layer_0.shape.mask.size = '(3, 3)
0.162	OUT SPE ^.layer_0.pos = '(0, 0)
0.146	OUT SPE ^.layer_0.shape.color = grey
0.139	OUT SPE ^.color = black
0.031	
0.030	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: rectangle with size '(3, 3) with model ? with color grey at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 7365.1 = 7407.1
DL output with Mo: L = 66.0 + 676.4 = 742.4
DL input+output M: L = 108.0 + 8041.5 = 8149.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: rectangle with size '(3, 3) with model ? with color grey at '(0, 0)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 66.0 + 676.4 = 742.4
DL input+output M: L = 68.3 + 676.4 = 744.7

# train input/output grids

## instance 1

> Input and output best reading:

data: 
2 0 0 0 0 
0 2 0 0 2 
2 0 0 2 0 
0 0 0 2 2 
0 0 2 2 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. 0 . 
. 0 . 
 with color grey at (0,0)
diff: 
   (10.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 0 0 0 0 
0 2 0 0 2 
2 0 0 2 0 
0 0 0 2 2 
0 0 2 2 0 

diff: 
! 4 wrong pixels (generated / expected)

TRAIN d4469b4b.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 
0 0 1 1 1 
0 1 0 1 1 
0 1 0 1 0 
0 0 0 0 1 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with model +-cross with color grey at (0,0)
diff: 
   (6.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 
0 0 1 1 1 
0 1 0 1 1 
0 1 0 1 0 
0 0 0 0 1 

diff: 
! 4 wrong pixels (generated / expected)

TRAIN d4469b4b.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
3 0 0 0 0 
0 0 0 3 3 
0 3 3 0 0 
0 3 0 3 0 
3 0 3 3 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
. . 0 
0 0 0 
 with color grey at (0,0)
diff: 
   (10.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 0 0 0 0 
0 0 0 3 3 
0 3 3 0 0 
0 3 0 3 0 
3 0 3 3 0 

diff: 
! 4 wrong pixels (generated / expected)

TRAIN d4469b4b.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: 
1 0 1 0 0 
1 0 0 1 1 
1 1 0 1 0 
0 1 0 1 0 
1 0 0 0 1 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with model +-cross with color grey at (0,0)
diff: 
   (6.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 0 1 0 0 
1 0 0 1 1 
1 1 0 1 0 
0 1 0 1 0 
1 0 0 0 1 

diff: 
! 4 wrong pixels (generated / expected)

TRAIN d4469b4b.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: 
2 0 2 0 2 
2 0 0 0 2 
2 2 0 0 0 
2 0 0 2 2 
2 2 2 0 2 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. 0 . 
. 0 . 
 with color grey at (0,0)
diff: 
   (10.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 0 2 0 2 
2 0 0 0 2 
2 2 0 0 0 
2 0 0 2 2 
2 2 2 0 2 

diff: 
! 4 wrong pixels (generated / expected)

TRAIN d4469b4b.json/5: 0 - (FAILURE)

## instance 6

> Input and output best reading:

data: 
0 2 0 2 0 
0 2 2 2 0 
0 2 2 0 2 
2 2 2 0 0 
0 0 2 0 2 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 0 0 
. 0 . 
. 0 . 
 with color grey at (0,0)
diff: 
   (10.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 2 0 2 0 
0 2 2 2 0 
0 2 2 0 2 
2 2 2 0 0 
0 0 2 0 2 

diff: 
! 4 wrong pixels (generated / expected)

TRAIN d4469b4b.json/6: 0 - (FAILURE)

## instance 7

> Input and output best reading:

data: 
0 3 0 3 0 
3 3 0 0 0 
0 3 0 0 0 
0 0 3 0 0 
3 3 3 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
. . 0 
0 0 0 
 with color grey at (0,0)
diff: 
   (10.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 3 0 3 0 
3 3 0 0 0 
0 3 0 0 0 
0 0 3 0 0 
3 3 3 0 0 

diff: 
! 4 wrong pixels (generated / expected)

TRAIN d4469b4b.json/7: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
1 1 1 1 0 
0 0 1 0 1 
0 1 0 0 0 
0 1 0 0 1 
0 0 1 0 0 

diff: 
! 4 wrong pixels (generated / expected)

TEST d4469b4b.json/1: 0 - (FAILURE)

## instance 2

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 3 0 3 3 
0 0 3 0 0 
3 0 0 0 0 
0 0 3 0 3 
0 0 0 0 3 

diff: 
! 4 wrong pixels (generated / expected)

TEST d4469b4b.json/2: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.8 sec (3.8 sec/task)
bits-train-error = 676.4 bits (676.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-66] Checking task d4a91cb9.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 136285.7 = 136288.0
DL output with Mo: L = 2.3 + 136285.7 = 136288.0
DL input+output M: L = 4.6 + 272571.4 = 272576.1

# learning a model for train pairs
2.000	
1.023	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.155	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.063	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.058	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.053	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.048	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.042	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.038	OUT SPE ^.size = ^.size
0.034	OUT SPE ^.layer_01 = ^.layer_01
0.030	OUT SPE ^.layer_011 = ^.layer_0
0.027	OUT SPE ^.layer_0.shape.mask.size = span(^.layer_0.pos, ^.layer_01.pos) - (1, 1)
0.025	IN  SPE ^.layer_0.shape.color = cyan
0.024	IN  SPE ^.layer_01.shape.color = red
0.023	OUT SPE ^.layer_0.shape.color = yellow
0.023	IN  SPE ^.color = black
0.022	OUT SPE ^.color = black
0.012	
0.012	IN  GEN ^.layer_01.shape.color = ?
0.012	IN  GEN ^.layer_0.shape.color = ?
0.012	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size span(^.layer_0.pos, ^.layer_01.pos) - (1, 1) with model ? with color yellow at (?,?)
  _01: ^.layer_01
  _011: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color cyan at (?,?)
  _01: point with color red at (?,?)

DL input  with Mi: L = 57.4 + 1294.4 = 1351.7
DL output with Mo: L = 96.8 + 1547.8 = 1644.6
DL input+output M: L = 154.2 + 2842.2 = 2996.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size span(^.layer_0.pos, ^.layer_01.pos) - (1, 1) with model ? with color yellow at (?,?)
  _01: ^.layer_01
  _011: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.6 + 0.0 = 50.6
DL output with Mo: L = 96.8 + 1547.8 = 1644.6
DL input+output M: L = 147.4 + 1547.8 = 1695.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,12) and color black and layers
  _0: point with color cyan at (2,1)
  _01: point with color red at (8,9)
diff: 
   (0.0 bits)
data: a background with size (10,12) and color black and layers
  _0: rectangle with size (6,8) with mask 
0 . . . . . . . 
0 . . . . . . . 
0 . . . . . . . 
0 . . . . . . . 
0 . . . . . . . 
0 0 0 0 0 0 0 0 
 with color yellow at (3,1)
  _01: 
2 
 at (8,9)
  _011: 
8 
 at (2,1)
diff: 
   (55.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,12) and color black and layers
  _0: point with color cyan at (2,1)
  _01: point with color red at (8,9)
diff: 
! 55 wrong pixels (generated / expected)

TRAIN d4a91cb9.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (8,11) and color black and layers
  _0: point with color cyan at (1,8)
  _01: point with color red at (5,1)
diff: 
   (0.0 bits)
data: a background with size (8,11) and color black and layers
  _0: rectangle with size (4,7) with mask 
. . . . . . 0 
. . . . . . 0 
. . . . . . 0 
0 0 0 0 0 0 0 
 with color yellow at (2,2)
  _01: 
2 
 at (5,1)
  _011: 
8 
 at (1,8)
diff: 
   (40.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,11) and color black and layers
  _0: point with color cyan at (1,8)
  _01: point with color red at (5,1)
diff: 
! 38 wrong pixels (generated / expected)

TRAIN d4a91cb9.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (12,11) and color black and layers
  _0: point with color red at (1,8)
  _01: point with color cyan at (10,2)
diff: 
   (0.0 bits)
data: a background with size (12,11) and color black and layers
  _0: rectangle with size (9,6) with mask 
0 0 0 0 0 0 
0 . . . . . 
0 . . . . . 
0 . . . . . 
0 . . . . . 
0 . . . . . 
0 . . . . . 
0 . . . . . 
0 . . . . . 
 with color yellow at (1,2)
  _01: 
8 
 at (10,2)
  _011: 
2 
 at (1,8)
diff: 
   (59.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,11) and color black and layers
  _0: point with color red at (1,8)
  _01: point with color cyan at (10,2)
diff: 
! 46 wrong pixels (generated / expected)

TRAIN d4a91cb9.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,13) and color black and layers
  _0: point with color red at (2,11)
  _01: point with color cyan at (8,3)
diff: 
! 45 wrong pixels (generated / expected)

TEST d4a91cb9.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.4 sec (3.4 sec/task)
bits-train-error = 1547.8 bits (1547.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-65] Checking task d4f3cd78.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79850.6 = 79852.9
DL output with Mo: L = 2.3 + 79850.6 = 79852.9
DL input+output M: L = 4.6 + 159701.1 = 159705.8

# learning a model for train pairs
2.000	
1.186	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.556	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.386	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.218	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.056	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.046	OUT SPE ^.layer_0 = ^.layer_0
0.041	OUT SPE ^.size = ^.size
0.040	OUT SPE ^.layer_01.shape.mask.size.j = ^.layer_0.shape.mask.size.j - 2
0.039	IN  SPE ^.layer_0.shape.color = grey
0.037	OUT SPE ^.layer_01.shape.color = cyan
0.036	OUT SPE ^.layer_01.pos.j = 3
0.035	IN  SPE ^.color = black
0.035	OUT SPE ^.color = black
0.014	
0.014	IN  GEN ^.layer_0.shape.color = ?
0.014	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (?,^.layer_0.shape.mask.size.j - 2) with model ? with color cyan at (?,3)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)

DL input  with Mi: L = 45.4 + 1671.3 = 1716.7
DL output with Mo: L = 76.3 + 969.2 = 1045.5
DL input+output M: L = 121.7 + 2640.4 = 2762.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (?,^.layer_0.shape.mask.size.j - 2) with model ? with color cyan at (?,3)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 76.3 + 969.2 = 1045.5
DL input+output M: L = 118.3 + 969.2 = 1087.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,6) with mask 
0 0 0 0 0 0 
0 . . . . 0 
0 . . . . 0 
0 . . . . 0 
0 . . . . 0 
0 0 0 . 0 0 
 with color grey at (2,2)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
5#5#5#5#5#5#
5#. . . . 5#
5#. . . . 5#
5#. . . . 5#
5#. . . . 5#
5#5#5#. 5#5#
 at (2,2)
  _01: rectangle with size (7,4) with mask 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
. . 0 . 
. . 0 . 
. . 0 . 
 with color cyan at (3,3)
diff: 
   (42.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,6) with mask 
0 0 0 0 0 0 
0 . . . . 0 
0 . . . . 0 
0 . . . . 0 
0 . . . . 0 
0 0 0 . 0 0 
 with color grey at (2,2)
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,6) with model Full with color grey at (2,2)
  + 13 delta pixels
diff: 
! 40 wrong pixels (generated / expected)

TRAIN d4f3cd78.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,6) with mask 
0 0 0 . 0 0 
0 . . . . 0 
0 . . . . 0 
0 . . . . 0 
0 0 0 0 0 0 
 with color grey at (5,2)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
5#5#5#. 5#5#
5#. . . . 5#
5#. . . . 5#
5#. . . . 5#
5#5#5#5#5#5#
 at (5,2)
  _01: rectangle with size (9,4) with mask 
. . 0 . 
. . 0 . 
. . 0 . 
. . 0 . 
. . 0 . 
. . 0 . 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color cyan at (0,3)
diff: 
   (54.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,6) with mask 
0 0 0 . 0 0 
0 . . . . 0 
0 . . . . 0 
0 . . . . 0 
0 0 0 0 0 0 
 with color grey at (5,2)
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,6) with model Full with color grey at (9,2)
  + 11 delta pixels
diff: 
! 33 wrong pixels (generated / expected)

TRAIN d4f3cd78.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,5) with mask 
0 0 0 0 0 
0 . . . 0 
0 . . . 0 
0 . . . . 
0 . . . 0 
0 0 0 0 0 
 with color grey at (2,2)
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,5) with model Full with color grey at (2,2)
  + 12 delta pixels
diff: 
! 34 wrong pixels (generated / expected)

TEST d4f3cd78.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.6 sec (3.6 sec/task)
bits-train-error = 969.2 bits (969.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-64] Checking task d511f180.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 16728.0 = 16730.3
DL output with Mo: L = 2.3 + 16728.0 = 16730.3
DL input+output M: L = 4.6 + 33456.0 = 33460.6

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = swapColor(^, cyan, grey)
0.739	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.592	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.551	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.511	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.470	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.429	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.411	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.401	IN  SPE ^.layer_0.shape.color = grey
0.391	IN  SPE ^.layer_011111.shape.color = red
0.010	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
swapColor(^, cyan, grey)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color red at (?,?)

DL input  with Mi: L = 148.3 + 6371.9 = 6520.2
DL output with Mo: L = 20.6 + 0.0 = 20.6
DL input+output M: L = 168.9 + 6371.9 = 6540.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
swapColor(^, cyan, grey)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 20.6 + 0.0 = 20.6
DL input+output M: L = 22.9 + 0.0 = 22.9

# train input/output grids

## instance 1

> Input and output best reading:

data: 
2 7#8 8 8 
5#5#6 5#4 
8 5#5#5#2 
8 8 4 3 6 
6 5#1 9#3 

diff: 
   (0.0 bits)
data: 
2 7#5#5#5#
8 8 6 8 4 
5#8 8 8 2 
5#5#4 3 6 
6 8 1 9#3 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 7#8 8 8 
5#5#6 5#4 
8 5#5#5#2 
8 8 4 3 6 
6 5#1 9#3 

diff: 
correct output grid

TRAIN d511f180.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
3 5#1 
4 5#8 
2 4 9#

diff: 
   (0.0 bits)
data: 
3 8 1 
4 8 5#
2 4 9#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 5#1 
4 5#8 
2 4 9#

diff: 
correct output grid

TRAIN d511f180.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
6 5#3 
5#7#5#
8 8 2 

diff: 
   (0.0 bits)
data: 
6 8 3 
8 7#8 
5#5#2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
6 5#3 
5#7#5#
8 8 2 

diff: 
correct output grid

TRAIN d511f180.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
8 8 4 5#
3 8 7#5#
3 7#1 9#
6 4 8 8 

diff: 
correct output grid

TEST d511f180.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 2.8 sec (2.8 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-63] Checking task d5d6de2d.json: 3 train, 2 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 171857.0 = 171859.4
DL output with Mo: L = 2.3 + 171857.0 = 171859.4
DL input+output M: L = 4.6 + 343714.1 = 343718.7

# learning a model for train pairs
2.000	
1.047	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.174	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.086	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.052	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.033	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.030	OUT SPE ^.size = ^.size
0.028	OUT SPE ^.layer_0.pos = ^.layer_0.pos + (1, 1)
0.027	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_0.shape.mask.size.i - 2
0.026	IN  SPE ^.layer_0.shape.color = red
0.025	IN  SPE ^.layer_01.shape.color = red
0.024	OUT SPE ^.layer_0.shape.color = green
0.023	OUT SPE ^.layer_0.shape.mask.model = Full
0.023	IN  SPE ^.color = black
0.022	OUT SPE ^.color = black
0.004	
0.004	IN  DEL ^.layer_01
0.004	IN  GEN ^.layer_0.shape.color = ?
0.004	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i - 2,?) with model Full with color green at ^.layer_0.pos + (1, 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at (?,?)
  _01: rectangle with size (?,?) with model ? with color red at (?,?)

DL input  with Mi: L = 77.0 + 3159.9 = 3236.9
DL output with Mo: L = 60.8 + 566.6 = 627.4
DL input+output M: L = 137.8 + 3726.5 = 3864.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (^.layer_0.shape.mask.size.i - 2,?) with model Full with color green at ^.layer_0.pos + (1, 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 60.8 + 566.6 = 627.4
DL input+output M: L = 102.8 + 566.6 = 669.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,4) with model Border with color red at (5,4)
  + 8 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,2) with model Full with color green at (6,5)
  + 1 delta pixels
diff: 
   (46.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,4) with model Border with color red at (5,4)
  + 8 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Border with color red at (1,1)
  + 14 delta pixels
diff: 
! 7 wrong pixels (generated / expected)

TRAIN d5d6de2d.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,3) with model Border with color red at (1,4)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,1) with model Full with color green at (2,5)
diff: 
   (3.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,3) with model Border with color red at (1,4)
diff: 
! 2 wrong pixels (generated / expected)

TRAIN d5d6de2d.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (5,5) with model Border with color red at (1,1)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (3,3) with model Full with color green at (2,2)
diff: 
   (6.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (5,5) with model Border with color red at (1,1)
  + 4 delta pixels
diff: 
! 3 wrong pixels (generated / expected)

TRAIN d5d6de2d.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,8) with model Border with color red at (4,1)
  + 8 delta pixels
diff: 
! 17 wrong pixels (generated / expected)

TEST d5d6de2d.json/1: 0 - (FAILURE)

## instance 2

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (25,25) and color black and layers
  _0: rectangle with size (4,9) with model Border with color red at (9,15)
  + 38 delta pixels
diff: 
! 27 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (25,25) and color black and layers
  _0: rectangle with size (6,5) with model Border with color red at (18,1)
  + 42 delta pixels
diff: 
! 23 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (25,25) and color black and layers
  _0: rectangle with size (3,7) with model Border with color red at (1,1)
  + 44 delta pixels
diff: 
! 29 wrong pixels (generated / expected)

TEST d5d6de2d.json/2: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 6.6 sec (6.6 sec/task)
bits-train-error = 566.6 bits (566.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-62] Checking task d631b094.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 14046.4 = 14048.7
DL output with Mo: L = 2.3 + 4215.0 = 4217.3
DL input+output M: L = 4.6 + 18261.4 = 18266.1

# learning a model for train pairs
2.000	
1.173	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.484	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.304	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.220	OUT SPE ^.color = majorityColor(^)
0.169	OUT SPE ^.size.j = area(^)
0.138	OUT SPE ^.size.i = 1
0.131	IN  SPE ^.color = black
0.010	
0.007	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (1,area(^)) and color majorityColor(^) and layers
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.1 + 1699.4 = 1741.5
DL output with Mo: L = 29.7 + 0.0 = 29.7
DL input+output M: L = 71.8 + 1699.4 = 1771.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (1,area(^)) and color majorityColor(^) and layers
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 29.7 + 0.0 = 29.7
DL input+output M: L = 32.0 + 0.0 = 32.0

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 
1 0 0 
0 1 0 

diff: 
   (0.0 bits)
data: a background with size (1,2) and color blue and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 
1 0 0 
0 1 0 

diff: 
correct output grid

TRAIN d631b094.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 2 0 
2 0 0 
0 2 0 

diff: 
   (0.0 bits)
data: a background with size (1,3) and color red and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 2 0 
2 0 0 
0 2 0 

diff: 
correct output grid

TRAIN d631b094.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 7#0 
0 0 0 
0 0 0 

diff: 
   (0.0 bits)
data: a background with size (1,1) and color orange and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 7#0 
0 0 0 
0 0 0 

diff: 
correct output grid

TRAIN d631b094.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: 
0 8 0 
8 8 0 
8 0 0 

diff: 
   (0.0 bits)
data: a background with size (1,4) and color cyan and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 8 0 
8 8 0 
8 0 0 

diff: 
correct output grid

TRAIN d631b094.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
4 4 0 
4 0 4 
0 0 4 

diff: 
correct output grid

TEST d631b094.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.2 sec (1.2 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-61] Checking task d687bc17.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 180931.5 = 180933.8
DL output with Mo: L = 2.3 + 180931.5 = 180933.8
DL input+output M: L = 4.6 + 361862.9 = 361867.6

# learning a model for train pairs
2.000	
1.316	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.641	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.560	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.485	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.414	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.342	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.278	OUT ADD ^.layer_00 = ^.layer_0
0.219	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.164	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.110	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.104	OUT ADD ^.layer_0111 = ^.layer_011
0.101	IN  ADD ^.layer_010 = point with color ? at (?,?)
0.097	IN  ADD ^.layer_0101 = point with color ? at (?,?)
0.093	IN  ADD ^.layer_01011 = point with color ? at (?,?)
0.089	IN  ADD ^.layer_010111 = point with color ? at (?,?)
0.088	OUT ADD ^.layer_0110 = ^.layer_0111
0.084	OUT SPE ^.size = ^.size
0.082	OUT ADD ^.layer_010 = ^.layer_010111.shape at (?,?)
0.026	
0.025	IN  DEL ^.layer_01
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_010111.shape at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: ^.layer_0111
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: ^.layer_011
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: point with color ? at (?,?)
  _0101: point with color ? at (?,?)
  _01011: point with color ? at (?,?)
  _010111: point with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 196.5 + 10229.5 = 10426.0
DL output with Mo: L = 152.0 + 4205.8 = 4357.8
DL input+output M: L = 348.5 + 14435.3 = 14783.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_010111.shape at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0110: ^.layer_0111
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: ^.layer_011
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: point with color ? at (?,?)
  _0101: point with color ? at (?,?)
  _01011: point with color ? at (?,?)
  _010111: point with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 169.1 + 40.0 = 209.1
DL output with Mo: L = 152.0 + 4181.5 = 4333.4
DL input+output M: L = 321.1 + 4221.5 = 4542.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,15) and color black and layers
  _0: rectangle with size (1,13) with model Full with color yellow at (0,1)
  _010: point with color green at (2,10)
  _0101: point with color red at (3,3)
  _01011: point with color orange at (4,7)
  _010111: point with color green at (5,3)
  _011: rectangle with size (1,13) with model Full with color cyan at (9,1)
  _0111: rectangle with size (8,1) with model Full with color green at (1,14)
  + 11 delta pixels
diff: 
   (2.0 bits)
data: a background with size (10,15) and color black and layers
  _00: 
4 4 4 4 4 4 4 4 4 4 4 4 4 
 at (0,1)
  _0: rectangle with size (8,2) with mask 
0 . 
0 . 
0 0 
0 . 
0 . 
0 . 
0 0 
0 . 
 with color red at (1,0)
  _010: 
3 
 at (2,13)
  _01: rectangle with size (2,1) with model Full with color cyan at (8,5)
  _0110: 
3 
3 
3 
3 
3 
3 
3 
3 
 at (1,14)
  _011: rectangle with size (2,1) with model Full with color yellow at (0,9)
  _0111: 
8 8 8 8 8 8 8 8 8 8 8 8 8 
 at (9,1)
  + 1 delta pixels
diff: 
   (164.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,15) and color black and layers
  _0: rectangle with size (1,13) with model Full with color yellow at (0,1)
  _010: point with color green at (2,10)
  _0101: point with color red at (3,3)
  _01011: point with color orange at (4,7)
  _010111: point with color green at (5,3)
  _011: rectangle with size (1,13) with model Full with color cyan at (9,1)
  _0111: rectangle with size (8,1) with model Full with color red at (1,0)
  + 11 delta pixels
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,15) and color black and layers
  _0: rectangle with size (1,13) with model Full with color yellow at (0,1)
  _010: point with color green at (2,10)
  _0101: point with color red at (3,3)
  _01011: point with color orange at (4,7)
  _010111: point with color green at (5,3)
  _011: rectangle with size (1,13) with model Full with color cyan at (9,1)
  _0111: rectangle with size (8,1) with model Full with color green at (1,14)
  + 11 delta pixels
diff: 
! 16 wrong pixels (generated / expected)

TRAIN d687bc17.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (1,10) with model Full with color blue at (0,1)
  _010: point with color orange at (2,9)
  _0101: point with color red at (3,7)
  _01011: point with color green at (4,4)
  _010111: point with color yellow at (6,8)
  _011: rectangle with size (10,1) with model Full with color red at (1,0)
  _0111: rectangle with size (10,1) with model Full with color yellow at (1,11)
  + 13 delta pixels
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _00: 
1 1 1 1 1 1 1 1 1 1 
 at (0,1)
  _0: rectangle with size (2,10) with mask 
. . . . . . . 0 0 . 
0 0 0 0 0 0 0 0 0 0 
 with color orange at (10,1)
  _010: 
4 
 at (6,10)
  _01: rectangle with size (1,2) with model Full with color red at (3,0)
  _0110: 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
 at (1,11)
  _011: rectangle with size (2,1) with model Full with color blue at (0,5)
  _0111: 
2 
2 
2 
2 
2 
2 
2 
2 
2 
2 
 at (1,0)
diff: 
   (126.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (1,10) with model Full with color blue at (0,1)
  _010: point with color orange at (2,9)
  _0101: point with color red at (3,7)
  _01011: point with color green at (4,4)
  _010111: point with color yellow at (6,8)
  _011: rectangle with size (10,1) with model Full with color red at (1,0)
  _0111: rectangle with size (10,1) with model Full with color yellow at (1,11)
  + 13 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (1,10) with model Full with color blue at (0,1)
  _010: point with color orange at (2,9)
  _0101: point with color red at (3,7)
  _01011: point with color green at (4,4)
  _010111: point with color yellow at (6,8)
  _011: rectangle with size (10,1) with model Full with color red at (1,0)
  _0111: rectangle with size (1,10) with model Full with color orange at (11,1)
  + 13 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TRAIN d687bc17.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (14,11) and color black and layers
  _0: rectangle with size (12,1) with model Full with color yellow at (1,0)
  _010: point with color red at (2,2)
  _0101: point with color pink at (3,8)
  _01011: point with color cyan at (4,4)
  _010111: point with color yellow at (7,3)
  _011: rectangle with size (12,1) with model Full with color cyan at (1,10)
  _0111: rectangle with size (1,9) with model Full with color green at (13,1)
  + 11 delta pixels
diff: 
   (2.0 bits)
data: a background with size (14,11) and color black and layers
  _00: 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
 at (1,0)
  _0: rectangle with size (2,9) with mask 
0 0 0 0 0 0 0 0 0 
. . . . . . . 0 . 
 with color pink at (0,1)
  _010: 
4 
 at (7,1)
  _01: rectangle with size (2,2) with model Full with color cyan at (9,9)
  _0110: 
3 3 3 3 3 3 3 3 3 
 at (13,1)
  _011: rectangle with size (1,2) with model Full with color cyan at (4,9)
  _0111: 
8 
8 
8 
8 
8 
8 
8 
8 
8 
8 
8 
8 
 at (1,10)
diff: 
   (127.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,11) and color black and layers
  _0: rectangle with size (12,1) with model Full with color yellow at (1,0)
  _010: point with color red at (2,2)
  _0101: point with color pink at (3,8)
  _01011: point with color cyan at (4,4)
  _010111: point with color yellow at (7,3)
  _011: rectangle with size (12,1) with model Full with color cyan at (1,10)
  _0111: rectangle with size (1,9) with model Full with color pink at (0,1)
  + 11 delta pixels
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,11) and color black and layers
  _0: rectangle with size (12,1) with model Full with color yellow at (1,0)
  _010: point with color red at (2,2)
  _0101: point with color pink at (3,8)
  _01011: point with color cyan at (4,4)
  _010111: point with color yellow at (7,3)
  _011: rectangle with size (12,1) with model Full with color cyan at (1,10)
  _0111: rectangle with size (1,9) with model Full with color green at (13,1)
  + 11 delta pixels
diff: 
! 16 wrong pixels (generated / expected)

TRAIN d687bc17.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,17) and color black and layers
  _0: rectangle with size (1,15) with model Full with color yellow at (0,1)
  _010: point with color cyan at (2,7)
  _0101: point with color blue at (2,12)
  _01011: point with color red at (3,3)
  _010111: point with color green at (3,14)
  _011: rectangle with size (1,15) with model Full with color cyan at (13,1)
  _0111: rectangle with size (12,1) with model Full with color blue at (1,0)
  + 21 delta pixels
diff: 
! 25 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,17) and color black and layers
  _0: rectangle with size (1,15) with model Full with color yellow at (0,1)
  _010: point with color cyan at (2,7)
  _0101: point with color blue at (2,12)
  _01011: point with color red at (3,3)
  _010111: point with color green at (3,14)
  _011: rectangle with size (1,15) with model Full with color cyan at (13,1)
  _0111: rectangle with size (12,1) with model Full with color red at (1,16)
  + 21 delta pixels
diff: 
! 24 wrong pixels (generated / expected)

TEST d687bc17.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.7 sec (59.7 sec/task)
bits-train-error = 4181.5 bits (4181.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-60] Checking task d6ad076f.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.365	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.845	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.626	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.398	OUT ADD ^.layer_0 = ^.layer_0
0.251	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.129	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.038	OUT ADD ^.layer_011 = ^.layer_01
0.033	OUT SPE ^.size = ^.size
0.031	OUT SPE ^.layer_01.shape.color = cyan
0.030	OUT SPE ^.layer_01.pos.j = right(^.layer_01) / '2
0.029	OUT SPE ^.layer_01.pos.i = min(^.layer_0.pos.i, ^.layer_01.pos.i) + 3
0.028	IN  SPE ^.layer_0.shape.mask.model = Full
0.028	IN  SPE ^.layer_01.shape.mask.model = Full
0.027	OUT SPE ^.layer_01.shape.mask.model = Full
0.026	IN  SPE ^.color = black
0.026	OUT SPE ^.color = black
0.005	
0.005	IN  GEN ^.layer_01.shape.mask.model = ?
0.005	IN  GEN ^.layer_0.shape.mask.model = ?
0.005	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model Full with color cyan at (min(^.layer_0.pos.i, ^.layer_01.pos.i) + 3,right(^.layer_01) / '2)
  _011: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 71.4 + 2503.3 = 2574.7
DL output with Mo: L = 110.9 + 400.9 = 511.7
DL input+output M: L = 182.2 + 2904.2 = 3086.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model Full with color cyan at (min(^.layer_0.pos.i, ^.layer_01.pos.i) + 3,right(^.layer_01) / '2)
  _011: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 110.9 + 400.9 = 511.7
DL input+output M: L = 181.1 + 400.9 = 581.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,6) with model Full with color orange at (7,0)
  _01: rectangle with size (3,4) with model Full with color red at (1,1)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
7#7#7#7#7#7#
7#7#7#7#7#7#
7#7#7#7#7#7#
 at (7,0)
  _01: rectangle with size (3,2) with model Full with color cyan at (4,2)
  _011: 
2 2 2 2 
2 2 2 2 
2 2 2 2 
 at (1,1)
diff: 
   (11.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,6) with model Full with color orange at (7,0)
  _01: rectangle with size (3,4) with model Full with color red at (1,1)
diff: 
! 2 wrong pixels (generated / expected)

TRAIN d6ad076f.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (8,3) with model Full with color yellow at (1,1)
  _01: rectangle with size (5,3) with model Full with color pink at (3,7)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
4 4 4 
4 4 4 
4 4 4 
4 4 4 
4 4 4 
4 4 4 
4 4 4 
4 4 4 
 at (1,1)
  _01: rectangle with size (3,3) with model Full with color cyan at (4,4)
  _011: 
6 6 6 
6 6 6 
6 6 6 
6 6 6 
6 6 6 
 at (3,7)
diff: 
   (13.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (8,3) with model Full with color yellow at (1,1)
  _01: rectangle with size (5,3) with model Full with color pink at (3,7)
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,3) with model Full with color pink at (3,7)
  _01: rectangle with size (8,3) with model Full with color yellow at (1,1)
diff: 
! 13 wrong pixels (generated / expected)

TRAIN d6ad076f.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,9) with model Full with color green at (0,0)
  _01: rectangle with size (2,6) with model Full with color brown at (8,3)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3 3 
 at (0,0)
  _01: rectangle with size (5,4) with model Full with color cyan at (3,4)
  _011: 
9#9#9#9#9#9#
9#9#9#9#9#9#
 at (8,3)
diff: 
   (15.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,9) with model Full with color green at (0,0)
  _01: rectangle with size (2,6) with model Full with color brown at (8,3)
diff: 
! 16 wrong pixels (generated / expected)

TRAIN d6ad076f.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (8,4) with model Full with color blue at (0,0)
  _01: rectangle with size (6,3) with model Full with color red at (1,7)
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,3) with model Full with color red at (1,7)
  _01: rectangle with size (8,4) with model Full with color blue at (0,0)
diff: 
! 16 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color blue and layers
  _0: rectangle with size (10,10) with mask 
. . . . 0 0 0 0 0 0 
. . . . 0 0 0 . . . 
. . . . 0 0 0 . . . 
. . . . 0 0 0 . . . 
. . . . 0 0 0 . . . 
. . . . 0 0 0 . . . 
. . . . 0 0 0 . . . 
. . . . 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
 with color black at (0,0)
  _01: rectangle with size (6,3) with model Full with color red at (1,7)
diff: 
! 44 wrong pixels (generated / expected)

TEST d6ad076f.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 4.1 sec (4.1 sec/task)
bits-train-error = 400.9 bits (400.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-59] Checking task d89b689b.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.046	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.133	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.101	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.095	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.088	OUT ADD ^.layer_0 = ^.layer_01.shape at (?,?)
0.082	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.075	OUT ADD ^.layer_01 = ^.layer_011.shape at (?,?)
0.070	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.062	OUT ADD ^.layer_011 = ^.layer_0111.shape at (?,?)
0.056	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.049	OUT ADD ^.layer_0111 = ^.layer_01111.shape at (?,?)
0.044	OUT SPE ^.size = ^.size
0.041	IN  SPE ^.layer_0.shape.mask = 
0 0 
0 0 

0.038	OUT SPE ^.layer_0111.pos = ^.layer_0.pos + (1, 0)
0.035	OUT SPE ^.layer_011.pos = ^.layer_0.pos + (1, 1)
0.034	OUT SPE ^.layer_0.pos.i = ^.layer_0.pos.i
0.033	IN  SPE ^.layer_0.shape.color = cyan
0.031	OUT SPE ^.layer_01.pos.i = ^.layer_0.pos.i
0.030	OUT SPE ^.layer_01.pos.j = min(^.layer_01.pos.j, ^.layer_011.pos.j) + 3
0.029	OUT SPE ^.layer_0.pos.j = span(^.layer_011.pos.i, ^.layer_0111.pos.i) - 2
0.028	IN  SPE ^.color = black
0.028	OUT SPE ^.color = black
0.003	
0.003	IN  GEN ^.layer_0.shape.color = ?
0.003	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_01.shape at (^.layer_0.pos.i,span(^.layer_011.pos.i, ^.layer_0111.pos.i) - 2)
  _01: ^.layer_011.shape at (^.layer_0.pos.i,min(^.layer_01.pos.j, ^.layer_011.pos.j) + 3)
  _011: ^.layer_0111.shape at ^.layer_0.pos + (1, 1)
  _0111: ^.layer_01111.shape at ^.layer_0.pos + (1, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
0 0 
0 0 
 with color cyan at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 114.7 + 2986.6 = 3101.3
DL output with Mo: L = 233.9 + 0.0 = 233.9
DL input+output M: L = 348.6 + 2986.6 = 3335.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_01.shape at (^.layer_0.pos.i,span(^.layer_011.pos.i, ^.layer_0111.pos.i) - 2)
  _01: ^.layer_011.shape at (^.layer_0.pos.i,min(^.layer_01.pos.j, ^.layer_011.pos.j) + 3)
  _011: ^.layer_0111.shape at ^.layer_0.pos + (1, 1)
  _0111: ^.layer_01111.shape at ^.layer_0.pos + (1, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 0 
0 0 
 with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 111.2 + 20.0 = 131.2
DL output with Mo: L = 233.9 + 0.0 = 233.9
DL input+output M: L = 345.1 + 20.0 = 365.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color cyan at (4,4)
  _01: point with color orange at (0,8)
  _011: point with color pink at (3,1)
  _0111: point with color brown at (9,9)
  _01111: point with color yellow at (8,1)
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
7#
 at (4,5)
  _01: 
6 
 at (4,4)
  _011: 
9#
 at (5,5)
  _0111: 
4 
 at (5,4)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color cyan at (4,4)
  _01: point with color orange at (0,8)
  _011: point with color pink at (3,1)
  _0111: point with color yellow at (8,1)
  _01111: point with color brown at (9,9)
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color cyan at (4,4)
  _01: point with color orange at (0,8)
  _011: point with color pink at (3,1)
  _0111: point with color brown at (9,9)
  _01111: point with color yellow at (8,1)
diff: 
correct output grid

TRAIN d89b689b.json/1: 1 2nd (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color cyan at (4,4)
  _01: point with color grey at (0,2)
  _011: point with color brown at (1,8)
  _0111: point with color blue at (6,9)
  _01111: point with color red at (8,1)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
5#
 at (4,4)
  _01: 
9#
 at (4,5)
  _011: 
1 
 at (5,5)
  _0111: 
2 
 at (5,4)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color cyan at (4,4)
  _01: point with color grey at (0,2)
  _011: point with color brown at (1,8)
  _0111: point with color blue at (6,9)
  _01111: point with color red at (8,1)
diff: 
correct output grid

TRAIN d89b689b.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color cyan at (2,5)
  _01: point with color blue at (0,3)
  _011: point with color yellow at (0,9)
  _0111: point with color pink at (6,9)
  _01111: point with color green at (7,2)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
1 
 at (2,5)
  _01: 
4 
 at (2,6)
  _011: 
6 
 at (3,6)
  _0111: 
3 
 at (3,5)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color cyan at (2,5)
  _01: point with color blue at (0,3)
  _011: point with color yellow at (0,9)
  _0111: point with color pink at (6,9)
  _01111: point with color green at (7,2)
diff: 
correct output grid

TRAIN d89b689b.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color cyan at (4,4)
  _01: point with color yellow at (1,6)
  _011: point with color green at (3,1)
  _0111: point with color orange at (8,8)
  _01111: point with color pink at (9,2)
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color cyan at (4,4)
  _01: point with color yellow at (1,6)
  _011: point with color green at (3,1)
  _0111: point with color pink at (9,2)
  _01111: point with color orange at (8,8)
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: 
0 0 
0 0 
 with color cyan at (4,4)
  _01: point with color yellow at (1,6)
  _011: point with color orange at (8,8)
  _0111: point with color green at (3,1)
  _01111: point with color pink at (9,2)
diff: 
! 4 wrong pixels (generated / expected)

TEST d89b689b.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 8.8 sec (8.8 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 0.83
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-58] Checking task d8c310e9.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 89151.2 = 89153.5
DL output with Mo: L = 2.3 + 89151.2 = 89153.5
DL input+output M: L = 4.6 + 178302.3 = 178307.0

# learning a model for train pairs
2.000	
1.194	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.194	OUT SPE ^ = fillResizeAlike(black, ^.size, ^)
0.130	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.101	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.075	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.067	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.058	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.057	IN  SPE ^.layer_0.shape.mask.model = Full
0.056	IN  SPE ^.layer_01.shape.mask.model = Full
0.055	IN  SPE ^.layer_011.shape.mask.model = Full
0.054	IN  SPE ^.layer_0111.shape.mask.model = Full
0.053	IN  SPE ^.layer_01111.shape.mask.model = Full
0.052	IN  SPE ^.color = black
0.002	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
fillResizeAlike(black, ^.size, ^)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 156.1 + 4463.4 = 4619.5
DL output with Mo: L = 20.8 + 0.0 = 20.8
DL input+output M: L = 176.9 + 4463.4 = 4640.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
fillResizeAlike(black, ^.size, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 20.8 + 0.0 = 20.8
DL input+output M: L = 23.2 + 0.0 = 23.2

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 2 2 0 2 2 0 0 0 0 0 0 0 0 0 
1 2 2 1 2 2 1 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 2 2 0 2 2 0 2 2 0 2 2 0 2 2 
1 2 2 1 2 2 1 2 2 1 2 2 1 2 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 2 2 0 2 2 0 0 0 0 0 0 0 0 0 
1 2 2 1 2 2 1 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN d8c310e9.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 
0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 
3 3 2 1 3 3 2 1 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 2 0 0 0 2 0 0 0 2 0 0 0 2 
0 0 2 0 0 0 2 0 0 0 2 0 0 0 2 
3 3 2 1 3 3 2 1 3 3 2 1 3 3 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 
0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 
3 3 2 1 3 3 2 1 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN d8c310e9.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
4 0 0 0 0 4 4 0 0 0 0 0 0 0 0 
4 3 0 0 3 4 4 3 0 0 0 0 0 0 0 
4 3 2 2 3 4 4 3 2 2 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
4 0 0 0 0 4 4 0 0 0 0 4 4 0 0 
4 3 0 0 3 4 4 3 0 0 3 4 4 3 0 
4 3 2 2 3 4 4 3 2 2 3 4 4 3 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
4 0 0 0 0 4 4 0 0 0 0 0 0 0 0 
4 3 0 0 3 4 4 3 0 0 0 0 0 0 0 
4 3 2 2 3 4 4 3 2 2 0 0 0 0 0 

diff: 
correct output grid

TRAIN d8c310e9.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 
6 2 2 0 6 2 2 0 6 2 0 0 0 0 0 
6 6 2 3 6 6 2 3 6 6 0 0 0 0 0 

diff: 
correct output grid

TEST d8c310e9.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 2.1 sec (2.1 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-57] Checking task d90796e8.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 39163.0 = 39165.3
DL output with Mo: L = 2.3 + 39163.0 = 39165.3
DL input+output M: L = 4.6 + 78325.9 = 78330.6

# learning a model for train pairs
2.000	
1.174	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.407	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.390	OUT ADD ^.layer_0 = point with color ? at (?,?)
0.372	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.355	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.338	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.320	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.308	OUT SPE ^.size = ^.size
0.300	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.294	OUT SPE ^.layer_01.pos = ^.layer_01.pos
0.292	IN  SPE ^.color = black
0.290	OUT SPE ^.color = black
0.113	
0.112	IN  DEL ^.layer_011
0.112	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: point with color ? at ^.layer_0.pos
  _01: point with color ? at ^.layer_01.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 68.8 + 6960.8 = 7029.6
DL output with Mo: L = 41.1 + 4280.7 = 4321.8
DL input+output M: L = 109.9 + 11241.5 = 11351.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: point with color ? at ^.layer_0.pos
  _01: point with color ? at ^.layer_01.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.6 + 20.0 = 70.6
DL output with Mo: L = 41.1 + 4280.7 = 4321.8
DL input+output M: L = 91.7 + 4300.7 = 4392.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: point with color green at (0,0)
  _01: point with color grey at (2,1)
  + 1 delta pixels
diff: 
   (2.0 bits)
data: a background with size (3,3) and color black and layers
  _0: point with color cyan at (0,0)
  _01: point with color grey at (2,1)
diff: 
   (11.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: point with color green at (0,0)
  _01: point with color red at (0,1)
  + 1 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color black and layers
  _0: point with color green at (0,0)
  _01: point with color grey at (2,1)
  + 1 delta pixels
diff: 
! 2 wrong pixels (generated / expected)

TRAIN d90796e8.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (7,6) and color black and layers
  _0: point with color grey at (0,0)
  _01: point with color green at (1,2)
  + 6 delta pixels
diff: 
   (0.0 bits)
data: a background with size (7,6) and color black and layers
  _0: point with color grey at (0,0)
  _01: point with color cyan at (1,2)
  + 4 delta pixels
diff: 
   (169.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,6) and color black and layers
  _0: point with color grey at (0,0)
  _01: point with color green at (1,2)
  + 6 delta pixels
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,6) and color black and layers
  _0: point with color grey at (0,0)
  _01: point with color red at (1,3)
  + 6 delta pixels
diff: 
! 7 wrong pixels (generated / expected)

TRAIN d90796e8.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (7,7) and color black and layers
  _0: point with color red at (0,5)
  _01: point with color green at (1,0)
  + 9 delta pixels
diff: 
   (0.0 bits)
data: a background with size (7,7) and color black and layers
  _0: point with color red at (0,5)
  _01: point with color green at (1,0)
  + 6 delta pixels
diff: 
   (247.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _0: point with color red at (0,5)
  _01: point with color green at (1,0)
  + 9 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,7) and color black and layers
  _0: point with color red at (0,5)
  _01: point with color green at (1,6)
  + 9 delta pixels
diff: 
! 8 wrong pixels (generated / expected)

TRAIN d90796e8.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,9) and color black and layers
  _0: point with color red at (0,4)
  _01: point with color grey at (0,8)
  + 13 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,9) and color black and layers
  _0: point with color red at (0,4)
  _01: point with color red at (1,1)
  + 13 delta pixels
diff: 
! 13 wrong pixels (generated / expected)

TEST d90796e8.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 13.8 sec (13.8 sec/task)
bits-train-error = 4280.7 bits (4280.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-56] Checking task d9f24cd1.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79850.6 = 79852.9
DL output with Mo: L = 2.3 + 79850.6 = 79852.9
DL input+output M: L = 4.6 + 159701.1 = 159705.8

# learning a model for train pairs
2.000	
1.062	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.401	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.306	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.216	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.124	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.119	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.113	OUT ADD ^.layer_01111 = point with color ? at (?,?)
0.107	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.102	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.096	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.090	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.084	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.079	OUT SPE ^.size = ^.size
0.075	OUT SPE ^.layer_0111 = ^.layer_01
0.071	OUT SPE ^.layer_01111 = ^.layer_0
0.066	OUT SPE ^.layer_011.shape = scaleTo(^.layer_0111.shape, projI(^.size) + (0, 1))
0.061	OUT SPE ^.layer_01.shape = scaleTo(^.layer_0111.shape, projI(^.size) + (0, 1))
0.057	OUT SPE ^.layer_0.shape.mask.size = projI(^.size) + (0, 2)
0.055	OUT SPE ^.layer_011.pos = projJ(^.layer_01111.pos)
0.052	OUT SPE ^.layer_0.pos = projJ(^.layer_0111.pos)
0.050	OUT SPE ^.layer_01.pos = projJ(^.layer_01111.pos) - (0, 3)
0.048	IN  SPE ^.layer_0.shape.color = grey
0.047	IN  SPE ^.layer_01.shape.color = grey
0.046	IN  SPE ^.layer_0111.shape.color = red
0.018	
0.018	IN  GEN ^.layer_0111.shape.color = ?
0.018	IN  GEN ^.layer_01.shape.color = ?
0.018	IN  GEN ^.layer_0.shape.color = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size projI(^.size) + (0, 2) with model ? with color ? at projJ(^.layer_0111.pos)
  _01: scaleTo(^.layer_0111.shape, projI(^.size) + (0, 1)) at projJ(^.layer_01111.pos) - (0, 3)
  _011: scaleTo(^.layer_0111.shape, projI(^.size) + (0, 1)) at projJ(^.layer_01111.pos)
  _0111: ^.layer_01
  _01111: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color grey at (?,?)
  _01: point with color grey at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color red at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 114.3 + 2257.0 = 2371.3
DL output with Mo: L = 245.4 + 1024.2 = 1269.6
DL input+output M: L = 359.7 + 3281.1 = 3640.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size projI(^.size) + (0, 2) with model ? with color ? at projJ(^.layer_0111.pos)
  _01: scaleTo(^.layer_0111.shape, projI(^.size) + (0, 1)) at projJ(^.layer_01111.pos) - (0, 3)
  _011: scaleTo(^.layer_0111.shape, projI(^.size) + (0, 1)) at projJ(^.layer_01111.pos)
  _0111: ^.layer_01
  _01111: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)

DL input  with Mi: L = 104.4 + 40.0 = 144.4
DL output with Mo: L = 245.4 + 1024.2 = 1269.6
DL input+output M: L = 349.8 + 1064.2 = 1413.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color grey at (3,6)
  _01: point with color grey at (5,2)
  _011: point with color red at (9,1)
  _0111: point with color red at (9,6)
  _01111: point with color red at (9,4)
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,2) with mask 
. 0 
. 0 
. 0 
. 0 
0 0 
0 . 
0 . 
0 . 
0 . 
0 . 
 with color red at (0,6)
  _01: 
2 
2 
2 
2 
2 
2 
2 
2 
2 
2 
 at (0,1)
  _011: 
2 
2 
2 
2 
2 
2 
2 
2 
2 
2 
 at (0,4)
  _0111: 
5#
 at (5,2)
  _01111: 
5#
 at (3,6)
diff: 
   (30.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color grey at (3,6)
  _01: point with color grey at (5,2)
  _011: point with color red at (9,1)
  _0111: point with color red at (9,4)
  _01111: point with color red at (9,6)
diff: 
! 49 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color grey at (3,6)
  _01: point with color grey at (5,2)
  _011: point with color red at (9,1)
  _0111: point with color red at (9,6)
  _01111: point with color red at (9,4)
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color grey at (3,6)
  _01: point with color grey at (5,2)
  _011: point with color red at (9,4)
  _0111: point with color red at (9,1)
  _01111: point with color red at (9,6)
diff: 
! 49 wrong pixels (generated / expected)

TRAIN d9f24cd1.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color grey at (3,5)
  _01: point with color grey at (5,1)
  _011: point with color grey at (6,8)
  _0111: point with color red at (9,1)
  _01111: point with color red at (9,7)
  + 1 delta pixels
diff: 
   (2.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,2) with mask 
. 0 
. 0 
. 0 
. 0 
. 0 
. 0 
0 0 
0 . 
0 . 
0 . 
 with color red at (0,1)
  _01: 
2 
2 
2 
2 
2 
2 
2 
2 
2 
2 
 at (0,4)
  _011: 
2 
2 
2 
2 
2 
2 
2 
2 
2 
2 
 at (0,7)
  _0111: 
5#
 at (5,1)
  _01111: 
5#
 at (3,5)
  + 1 delta pixels
diff: 
   (72.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color grey at (3,5)
  _01: point with color grey at (5,1)
  _011: point with color grey at (6,8)
  _0111: point with color red at (9,1)
  _01111: point with color red at (9,4)
  + 1 delta pixels
diff: 
! 31 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color grey at (3,5)
  _01: point with color grey at (5,1)
  _011: point with color grey at (6,8)
  _0111: point with color red at (9,1)
  _01111: point with color red at (9,7)
  + 1 delta pixels
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color grey at (3,5)
  _01: point with color grey at (5,1)
  _011: point with color grey at (6,8)
  _0111: point with color red at (9,4)
  _01111: point with color red at (9,1)
  + 1 delta pixels
diff: 
! 44 wrong pixels (generated / expected)

TRAIN d9f24cd1.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color grey at (2,7)
  _01: point with color grey at (4,1)
  _011: point with color grey at (6,4)
  _0111: point with color red at (9,1)
  _01111: point with color red at (9,4)
  + 1 delta pixels
diff: 
! 45 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color grey at (2,7)
  _01: point with color grey at (4,1)
  _011: point with color grey at (6,4)
  _0111: point with color red at (9,1)
  _01111: point with color red at (9,8)
  + 1 delta pixels
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color grey at (2,7)
  _01: point with color grey at (4,1)
  _011: point with color grey at (6,4)
  _0111: point with color red at (9,4)
  _01111: point with color red at (9,1)
  + 1 delta pixels
diff: 
! 41 wrong pixels (generated / expected)

TEST d9f24cd1.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.5 sec (59.5 sec/task)
bits-train-error = 1024.2 bits (1024.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-55] Checking task d9fac9be.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 135112.0 = 135114.3
DL output with Mo: L = 2.3 + 1944.9 = 1947.3
DL input+output M: L = 4.6 + 137056.9 = 137061.6

# learning a model for train pairs
2.000	
1.283	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.610	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.476	OUT SPE ^.size = '(1, 1)
0.388	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.362	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.353	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.177	OUT SPE ^.color = ^.layer_011.shape.color
0.168	IN  ADD ^.layer_0110 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.161	IN  ADD ^.layer_01100 = point with color ? at (?,?)
0.155	IN  ADD ^.layer_011001 = point with color ? at (?,?)
0.148	IN  ADD ^.layer_01101 = point with color ? at (?,?)
0.142	IN  ADD ^.layer_0110010 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.141	IN  SPE ^.layer_011.shape.mask.model = Full
0.140	IN  SPE ^.color = black
0.018	
0.018	IN  DEL ^.layer_0110
0.018	IN  DEL ^.layer_0110010
0.018	IN  DEL ^.layer_01101
0.018	IN  GEN ^.layer_011.shape.mask.model = ?
0.018	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(1, 1) and color ^.layer_011.shape.color and layers
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01100: point with color ? at (?,?)
  _0110010: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011001: point with color ? at (?,?)
  _0110: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01101: point with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 207.0 + 16471.2 = 16678.2
DL output with Mo: L = 32.9 + 0.0 = 32.9
DL input+output M: L = 239.9 + 16471.2 = 16711.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(1, 1) and color ^.layer_011.shape.color and layers
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01100: point with color ? at (?,?)
  _011001: point with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 133.8 + 0.0 = 133.8
DL output with Mo: L = 32.9 + 0.0 = 32.9
DL input+output M: L = 166.7 + 0.0 = 166.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (5,9) and color black and layers
  _0: rectangle with size (3,3) with model Full with color yellow at (1,1)
  _01: rectangle with size (2,2) with model Even Checkboard with color red at (2,6)
  _01100: point with color red at (0,0)
  _011001: point with color red at (0,5)
  _011: rectangle with size (1,1) with model Full with color red at (0,8)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (1,1) and color red and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,9) and color black and layers
  _0: rectangle with size (3,3) with model Full with color yellow at (1,1)
  _01: rectangle with size (2,2) with model Even Checkboard with color red at (2,6)
  _01100: point with color red at (0,0)
  _011001: point with color red at (0,5)
  _011: rectangle with size (1,1) with model Full with color red at (0,8)
  + 3 delta pixels
diff: 
correct output grid

TRAIN d9fac9be.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (7,9) and color black and layers
  _0: rectangle with size (3,3) with model Full with color green at (2,5)
  _01: rectangle with size (2,2) with model Even Checkboard with color cyan at (5,2)
  _01100: point with color cyan at (0,0)
  _011001: point with color cyan at (0,2)
  _011: rectangle with size (1,1) with model Full with color cyan at (0,8)
  + 7 delta pixels
diff: 
   (0.0 bits)
data: a background with size (1,1) and color cyan and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,9) and color black and layers
  _0: rectangle with size (3,3) with model Full with color green at (2,5)
  _01: rectangle with size (2,2) with model Even Checkboard with color cyan at (5,2)
  _01100: point with color cyan at (0,0)
  _011001: point with color cyan at (0,2)
  _011: rectangle with size (1,1) with model Full with color cyan at (0,8)
  + 7 delta pixels
diff: 
correct output grid

TRAIN d9fac9be.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (11,9) and color black and layers
  _0: rectangle with size (3,3) with model Full with color red at (6,1)
  _01: rectangle with size (4,5) with mask 
0 . . . . 
. 0 . . . 
. . 0 . 0 
. . . 0 . 
 with color red at (0,1)
  _01100: point with color blue at (0,0)
  _011001: point with color blue at (2,2)
  _011: rectangle with size (1,2) with model Full with color blue at (2,7)
  + 11 delta pixels
diff: 
   (0.0 bits)
data: a background with size (1,1) and color blue and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,9) and color black and layers
  _0: rectangle with size (3,3) with model Full with color red at (6,1)
  _01: rectangle with size (4,5) with mask 
0 . . . . 
. 0 . . . 
. . 0 . 0 
. . . 0 . 
 with color red at (0,1)
  _01100: point with color blue at (0,0)
  _011001: point with color blue at (2,2)
  _011: rectangle with size (1,2) with model Full with color blue at (2,7)
  + 11 delta pixels
diff: 
correct output grid

TRAIN d9fac9be.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: a background with size (11,12) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 0 0 
0 0 . 0 
. 0 0 0 
0 . . . 
 with color green at (7,2)
  _01: rectangle with size (3,4) with mask 
0 . . . 
. 0 0 . 
. . . 0 
 with color green at (1,0)
  _01100: point with color cyan at (0,1)
  _011001: point with color green at (0,10)
  _011: rectangle with size (2,2) with model Even Checkboard with color cyan at (2,3)
  + 12 delta pixels
diff: 
   (0.0 bits)
data: a background with size (1,1) and color cyan and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,12) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 0 0 
0 0 . 0 
. 0 0 0 
0 . . . 
 with color green at (7,2)
  _01: rectangle with size (3,4) with mask 
0 . . . 
. 0 0 . 
. . . 0 
 with color green at (1,0)
  _01100: point with color cyan at (0,1)
  _011001: point with color green at (0,10)
  _011: rectangle with size (2,2) with model Even Checkboard with color cyan at (2,3)
  + 12 delta pixels
diff: 
correct output grid

TRAIN d9fac9be.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 . . . . 
. 0 0 0 . 
. 0 . 0 0 
. 0 0 0 . 
. . . . 0 
 with color blue at (7,3)
  _01: rectangle with size (2,1) with model Full with color blue at (0,9)
  _01100: point with color blue at (1,0)
  _011001: point with color yellow at (1,6)
  _011: rectangle with size (1,2) with model Full with color yellow at (5,7)
  + 15 delta pixels
diff: 
correct output grid

TEST d9fac9be.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 3.8 sec (3.8 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-54] Checking task dae9d2b5.json: 5 train, 2 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 34872.1 = 34874.5
DL output with Mo: L = 2.3 + 17558.0 = 17560.3
DL input+output M: L = 4.6 + 52430.1 = 52434.8

# learning a model for train pairs
2.000	
1.395	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.791	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.550	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.422	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.344	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.308	OUT SPE ^.size = ^.size - (0, 3)
0.283	OUT SPE ^.color = pink
0.267	OUT SPE ^.layer_0.shape.color = black
0.252	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.227	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.218	OUT SPE ^.layer_0.pos.i = ^.layer_011.pos.i / '2
0.209	OUT SPE ^.layer_0.pos.j = ^.layer_011.pos.i / '2
0.198	OUT SPE ^.layer_0.shape.mask.size.j = ^.layer_01.shape.mask.size.i + ^.layer_0111.pos.i - ^.layer_01.pos.i
0.194	IN  SPE ^.layer_01.shape.mask.model = Full
0.191	IN  SPE ^.color = black
0.052	
0.052	IN  GEN ^.layer_01.shape.mask.model = ?
0.052	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size - (0, 3) and color pink and layers
  _0: rectangle with size (?,^.layer_01.shape.mask.size.i + ^.layer_0111.pos.i - ^.layer_01.pos.i) with model ? with color black at (^.layer_011.pos.i / '2,^.layer_011.pos.i / '2)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 106.8 + 4881.5 = 4988.3
DL output with Mo: L = 200.0 + 634.0 = 834.0
DL input+output M: L = 306.9 + 5515.5 = 5822.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size - (0, 3) and color pink and layers
  _0: rectangle with size (?,^.layer_01.shape.mask.size.i + ^.layer_0111.pos.i - ^.layer_01.pos.i) with model ? with color black at (^.layer_011.pos.i / '2,^.layer_011.pos.i / '2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 106.2 + 40.0 = 146.2
DL output with Mo: L = 200.0 + 634.0 = 834.0
DL input+output M: L = 306.2 + 674.0 = 980.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,6) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color yellow at (0,0)
  _01: rectangle with size (1,2) with model Full with color green at (0,3)
  _011: point with color green at (1,3)
  _0111: point with color green at (2,5)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color pink and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
. 0 0 
0 0 . 
 with color black at (0,0)
diff: 
   (17.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color yellow at (0,0)
  _01: rectangle with size (1,2) with model Full with color green at (0,3)
  _011: point with color green at (1,3)
  _0111: point with color green at (2,5)
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color yellow at (0,0)
  _01: rectangle with size (1,2) with model Full with color green at (0,3)
  _011: point with color green at (2,5)
  _0111: point with color green at (1,3)
diff: 
! 3 wrong pixels (generated / expected)

TRAIN dae9d2b5.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (3,6) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 0 
0 . 
0 . 
 with color green at (0,3)
  _01: rectangle with size (2,1) with model Full with color yellow at (0,0)
  _011: point with color yellow at (2,2)
  _0111: point with color yellow at (0,2)
diff: 
   (2.0 bits)
data: a background with size (3,3) and color pink and layers
  _0: rectangle with size (2,2) with mask 
0 0 
0 . 
 with color black at (1,1)
diff: 
   (10.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 0 
0 . 
0 . 
 with color green at (0,3)
  _01: rectangle with size (2,1) with model Full with color yellow at (0,0)
  _011: point with color yellow at (0,2)
  _0111: point with color yellow at (2,2)
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 0 
0 . 
0 . 
 with color green at (0,3)
  _01: rectangle with size (2,1) with model Full with color yellow at (0,0)
  _011: point with color yellow at (2,2)
  _0111: point with color yellow at (0,2)
diff: 
! 1 wrong pixels (generated / expected)

TRAIN dae9d2b5.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (3,6) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
. 0 0 
0 0 . 
 with color yellow at (0,0)
  _01: rectangle with size (2,1) with model Full with color green at (1,5)
  _011: point with color green at (1,3)
  _0111: point with color green at (0,4)
diff: 
   (2.0 bits)
data: a background with size (3,3) and color pink and layers
  _0: rectangle with size (1,1) with model Full with color black at (0,0)
diff: 
   (6.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
. 0 0 
0 0 . 
 with color yellow at (0,0)
  _01: rectangle with size (2,1) with model Full with color green at (1,5)
  _011: point with color green at (0,4)
  _0111: point with color green at (1,3)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
. 0 0 
0 0 . 
 with color yellow at (0,0)
  _01: rectangle with size (2,1) with model Full with color green at (1,5)
  _011: point with color green at (1,3)
  _0111: point with color green at (0,4)
diff: 
! 1 wrong pixels (generated / expected)

TRAIN dae9d2b5.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (3,6) and color black and layers
  _0: rectangle with size (1,2) with model Full with color yellow at (0,0)
  _01: rectangle with size (1,1) with model Full with color green at (0,3)
  _011: point with color green at (1,5)
  _0111: point with color yellow at (2,0)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color pink and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
. 0 0 
 with color black at (0,0)
diff: 
   (17.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (1,2) with model Full with color yellow at (0,0)
  _01: rectangle with size (1,1) with model Full with color green at (0,3)
  _011: point with color green at (1,5)
  _0111: point with color yellow at (2,0)
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (1,2) with model Full with color yellow at (0,0)
  _01: rectangle with size (1,1) with model Full with color green at (0,3)
  _011: point with color yellow at (2,0)
  _0111: point with color green at (1,5)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (1,2) with model Full with color yellow at (0,0)
  _01: rectangle with size (1,1) with model Full with color green at (1,5)
  _011: point with color green at (0,3)
  _0111: point with color yellow at (2,0)
diff: 
! 5 wrong pixels (generated / expected)

TRAIN dae9d2b5.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: a background with size (3,6) and color black and layers
  _0: rectangle with size (1,2) with model Full with color green at (2,3)
  _01: rectangle with size (1,1) with model Full with color green at (0,4)
  _011: point with color yellow at (1,0)
  _0111: point with color yellow at (2,2)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color pink and layers
  _0: rectangle with size (2,3) with mask 
0 . 0 
. 0 0 
 with color black at (0,0)
diff: 
   (12.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (1,2) with model Full with color green at (2,3)
  _01: rectangle with size (1,1) with model Full with color green at (0,4)
  _011: point with color yellow at (1,0)
  _0111: point with color yellow at (2,2)
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (1,2) with model Full with color green at (2,3)
  _01: rectangle with size (1,1) with model Full with color green at (0,4)
  _011: point with color yellow at (2,2)
  _0111: point with color yellow at (1,0)
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (1,2) with model Full with color green at (2,3)
  _01: rectangle with size (1,1) with model Full with color yellow at (1,0)
  _011: point with color green at (0,4)
  _0111: point with color yellow at (2,2)
diff: 
! 4 wrong pixels (generated / expected)

TRAIN dae9d2b5.json/5: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 . 
0 0 
0 . 
 with color green at (0,3)
  _01: rectangle with size (1,2) with model Full with color yellow at (0,1)
  _011: point with color yellow at (1,0)
  _0111: point with color yellow at (2,1)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 . 
0 0 
0 . 
 with color green at (0,3)
  _01: rectangle with size (1,2) with model Full with color yellow at (0,1)
  _011: point with color yellow at (2,1)
  _0111: point with color yellow at (1,0)
diff: 
! 2 wrong pixels (generated / expected)

TEST dae9d2b5.json/1: 0 - (FAILURE)

## instance 2

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
0 . . 
 with color green at (0,3)
  _01: rectangle with size (1,1) with model Full with color yellow at (0,2)
  _011: point with color yellow at (1,1)
  _0111: point with color yellow at (2,0)
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
0 . . 
 with color green at (0,3)
  _01: rectangle with size (1,1) with model Full with color yellow at (0,2)
  _011: point with color yellow at (2,0)
  _0111: point with color yellow at (1,1)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (3,6) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 0 0 
0 . . 
 with color green at (0,3)
  _01: rectangle with size (1,1) with model Full with color yellow at (1,1)
  _011: point with color yellow at (0,2)
  _0111: point with color yellow at (2,0)
diff: 
! 5 wrong pixels (generated / expected)

TEST dae9d2b5.json/2: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 7.8 sec (7.8 sec/task)
bits-train-error = 634.0 bits (634.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-53] Checking task db3e9e38.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 35680.0 = 35682.3
DL output with Mo: L = 2.3 + 35680.0 = 35682.3
DL input+output M: L = 4.6 + 71360.0 = 71364.6

# learning a model for train pairs
2.000	
1.111	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.537	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.392	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.310	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.224	OUT ADD ^.layer_00 = ^.layer_0
0.134	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.107	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.097	OUT SPE ^.size = ^.size
0.090	OUT SPE ^.layer_0.shape.mask.size = tiling(^.layer_0.shape.mask.size - (1, 0), 1, 3)
0.084	OUT SPE ^.layer_011.pos = '(0, 0)
0.079	OUT SPE ^.layer_0.pos = ^.layer_0.pos - (0, 1)
0.075	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.070	OUT SPE ^.layer_0111.pos = tiling('(0, 3), 1, 2)
0.067	IN  SPE ^.layer_0.shape.color = orange
0.064	OUT SPE ^.layer_0.shape.color = cyan
0.061	OUT SPE ^.layer_01.shape.mask.size.i = 2
0.058	OUT SPE ^.layer_01.pos.i = '0
0.057	IN  SPE ^.layer_0.shape.mask.model = Full
0.055	OUT SPE ^.layer_0.shape.mask.model = Full
0.054	OUT SPE ^.layer_01.shape.mask.model = Full
0.052	OUT SPE ^.layer_011.shape.mask.model = Full
0.051	IN  SPE ^.color = black
0.049	OUT SPE ^.color = black
0.028	
0.028	IN  GEN ^.layer_0.shape.color = ?
0.028	IN  GEN ^.layer_0.shape.mask.model = ?
0.027	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size tiling(^.layer_0.shape.mask.size - (1, 0), 1, 3) with model Full with color cyan at ^.layer_0.pos - (0, 1)
  _01: rectangle with size (2,?) with model Full with color ? at ('0,?)
  _011: rectangle with size (?,?) with model Full with color ? at '(0, 0)
  _0111: point with color ? at tiling('(0, 3), 1, 2)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color orange at (?,?)

DL input  with Mi: L = 45.9 + 773.2 = 819.1
DL output with Mo: L = 173.0 + 766.2 = 939.2
DL input+output M: L = 219.0 + 1539.3 = 1758.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size tiling(^.layer_0.shape.mask.size - (1, 0), 1, 3) with model Full with color cyan at ^.layer_0.pos - (0, 1)
  _01: rectangle with size (2,?) with model Full with color ? at ('0,?)
  _011: rectangle with size (?,?) with model Full with color ? at '(0, 0)
  _0111: point with color ? at tiling('(0, 3), 1, 2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 173.0 + 766.2 = 939.2
DL input+output M: L = 215.0 + 766.2 = 981.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (5,7) and color black and layers
  _0: rectangle with size (4,1) with model Full with color orange at (0,3)
diff: 
   (0.0 bits)
data: a background with size (5,7) and color black and layers
  _00: 
7#
7#
7#
7#
 at (0,3)
  _0: rectangle with size (3,3) with model Full with color cyan at (0,2)
  _01: rectangle with size (2,5) with model Full with color orange at (0,1)
  _011: rectangle with size (1,1) with model Full with color cyan at (0,0)
  _0111: point with color cyan at (0,6)
diff: 
   (36.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,7) and color black and layers
  _0: rectangle with size (4,1) with model Full with color orange at (0,3)
diff: 
! 7 wrong pixels (generated / expected)

TRAIN db3e9e38.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (7,8) and color black and layers
  _0: rectangle with size (5,1) with model Full with color orange at (0,2)
diff: 
   (0.0 bits)
data: a background with size (7,8) and color black and layers
  _00: 
7#
7#
7#
7#
7#
 at (0,2)
  _0: rectangle with size (4,3) with model Full with color cyan at (0,1)
  _01: rectangle with size (2,1) with model Full with color cyan at (0,5)
  _011: rectangle with size (3,5) with model Full with color orange at (0,0)
  _0111: point with color orange at (0,6)
diff: 
   (40.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,8) and color black and layers
  _0: rectangle with size (5,1) with model Full with color orange at (0,2)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN db3e9e38.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (7,1) with model Full with color orange at (0,5)
diff: 
! 23 wrong pixels (generated / expected)

TEST db3e9e38.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 7.5 sec (7.5 sec/task)
bits-train-error = 766.2 bits (766.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-52] Checking task db93a21d.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 465072.6 = 465074.9
DL output with Mo: L = 2.3 + 465072.6 = 465074.9
DL input+output M: L = 4.6 + 930145.2 = 930149.9

# learning a model for train pairs
2.000	
1.134	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.743	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.518	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.405	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.326	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.247	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.197	OUT ADD ^.layer_00 = ^.layer_0
0.156	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.123	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.091	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.069	OUT ADD ^.layer_010 = ^.layer_01
0.066	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.064	OUT SPE ^.size = ^.size
0.061	OUT SPE ^.layer_01.pos.i = right(^.layer_01) + ^.layer_01.pos.i - ^.layer_0.pos.i
0.060	IN  SPE ^.layer_0.shape.color = brown
0.060	IN  SPE ^.layer_01.shape.color = brown
0.059	IN  SPE ^.layer_0.shape.mask.model = Full
0.059	IN  SPE ^.layer_01.shape.mask.model = Full
0.059	OUT SPE ^.layer_01111.shape.mask.model = Full
0.058	OUT SPE ^.layer_0111.shape.mask.size.j = average(^.layer_0.shape.mask.size.j, ^.layer_01.shape.mask.size.j) - 1
0.058	OUT SPE ^.layer_011111.shape.mask.model = Full
0.058	IN  SPE ^.color = black
0.058	OUT SPE ^.color = black
0.037	
0.037	IN  GEN ^.layer_01.shape.color = ?
0.037	IN  GEN ^.layer_0.shape.color = ?
0.037	IN  GEN ^.layer_01.shape.mask.model = ?
0.037	IN  GEN ^.layer_0.shape.mask.model = ?
0.037	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _01: rectangle with size (?,?) with model ? with color ? at (right(^.layer_01) + ^.layer_01.pos.i - ^.layer_0.pos.i,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,average(^.layer_0.shape.mask.size.j, ^.layer_01.shape.mask.size.j) - 1) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011111: rectangle with size (?,?) with model Full with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color brown at (?,?)
  _01: rectangle with size (?,?) with model Full with color brown at (?,?)

DL input  with Mi: L = 78.0 + 9771.9 = 9849.9
DL output with Mo: L = 277.0 + 16765.4 = 17042.4
DL input+output M: L = 355.0 + 26537.3 = 26892.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _01: rectangle with size (?,?) with model ? with color ? at (right(^.layer_01) + ^.layer_01.pos.i - ^.layer_0.pos.i,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,average(^.layer_0.shape.mask.size.j, ^.layer_01.shape.mask.size.j) - 1) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011111: rectangle with size (?,?) with model Full with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 277.0 + 16765.4 = 17042.4
DL input+output M: L = 347.3 + 16765.4 = 17112.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color brown at (0,6)
  _01: rectangle with size (2,2) with model Full with color brown at (7,1)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
9#9#
9#9#
 at (0,6)
  _0: rectangle with size (7,2) with model Full with color blue at (3,6)
  _010: 
9#9#
9#9#
 at (7,1)
  _01: rectangle with size (1,4) with model Full with color green at (9,0)
  _011: rectangle with size (3,4) with model Full with color green at (0,5)
  _0111: rectangle with size (4,1) with model Full with color green at (6,0)
  _01111: rectangle with size (1,4) with model Full with color green at (6,0)
  _011111: rectangle with size (4,1) with model Full with color green at (6,3)
diff: 
   (174.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color brown at (0,6)
  _01: rectangle with size (2,2) with model Full with color brown at (7,1)
diff: 
! 38 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,2) with model Full with color brown at (7,1)
  _01: rectangle with size (2,2) with model Full with color brown at (0,6)
diff: 
! 38 wrong pixels (generated / expected)

TRAIN db93a21d.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (4,4) with model Full with color brown at (2,8)
  _01: rectangle with size (2,2) with model Full with color brown at (6,3)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _00: 
9#9#9#9#
9#9#9#9#
9#9#9#9#
9#9#9#9#
 at (2,8)
  _0: rectangle with size (7,4) with model Full with color blue at (8,8)
  _010: 
9#9#
9#9#
 at (6,3)
  _01: rectangle with size (1,13) with model Full with color green at (8,2)
  _011: rectangle with size (12,13) with mask 
. . . . 0 0 0 0 0 0 0 0 . 
. . . . 0 0 0 0 0 0 0 0 . 
. . . . 0 0 . . . . 0 0 . 
. . . . 0 0 . . . . 0 0 . 
. . . . 0 0 . . . . 0 0 . 
0 0 0 0 0 0 . . . . 0 0 . 
0 . . 0 0 0 0 0 0 0 0 0 . 
0 . . 0 0 0 0 0 0 0 0 0 . 
0 0 0 0 . . . . . . 0 0 0 
. . . . . . . . . . 0 . . 
. . . . . . . . . . 0 . . 
. . . . . . . . . . 0 0 0 
 with color green at (0,2)
  _0111: rectangle with size (6,2) with model Full with color blue at (9,3)
  _01111: rectangle with size (3,2) with model Full with color blue at (12,13)
  _011111: rectangle with size (2,2) with model Full with color brown at (9,13)
  + 2 delta pixels
diff: 
   (435.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (4,4) with model Full with color brown at (2,8)
  _01: rectangle with size (2,2) with model Full with color brown at (6,3)
  + 4 delta pixels
diff: 
! 126 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (2,2) with model Full with color brown at (6,3)
  _01: rectangle with size (4,4) with model Full with color brown at (2,8)
  + 4 delta pixels
diff: 
! 126 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (4,4) with model Full with color brown at (2,8)
  _01: rectangle with size (2,2) with model Full with color brown at (9,13)
  + 4 delta pixels
diff: 
! 122 wrong pixels (generated / expected)

TRAIN db93a21d.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (6,6) with model Full with color brown at (12,6)
  _01: rectangle with size (4,4) with model Full with color brown at (6,15)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _00: 
9#9#9#9#9#9#
9#9#9#9#9#9#
9#9#9#9#9#9#
9#9#9#9#9#9#
9#9#9#9#9#9#
9#9#9#9#9#9#
 at (12,6)
  _0: rectangle with size (16,17) with mask 
. . . . . . . . . . 0 0 0 0 0 0 0 
. . . . . . . . . . 0 0 0 0 0 0 0 
. . . . . . . . . . 0 0 . . . . 0 
. . . . . . . . . . 0 0 . . . . 0 
. . . . . . . . . . 0 0 . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 . . . . . . 0 0 0 . . . . . 
0 0 0 . . . . . . 0 0 0 . . . . . 
0 0 0 . . . . . . 0 0 0 . . . . . 
0 0 0 . . . . . . 0 0 0 . . . . . 
0 0 0 . . . . . . 0 0 0 . . . . . 
0 0 0 . . . . . . 0 0 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . . 
0 0 0 0 0 0 0 0 0 0 0 0 . . . . . 
 with color green at (4,3)
  _010: 
9#9#9#9#
9#9#9#9#
9#9#9#9#
9#9#9#9#
 at (6,15)
  _01: rectangle with size (8,4) with model Full with color blue at (12,15)
  _011: rectangle with size (14,1) with model Full with color blue at (6,2)
  _0111: rectangle with size (4,4) with model Border with color green at (2,1)
  _01111: rectangle with size (2,2) with model Full with color brown at (3,2)
  _011111: rectangle with size (3,2) with model Full with color blue at (6,2)
diff: 
   (477.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (6,6) with model Full with color brown at (12,6)
  _01: rectangle with size (4,4) with model Full with color brown at (6,15)
  + 4 delta pixels
diff: 
! 207 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (4,4) with model Full with color brown at (6,15)
  _01: rectangle with size (6,6) with model Full with color brown at (12,6)
  + 4 delta pixels
diff: 
! 207 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (6,6) with model Full with color brown at (12,6)
  _01: rectangle with size (2,2) with model Full with color brown at (3,2)
  + 16 delta pixels
diff: 
! 213 wrong pixels (generated / expected)

TRAIN db93a21d.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (20,20) and color black and layers
  _0: rectangle with size (6,6) with model Full with color brown at (9,14)
  _01: rectangle with size (4,4) with model Full with color brown at (8,2)
  + 8 delta pixels
diff: 
   (0.0 bits)
data: a background with size (20,20) and color black and layers
  _00: 
9#9#9#9#9#9#
9#9#9#9#9#9#
9#9#9#9#9#9#
9#9#9#9#9#9#
9#9#9#9#9#9#
9#9#9#9#9#9#
 at (9,14)
  _0: rectangle with size (12,9) with model Full with color green at (6,11)
  _010: 
9#9#9#9#
9#9#9#9#
9#9#9#9#
9#9#9#9#
 at (8,2)
  _01: rectangle with size (16,4) with mask 
0 0 0 0 
0 0 0 0 
. 0 0 0 
. 0 0 0 
. 0 0 0 
. 0 0 0 
. 0 0 0 
. 0 0 0 
. 0 0 0 
. 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
 with color blue at (4,7)
  _011: rectangle with size (8,8) with model Full with color green at (6,0)
  _0111: rectangle with size (6,4) with model Full with color blue at (14,2)
  _01111: rectangle with size (4,8) with model Full with color green at (0,5)
  _011111: rectangle with size (2,6) with model Full with color blue at (18,14)
  + 8 delta pixels
diff: 
   (588.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (6,6) with model Full with color brown at (9,14)
  _01: rectangle with size (4,4) with model Full with color brown at (8,2)
  + 8 delta pixels
diff: 
! 256 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (4,4) with model Full with color brown at (8,2)
  _01: rectangle with size (6,6) with model Full with color brown at (9,14)
  + 8 delta pixels
diff: 
! 252 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (6,6) with model Full with color brown at (9,14)
  _01: rectangle with size (2,4) with model Full with color brown at (0,7)
  + 16 delta pixels
diff: 
! 262 wrong pixels (generated / expected)

TRAIN db93a21d.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (6,6) with model Full with color brown at (16,21)
  _01: rectangle with size (4,4) with model Full with color brown at (2,16)
  + 20 delta pixels
diff: 
! 417 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (6,6) with model Full with color brown at (16,21)
  _01: rectangle with size (4,4) with model Full with color brown at (7,9)
  + 20 delta pixels
diff: 
! 417 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (30,30) and color black and layers
  _0: rectangle with size (4,4) with model Full with color brown at (2,16)
  _01: rectangle with size (6,6) with model Full with color brown at (16,21)
  + 20 delta pixels
diff: 
! 413 wrong pixels (generated / expected)

TEST db93a21d.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 49.9 sec (49.9 sec/task)
bits-train-error = 16765.4 bits (16765.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-51] Checking task dbc1a6ce.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 166456.9 = 166459.2
DL output with Mo: L = 2.3 + 166456.9 = 166459.2
DL input+output M: L = 4.6 + 332913.8 = 332918.5

# learning a model for train pairs
2.000	
1.095	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.350	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.256	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.217	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.203	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.194	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.184	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.177	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.171	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.166	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.160	OUT ADD ^.layer_010 = ^.layer_01
0.153	OUT ADD ^.layer_00 = ^.layer_0
0.148	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.142	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.137	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.131	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.126	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.121	OUT SPE ^.size = ^.size
0.118	OUT SPE ^.layer_0111.pos = ^.layer_01111.pos
0.117	OUT SPE ^.layer_011111.shape.color = ^.layer_011111.shape.color
0.115	OUT SPE ^.layer_01111.shape.color = ^.layer_01111.shape.color
0.114	OUT SPE ^.layer_0111.shape.color = ^.layer_0111.shape.color
0.113	IN  SPE ^.layer_0.shape.color = blue
0.058	
0.058	IN  DEL ^.layer_0111111
0.058	IN  GEN ^.layer_0.shape.color = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ^.layer_0111.shape.color at ^.layer_01111.pos
  _01111: rectangle with size (?,?) with model ? with color ^.layer_01111.shape.color at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ^.layer_011111.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color blue at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)

DL input  with Mi: L = 143.0 + 9098.9 = 9241.9
DL output with Mo: L = 203.4 + 9335.1 = 9538.4
DL input+output M: L = 346.4 + 18434.0 = 18780.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ^.layer_0111.shape.color at ^.layer_01111.pos
  _01111: rectangle with size (?,?) with model ? with color ^.layer_01111.shape.color at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ^.layer_011111.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)

DL input  with Mi: L = 122.1 + 0.0 = 122.1
DL output with Mo: L = 203.4 + 9335.1 = 9538.4
DL input+output M: L = 325.4 + 9335.1 = 9660.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,9) and color black and layers
  _0: point with color blue at (0,3)
  _01: point with color blue at (1,8)
  _011: point with color blue at (4,1)
  _0111: point with color blue at (4,7)
  _01111: point with color blue at (6,1)
  _011111: point with color blue at (8,6)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,9) and color black and layers
  _00: 
1 
 at (0,3)
  _0: rectangle with size (8,6) with mask 
. . 0 . . . 
. . 0 . . . 
. . 0 . . . 
. 0 0 0 0 0 
0 . 0 . . . 
. . 0 . . . 
. . 0 . . . 
. . 0 . . . 
 with color cyan at (1,1)
  _010: 
1 
 at (1,8)
  _01: rectangle with size (1,1) with model Full with color blue at (4,1)
  _011: rectangle with size (1,1) with model Full with color blue at (4,7)
  _0111: rectangle with size (1,1) with model Full with color blue at (6,1)
  _01111: rectangle with size (1,1) with model Full with color blue at (8,6)
  _011111: rectangle with size (1,1) with model Full with color blue at (9,3)
diff: 
   (183.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,9) and color black and layers
  _0: point with color blue at (0,3)
  _01: point with color blue at (1,8)
  _011: point with color blue at (4,1)
  _0111: point with color blue at (4,7)
  _01111: point with color blue at (6,1)
  _011111: point with color blue at (8,6)
  + 1 delta pixels
diff: 
! 24 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,9) and color black and layers
  _0: point with color blue at (0,3)
  _01: point with color blue at (1,8)
  _011: point with color blue at (4,1)
  _0111: point with color blue at (4,7)
  _01111: point with color blue at (8,6)
  _011111: point with color blue at (6,1)
  + 1 delta pixels
diff: 
! 24 wrong pixels (generated / expected)

TRAIN dbc1a6ce.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,11) and color black and layers
  _0: point with color blue at (0,4)
  _01: point with color blue at (0,9)
  _011: point with color blue at (2,4)
  _0111: point with color blue at (2,8)
  _01111: point with color blue at (3,2)
  _011111: point with color blue at (7,0)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,11) and color black and layers
  _00: 
1 
 at (0,4)
  _0: rectangle with size (3,5) with mask 
. 0 0 0 0 
0 . . . . 
. 0 0 0 . 
 with color cyan at (0,4)
  _010: 
1 
 at (0,9)
  _01: rectangle with size (1,6) with model Full with color cyan at (7,1)
  _011: rectangle with size (1,5) with model Full with color blue at (2,4)
  _0111: rectangle with size (1,1) with model Full with color blue at (3,2)
  _01111: rectangle with size (1,8) with model Full with color blue at (7,0)
  _011111: rectangle with size (1,1) with model Full with color blue at (9,6)
diff: 
   (171.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,11) and color black and layers
  _0: point with color blue at (0,4)
  _01: point with color blue at (0,9)
  _011: point with color blue at (2,4)
  _0111: point with color blue at (2,8)
  _01111: point with color blue at (3,2)
  _011111: point with color blue at (7,0)
  + 2 delta pixels
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,11) and color black and layers
  _0: point with color blue at (0,4)
  _01: point with color blue at (0,9)
  _011: point with color blue at (2,4)
  _0111: point with color blue at (2,8)
  _01111: point with color blue at (7,0)
  _011111: point with color blue at (3,2)
  + 2 delta pixels
diff: 
! 25 wrong pixels (generated / expected)

TRAIN dbc1a6ce.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: point with color blue at (0,6)
  _01: point with color blue at (0,11)
  _011: point with color blue at (2,10)
  _0111: point with color blue at (4,5)
  _01111: point with color blue at (5,1)
  _011111: point with color blue at (5,9)
  + 7 delta pixels
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _00: 
1 
 at (0,6)
  _0: rectangle with size (7,9) with mask 
. . . . . 0 0 0 0 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . 0 
. . . . 0 . . . 0 
0 0 0 0 0 0 0 . 0 
. . . . . 0 0 0 . 
 with color cyan at (0,2)
  _010: 
1 
 at (0,11)
  _01: rectangle with size (3,5) with mask 
. 0 0 0 . 
0 . . . 0 
. 0 0 0 . 
 with color cyan at (9,4)
  _011: rectangle with size (5,1) with model Full with color blue at (2,10)
  _0111: rectangle with size (1,9) with model Full with color blue at (5,1)
  _01111: rectangle with size (3,1) with model Full with color blue at (9,4)
  _011111: rectangle with size (3,1) with model Full with color blue at (9,8)
  + 3 delta pixels
diff: 
   (369.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: point with color blue at (0,6)
  _01: point with color blue at (0,11)
  _011: point with color blue at (2,10)
  _0111: point with color blue at (4,5)
  _01111: point with color blue at (5,1)
  _011111: point with color blue at (5,9)
  + 7 delta pixels
diff: 
! 45 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: point with color blue at (0,6)
  _01: point with color blue at (0,11)
  _011: point with color blue at (2,10)
  _0111: point with color blue at (4,5)
  _01111: point with color blue at (5,9)
  _011111: point with color blue at (5,1)
  + 7 delta pixels
diff: 
! 42 wrong pixels (generated / expected)

TRAIN dbc1a6ce.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (8,9) and color black and layers
  _0: point with color blue at (0,1)
  _01: point with color blue at (0,4)
  _011: point with color blue at (2,4)
  _0111: point with color blue at (2,6)
  _01111: point with color blue at (3,0)
  _011111: point with color blue at (4,5)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (8,9) and color black and layers
  _00: 
1 
 at (0,1)
  _0: rectangle with size (3,4) with mask 
0 0 . . 
. . 0 . 
. . . 0 
 with color cyan at (0,2)
  _010: 
1 
 at (0,4)
  _01: rectangle with size (1,4) with model Full with color cyan at (5,3)
  _011: rectangle with size (3,1) with model Full with color cyan at (4,0)
  _0111: rectangle with size (5,1) with model Full with color blue at (3,0)
  _01111: rectangle with size (1,3) with model Full with color blue at (2,4)
  _011111: rectangle with size (1,6) with model Full with color blue at (5,2)
  + 1 delta pixels
diff: 
   (209.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,9) and color black and layers
  _0: point with color blue at (0,1)
  _01: point with color blue at (0,4)
  _011: point with color blue at (2,4)
  _0111: point with color blue at (2,6)
  _01111: point with color blue at (3,0)
  _011111: point with color blue at (4,5)
  + 3 delta pixels
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,9) and color black and layers
  _0: point with color blue at (0,1)
  _01: point with color blue at (0,4)
  _011: point with color blue at (2,4)
  _0111: point with color blue at (2,6)
  _01111: point with color blue at (4,5)
  _011111: point with color blue at (3,0)
  + 3 delta pixels
diff: 
! 21 wrong pixels (generated / expected)

TRAIN dbc1a6ce.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (19,21) and color black and layers
  _0: point with color blue at (0,7)
  _01: point with color blue at (0,10)
  _011: point with color blue at (0,14)
  _0111: point with color blue at (1,2)
  _01111: point with color blue at (2,10)
  _011111: point with color blue at (3,19)
  + 13 delta pixels
diff: 
! 78 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (19,21) and color black and layers
  _0: point with color blue at (0,7)
  _01: point with color blue at (0,10)
  _011: point with color blue at (0,14)
  _0111: point with color blue at (1,2)
  _01111: point with color blue at (3,19)
  _011111: point with color blue at (2,10)
  + 13 delta pixels
diff: 
! 79 wrong pixels (generated / expected)

TEST dbc1a6ce.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.8 sec (59.8 sec/task)
bits-train-error = 9335.1 bits (9335.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-50] Checking task dc0a314f.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 315315.2 = 315317.5
DL output with Mo: L = 2.3 + 29114.4 = 29116.7
DL input+output M: L = 4.6 + 344429.6 = 344434.2

# learning a model for train pairs
2.000	
1.588	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.281	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.022	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.877	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.804	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.741	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.704	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.672	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.643	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.616	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.589	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.562	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.542	IN  ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.538	OUT SPE ^.layer_0.pos.i = '0
0.533	OUT SPE ^.layer_011.pos.j = '0
0.529	OUT SPE ^.layer_01.pos.i = ^.layer_01.pos.i + 1
0.522	OUT SPE ^.layer_0.shape.mask.size.i = min(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i)
0.515	OUT SPE ^.size.i = min(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i)
0.166	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (min(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i),?) and color ? and layers
  _0: rectangle with size (min(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i),?) with model ? with color ? at ('0,?)
  _01: rectangle with size (?,?) with model ? with color ? at (^.layer_01.pos.i + 1,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,'0)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 208.3 + 110119.5 = 110327.9
DL output with Mo: L = 217.9 + 4591.8 = 4809.8
DL input+output M: L = 426.3 + 114711.4 = 115137.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (min(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i),?) and color ? and layers
  _0: rectangle with size (min(^.layer_0.shape.mask.size.i, ^.layer_01.shape.mask.size.i),?) with model ? with color ? at ('0,?)
  _01: rectangle with size (?,?) with model ? with color ? at (^.layer_01.pos.i + 1,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,'0)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 208.3 + 31.7 = 240.0
DL output with Mo: L = 217.9 + 4591.8 = 4809.8
DL input+output M: L = 426.3 + 4623.5 = 5049.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (16,16) and color grey and layers
  _0: rectangle with size (5,5) with model Full with color green at (5,9)
  _01: rectangle with size (14,4) with model Full with color pink at (1,11)
  _011: rectangle with size (6,4) with mask 
. . 0 0 
. . 0 0 
0 0 0 0 
0 0 0 0 
. . 0 0 
. . 0 0 
 with color cyan at (5,5)
  _0111: rectangle with size (14,2) with model Full with color red at (1,7)
  _01111: rectangle with size (6,3) with mask 
. . 0 
. . 0 
0 0 0 
0 0 0 
. . 0 
. . 0 
 with color red at (5,1)
  _011111: rectangle with size (4,4) with mask 
0 0 . . 
0 . 0 . 
. 0 0 0 
. . 0 . 
 with color pink at (1,1)
  _0111111: rectangle with size (4,4) with mask 
. . 0 . 
. 0 0 0 
0 . 0 . 
0 0 . . 
 with color pink at (11,1)
  + 104 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,5) and color grey and layers
  _0: rectangle with size (5,2) with mask 
0 . 
0 . 
0 0 
0 0 
0 . 
 with color red at (0,3)
  _01: rectangle with size (2,1) with model Full with color orange at (2,2)
  _011: rectangle with size (2,2) with model Full with color cyan at (2,0)
  _0111: rectangle with size (1,2) with model Full with color cyan at (0,1)
diff: 
   (115.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color grey and layers
  _0: rectangle with size (5,5) with model Full with color green at (5,9)
  _01: rectangle with size (14,4) with model Full with color pink at (1,11)
  _011: rectangle with size (6,4) with mask 
. . 0 0 
. . 0 0 
0 0 0 0 
0 0 0 0 
. . 0 0 
. . 0 0 
 with color cyan at (5,5)
  _0111: rectangle with size (14,2) with model Full with color red at (1,7)
  _01111: rectangle with size (6,3) with mask 
. . 0 
. . 0 
0 0 0 
0 0 0 
. . 0 
. . 0 
 with color red at (5,1)
  _011111: rectangle with size (4,4) with mask 
0 0 . . 
0 . 0 . 
. 0 0 0 
. . 0 . 
 with color pink at (1,1)
  _0111111: rectangle with size (4,4) with mask 
. . 0 . 
. 0 0 0 
0 . 0 . 
0 0 . . 
 with color pink at (11,1)
  + 104 delta pixels
diff: 
! size mismatch, 5x10 instead of 5x5

TRAIN dc0a314f.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (16,16) and color red and layers
  _0: rectangle with size (16,16) with mask 
. . . . . . . . . . 0 0 . . . . 
. . . . . . . . . 0 . 0 . . . . 
. . . . . . . . 0 . 0 . . . . . 
. . . . . . . . . 0 . . . . . . 
0 0 . . . . . . 0 . 0 . . . 0 0 
0 . 0 . 0 . 0 0 0 0 . 0 . 0 . 0 
. 0 . 0 . 0 . . . . 0 . 0 . 0 . 
. . 0 . 0 0 . . . . 0 0 . 0 . . 
. . 0 . 0 0 . . . . 0 0 . 0 . . 
. 0 . 0 . 0 . . . . 0 . 0 . 0 . 
0 . 0 . 0 . 0 0 0 0 . 0 . 0 . 0 
0 0 . . . 0 . 0 0 . 0 . . . 0 0 
. . . . . . 0 . . 0 . . . . . . 
. . . . . 0 . 0 0 . 0 . . . . . 
. . . . 0 . 0 . . 0 . 0 . . . . 
. . . . 0 0 . . . . 0 0 . . . . 
 with color orange at (0,0)
  _01: rectangle with size (5,5) with model Full with color green at (0,3)
  _011: rectangle with size (4,4) with mask 
. 0 0 . 
0 0 . 0 
. . 0 0 
. . 0 . 
 with color brown at (0,12)
  _0111: rectangle with size (4,4) with mask 
. 0 0 . 
0 . . 0 
0 . . 0 
. 0 0 . 
 with color cyan at (6,6)
  _01111: rectangle with size (4,4) with mask 
. 0 . . 
0 0 . . 
0 . 0 0 
. 0 0 . 
 with color brown at (12,0)
  _011111: rectangle with size (4,4) with mask 
. . 0 . 
. . 0 0 
0 0 . 0 
. 0 0 . 
 with color brown at (12,12)
  _0111111: rectangle with size (4,3) with mask 
. 0 0 
0 . 0 
0 0 . 
. 0 . 
 with color brown at (0,0)
  + 43 delta pixels
diff: 
   (3.2 bits)
data: a background with size (5,5) and color orange and layers
  _0: rectangle with size (5,5) with mask 
. . . 0 0 
. . . . 0 
0 0 . 0 . 
. 0 0 . . 
0 0 . . . 
 with color red at (0,0)
  _01: rectangle with size (3,1) with model Full with color brown at (1,0)
  _011: rectangle with size (1,1) with model Full with color cyan at (0,0)
  _0111: rectangle with size (1,1) with model Full with color blue at (1,2)
  + 2 delta pixels
diff: 
   (207.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (16,16) with mask 
. . . . . . . . . . 0 0 . . . . 
. . . . . . . . . 0 . 0 . . . . 
. . . . . . . . 0 . 0 . . . . . 
. . . . . . . . . 0 . . . . . . 
0 0 . . . . . . 0 . 0 . . . 0 0 
0 . 0 . 0 . 0 0 0 0 . 0 . 0 . 0 
. 0 . 0 . 0 . . . . 0 . 0 . 0 . 
. . 0 . 0 0 . . . . 0 0 . 0 . . 
. . 0 . 0 0 . . . . 0 0 . 0 . . 
. 0 . 0 . 0 . . . . 0 . 0 . 0 . 
0 . 0 . 0 . 0 0 0 0 . 0 . 0 . 0 
0 0 . . . 0 . 0 0 . 0 . . . 0 0 
. . . . . . 0 . . 0 . . . . . . 
. . . . . 0 . 0 0 . 0 . . . . . 
. . . . 0 . 0 . . 0 . 0 . . . . 
. . . . 0 0 . . . . 0 0 . . . . 
 with color orange at (0,0)
  _01: rectangle with size (16,16) with mask 
. . . . . . . . 0 0 . . . . . . 
. . . . . . . . 0 . . . . . . . 
. . . . . . . . . 0 . 0 0 . . . 
. . 0 . . . . . . . 0 0 . 0 . . 
. . 0 . . . . . . . . 0 0 0 . . 
. . . 0 . 0 . . . . 0 . 0 . . . 
0 . 0 . . . 0 . . 0 . . . 0 . 0 
0 0 . . . . . 0 0 . . . . . 0 0 
0 0 . . . . . 0 0 . . . . . 0 0 
0 . 0 . . . 0 . . 0 . . . 0 . 0 
. . . 0 . 0 . . . . 0 . 0 . . . 
. . 0 0 0 . . . . . . 0 0 0 . . 
. . 0 . 0 0 . . . . 0 0 . 0 . . 
. . . 0 0 . 0 . . 0 . 0 0 . . . 
. . . . . . . 0 0 . . . . . . . 
. . . . . . 0 0 0 0 . . . . . . 
 with color red at (0,0)
  _011: rectangle with size (5,5) with model Full with color green at (0,3)
  _0111: rectangle with size (4,16) with model Full with color brown at (12,0)
  _01111: rectangle with size (4,16) with model Full with color brown at (0,0)
  _011111: rectangle with size (4,4) with model Full with color cyan at (6,6)
  _0111111: rectangle with size (2,10) with model Full with color blue at (7,3)
  + 39 delta pixels
diff: 
! size mismatch, 16x10 instead of 5x5
>> Trial 2
data: a background with size (16,16) and color red and layers
  _0: rectangle with size (16,16) with mask 
. . . . . . . . . . 0 0 . . . . 
. . . . . . . . . 0 . 0 . . . . 
. . . . . . . . 0 . 0 . . . . . 
. . . . . . . . . 0 . . . . . . 
0 0 . . . . . . 0 . 0 . . . 0 0 
0 . 0 . 0 . 0 0 0 0 . 0 . 0 . 0 
. 0 . 0 . 0 . . . . 0 . 0 . 0 . 
. . 0 . 0 0 . . . . 0 0 . 0 . . 
. . 0 . 0 0 . . . . 0 0 . 0 . . 
. 0 . 0 . 0 . . . . 0 . 0 . 0 . 
0 . 0 . 0 . 0 0 0 0 . 0 . 0 . 0 
0 0 . . . 0 . 0 0 . 0 . . . 0 0 
. . . . . . 0 . . 0 . . . . . . 
. . . . . 0 . 0 0 . 0 . . . . . 
. . . . 0 . 0 . . 0 . 0 . . . . 
. . . . 0 0 . . . . 0 0 . . . . 
 with color orange at (0,0)
  _01: rectangle with size (5,5) with model Full with color green at (0,3)
  _011: rectangle with size (4,4) with mask 
. 0 0 . 
0 0 . 0 
. . 0 0 
. . 0 . 
 with color brown at (0,12)
  _0111: rectangle with size (4,4) with mask 
. 0 0 . 
0 . . 0 
0 . . 0 
. 0 0 . 
 with color cyan at (6,6)
  _01111: rectangle with size (4,4) with mask 
. 0 . . 
0 0 . . 
0 . 0 0 
. 0 0 . 
 with color brown at (12,0)
  _011111: rectangle with size (4,4) with mask 
. . 0 . 
. . 0 0 
0 0 . 0 
. 0 0 . 
 with color brown at (12,12)
  _0111111: rectangle with size (4,3) with mask 
. 0 0 
0 . 0 
0 0 . 
. 0 . 
 with color brown at (0,0)
  + 43 delta pixels
diff: 
! size mismatch, 5x10 instead of 5x5

TRAIN dc0a314f.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (16,16) and color black and layers
  _0: rectangle with size (16,16) with mask 
. . . . 0 0 0 . . . . . . . . . 
. . . . 0 . . . . . . . . . . . 
. . . . 0 . . . . . . . . . . . 
. . . . . 0 . . . . . . . . . . 
0 0 0 . 0 . 0 . . . . . . 0 0 0 
0 . . 0 . . 0 0 0 0 . . 0 . . 0 
0 . . . 0 0 . 0 0 . 0 0 . . . 0 
. 0 . . 0 0 0 . . 0 0 0 . . 0 . 
. 0 . . 0 0 0 . . 0 0 0 . . 0 . 
0 . . . 0 0 . 0 0 . 0 0 . . . 0 
0 . . 0 . . 0 0 0 0 . . 0 . . 0 
0 0 0 . 0 . 0 0 0 0 . 0 . 0 0 0 
. . . . . 0 . . . . 0 . . . . . 
. . . . 0 . . . . . . 0 . . . . 
. . . . 0 . . 0 0 . . 0 . . . . 
. . . . 0 0 0 . . 0 0 0 . . . . 
 with color brown at (0,0)
  _01: rectangle with size (5,5) with model Full with color green at (0,7)
  _011: rectangle with size (6,14) with model Full with color grey at (5,1)
  _0111: rectangle with size (14,3) with model Full with color yellow at (1,1)
  _01111: rectangle with size (14,3) with model Full with color yellow at (1,12)
  _011111: rectangle with size (3,6) with model Full with color grey at (12,5)
  _0111111: rectangle with size (1,16) with model Full with color red at (0,0)
  + 85 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,5) and color grey and layers
  _0: rectangle with size (5,5) with mask 
. . 0 0 0 
0 0 . . 0 
. . . . 0 
. . . 0 . 
0 0 0 . 0 
 with color brown at (0,0)
  _01: rectangle with size (2,2) with model Even Checkboard with color red at (1,2)
  _011: rectangle with size (1,2) with model Full with color red at (3,0)
  _0111: rectangle with size (1,1) with model Full with color pink at (4,3)
diff: 
   (136.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color black and layers
  _0: rectangle with size (16,16) with mask 
. . . . 0 0 0 . . . . . . . . . 
. . . . 0 . . . . . . . . . . . 
. . . . 0 . . . . . . . . . . . 
. . . . . 0 . . . . . . . . . . 
0 0 0 . 0 . 0 . . . . . . 0 0 0 
0 . . 0 . . 0 0 0 0 . . 0 . . 0 
0 . . . 0 0 . 0 0 . 0 0 . . . 0 
. 0 . . 0 0 0 . . 0 0 0 . . 0 . 
. 0 . . 0 0 0 . . 0 0 0 . . 0 . 
0 . . . 0 0 . 0 0 . 0 0 . . . 0 
0 . . 0 . . 0 0 0 0 . . 0 . . 0 
0 0 0 . 0 . 0 0 0 0 . 0 . 0 0 0 
. . . . . 0 . . . . 0 . . . . . 
. . . . 0 . . . . . . 0 . . . . 
. . . . 0 . . 0 0 . . 0 . . . . 
. . . . 0 0 0 . . 0 0 0 . . . . 
 with color brown at (0,0)
  _01: rectangle with size (5,5) with model Full with color green at (0,7)
  _011: rectangle with size (6,14) with model Full with color grey at (5,1)
  _0111: rectangle with size (14,3) with model Full with color yellow at (1,1)
  _01111: rectangle with size (14,3) with model Full with color yellow at (1,12)
  _011111: rectangle with size (3,6) with model Full with color grey at (12,5)
  _0111111: rectangle with size (1,16) with model Full with color red at (0,0)
  + 85 delta pixels
diff: 
! size mismatch, 5x10 instead of 5x5

TRAIN dc0a314f.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,16) and color red and layers
  _0: rectangle with size (16,16) with mask 
. . . 0 . 0 0 0 0 0 0 . 0 . . . 
. . . 0 0 0 . . . . 0 0 0 . . . 
. . 0 . 0 . . . . . . 0 . 0 . . 
0 0 . 0 0 . . . . . . 0 0 . 0 0 
. 0 0 0 . . . . . . . . . 0 0 . 
0 0 . . . . . . . . . . . . 0 0 
0 . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . 0 
0 0 . . . . . . . . . . . . 0 0 
. 0 0 0 . . . . . . . . 0 0 0 . 
0 0 . 0 0 . . . . . . 0 0 . 0 0 
. . 0 . 0 . . . . . . 0 . 0 . . 
. . . 0 0 0 . . . . 0 0 0 . . . 
. . . 0 . 0 0 0 0 0 0 . 0 . . . 
 with color grey at (0,0)
  _01: rectangle with size (5,5) with model Full with color green at (4,8)
  _011: rectangle with size (8,7) with mask 
. . . 0 . . . 
. . 0 0 . . . 
. 0 . 0 . . . 
0 0 0 0 . . . 
0 0 0 0 . . . 
. 0 . 0 0 . 0 
. . 0 0 0 0 . 
. . . 0 0 . . 
 with color brown at (4,4)
  _0111: rectangle with size (8,3) with model Full with color pink at (4,4)
  _01111: rectangle with size (12,4) with model Full with color grey at (2,6)
  _011111: rectangle with size (2,16) with model Full with color grey at (0,0)
  _0111111: rectangle with size (4,2) with mask 
. 0 
0 0 
0 0 
. 0 
 with color grey at (6,2)
  + 42 delta pixels
diff: 
! size mismatch, 5x10 instead of 5x5

TEST dc0a314f.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.6 sec (59.6 sec/task)
bits-train-error = 4591.8 bits (4591.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-49] Checking task dc1df850.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 42716.3 = 42718.6
DL output with Mo: L = 2.3 + 42716.3 = 42718.6
DL input+output M: L = 4.6 + 85432.6 = 85437.2

# learning a model for train pairs
2.000	
1.088	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.444	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.229	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.202	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.186	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.174	OUT SPE ^.size = ^.size
0.166	OUT ADD ^.layer_00 = ^.layer_0
0.149	OUT ADD ^.layer_010 = point with color ? at (?,?)
0.143	OUT SPE ^.layer_0.pos = projJ(^.layer_0.pos) - (0, 1)
0.139	OUT SPE ^.layer_01.shape.mask.size.i = 3
0.135	OUT SPE ^.layer_01.shape.color = blue
0.132	OUT SPE ^.layer_010.pos.i = center(^.layer_0) / '2
0.130	OUT SPE ^.layer_0.shape.mask.size.j = ^.size.j / '3
0.128	OUT SPE ^.layer_0.shape.mask.model = Full
0.126	IN  SPE ^.color = black
0.125	OUT SPE ^.color = black
0.056	
0.056	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,^.size.j / '3) with model Full with color ? at projJ(^.layer_0.pos) - (0, 1)
  _010: point with color ? at (center(^.layer_0) / '2,?)
  _01: rectangle with size (3,?) with model ? with color blue at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.3 + 2976.7 = 3009.0
DL output with Mo: L = 165.6 + 2148.3 = 2313.9
DL input+output M: L = 197.9 + 5124.9 = 5322.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,^.size.j / '3) with model Full with color ? at projJ(^.layer_0.pos) - (0, 1)
  _010: point with color ? at (center(^.layer_0) / '2,?)
  _01: rectangle with size (3,?) with model ? with color blue at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 31.7 = 63.9
DL output with Mo: L = 165.6 + 2148.3 = 2313.9
DL input+output M: L = 197.8 + 2180.0 = 2377.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (5,5) and color black and layers
  _0: point with color pink at (3,1)
  + 2 delta pixels
diff: 
   (3.2 bits)
data: a background with size (5,5) and color black and layers
  _00: 
6 
 at (3,1)
  _0: rectangle with size (1,1) with model Full with color red at (0,0)
  _010: point with color red at (1,3)
  _01: rectangle with size (3,5) with mask 
. 0 0 0 0 
0 0 0 . 0 
. . 0 0 0 
 with color blue at (0,0)
diff: 
   (51.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color black and layers
  _0: point with color red at (0,0)
  + 2 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,5) and color black and layers
  _0: point with color red at (1,3)
  + 2 delta pixels
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (5,5) and color black and layers
  _0: point with color pink at (3,1)
  + 2 delta pixels
diff: 
! 13 wrong pixels (generated / expected)

TRAIN dc1df850.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (8,8) and color black and layers
  _0: point with color red at (0,7)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (8,8) and color black and layers
  _00: 
2 
 at (0,7)
  _0: rectangle with size (2,2) with model Full with color blue at (0,6)
  _010: point with color cyan at (4,6)
  _01: rectangle with size (3,3) with model Full with color blue at (5,1)
  + 2 delta pixels
diff: 
   (122.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color black and layers
  _0: point with color red at (0,7)
  + 3 delta pixels
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color black and layers
  _0: point with color green at (2,3)
  + 3 delta pixels
diff: 
! 24 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (8,8) and color black and layers
  _0: point with color cyan at (4,6)
  + 3 delta pixels
diff: 
! 23 wrong pixels (generated / expected)

TRAIN dc1df850.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (4,5) and color black and layers
  _0: point with color red at (1,1)
diff: 
   (0.0 bits)
data: a background with size (4,5) and color black and layers
  _00: 
2 
 at (1,1)
  _0: rectangle with size (3,1) with model Full with color blue at (0,0)
  _010: point with color blue at (1,2)
  _01: rectangle with size (3,3) with model Full with color blue at (0,0)
diff: 
   (40.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,5) and color black and layers
  _0: point with color red at (1,1)
diff: 
! 5 wrong pixels (generated / expected)

TRAIN dc1df850.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
undefined expression: ScaleDown: not an integer

TEST dc1df850.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 12.2 sec (12.2 sec/task)
bits-train-error = 2148.3 bits (2148.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-48] Checking task dc433765.json: 7 train, 2 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 130259.2 = 130261.5
DL output with Mo: L = 2.3 + 130259.2 = 130261.5
DL input+output M: L = 4.6 + 260518.4 = 260523.0

# learning a model for train pairs
2.000	
1.052	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.105	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.092	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.072	OUT ADD ^.layer_0 = ^.layer_0
0.059	IN  ADD ^.layer_00 = point with color ? at (?,?)
0.042	OUT ADD ^.layer_00 = ^.layer_00.shape at (?,?)
0.034	OUT SPE ^.size = ^.size
0.029	OUT SPE ^.layer_00.pos = ^.layer_0.pos + translationOnto(^.layer_0, ^.layer_00)
0.026	IN  SPE ^.layer_00.shape.color = green
0.023	IN  SPE ^.layer_0.shape.color = yellow
0.021	IN  SPE ^.color = black
0.020	OUT SPE ^.color = black
0.001	
0.001	IN  GEN ^.layer_0.shape.color = ?
0.001	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_00.shape at ^.layer_0.pos + translationOnto(^.layer_0, ^.layer_00)
  _0: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: point with color green at (?,?)
  _0: point with color yellow at (?,?)

DL input  with Mi: L = 57.4 + 2477.9 = 2535.3
DL output with Mo: L = 55.2 + 0.0 = 55.2
DL input+output M: L = 112.5 + 2477.9 = 2590.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_00.shape at ^.layer_0.pos + translationOnto(^.layer_0, ^.layer_00)
  _0: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: point with color green at (?,?)
  _0: point with color ? at (?,?)

DL input  with Mi: L = 53.9 + 0.0 = 53.9
DL output with Mo: L = 55.2 + 0.0 = 55.2
DL input+output M: L = 109.1 + 0.0 = 109.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _00: point with color green at (0,0)
  _0: point with color yellow at (2,2)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _00: 
3 
 at (1,1)
  _0: 
4 
 at (2,2)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _00: point with color green at (0,0)
  _0: point with color yellow at (2,2)
diff: 
correct output grid

TRAIN dc433765.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (5,3) and color black and layers
  _00: point with color green at (1,0)
  _0: point with color yellow at (1,2)
diff: 
   (0.0 bits)
data: a background with size (5,3) and color black and layers
  _00: 
3 
 at (1,1)
  _0: 
4 
 at (1,2)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,3) and color black and layers
  _00: point with color green at (1,0)
  _0: point with color yellow at (1,2)
diff: 
correct output grid

TRAIN dc433765.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (5,5) and color black and layers
  _00: point with color green at (2,1)
  _0: point with color yellow at (2,4)
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _00: 
3 
 at (2,2)
  _0: 
4 
 at (2,4)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color black and layers
  _00: point with color green at (2,1)
  _0: point with color yellow at (2,4)
diff: 
correct output grid

TRAIN dc433765.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: a background with size (7,7) and color black and layers
  _00: point with color green at (1,1)
  _0: point with color yellow at (4,4)
diff: 
   (0.0 bits)
data: a background with size (7,7) and color black and layers
  _00: 
3 
 at (2,2)
  _0: 
4 
 at (4,4)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color black and layers
  _00: point with color green at (1,1)
  _0: point with color yellow at (4,4)
diff: 
correct output grid

TRAIN dc433765.json/4: 1 1st (SUCCESS)

## instance 5

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _00: point with color green at (7,2)
  _0: point with color yellow at (2,2)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
3 
 at (6,2)
  _0: 
4 
 at (2,2)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _00: point with color green at (7,2)
  _0: point with color yellow at (2,2)
diff: 
correct output grid

TRAIN dc433765.json/5: 1 1st (SUCCESS)

## instance 6

> Input and output best reading:

data: a background with size (11,11) and color black and layers
  _00: point with color green at (2,3)
  _0: point with color yellow at (8,3)
diff: 
   (0.0 bits)
data: a background with size (11,11) and color black and layers
  _00: 
3 
 at (3,3)
  _0: 
4 
 at (8,3)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _00: point with color green at (2,3)
  _0: point with color yellow at (8,3)
diff: 
correct output grid

TRAIN dc433765.json/6: 1 1st (SUCCESS)

## instance 7

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _00: point with color green at (0,2)
  _0: point with color yellow at (2,0)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _00: 
3 
 at (1,1)
  _0: 
4 
 at (2,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _00: point with color green at (0,2)
  _0: point with color yellow at (2,0)
diff: 
correct output grid

TRAIN dc433765.json/7: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color black and layers
  _00: point with color green at (2,3)
  _0: point with color yellow at (8,3)
diff: 
correct output grid

TEST dc433765.json/1: 1 1st (SUCCESS)

## instance 2

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _00: point with color green at (2,2)
  _0: point with color yellow at (0,0)
diff: 
correct output grid

TEST dc433765.json/2: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.4 sec (1.4 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-47] Checking task ddf7fa4f.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.342	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.683	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.539	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.412	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.328	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.243	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.175	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.123	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.117	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.107	OUT ADD ^.layer_0111 = ^.layer_0111
0.101	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.091	OUT ADD ^.layer_01111 = ^.layer_01111
0.085	OUT ADD ^.layer_011111 = point with color ? at (?,?)
0.080	OUT SPE ^.size = ^.size
0.075	IN  ADD ^.layer_011111 = point with color ? at (?,?)
0.067	OUT SPE ^.layer_0 = coloring(^.layer_0, ^.layer_01111.shape.color)
0.062	OUT SPE ^.layer_011111 = ^.layer_011111
0.058	OUT SPE ^.layer_01.shape.mask = ^.layer_01.shape.mask
0.054	OUT SPE ^.layer_011.shape.mask = ^.layer_011.shape.mask
0.052	OUT SPE ^.layer_011.pos = ^.layer_011.pos
0.049	OUT SPE ^.layer_01.pos = ^.layer_01.pos
0.047	IN  SPE ^.layer_0.shape.color = grey
0.046	IN  SPE ^.layer_01.shape.color = grey
0.045	IN  SPE ^.layer_011.shape.color = grey
0.044	IN  SPE ^.layer_0.shape.mask.model = Full
0.043	IN  SPE ^.layer_01.shape.mask.model = Full
0.042	IN  SPE ^.layer_011.shape.mask.model = Full
0.042	IN  SPE ^.color = black
0.041	OUT SPE ^.color = black
0.005	
0.005	IN  GEN ^.layer_011.shape.color = ?
0.005	IN  GEN ^.layer_01.shape.color = ?
0.005	IN  GEN ^.layer_0.shape.color = ?
0.005	IN  GEN ^.layer_011.shape.mask.model = ?
0.005	IN  GEN ^.layer_01.shape.mask.model = ?
0.005	IN  GEN ^.layer_0.shape.mask.model = ?
0.005	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, ^.layer_01111.shape.color)
  _01: ^.layer_01.shape.mask with color ? at ^.layer_01.pos
  _011: ^.layer_011.shape.mask with color ? at ^.layer_011.pos
  _0111: ^.layer_0111
  _01111: ^.layer_01111
  _011111: ^.layer_011111
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color grey at (?,?)
  _01: rectangle with size (?,?) with model Full with color grey at (?,?)
  _011: rectangle with size (?,?) with model Full with color grey at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)

DL input  with Mi: L = 163.1 + 4354.4 = 4517.4
DL output with Mo: L = 79.8 + 337.8 = 417.5
DL input+output M: L = 242.8 + 4692.1 = 4935.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, ^.layer_01111.shape.color)
  _01: ^.layer_01.shape.mask with color ? at ^.layer_01.pos
  _011: ^.layer_011.shape.mask with color ? at ^.layer_011.pos
  _0111: ^.layer_0111
  _01111: ^.layer_01111
  _011111: ^.layer_011111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)

DL input  with Mi: L = 151.5 + 31.7 = 183.2
DL output with Mo: L = 79.8 + 337.8 = 417.5
DL input+output M: L = 231.2 + 369.5 = 600.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with model Full with color grey at (2,4)
  _01: rectangle with size (5,2) with model Full with color grey at (4,1)
  _011: rectangle with size (3,3) with model Full with color grey at (7,7)
  _0111: point with color red at (0,2)
  _01111: point with color pink at (0,5)
  _011111: point with color cyan at (0,9)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
6 6 6 6 
6 6 6 6 
6 6 6 6 
6 6 6 6 
 at (2,4)
  _01: 
0 0 
0 0 
0 0 
0 0 
0 0 
 with color red at (4,1)
  _011: 
0 0 0 
0 0 0 
0 0 0 
 with color cyan at (7,7)
  _0111: 
2 
 at (0,2)
  _01111: 
6 
 at (0,5)
  _011111: 
8 
 at (0,9)
diff: 
   (11.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with model Full with color grey at (2,4)
  _01: rectangle with size (5,2) with model Full with color grey at (4,1)
  _011: rectangle with size (3,3) with model Full with color grey at (7,7)
  _0111: point with color red at (0,2)
  _01111: point with color pink at (0,5)
  _011111: point with color cyan at (0,9)
diff: 
! 19 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with model Full with color grey at (2,4)
  _01: rectangle with size (5,2) with model Full with color grey at (4,1)
  _011: rectangle with size (3,3) with model Full with color grey at (7,7)
  _0111: point with color red at (0,2)
  _01111: point with color cyan at (0,9)
  _011111: point with color pink at (0,5)
diff: 
! 35 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with model Full with color grey at (2,4)
  _01: rectangle with size (5,2) with model Full with color grey at (4,1)
  _011: rectangle with size (3,3) with model Full with color grey at (7,7)
  _0111: point with color pink at (0,5)
  _01111: point with color red at (0,2)
  _011111: point with color cyan at (0,9)
diff: 
! 35 wrong pixels (generated / expected)

TRAIN ddf7fa4f.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with model Full with color grey at (2,0)
  _01: rectangle with size (4,3) with model Full with color grey at (2,7)
  _011: rectangle with size (2,4) with model Full with color grey at (7,3)
  _0111: point with color yellow at (0,5)
  _01111: point with color blue at (0,1)
  _011111: point with color orange at (0,8)
diff: 
   (3.2 bits)
data: a background with size (10,10) and color black and layers
  _0: 
1 1 1 1 
1 1 1 1 
1 1 1 1 
1 1 1 1 
 at (2,0)
  _01: 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
 with color orange at (2,7)
  _011: 
0 0 0 0 
0 0 0 0 
 with color yellow at (7,3)
  _0111: 
4 
 at (0,5)
  _01111: 
1 
 at (0,1)
  _011111: 
7#
 at (0,8)
diff: 
   (11.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with model Full with color grey at (2,0)
  _01: rectangle with size (4,3) with model Full with color grey at (2,7)
  _011: rectangle with size (2,4) with model Full with color grey at (7,3)
  _0111: point with color blue at (0,1)
  _01111: point with color yellow at (0,5)
  _011111: point with color orange at (0,8)
diff: 
! 36 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with model Full with color grey at (2,0)
  _01: rectangle with size (4,3) with model Full with color grey at (2,7)
  _011: rectangle with size (2,4) with model Full with color grey at (7,3)
  _0111: point with color blue at (0,1)
  _01111: point with color orange at (0,8)
  _011111: point with color yellow at (0,5)
diff: 
! 36 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with model Full with color grey at (2,0)
  _01: rectangle with size (4,3) with model Full with color grey at (2,7)
  _011: rectangle with size (2,4) with model Full with color grey at (7,3)
  _0111: point with color yellow at (0,5)
  _01111: point with color blue at (0,1)
  _011111: point with color orange at (0,8)
diff: 
! 20 wrong pixels (generated / expected)

TRAIN ddf7fa4f.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Full with color grey at (5,3)
  _01: rectangle with size (3,2) with model Full with color grey at (2,1)
  _011: rectangle with size (2,3) with model Full with color grey at (3,7)
  _0111: point with color blue at (0,1)
  _01111: point with color pink at (0,5)
  _011111: point with color orange at (0,8)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
6 6 6 
6 6 6 
6 6 6 
 at (5,3)
  _01: 
0 0 
0 0 
0 0 
 with color blue at (2,1)
  _011: 
0 0 0 
0 0 0 
 with color orange at (3,7)
  _0111: 
1 
 at (0,1)
  _01111: 
6 
 at (0,5)
  _011111: 
7#
 at (0,8)
diff: 
   (11.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Full with color grey at (5,3)
  _01: rectangle with size (3,2) with model Full with color grey at (2,1)
  _011: rectangle with size (2,3) with model Full with color grey at (3,7)
  _0111: point with color blue at (0,1)
  _01111: point with color pink at (0,5)
  _011111: point with color orange at (0,8)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Full with color grey at (5,3)
  _01: rectangle with size (3,2) with model Full with color grey at (2,1)
  _011: rectangle with size (2,3) with model Full with color grey at (3,7)
  _0111: point with color blue at (0,1)
  _01111: point with color orange at (0,8)
  _011111: point with color pink at (0,5)
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Full with color grey at (5,3)
  _01: rectangle with size (3,2) with model Full with color grey at (2,1)
  _011: rectangle with size (2,3) with model Full with color grey at (3,7)
  _0111: point with color pink at (0,5)
  _01111: point with color blue at (0,1)
  _011111: point with color orange at (0,8)
diff: 
! 21 wrong pixels (generated / expected)

TRAIN ddf7fa4f.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,5) with model Full with color grey at (2,2)
  _01: rectangle with size (7,2) with model Full with color grey at (2,8)
  _011: rectangle with size (2,4) with model Full with color grey at (7,0)
  _0111: point with color green at (0,0)
  _01111: point with color pink at (0,4)
  _011111: point with color brown at (0,8)
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,5) with model Full with color grey at (2,2)
  _01: rectangle with size (7,2) with model Full with color grey at (2,8)
  _011: rectangle with size (2,4) with model Full with color grey at (7,0)
  _0111: point with color green at (0,0)
  _01111: point with color brown at (0,8)
  _011111: point with color pink at (0,4)
diff: 
! 42 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,5) with model Full with color grey at (2,2)
  _01: rectangle with size (7,2) with model Full with color grey at (2,8)
  _011: rectangle with size (2,4) with model Full with color grey at (7,0)
  _0111: point with color pink at (0,4)
  _01111: point with color green at (0,0)
  _011111: point with color brown at (0,8)
diff: 
! 42 wrong pixels (generated / expected)

TEST ddf7fa4f.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 23.1 sec (23.1 sec/task)
bits-train-error = 337.8 bits (337.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-46] Checking task de1cd16c.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 426035.0 = 426037.3
DL output with Mo: L = 2.3 + 1944.9 = 1947.3
DL input+output M: L = 4.6 + 427979.9 = 427984.6

# learning a model for train pairs
2.000	
1.327	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.971	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.682	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.446	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.312	OUT SPE ^.size = '(1, 1)
0.229	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.050	OUT SPE ^.color = ^.layer_0.shape.color
0.048	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.046	IN  ADD ^.layer_010 = point with color ? at (?,?)
0.046	IN  SPE ^.layer_0111.shape.mask.model = Full
0.045	IN  SPE ^.layer_011.shape.mask.model = Full
0.014	
0.014	IN  GEN ^.layer_011.shape.mask.model = ?
0.014	IN  GEN ^.layer_0111.shape.mask.model = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(1, 1) and color ^.layer_0.shape.color and layers
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: point with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 144.6 + 13259.8 = 13404.4
DL output with Mo: L = 27.2 + 0.0 = 27.2
DL input+output M: L = 171.8 + 13259.8 = 13431.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(1, 1) and color ^.layer_0.shape.color and layers
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: point with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 143.6 + 20.0 = 163.6
DL output with Mo: L = 27.2 + 0.0 = 27.2
DL input+output M: L = 170.8 + 20.0 = 190.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (17,13) and color black and layers
  _0: rectangle with size (10,8) with mask 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 . 0 0 
0 0 0 0 0 0 0 0 
0 0 . 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 . 0 0 
0 0 0 0 0 0 0 0 
 with color cyan at (7,0)
  _010: point with color pink at (2,3)
  _01: rectangle with size (7,8) with mask 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 . 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
 with color yellow at (0,0)
  _011: rectangle with size (10,5) with model Full with color blue at (7,8)
  _0111: rectangle with size (12,1) with model Full with color pink at (4,5)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (1,1) and color cyan and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,13) and color black and layers
  _0: rectangle with size (10,8) with mask 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 . 0 0 
0 0 0 0 0 0 0 0 
0 0 . 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 . 0 0 
0 0 0 0 0 0 0 0 
 with color cyan at (7,0)
  _010: point with color pink at (2,3)
  _01: rectangle with size (7,8) with mask 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 . 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
 with color yellow at (0,0)
  _011: rectangle with size (10,5) with model Full with color blue at (7,8)
  _0111: rectangle with size (12,1) with model Full with color pink at (4,5)
  + 3 delta pixels
diff: 
correct output grid

TRAIN de1cd16c.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (16,15) and color cyan and layers
  _0: rectangle with size (9,8) with model Full with color red at (0,7)
  _010: point with color blue at (4,2)
  _01: rectangle with size (9,7) with model Full with color green at (0,0)
  _011: rectangle with size (1,1) with model Full with color blue at (12,11)
  _0111: rectangle with size (1,1) with model Full with color blue at (13,6)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (1,1) and color red and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,15) and color cyan and layers
  _0: rectangle with size (9,8) with model Full with color red at (0,7)
  _010: point with color blue at (4,2)
  _01: rectangle with size (9,7) with model Full with color green at (0,0)
  _011: rectangle with size (1,1) with model Full with color blue at (12,11)
  _0111: rectangle with size (1,1) with model Full with color blue at (13,6)
  + 4 delta pixels
diff: 
correct output grid

TRAIN de1cd16c.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (16,17) and color grey and layers
  _0: rectangle with size (8,10) with mask 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 . 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 . 0 0 0 
0 0 0 0 0 0 0 0 0 0 
 with color pink at (8,7)
  _010: point with color yellow at (1,1)
  _01: rectangle with size (8,7) with model Full with color black at (8,0)
  _011: rectangle with size (8,7) with model Full with color blue at (0,0)
  _0111: rectangle with size (1,6) with model Full with color yellow at (11,10)
  + 5 delta pixels
diff: 
   (2.0 bits)
data: a background with size (1,1) and color pink and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,17) and color black and layers
  _0: rectangle with size (8,10) with model Full with color grey at (0,7)
  _010: point with color yellow at (1,1)
  _01: rectangle with size (8,10) with mask 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 . 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 . 0 0 0 
0 0 0 0 0 0 0 0 0 0 
 with color pink at (8,7)
  _011: rectangle with size (8,7) with model Full with color blue at (0,0)
  _0111: rectangle with size (1,6) with model Full with color yellow at (11,10)
  + 5 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (16,17) and color grey and layers
  _0: rectangle with size (8,10) with mask 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 . 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 . 0 0 0 
0 0 0 0 0 0 0 0 0 0 
 with color pink at (8,7)
  _010: point with color yellow at (1,1)
  _01: rectangle with size (8,7) with model Full with color black at (8,0)
  _011: rectangle with size (8,7) with model Full with color blue at (0,0)
  _0111: rectangle with size (1,6) with model Full with color yellow at (11,10)
  + 5 delta pixels
diff: 
correct output grid

TRAIN de1cd16c.json/3: 1 2nd (SUCCESS)

## instance 4

> Input and output best reading:

data: a background with size (16,19) and color blue and layers
  _0: rectangle with size (7,12) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 . 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 . 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color yellow at (9,7)
  _010: point with color red at (4,11)
  _01: rectangle with size (9,12) with model Full with color cyan at (0,7)
  _011: rectangle with size (1,1) with model Full with color red at (13,9)
  _0111: rectangle with size (1,1) with model Full with color red at (14,12)
diff: 
   (0.0 bits)
data: a background with size (1,1) and color yellow and layers
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,19) and color blue and layers
  _0: rectangle with size (7,12) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 . 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 . 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color yellow at (9,7)
  _010: point with color red at (4,11)
  _01: rectangle with size (9,12) with model Full with color cyan at (0,7)
  _011: rectangle with size (1,1) with model Full with color red at (13,9)
  _0111: rectangle with size (1,1) with model Full with color red at (14,12)
diff: 
correct output grid

TRAIN de1cd16c.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,19) and color cyan and layers
  _0: rectangle with size (4,19) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color green at (0,0)
  _010: point with color yellow at (5,1)
  _01: rectangle with size (8,9) with mask 
0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 0 . 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 
0 0 . 0 0 0 0 0 0 
0 0 0 0 0 0 . 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color red at (4,0)
  _011: rectangle with size (6,9) with model Full with color blue at (12,0)
  _0111: rectangle with size (5,1) with model Full with color yellow at (1,7)
  + 8 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (18,19) and color cyan and layers
  _0: rectangle with size (8,9) with mask 
0 0 0 0 0 0 0 0 0 
0 . 0 0 0 0 0 . 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 
0 0 . 0 0 0 0 0 0 
0 0 0 0 0 0 . 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color red at (4,0)
  _010: point with color yellow at (1,7)
  _01: rectangle with size (4,19) with model Full with color green at (0,0)
  _011: rectangle with size (6,9) with mask 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 
0 . 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
 with color blue at (12,0)
  _0111: rectangle with size (1,7) with model Full with color yellow at (5,1)
  + 8 delta pixels
diff: 
correct output grid

TEST de1cd16c.json/1: 1 2nd (SUCCESS)

# Performance measures on task
runtime-learning = 5.4 sec (5.4 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 0.88
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 0.50

=====================================
[-45] Checking task ded97339.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.056	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.209	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.106	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.090	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.084	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.078	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.073	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.067	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.062	OUT SPE ^.size = ^.size
0.060	OUT SPE ^.layer_01.pos = min(^.layer_01.pos, ^.layer_0111.pos)
0.058	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.057	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.056	IN  SPE ^.layer_0.shape.color = cyan
0.054	IN  SPE ^.layer_01.shape.color = cyan
0.053	IN  SPE ^.layer_011.shape.color = cyan
0.051	IN  SPE ^.layer_0111.shape.color = cyan
0.051	OUT SPE ^.layer_0.shape.mask.size.i = 1
0.050	OUT SPE ^.layer_0.pos.i = center(^.layer_011) - ^.layer_0111.pos.i - ^.layer_011.pos.i
0.049	OUT SPE ^.layer_0.shape.mask.model = Full
0.049	IN  SPE ^.color = black
0.048	OUT SPE ^.color = black
0.021	
0.021	IN  GEN ^.layer_0111.shape.color = ?
0.021	IN  GEN ^.layer_011.shape.color = ?
0.021	IN  GEN ^.layer_01.shape.color = ?
0.021	IN  GEN ^.layer_0.shape.color = ?
0.021	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (1,?) with model Full with color ^.layer_0.shape.color at (center(^.layer_011) - ^.layer_0111.pos.i - ^.layer_011.pos.i,?)
  _01: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at min(^.layer_01.pos, ^.layer_0111.pos)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color cyan at (?,?)
  _01: point with color cyan at (?,?)
  _011: point with color cyan at (?,?)
  _0111: point with color cyan at (?,?)

DL input  with Mi: L = 100.0 + 3221.5 = 3321.5
DL output with Mo: L = 158.2 + 2258.0 = 2416.2
DL input+output M: L = 258.2 + 5479.5 = 5737.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (1,?) with model Full with color ^.layer_0.shape.color at (center(^.layer_011) - ^.layer_0111.pos.i - ^.layer_011.pos.i,?)
  _01: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at min(^.layer_01.pos, ^.layer_0111.pos)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 86.6 + 31.7 = 118.3
DL output with Mo: L = 158.2 + 2258.0 = 2416.2
DL input+output M: L = 244.8 + 2289.7 = 2534.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color cyan at (3,1)
  _01: point with color cyan at (3,6)
  _011: point with color cyan at (7,4)
  _0111: point with color cyan at (9,6)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,6) with model Full with color cyan at (3,1)
  _01: rectangle with size (7,1) with model Full with color cyan at (3,6)
  + 1 delta pixels
diff: 
   (70.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color cyan at (3,1)
  _01: point with color cyan at (3,6)
  _011: point with color cyan at (7,4)
  _0111: point with color cyan at (9,6)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color cyan at (3,1)
  _01: point with color cyan at (3,6)
  _011: point with color cyan at (9,6)
  _0111: point with color cyan at (7,4)
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color cyan at (3,1)
  _01: point with color cyan at (7,4)
  _011: point with color cyan at (3,6)
  _0111: point with color cyan at (9,6)
diff: 
! 17 wrong pixels (generated / expected)

TRAIN ded97339.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color cyan at (1,7)
  _01: point with color cyan at (3,2)
  _011: point with color cyan at (6,5)
  _0111: point with color cyan at (6,9)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,5) with model Full with color cyan at (6,5)
  _01: rectangle with size (6,1) with model Full with color cyan at (3,2)
  + 1 delta pixels
diff: 
   (69.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color cyan at (1,7)
  _01: point with color cyan at (3,2)
  _011: point with color cyan at (6,5)
  _0111: point with color cyan at (6,9)
  + 1 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color cyan at (1,7)
  _01: point with color cyan at (3,2)
  _011: point with color cyan at (6,5)
  _0111: point with color cyan at (8,2)
  + 1 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color cyan at (1,7)
  _01: point with color cyan at (3,2)
  _011: point with color cyan at (6,9)
  _0111: point with color cyan at (6,5)
  + 1 delta pixels
diff: 
! 12 wrong pixels (generated / expected)

TRAIN ded97339.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color cyan at (1,1)
  _01: point with color cyan at (1,5)
  _011: point with color cyan at (7,5)
  _0111: point with color cyan at (4,1)
  + 2 delta pixels
diff: 
   (3.2 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (9,2)
  _01: rectangle with size (7,9) with mask 
0 0 0 0 0 . . . . 
0 . . . 0 . . . . 
0 . . . 0 . . . . 
0 . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 . . . . 
. . . . 0 0 0 0 0 
 with color cyan at (1,1)
diff: 
   (85.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color cyan at (1,1)
  _01: point with color cyan at (1,5)
  _011: point with color cyan at (4,1)
  _0111: point with color cyan at (7,5)
  + 2 delta pixels
diff: 
! 19 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color cyan at (1,1)
  _01: point with color cyan at (1,5)
  _011: point with color cyan at (7,5)
  _0111: point with color cyan at (4,1)
  + 2 delta pixels
diff: 
! 19 wrong pixels (generated / expected)

TRAIN ded97339.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color cyan at (1,1)
  _01: point with color cyan at (2,3)
  _011: point with color cyan at (3,7)
  _0111: point with color cyan at (5,1)
  + 2 delta pixels
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: point with color cyan at (1,1)
  _01: point with color cyan at (2,3)
  _011: point with color cyan at (3,7)
  _0111: point with color cyan at (8,4)
  + 2 delta pixels
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: point with color cyan at (1,1)
  _01: point with color cyan at (2,3)
  _011: point with color cyan at (5,1)
  _0111: point with color cyan at (3,7)
  + 2 delta pixels
diff: 
! 17 wrong pixels (generated / expected)

TEST ded97339.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 12.5 sec (12.5 sec/task)
bits-train-error = 2258.0 bits (2258.0 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-44] Checking task e179c5f4.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 35052.8 = 35055.1
DL output with Mo: L = 2.3 + 35052.8 = 35055.1
DL input+output M: L = 4.6 + 70105.7 = 70110.3

# learning a model for train pairs
2.000	
1.050	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.401	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.121	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.100	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.086	OUT SPE ^.size = ^.size
0.072	OUT SPE ^.layer_0.shape.mask.size = ^.size
0.064	OUT SPE ^.layer_0.pos = '(0, 0)
0.057	OUT SPE ^.color = cyan
0.052	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.047	IN  SPE ^.layer_0.shape.color = blue
0.045	IN  SPE ^.color = black
0.023	
0.023	IN  GEN ^.layer_0.shape.color = ?
0.023	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color cyan and layers
  _0: rectangle with size ^.size with model ? with color ^.layer_0.shape.color at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color blue at (?,?)

DL input  with Mi: L = 35.6 + 775.2 = 810.8
DL output with Mo: L = 49.6 + 724.3 = 773.9
DL input+output M: L = 85.2 + 1499.5 = 1584.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color cyan and layers
  _0: rectangle with size ^.size with model ? with color ^.layer_0.shape.color at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 0.0 = 32.2
DL output with Mo: L = 49.6 + 724.3 = 773.9
DL input+output M: L = 81.8 + 724.3 = 806.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,2) and color black and layers
  _0: point with color blue at (9,0)
diff: 
   (0.0 bits)
data: a background with size (10,2) and color cyan and layers
  _0: rectangle with size (10,2) with model Odd Checkboard with color blue at (0,0)
diff: 
   (6.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,2) and color black and layers
  _0: point with color blue at (9,0)
diff: 
! 10 wrong pixels (generated / expected)

TRAIN e179c5f4.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,3) and color black and layers
  _0: point with color blue at (9,0)
diff: 
   (0.0 bits)
data: a background with size (10,3) and color cyan and layers
  _0: rectangle with size (10,3) with mask 
. 0 . 
0 . . 
. 0 . 
. . 0 
. 0 . 
0 . . 
. 0 . 
. . 0 
. 0 . 
0 . . 
 with color blue at (0,0)
diff: 
   (30.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,3) and color black and layers
  _0: point with color blue at (9,0)
diff: 
! 20 wrong pixels (generated / expected)

TRAIN e179c5f4.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,4) and color black and layers
  _0: point with color blue at (9,0)
diff: 
   (0.0 bits)
data: a background with size (10,4) and color cyan and layers
  _0: rectangle with size (10,4) with mask 
. . . 0 
. . 0 . 
. 0 . . 
0 . . . 
. 0 . . 
. . 0 . 
. . . 0 
. . 0 . 
. 0 . . 
0 . . . 
 with color blue at (0,0)
diff: 
   (35.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,4) and color black and layers
  _0: point with color blue at (9,0)
diff: 
! 30 wrong pixels (generated / expected)

TRAIN e179c5f4.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,5) and color black and layers
  _0: point with color blue at (9,0)
diff: 
! 40 wrong pixels (generated / expected)

TEST e179c5f4.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 1.4 sec (1.4 sec/task)
bits-train-error = 724.3 bits (724.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-43] Checking task e21d9049.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 138806.6 = 138809.0
DL output with Mo: L = 2.3 + 138806.6 = 138809.0
DL input+output M: L = 4.6 + 277613.3 = 277617.9

# learning a model for train pairs
2.000	
1.039	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.189	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.183	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.171	OUT ADD ^.layer_0 = ^.layer_0
0.165	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.149	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.134	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.129	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.121	OUT ADD ^.layer_010 = ^.layer_01
0.117	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.113	OUT ADD ^.layer_0101 = ^.layer_011.shape at (?,?)
0.110	OUT ADD ^.layer_0110 = ^.layer_011.shape at (?,?)
0.106	OUT ADD ^.layer_01111 = ^.layer_011.shape at (?,?)
0.103	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.099	OUT SPE ^.size = ^.size
0.098	OUT SPE ^.layer_0101 = ^.layer_011
0.097	OUT SPE ^.layer_01.pos = projI(^.layer_01.pos) + (0, 2)
0.095	OUT SPE ^.layer_011.shape.mask.size.i = ^.size.j - 1
0.094	IN  ADD ^.layer_010 = point with color ? at (?,?)
0.092	OUT SPE ^.layer_011.pos = projJ(^.layer_011.pos)
0.091	OUT SPE ^.layer_0111.pos = projI(^.layer_0111.pos) + (0, 1)
0.089	OUT SPE ^.layer_0110.pos = ^.layer_010.pos - (2, 0)
0.088	OUT SPE ^.layer_0111.shape.mask.size.j = ^.size.j - 1
0.087	IN  SPE ^.layer_0.shape.color = cyan
0.086	OUT SPE ^.layer_01111.pos.j = ^.layer_011.pos.j
0.085	OUT SPE ^.layer_011.shape.color = ^.layer_0111.shape.color
0.085	OUT SPE ^.layer_01111.pos.i = middle(^.layer_0111) * '2
0.084	OUT SPE ^.layer_011.shape.mask.size.j = 1
0.084	OUT SPE ^.layer_0111.shape.mask.size.i = 1
0.083	OUT SPE ^.layer_011.shape.mask.model = Full
0.083	OUT SPE ^.layer_0111.shape.mask.model = Full
0.083	IN  SPE ^.color = black
0.082	OUT SPE ^.color = black
0.082	OUT SPE ^.layer_01.shape.mask.size.i = ^.layer_01.shape.mask.size.i + ^.layer_010.pos.i - ^.layer_0.pos.i
0.063	
0.063	IN  GEN ^.layer_0.shape.color = ?
0.063	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _010: ^.layer_01
  _0101: ^.layer_011
  _01: rectangle with size (^.layer_01.shape.mask.size.i + ^.layer_010.pos.i - ^.layer_0.pos.i,?) with model ? with color ? at projI(^.layer_01.pos) + (0, 2)
  _0110: ^.layer_011.shape at ^.layer_010.pos - (2, 0)
  _011: rectangle with size (^.size.j - 1,1) with model Full with color ^.layer_0111.shape.color at projJ(^.layer_011.pos)
  _0111: rectangle with size (1,^.size.j - 1) with model Full with color ? at projI(^.layer_0111.pos) + (0, 1)
  _01111: ^.layer_011.shape at (middle(^.layer_0111) * '2,^.layer_011.pos.j)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color cyan at (?,?)
  _010: point with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 127.4 + 2636.1 = 2763.5
DL output with Mo: L = 347.1 + 8269.5 = 8616.5
DL input+output M: L = 474.5 + 10905.5 = 11380.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _010: ^.layer_01
  _0101: ^.layer_011
  _01: rectangle with size (^.layer_01.shape.mask.size.i + ^.layer_010.pos.i - ^.layer_0.pos.i,?) with model ? with color ? at projI(^.layer_01.pos) + (0, 2)
  _0110: ^.layer_011.shape at ^.layer_010.pos - (2, 0)
  _011: rectangle with size (^.size.j - 1,1) with model Full with color ^.layer_0111.shape.color at projJ(^.layer_011.pos)
  _0111: rectangle with size (1,^.size.j - 1) with model Full with color ? at projI(^.layer_0111.pos) + (0, 1)
  _01111: ^.layer_011.shape at (middle(^.layer_0111) * '2,^.layer_011.pos.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: point with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 124.0 + 20.0 = 144.0
DL output with Mo: L = 347.1 + 8269.5 = 8616.5
DL input+output M: L = 471.0 + 8289.5 = 8760.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (12,11) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (2,2)
  _010: point with color green at (3,2)
  _01: rectangle with size (1,1) with model Full with color cyan at (4,0)
  _011: point with color red at (4,2)
  _0111: point with color green at (4,1)
diff: 
   (2.0 bits)
data: a background with size (12,11) and color black and layers
  _0: 
8 
 at (2,2)
  _010: 
8 
 at (4,0)
  _0101: 
2 
 at (4,2)
  _01: rectangle with size (2,2) with model Odd Checkboard with color cyan at (4,2)
  _0110: 
2 
 at (1,2)
  _011: rectangle with size (10,1) with model Full with color green at (0,2)
  _0111: rectangle with size (1,10) with model Full with color green at (4,1)
  _01111: 
2 
 at (10,2)
  + 7 delta pixels
diff: 
   (308.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,11) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (2,2)
  _010: point with color green at (3,2)
  _01: rectangle with size (1,1) with model Full with color cyan at (4,0)
  _011: point with color green at (4,1)
  _0111: point with color red at (4,2)
diff: 
! 30 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,11) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (2,2)
  _010: point with color green at (3,2)
  _01: rectangle with size (1,1) with model Full with color cyan at (4,0)
  _011: point with color red at (4,2)
  _0111: point with color green at (4,1)
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,11) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (2,2)
  _010: point with color green at (3,2)
  _01: rectangle with size (1,1) with model Full with color green at (4,1)
  _011: point with color cyan at (4,0)
  _0111: point with color red at (4,2)
diff: 
! 30 wrong pixels (generated / expected)

TRAIN e21d9049.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (15,14) and color black and layers
  _0: rectangle with size (2,2) with model Even Checkboard with color cyan at (5,8)
  _010: point with color yellow at (4,8)
  _01: rectangle with size (2,2) with model Even Checkboard with color red at (6,7)
  _011: point with color green at (6,8)
  _0111: point with color yellow at (6,10)
diff: 
   (0.0 bits)
data: a background with size (15,14) and color black and layers
  _0: 
8 . 
. 8 
 at (5,8)
  _010: 
2 . 
. 2 
 at (6,7)
  _0101: 
3 
 at (6,8)
  _01: rectangle with size (1,9) with model Full with color yellow at (6,2)
  _0110: 
3 
 at (2,8)
  _011: rectangle with size (13,1) with model Full with color yellow at (0,8)
  _0111: rectangle with size (1,13) with model Full with color cyan at (6,1)
  _01111: 
3 
 at (14,8)
  + 12 delta pixels
diff: 
   (518.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,14) and color black and layers
  _0: rectangle with size (2,2) with model Even Checkboard with color cyan at (5,8)
  _010: point with color yellow at (4,8)
  _01: rectangle with size (2,2) with model Even Checkboard with color red at (6,7)
  _011: point with color green at (6,8)
  _0111: point with color yellow at (6,10)
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,14) and color black and layers
  _0: rectangle with size (2,2) with model Even Checkboard with color cyan at (5,8)
  _010: point with color yellow at (4,8)
  _01: rectangle with size (2,2) with model Even Checkboard with color red at (6,7)
  _011: point with color yellow at (6,10)
  _0111: point with color green at (6,8)
diff: 
! 36 wrong pixels (generated / expected)

TRAIN e21d9049.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (2,2) with model Odd Checkboard with color yellow at (5,5)
  _010: point with color red at (6,6)
  _01: rectangle with size (2,2) with model Odd Checkboard with color green at (6,6)
  _011: point with color blue at (6,8)
  _0111: point with color blue at (8,6)
diff: 
! 70 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (2,2) with model Odd Checkboard with color yellow at (5,5)
  _010: point with color red at (6,6)
  _01: rectangle with size (2,2) with model Odd Checkboard with color green at (6,6)
  _011: point with color blue at (8,6)
  _0111: point with color blue at (6,8)
diff: 
! 34 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (20,20) and color black and layers
  _0: rectangle with size (2,2) with model Odd Checkboard with color yellow at (5,5)
  _010: point with color blue at (6,8)
  _01: rectangle with size (2,2) with model Odd Checkboard with color green at (6,6)
  _011: point with color red at (6,6)
  _0111: point with color blue at (8,6)
diff: 
! 50 wrong pixels (generated / expected)

TEST e21d9049.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 48.8 sec (48.8 sec/task)
bits-train-error = 8269.5 bits (8269.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-42] Checking task e26a3af2.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 249950.3 = 249952.6
DL output with Mo: L = 2.3 + 249950.3 = 249952.6
DL input+output M: L = 4.6 + 499900.5 = 499905.2

# learning a model for train pairs
2.000	
1.632	OUT SPE ^ = a background with size (?,?) and color ? and layers
1.324	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.027	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.778	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.566	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.384	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.279	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.184	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.178	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.172	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.168	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.164	IN  ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.160	IN  ADD ^.layer_01110 = point with color ? at (?,?)
0.157	OUT SPE ^.size = ^.size
0.155	OUT SPE ^.layer_01.shape.mask.size = ^.layer_01.shape.mask.size
0.153	OUT SPE ^.layer_0.shape.mask.size = ^.layer_0.shape.mask.size
0.151	OUT SPE ^.layer_01.pos = ^.layer_01.pos
0.150	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.149	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.149	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.148	IN  SPE ^.layer_011111.shape.color = grey
0.147	OUT SPE ^.layer_011.pos.j = ^.layer_011111.pos.i - ^.layer_0111.pos.j - ^.layer_011.pos.j
0.147	OUT SPE ^.layer_011.shape.mask.size.j = area(^.layer_011111.shape) - ^.layer_0111.pos.i - ^.layer_011111.pos.i
0.146	OUT SPE ^.layer_011.pos.i = ^.layer_01.pos.i - ^.layer_01110.pos.i - ^.layer_0.pos.i
0.146	IN  SPE ^.layer_011111.shape.mask.model = Full
0.145	IN  SPE ^.layer_0111111.shape.mask.model = Full
0.145	OUT SPE ^.layer_0.shape.mask.model = Full
0.145	OUT SPE ^.layer_01.shape.mask.model = Full
0.144	OUT SPE ^.layer_011.shape.mask.model = Full
0.005	
0.004	IN  DEL ^.layer_0111111
0.004	IN  DEL ^.layer_01111
0.004	IN  GEN ^.layer_011111.shape.color = ?
0.004	IN  GEN ^.layer_011111.shape.mask.model = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size ^.layer_0.shape.mask.size with model Full with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: rectangle with size ^.layer_01.shape.mask.size with model Full with color ^.layer_01.shape.color at ^.layer_01.pos
  _011: rectangle with size (?,area(^.layer_011111.shape) - ^.layer_0111.pos.i - ^.layer_011111.pos.i) with model Full with color ? at (^.layer_01.pos.i - ^.layer_01110.pos.i - ^.layer_0.pos.i,^.layer_011111.pos.i - ^.layer_0111.pos.j - ^.layer_011.pos.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01110: point with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model Full with color grey at (?,?)
  _0111111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 230.3 + 34950.6 = 35180.9
DL output with Mo: L = 265.9 + 640.5 = 906.4
DL input+output M: L = 496.2 + 35591.1 = 36087.3

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size ^.layer_0.shape.mask.size with model Full with color ^.layer_0.shape.color at ^.layer_0.pos
  _01: rectangle with size ^.layer_01.shape.mask.size with model Full with color ^.layer_01.shape.color at ^.layer_01.pos
  _011: rectangle with size (?,area(^.layer_011111.shape) - ^.layer_0111.pos.i - ^.layer_011111.pos.i) with model Full with color ? at (^.layer_01.pos.i - ^.layer_01110.pos.i - ^.layer_0.pos.i,^.layer_011111.pos.i - ^.layer_0111.pos.j - ^.layer_011.pos.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01110: point with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 171.1 + 0.0 = 171.1
DL output with Mo: L = 265.9 + 640.5 = 906.4
DL input+output M: L = 437.0 + 640.5 = 1077.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (13,17) and color red and layers
  _0: rectangle with size (13,5) with mask 
0 0 0 0 0 
. . 0 . 0 
. 0 0 . 0 
0 0 0 0 0 
. 0 0 0 . 
. 0 . 0 0 
0 0 0 0 . 
0 0 0 0 0 
0 0 0 . 0 
. 0 0 . 0 
0 0 0 0 0 
0 0 0 0 0 
0 . 0 . 0 
 with color blue at (0,0)
  _01: rectangle with size (13,4) with model Full with color green at (0,8)
  _011: rectangle with size (13,4) with model Full with color cyan at (0,4)
  _01110: point with color cyan at (0,15)
  _0111: rectangle with size (4,1) with model Full with color brown at (1,0)
  _011111: rectangle with size (1,3) with model Full with color grey at (1,1)
  + 32 delta pixels
diff: 
   (0.0 bits)
data: a background with size (13,17) and color red and layers
  _0: rectangle with size (13,5) with model Full with color blue at (0,0)
  _01: rectangle with size (13,4) with model Full with color green at (0,8)
  _011: rectangle with size (13,3) with model Full with color cyan at (0,5)
diff: 
   (25.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,17) and color red and layers
  _0: rectangle with size (13,5) with mask 
0 0 0 0 0 
. . 0 . 0 
. 0 0 . 0 
0 0 0 0 0 
. 0 0 0 . 
. 0 . 0 0 
0 0 0 0 . 
0 0 0 0 0 
0 0 0 . 0 
. 0 0 . 0 
0 0 0 0 0 
0 0 0 0 0 
0 . 0 . 0 
 with color blue at (0,0)
  _01: rectangle with size (13,4) with model Full with color green at (0,8)
  _011: rectangle with size (13,4) with model Full with color cyan at (0,4)
  _01110: point with color cyan at (0,15)
  _0111: rectangle with size (4,1) with model Full with color brown at (1,0)
  _011111: rectangle with size (1,3) with model Full with color grey at (1,1)
  + 32 delta pixels
diff: 
! 104 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,17) and color red and layers
  _0: rectangle with size (13,5) with mask 
0 0 0 0 0 
. . 0 . 0 
. 0 0 . 0 
0 0 0 0 0 
. 0 0 0 . 
. 0 . 0 0 
0 0 0 0 . 
0 0 0 0 0 
0 0 0 . 0 
. 0 0 . 0 
0 0 0 0 0 
0 0 0 0 0 
0 . 0 . 0 
 with color blue at (0,0)
  _01: rectangle with size (13,4) with model Full with color green at (0,8)
  _011: rectangle with size (13,4) with mask 
. 0 0 0 
. 0 0 0 
. 0 0 . 
. 0 0 . 
0 0 0 0 
. . 0 0 
. 0 0 0 
. 0 . 0 
. 0 0 0 
. . 0 0 
. 0 0 0 
. 0 0 0 
. 0 0 0 
 with color cyan at (0,4)
  _01110: point with color cyan at (0,15)
  _0111: rectangle with size (4,1) with model Full with color brown at (1,0)
  _011111: rectangle with size (2,1) with model Full with color pink at (5,14)
  + 31 delta pixels
diff: 
! 104 wrong pixels (generated / expected)

TRAIN e26a3af2.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (13,14) and color cyan and layers
  _0: rectangle with size (13,5) with mask 
0 0 0 0 0 
0 0 . 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 . 0 
0 . . 0 0 
0 0 0 0 0 
0 0 0 . 0 
0 0 0 0 . 
0 0 0 0 0 
0 . 0 0 0 
 with color red at (0,0)
  _01: rectangle with size (13,3) with mask 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 . 
0 0 0 
0 0 . 
. 0 0 
0 0 0 
. 0 . 
. 0 0 
 with color blue at (0,11)
  _011: rectangle with size (2,2) with model Odd Checkboard with color brown at (2,6)
  _01110: point with color blue at (0,7)
  _0111: rectangle with size (2,1) with model Full with color grey at (5,10)
  _011111: rectangle with size (2,1) with model Full with color grey at (9,8)
  + 17 delta pixels
diff: 
   (0.0 bits)
data: a background with size (13,14) and color black and layers
  _0: rectangle with size (13,5) with model Full with color red at (0,0)
  _01: rectangle with size (13,3) with model Full with color blue at (0,11)
  _011: rectangle with size (13,6) with model Full with color cyan at (0,5)
diff: 
   (18.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,14) and color cyan and layers
  _0: rectangle with size (13,5) with mask 
0 0 0 0 0 
0 0 . 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 . 0 
0 . . 0 0 
0 0 0 0 0 
0 0 0 . 0 
0 0 0 0 . 
0 0 0 0 0 
0 . 0 0 0 
 with color red at (0,0)
  _01: rectangle with size (13,3) with mask 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 . 
0 0 0 
0 0 . 
. 0 0 
0 0 0 
. 0 . 
. 0 0 
 with color blue at (0,11)
  _011: rectangle with size (2,2) with model Odd Checkboard with color brown at (2,6)
  _01110: point with color blue at (0,7)
  _0111: rectangle with size (2,1) with model Full with color grey at (5,10)
  _011111: rectangle with size (2,1) with model Full with color grey at (9,8)
  + 17 delta pixels
diff: 
! 78 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,14) and color cyan and layers
  _0: rectangle with size (13,5) with mask 
0 0 0 0 0 
0 0 . 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 . 0 
0 . . 0 0 
0 0 0 0 0 
0 0 0 . 0 
0 0 0 0 . 
0 0 0 0 0 
0 . 0 0 0 
 with color red at (0,0)
  _01: rectangle with size (13,3) with mask 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 0 
0 0 . 
0 0 0 
0 0 . 
. 0 0 
0 0 0 
. 0 . 
. 0 0 
 with color blue at (0,11)
  _011: rectangle with size (2,2) with model Odd Checkboard with color brown at (2,6)
  _01110: point with color blue at (0,7)
  _0111: rectangle with size (2,1) with model Full with color grey at (5,10)
  _011111: rectangle with size (4,1) with model Full with color pink at (6,3)
  + 17 delta pixels
diff: 
! 78 wrong pixels (generated / expected)

TRAIN e26a3af2.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (15,14) and color green and layers
  _0: rectangle with size (6,14) with mask 
0 0 0 0 0 0 . 0 0 . . 0 0 . 
. 0 0 0 . 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 . . 
0 0 0 0 0 . 0 0 0 0 0 0 . . 
0 0 0 0 0 0 . 0 0 0 0 . 0 0 
0 0 0 . . 0 0 0 0 0 . 0 0 0 
 with color orange at (4,0)
  _01: rectangle with size (3,14) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 . 0 
0 0 0 0 0 0 0 0 0 0 0 . 0 0 
0 0 0 . 0 0 0 . . 0 0 0 0 0 
 with color cyan at (10,0)
  _011: rectangle with size (2,14) with model Full with color blue at (13,0)
  _01110: point with color red at (1,5)
  _0111: rectangle with size (2,2) with model Odd Checkboard with color red at (1,7)
  _011111: rectangle with size (1,8) with model Full with color grey at (7,5)
  + 22 delta pixels
diff: 
   (0.0 bits)
data: a background with size (15,14) and color green and layers
  _0: rectangle with size (6,14) with model Full with color orange at (4,0)
  _01: rectangle with size (3,14) with model Full with color cyan at (10,0)
  _011: rectangle with size (2,14) with model Full with color blue at (13,0)
diff: 
   (19.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,14) and color green and layers
  _0: rectangle with size (6,14) with mask 
0 0 0 0 0 0 . 0 0 . . 0 0 . 
. 0 0 0 . 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 . . 
0 0 0 0 0 . 0 0 0 0 0 0 . . 
0 0 0 0 0 0 . 0 0 0 0 . 0 0 
0 0 0 . . 0 0 0 0 0 . 0 0 0 
 with color orange at (4,0)
  _01: rectangle with size (3,14) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 . 0 
0 0 0 0 0 0 0 0 0 0 0 . 0 0 
0 0 0 . 0 0 0 . . 0 0 0 0 0 
 with color cyan at (10,0)
  _011: rectangle with size (2,14) with model Full with color blue at (13,0)
  _01110: point with color red at (1,5)
  _0111: rectangle with size (2,2) with model Odd Checkboard with color red at (1,7)
  _011111: rectangle with size (1,8) with model Full with color grey at (7,5)
  + 22 delta pixels
diff: 
! 84 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,14) and color green and layers
  _0: rectangle with size (6,14) with mask 
0 0 0 0 0 0 . 0 0 . . 0 0 . 
. 0 0 0 . 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 . . 
0 0 0 0 0 . 0 0 0 0 0 0 . . 
0 0 0 0 0 0 . 0 0 0 0 . 0 0 
0 0 0 . . 0 0 0 0 0 . 0 0 0 
 with color orange at (4,0)
  _01: rectangle with size (3,14) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 . 0 
0 0 0 0 0 0 0 0 0 0 0 . 0 0 
0 0 0 . 0 0 0 . . 0 0 0 0 0 
 with color cyan at (10,0)
  _011: rectangle with size (2,14) with model Full with color blue at (13,0)
  _01110: point with color red at (1,5)
  _0111: rectangle with size (2,2) with model Odd Checkboard with color red at (1,7)
  _011111: rectangle with size (2,2) with model Even Checkboard with color cyan at (6,12)
  + 22 delta pixels
diff: 
! 84 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,14) and color green and layers
  _0: rectangle with size (6,14) with mask 
0 0 0 0 0 0 . 0 0 . . 0 0 . 
. 0 0 0 . 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 . . 
0 0 0 0 0 . 0 0 0 0 0 0 . . 
0 0 0 0 0 0 . 0 0 0 0 . 0 0 
0 0 0 . . 0 0 0 0 0 . 0 0 0 
 with color orange at (4,0)
  _01: rectangle with size (3,14) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 . 0 
0 0 0 0 0 0 0 0 0 0 0 . 0 0 
0 0 0 . 0 0 0 . . 0 0 0 0 0 
 with color cyan at (10,0)
  _011: rectangle with size (2,14) with model Full with color blue at (13,0)
  _01110: point with color yellow at (0,1)
  _0111: rectangle with size (2,2) with model Odd Checkboard with color red at (1,7)
  _011111: rectangle with size (2,2) with model Even Checkboard with color cyan at (6,12)
  + 22 delta pixels
diff: 
! 84 wrong pixels (generated / expected)

TRAIN e26a3af2.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color cyan and layers
  _0: rectangle with size (4,15) with mask 
. 0 0 0 0 . 0 . 0 0 . 0 . 0 0 
0 0 . 0 . 0 0 0 . 0 0 . 0 . 0 
0 . 0 0 . . . 0 0 0 . 0 . 0 0 
0 0 0 0 0 0 0 0 0 0 . 0 . 0 0 
 with color red at (3,0)
  _01: rectangle with size (3,15) with model Full with color blue at (0,0)
  _011: rectangle with size (2,15) with mask 
0 0 0 0 0 0 . . 0 0 0 0 0 . 0 
0 0 . 0 0 0 0 0 0 0 . 0 0 0 0 
 with color yellow at (11,0)
  _01110: point with color orange at (3,0)
  _0111: rectangle with size (2,15) with mask 
0 0 . . 0 0 0 0 0 0 0 0 0 0 0 
. . 0 0 . 0 0 0 0 0 0 0 0 0 0 
 with color green at (13,0)
  _011111: rectangle with size (1,12) with model Full with color grey at (5,1)
  + 34 delta pixels
diff: 
! 120 wrong pixels (generated / expected)

TEST e26a3af2.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 31.2 sec (31.2 sec/task)
bits-train-error = 640.5 bits (640.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-41] Checking task e3497940.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 107490.8 = 107493.1
DL output with Mo: L = 2.3 + 46893.0 = 46895.3
DL input+output M: L = 4.6 + 154383.7 = 154388.4

# learning a model for train pairs
2.000	
1.269	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.580	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.417	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.316	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.273	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.231	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.210	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.193	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.179	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.171	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.162	OUT ADD ^.layer_0111 = ^.layer_0111.shape at (?,?)
0.152	OUT SPE ^.size = ^.layer_0.shape.mask.size + (0, 3)
0.147	IN  SPE ^.layer_0.shape.mask = 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 

0.144	OUT SPE ^.layer_0.shape.mask.size.j = 2
0.140	IN  ADD ^.layer_01110 = point with color ? at (?,?)
0.134	OUT SPE ^.layer_0111.pos = projI(^.layer_0111.pos) + (0, 1)
0.129	OUT ADD ^.layer_01110 = ^.layer_01110.shape at (?,?)
0.123	OUT SPE ^.layer_01.pos = projI(^.layer_01.pos) + (0, 3)
0.119	OUT SPE ^.layer_01110.pos.i = ^.layer_01110.pos.i
0.116	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.113	OUT SPE ^.layer_0.shape.color = ^.layer_01111.shape.color
0.110	OUT SPE ^.layer_0.pos.j = 2
0.108	OUT SPE ^.layer_011.shape.mask.size.j = area(^.layer_011.shape.mask) - 1
0.105	OUT SPE ^.layer_011.pos.j = min(^.layer_01.pos.j, ^.layer_011.pos.j)
0.103	OUT SPE ^.layer_01.shape.mask.size.j = 1
0.101	OUT SPE ^.layer_01110.pos.j = min(^.layer_01111.pos.j, ^.layer_01110.pos.j)
0.099	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_01.shape.mask.size.j
0.097	OUT SPE ^.layer_0.shape.mask.model = Full
0.095	OUT SPE ^.layer_011.pos.i = bottom(^.layer_011) - ^.layer_0111.pos.j - ^.layer_0.pos.j
0.092	OUT SPE ^.layer_0.pos.i = ^.layer_01110.pos.i + ^.layer_01110.pos.j - ^.layer_01.pos.j
0.091	OUT SPE ^.layer_01.shape.mask.model = Full
0.089	OUT SPE ^.layer_011.shape.mask.model = Full
0.087	OUT SPE ^.color = black
0.086	IN  SPE ^.layer_0.shape.color = grey
0.084	OUT SPE ^.layer_011.shape.mask.size.i = ^.layer_01.shape.mask.size.i - max(^.layer_011.shape.mask.size.i, ^.layer_01111.shape.mask.size.i)
0.084	IN  SPE ^.layer_0111.shape.mask.model = Full
0.083	IN  SPE ^.layer_01111.shape.mask.model = Full
0.082	IN  SPE ^.color = black
0.021	
0.021	IN  GEN ^.layer_0.shape.color = ?
0.021	IN  GEN ^.layer_01111.shape.mask.model = ?
0.021	IN  GEN ^.layer_0111.shape.mask.model = ?
0.021	IN  GEN ^.layer_0.shape.mask = rectangle with size (?,?) with model ?
0.021	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size + (0, 3) and color black and layers
  _0: rectangle with size (^.layer_01.shape.mask.size.j,2) with model Full with color ^.layer_01111.shape.color at (^.layer_01110.pos.i + ^.layer_01110.pos.j - ^.layer_01.pos.j,2)
  _01: rectangle with size (?,1) with model Full with color ^.layer_01.shape.color at projI(^.layer_01.pos) + (0, 3)
  _011: rectangle with size (^.layer_01.shape.mask.size.i - max(^.layer_011.shape.mask.size.i, ^.layer_01111.shape.mask.size.i),area(^.layer_011.shape.mask) - 1) with model Full with color ? at (bottom(^.layer_011) - ^.layer_0111.pos.j - ^.layer_0.pos.j,min(^.layer_01.pos.j, ^.layer_011.pos.j))
  _01110: ^.layer_01110.shape at (^.layer_01110.pos.i,min(^.layer_01111.pos.j, ^.layer_01110.pos.j))
  _0111: ^.layer_0111.shape at projI(^.layer_0111.pos) + (0, 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color grey at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01110: point with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 175.9 + 6609.1 = 6785.0
DL output with Mo: L = 467.3 + 424.7 = 892.0
DL input+output M: L = 643.2 + 7033.8 = 7677.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size + (0, 3) and color black and layers
  _0: rectangle with size (^.layer_01.shape.mask.size.j,2) with model Full with color ^.layer_01111.shape.color at (^.layer_01110.pos.i + ^.layer_01110.pos.j - ^.layer_01.pos.j,2)
  _01: rectangle with size (?,1) with model Full with color ^.layer_01.shape.color at projI(^.layer_01.pos) + (0, 3)
  _011: rectangle with size (^.layer_01.shape.mask.size.i - max(^.layer_011.shape.mask.size.i, ^.layer_01111.shape.mask.size.i),area(^.layer_011.shape.mask) - 1) with model Full with color ? at (bottom(^.layer_011) - ^.layer_0111.pos.j - ^.layer_0.pos.j,min(^.layer_01.pos.j, ^.layer_011.pos.j))
  _01110: ^.layer_01110.shape at (^.layer_01110.pos.i,min(^.layer_01111.pos.j, ^.layer_01110.pos.j))
  _0111: ^.layer_0111.shape at projI(^.layer_0111.pos) + (0, 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01110: point with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 171.1 + 63.4 = 234.5
DL output with Mo: L = 467.3 + 424.7 = 892.0
DL input+output M: L = 638.4 + 488.1 = 1126.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,9) and color black and layers
  _0: rectangle with size (10,1) with model Full with color grey at (0,4)
  _01: rectangle with size (4,1) with model Full with color green at (4,3)
  _011: rectangle with size (2,1) with model Full with color yellow at (2,3)
  _01110: point with color green at (4,2)
  _0111: rectangle with size (1,3) with model Full with color green at (6,5)
  _01111: rectangle with size (1,2) with model Full with color yellow at (3,5)
diff: 
   (0.0 bits)
data: a background with size (10,4) and color black and layers
  _0: rectangle with size (1,2) with model Full with color yellow at (3,2)
  _01: rectangle with size (4,1) with model Full with color green at (4,3)
  _011: rectangle with size (2,1) with model Full with color yellow at (2,3)
  _01110: 
3 
 at (4,2)
  _0111: 
3 3 3 
 at (6,1)
diff: 
   (13.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,9) and color black and layers
  _0: rectangle with size (10,1) with model Full with color grey at (0,4)
  _01: rectangle with size (4,1) with model Full with color green at (4,3)
  _011: rectangle with size (2,1) with model Full with color yellow at (2,3)
  _01110: point with color green at (4,2)
  _0111: rectangle with size (1,3) with model Full with color green at (6,5)
  _01111: rectangle with size (1,2) with model Full with color yellow at (3,5)
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,9) and color black and layers
  _0: rectangle with size (10,1) with model Full with color grey at (0,4)
  _01: rectangle with size (4,1) with model Full with color green at (4,3)
  _011: rectangle with size (2,1) with model Full with color yellow at (2,3)
  _01110: point with color green at (4,2)
  _0111: rectangle with size (1,2) with model Full with color yellow at (3,5)
  _01111: rectangle with size (1,3) with model Full with color green at (6,5)
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,9) and color black and layers
  _0: rectangle with size (10,1) with model Full with color grey at (0,4)
  _01: rectangle with size (4,1) with model Full with color green at (4,3)
  _011: rectangle with size (1,3) with model Full with color green at (6,5)
  _01110: point with color green at (4,2)
  _0111: rectangle with size (2,1) with model Full with color yellow at (2,3)
  _01111: rectangle with size (1,2) with model Full with color yellow at (3,5)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN e3497940.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,9) and color black and layers
  _0: rectangle with size (10,1) with model Full with color grey at (0,4)
  _01: rectangle with size (4,1) with model Full with color red at (1,3)
  _011: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
. . 0 
 with color red at (6,1)
  _01110: point with color pink at (2,6)
  _0111: rectangle with size (1,3) with model Full with color red at (4,5)
  _01111: rectangle with size (1,4) with model Full with color pink at (5,2)
  + 2 delta pixels
diff: 
   (3.2 bits)
data: a background with size (10,4) and color black and layers
  _0: rectangle with size (1,2) with model Full with color pink at (5,2)
  _01: rectangle with size (8,1) with model Full with color red at (1,3)
  _011: rectangle with size (1,3) with model Full with color red at (7,1)
  _01110: 
6 
 at (2,2)
  _0111: 
2 2 2 
 at (4,1)
diff: 
   (15.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,9) and color black and layers
  _0: rectangle with size (10,1) with model Full with color grey at (0,4)
  _01: rectangle with size (4,1) with model Full with color red at (1,3)
  _011: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
. . 0 
 with color red at (6,1)
  _01110: point with color red at (2,5)
  _0111: rectangle with size (1,3) with model Full with color red at (4,5)
  _01111: rectangle with size (1,4) with model Full with color pink at (5,2)
  + 2 delta pixels
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,9) and color black and layers
  _0: rectangle with size (10,1) with model Full with color grey at (0,4)
  _01: rectangle with size (4,1) with model Full with color red at (1,3)
  _011: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
. . 0 
 with color red at (6,1)
  _01110: point with color red at (2,5)
  _0111: rectangle with size (1,4) with model Full with color pink at (5,2)
  _01111: rectangle with size (1,3) with model Full with color red at (4,5)
  + 2 delta pixels
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,9) and color black and layers
  _0: rectangle with size (10,1) with model Full with color grey at (0,4)
  _01: rectangle with size (4,1) with model Full with color red at (1,3)
  _011: rectangle with size (3,3) with mask 
. . 0 
0 0 . 
. . 0 
 with color red at (6,1)
  _01110: point with color pink at (2,6)
  _0111: rectangle with size (1,3) with model Full with color red at (4,5)
  _01111: rectangle with size (1,4) with model Full with color pink at (5,2)
  + 2 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TRAIN e3497940.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,9) and color black and layers
  _0: rectangle with size (10,1) with model Full with color grey at (0,4)
  _01: rectangle with size (3,2) with mask 
. 0 
. 0 
0 0 
 with color cyan at (2,2)
  _011: rectangle with size (1,2) with model Full with color cyan at (5,5)
  _01110: point with color orange at (1,5)
  _0111: rectangle with size (1,1) with model Full with color orange at (4,1)
  _01111: rectangle with size (2,1) with model Full with color cyan at (6,3)
  + 2 delta pixels
diff: 
   (3.2 bits)
data: a background with size (10,4) and color black and layers
  _0: rectangle with size (2,2) with model Full with color cyan at (4,2)
  _01: rectangle with size (7,1) with model Full with color cyan at (2,3)
  _011: rectangle with size (1,1) with model Full with color orange at (8,2)
  _01110: 
7#
 at (1,3)
  _0111: 
7#
 at (4,1)
diff: 
   (14.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,9) and color black and layers
  _0: rectangle with size (10,1) with model Full with color grey at (0,4)
  _01: rectangle with size (3,2) with mask 
. 0 
. 0 
0 0 
 with color cyan at (2,2)
  _011: rectangle with size (1,2) with model Full with color cyan at (5,5)
  _01110: point with color orange at (1,5)
  _0111: rectangle with size (2,1) with model Full with color cyan at (6,3)
  _01111: rectangle with size (1,1) with model Full with color orange at (4,1)
  + 2 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,9) and color black and layers
  _0: rectangle with size (10,1) with model Full with color grey at (0,4)
  _01: rectangle with size (3,2) with mask 
. 0 
. 0 
0 0 
 with color cyan at (2,2)
  _011: rectangle with size (1,2) with model Full with color cyan at (5,5)
  _01110: point with color orange at (1,5)
  _0111: rectangle with size (2,1) with model Full with color cyan at (6,3)
  _01111: rectangle with size (1,1) with model Full with color cyan at (8,5)
  + 2 delta pixels
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,9) and color black and layers
  _0: rectangle with size (10,1) with model Full with color grey at (0,4)
  _01: rectangle with size (3,2) with mask 
. 0 
. 0 
0 0 
 with color cyan at (2,2)
  _011: rectangle with size (1,2) with model Full with color cyan at (5,5)
  _01110: point with color orange at (1,5)
  _0111: rectangle with size (1,1) with model Full with color orange at (4,1)
  _01111: rectangle with size (2,1) with model Full with color cyan at (6,3)
  + 2 delta pixels
diff: 
! 4 wrong pixels (generated / expected)

TRAIN e3497940.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
Invalid_argument("Model2.mask_rectangle: negative or null mask size")

TEST e3497940.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 45.2 sec (45.2 sec/task)
bits-train-error = 424.7 bits (424.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-40] Checking task e40b9e2f.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.096	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.243	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.167	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.110	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.084	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.068	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.063	OUT SPE ^.size = ^.size
0.060	OUT SPE ^.layer_0.pos = ^.layer_0.pos - (1, 1)
0.059	OUT SPE ^.layer_01.pos.i = 3
0.058	OUT SPE ^.layer_01.pos.j = center(^.layer_01) / '2
0.057	OUT SPE ^.layer_01.shape.mask.model = ^.layer_01.shape.mask.model
0.056	IN  SPE ^.color = black
0.055	OUT SPE ^.color = black
0.033	
0.033	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at ^.layer_0.pos - (1, 1)
  _01: rectangle with size (?,?) with model ^.layer_01.shape.mask.model with color ? at (3,center(^.layer_01) / '2)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.3 + 2662.2 = 2732.6
DL output with Mo: L = 106.7 + 3795.1 = 3901.8
DL input+output M: L = 177.0 + 6457.4 = 6634.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at ^.layer_0.pos - (1, 1)
  _01: rectangle with size (?,?) with model ^.layer_01.shape.mask.model with color ? at (3,center(^.layer_01) / '2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 106.7 + 3795.1 = 3901.8
DL input+output M: L = 176.9 + 3795.1 = 3972.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . 0 . 
. 0 . . 
0 . 0 . 
. . . 0 
 with color yellow at (4,3)
  _01: rectangle with size (4,3) with model +-cross with color orange at (3,3)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,5) with model x-cross with color yellow at (3,2)
  _01: rectangle with size (5,5) with model +-cross with color orange at (3,2)
diff: 
   (49.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 . 0 . 
. 0 . . 
0 . 0 . 
. . . 0 
 with color yellow at (4,3)
  _01: rectangle with size (4,3) with model +-cross with color orange at (3,3)
diff: 
! 19 wrong pixels (generated / expected)

TRAIN e40b9e2f.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 0 
0 0 
. 0 
 with color pink at (4,2)
  _01: rectangle with size (1,1) with model Full with color green at (3,1)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 . . 
. 0 0 0 
0 0 0 . 
. . 0 . 
 with color pink at (3,1)
  _01: rectangle with size (1,1) with model Full with color green at (3,1)
  + 3 delta pixels
diff: 
   (173.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 0 
0 0 
. 0 
 with color pink at (4,2)
  _01: rectangle with size (1,1) with model Full with color green at (3,1)
diff: 
! 13 wrong pixels (generated / expected)

TRAIN e40b9e2f.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Full with color cyan at (3,3)
  _01: rectangle with size (1,1) with model Full with color brown at (2,6)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color brown at (2,2)
  _01: rectangle with size (3,3) with model Full with color cyan at (3,3)
  + 3 delta pixels
diff: 
   (156.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Full with color cyan at (3,3)
  _01: rectangle with size (1,1) with model Full with color brown at (2,6)
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,1) with model Full with color brown at (2,6)
  _01: rectangle with size (3,3) with model Full with color cyan at (3,3)
diff: 
! 18 wrong pixels (generated / expected)

TRAIN e40b9e2f.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,5) with mask 
0 0 0 . 0 
. . . 0 . 
0 0 0 . 0 
 with color green at (3,1)
  _01: rectangle with size (4,3) with model +-cross with color red at (2,3)
diff: 
! 32 wrong pixels (generated / expected)

TEST e40b9e2f.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 6.7 sec (6.7 sec/task)
bits-train-error = 3795.1 bits (3795.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-39] Checking task e48d4e1a.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 159701.1 = 159703.5
DL output with Mo: L = 2.3 + 159701.1 = 159703.5
DL input+output M: L = 4.6 + 319402.3 = 319406.9

# learning a model for train pairs
2.000	
1.196	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.414	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.252	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.090	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.073	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.062	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.053	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.047	OUT SPE ^.layer_01.shape = ^.layer_01.shape
0.041	OUT SPE ^.layer_0.shape = ^.layer_0.shape
0.036	OUT SPE ^.size = ^.size
0.032	IN  SPE ^.layer_0.shape.mask = 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 

0.028	IN  SPE ^.layer_01.shape.mask = 
0 0 0 0 0 0 0 0 0 0 

0.026	OUT SPE ^.layer_01.pos = ^.layer_01.pos + projI(^.layer_011.shape.mask.size)
0.024	OUT SPE ^.layer_0.pos.i = ^.layer_0.pos.i
0.023	IN  SPE ^.layer_011.shape.color = grey
0.022	OUT SPE ^.layer_0.pos.j = ^.layer_0.pos.j - area(^.layer_011.shape)
0.021	IN  SPE ^.layer_011.shape.mask.model = Full
0.020	IN  SPE ^.color = black
0.020	OUT SPE ^.color = black
0.001	
0.001	IN  GEN ^.layer_011.shape.color = ?
0.001	IN  GEN ^.layer_011.shape.mask.model = ?
0.001	IN  GEN ^.layer_01.shape.mask = rectangle with size (?,?) with model ?
0.001	IN  GEN ^.layer_0.shape.mask = rectangle with size (?,?) with model ?
0.001	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0.shape at (^.layer_0.pos.i,^.layer_0.pos.j - area(^.layer_011.shape))
  _01: ^.layer_01.shape at ^.layer_01.pos + projI(^.layer_011.shape.mask.size)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
 with color ? at (?,?)
  _01: 
0 0 0 0 0 0 0 0 0 0 
 with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color grey at (?,?)

DL input  with Mi: L = 102.7 + 2951.3 = 3054.1
DL output with Mo: L = 97.8 + 0.0 = 97.8
DL input+output M: L = 200.5 + 2951.3 = 3151.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0.shape at (^.layer_0.pos.i,^.layer_0.pos.j - area(^.layer_011.shape))
  _01: ^.layer_01.shape at ^.layer_01.pos + projI(^.layer_011.shape.mask.size)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 0.0 = 98.1
DL output with Mo: L = 97.8 + 0.0 = 97.8
DL input+output M: L = 195.9 + 0.0 = 195.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color red at (0,3)
  _01: rectangle with size (1,10) with model Full with color red at (6,0)
  _011: rectangle with size (2,1) with model Full with color grey at (0,9)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
2 
2 
2 
2 
2 
2 
2 
2 
2 
2 
 at (0,1)
  _01: 
2 2 2 2 2 2 2 2 2 2 
 at (8,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color red at (0,3)
  _01: rectangle with size (1,10) with model Full with color red at (6,0)
  _011: rectangle with size (2,1) with model Full with color grey at (0,9)
diff: 
correct output grid

TRAIN e48d4e1a.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color yellow at (0,3)
  _01: rectangle with size (1,10) with model Full with color yellow at (3,0)
  _011: rectangle with size (3,1) with model Full with color grey at (0,9)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
 at (0,0)
  _01: 
4 4 4 4 4 4 4 4 4 4 
 at (6,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color yellow at (0,3)
  _01: rectangle with size (1,10) with model Full with color yellow at (3,0)
  _011: rectangle with size (3,1) with model Full with color grey at (0,9)
diff: 
correct output grid

TRAIN e48d4e1a.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color pink at (0,6)
  _01: rectangle with size (1,10) with model Full with color pink at (4,0)
  _011: rectangle with size (3,1) with model Full with color grey at (0,9)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
6 
6 
6 
6 
6 
6 
6 
6 
6 
6 
 at (0,3)
  _01: 
6 6 6 6 6 6 6 6 6 6 
 at (7,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color pink at (0,6)
  _01: rectangle with size (1,10) with model Full with color pink at (4,0)
  _011: rectangle with size (3,1) with model Full with color grey at (0,9)
diff: 
correct output grid

TRAIN e48d4e1a.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color green at (0,4)
  _01: rectangle with size (1,10) with model Full with color green at (2,0)
  _011: rectangle with size (1,1) with model Full with color grey at (0,9)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
3 
3 
3 
3 
3 
3 
3 
3 
3 
3 
 at (0,3)
  _01: 
3 3 3 3 3 3 3 3 3 3 
 at (3,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color green at (0,4)
  _01: rectangle with size (1,10) with model Full with color green at (2,0)
  _011: rectangle with size (1,1) with model Full with color grey at (0,9)
diff: 
correct output grid

TRAIN e48d4e1a.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,1) with model Full with color cyan at (0,5)
  _01: rectangle with size (1,10) with model Full with color cyan at (3,0)
  _011: rectangle with size (2,1) with model Full with color grey at (0,9)
diff: 
correct output grid

TEST e48d4e1a.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 5.4 sec (5.4 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-38] Checking task e5062a87.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.425	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.884	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.652	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.446	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.357	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.282	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.225	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.201	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.191	OUT ADD ^.layer_00 = ^.layer_0
0.175	OUT ADD ^.layer_010 = ^.layer_01.shape at (?,?)
0.167	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.157	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.152	OUT SPE ^.size = ^.size
0.149	OUT SPE ^.layer_010 = ^.layer_01
0.147	OUT SPE ^.layer_011.pos = ^.layer_011.pos + translationOnto(^.layer_01, ^.layer_011)
0.145	OUT SPE ^.layer_01.shape.mask.size.j = ^.layer_011.shape.mask.size.j
0.144	OUT SPE ^.layer_011.shape.color = ^.layer_011.shape.color
0.051	
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _01: rectangle with size (?,^.layer_011.shape.mask.size.j) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ^.layer_011.shape.color at ^.layer_011.pos + translationOnto(^.layer_01, ^.layer_011)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 11138.3 = 11236.4
DL output with Mo: L = 205.3 + 5793.7 = 5999.0
DL input+output M: L = 303.4 + 16932.1 = 17235.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _010: ^.layer_01
  _01: rectangle with size (?,^.layer_011.shape.mask.size.j) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ^.layer_011.shape.color at ^.layer_011.pos + translationOnto(^.layer_01, ^.layer_011)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 31.7 = 129.8
DL output with Mo: L = 205.3 + 5793.7 = 5999.0
DL input+output M: L = 303.4 + 5825.4 = 6128.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,6) with mask 
. 0 0 0 . . 
. 0 . . . . 
. 0 0 . . . 
0 . 0 0 0 0 
0 . . . . 0 
0 0 . 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (7,4) with mask 
. 0 0 0 
0 . . 0 
. . 0 . 
. 0 . 0 
. . 0 . 
. . 0 0 
. 0 . . 
 with color grey at (0,6)
  _011: rectangle with size (3,4) with mask 
. . . 0 
0 . 0 0 
. 0 0 . 
 with color grey at (7,6)
  + 11 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
. 5#5#5#. . 
. 5#. . . . 
. 5#5#. . . 
5#. 5#5#5#5#
5#. . . . 5#
5#5#. 5#5#5#
 at (0,0)
  _0: rectangle with size (4,5) with mask 
. 0 . . . 
0 . 0 0 . 
. 0 0 . 0 
. . . 0 . 
 with color red at (0,5)
  _010: 
. 5#5#5#
5#. . 5#
. . 5#. 
. 5#. 5#
. . 5#. 
. . 5#5#
. 5#. . 
 at (0,6)
  _01: rectangle with size (5,4) with mask 
. . 0 . 
. 0 . 0 
. 0 0 . 
0 . 0 . 
. 0 . . 
 with color red at (5,5)
  _011: rectangle with size (3,4) with mask 
. . . 0 
0 . 0 0 
. 0 0 . 
 with color grey at (7,6)
  _0111: rectangle with size (3,2) with mask 
0 0 
0 . 
0 0 
 with color grey at (7,3)
  _01111: rectangle with size (3,3) with model Odd Checkboard with color red at (6,0)
  + 2 delta pixels
diff: 
   (284.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,6) with mask 
. 0 0 0 . . 
. 0 . . . . 
. 0 0 . . . 
0 . 0 0 0 0 
0 . . . . 0 
0 0 . 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (7,4) with mask 
. 0 0 0 
0 . . 0 
. . 0 . 
. 0 . 0 
. . 0 . 
. . 0 0 
. 0 . . 
 with color grey at (0,6)
  _011: rectangle with size (3,4) with mask 
. . . 0 
0 . 0 0 
. 0 0 . 
 with color grey at (7,6)
  + 11 delta pixels
diff: 
! 36 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (7,4) with mask 
. 0 0 0 
0 . . 0 
. . 0 . 
. 0 . 0 
. . 0 . 
. . 0 0 
. 0 . . 
 with color grey at (0,6)
  _01: rectangle with size (6,6) with mask 
. 0 0 0 . . 
. 0 . . . . 
. 0 0 . . . 
0 . 0 0 0 0 
0 . . . . 0 
0 0 . 0 0 0 
 with color grey at (0,0)
  _011: rectangle with size (3,4) with mask 
. . . 0 
0 . 0 0 
. 0 0 . 
 with color grey at (7,6)
  + 11 delta pixels
diff: 
! 37 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,6) with mask 
. 0 0 0 . . 
. 0 . . . . 
. 0 0 . . . 
0 . 0 0 0 0 
0 . . . . 0 
0 0 . 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (3,4) with mask 
. . . 0 
0 . 0 0 
. 0 0 . 
 with color grey at (7,6)
  _011: rectangle with size (7,4) with mask 
. 0 0 0 
0 . . 0 
. . 0 . 
. 0 . 0 
. . 0 . 
. . 0 0 
. 0 . . 
 with color grey at (0,6)
  + 11 delta pixels
diff: 
! 41 wrong pixels (generated / expected)

TRAIN e5062a87.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
. 0 0 0 0 . . . . . 
0 . 0 . . . . . . . 
0 0 0 0 0 . . . . . 
0 . 0 0 0 . . . . . 
0 0 0 0 . . 0 . . . 
0 . . . . 0 . . . . 
. 0 0 0 0 0 0 . 0 0 
. . 0 0 0 . . 0 0 . 
0 . 0 0 . 0 . 0 . 0 
0 0 . 0 . 0 0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (1,4) with model Full with color red at (5,1)
  _011: rectangle with size (5,4) with mask 
. 0 . 0 
. 0 0 0 
0 . . 0 
. . 0 0 
. . 0 0 
 with color grey at (0,6)
diff: 
   (3.2 bits)
data: a background with size (10,10) and color black and layers
  _00: 
. 5#5#5#5#. . . . . 
5#. 5#. . . . . . . 
5#5#5#5#5#. . . . . 
5#. 5#5#5#. . . . . 
5#5#5#5#. . 5#. . . 
5#. . . . 5#. . . . 
. 5#5#5#5#5#5#. 5#5#
. . 5#5#5#. . 5#5#. 
5#. 5#5#. 5#. 5#. 5#
5#5#. 5#. 5#5#5#5#5#
 at (0,0)
  _0: rectangle with size (5,1) with model Full with color grey at (0,9)
  _010: 
2 2 2 2 
 at (5,1)
  _01: rectangle with size (1,4) with model Full with color red at (5,6)
  _011: rectangle with size (2,1) with model Full with color grey at (0,7)
  _0111: rectangle with size (2,2) with model Full with color grey at (3,8)
  _01111: rectangle with size (1,1) with model Full with color grey at (2,6)
  + 1 delta pixels
diff: 
   (166.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
. 0 0 0 0 . . . . . 
0 . 0 . . . . . . . 
0 0 0 0 0 . . . . . 
0 . 0 0 0 . . . . . 
0 0 0 0 . . 0 . . . 
0 . . . . 0 . . . . 
. 0 0 0 0 0 0 . 0 0 
. . 0 0 0 . . 0 0 . 
0 . 0 0 . 0 . 0 . 0 
0 0 . 0 . 0 0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (5,4) with mask 
. 0 . 0 
. 0 0 0 
0 . . 0 
. . 0 0 
. . 0 0 
 with color grey at (0,6)
  _011: rectangle with size (1,4) with model Full with color red at (5,1)
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,4) with mask 
. 0 . 0 
. 0 0 0 
0 . . 0 
. . 0 0 
. . 0 0 
 with color grey at (0,6)
  _01: rectangle with size (10,10) with mask 
. 0 0 0 0 . . . . . 
0 . 0 . . . . . . . 
0 0 0 0 0 . . . . . 
0 . 0 0 0 . . . . . 
0 0 0 0 . . 0 . . . 
0 . . . . 0 . . . . 
. 0 0 0 0 0 0 . 0 0 
. . 0 0 0 . . 0 0 . 
0 . 0 0 . 0 . 0 . 0 
0 0 . 0 . 0 0 0 0 0 
 with color grey at (0,0)
  _011: rectangle with size (1,4) with model Full with color red at (5,1)
diff: 
! 11 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
. 0 0 0 0 . . . . . 
0 . 0 . . . . . . . 
0 0 0 0 0 . . . . . 
0 . 0 0 0 . . . . . 
0 0 0 0 . . 0 . . . 
0 . . . . 0 . . . . 
. 0 0 0 0 0 0 . 0 0 
. . 0 0 0 . . 0 0 . 
0 . 0 0 . 0 . 0 . 0 
0 0 . 0 . 0 0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (1,4) with model Full with color red at (5,1)
  _011: rectangle with size (5,4) with mask 
. 0 . 0 
. 0 0 0 
0 . . 0 
. . 0 0 
. . 0 0 
 with color grey at (0,6)
diff: 
! 16 wrong pixels (generated / expected)

TRAIN e5062a87.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
0 0 0 0 . 0 0 0 0 0 
0 0 0 0 . 0 0 0 . 0 
0 . 0 . 0 0 . 0 0 0 
0 . 0 . 0 0 . . 0 0 
0 . . . . 0 0 0 . 0 
0 0 0 . 0 . 0 . . 0 
. 0 . . 0 . 0 0 0 0 
0 0 0 . . . 0 . 0 . 
. 0 0 0 0 . 0 . 0 . 
0 . . . . . 0 . . 0 
 with color grey at (0,0)
  _01: rectangle with size (3,1) with model Full with color red at (7,7)
  _011: rectangle with size (1,2) with model Full with color red at (9,7)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
5#5#5#5#. 5#5#5#5#5#
5#5#5#5#. 5#5#5#. 5#
5#. 5#. 5#5#. 5#5#5#
5#. 5#. 5#5#. . 5#5#
5#. . . . 5#5#5#. 5#
5#5#5#. 5#. 5#. . 5#
. 5#. . 5#. 5#5#5#5#
5#5#5#. . . 5#. 5#. 
. 5#5#5#5#. 5#. 5#. 
5#. . . . . 5#. . 5#
 at (0,0)
  _0: rectangle with size (6,1) with model Full with color red at (2,3)
  _010: 
2 
2 
2 
 at (7,7)
  _01: rectangle with size (1,2) with model Full with color red at (7,3)
  _011: rectangle with size (1,2) with model Full with color red at (9,7)
  _0111: rectangle with size (3,1) with model Full with color red at (2,1)
  _01111: rectangle with size (1,4) with model Full with color red at (4,1)
diff: 
   (128.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
0 0 0 0 . 0 0 0 0 0 
0 0 0 0 . 0 0 0 . 0 
0 . 0 . 0 0 . 0 0 0 
0 . 0 . 0 0 . . 0 0 
0 . . . . 0 0 0 . 0 
0 0 0 . 0 . 0 . . 0 
. 0 . . 0 . 0 0 0 0 
0 0 0 . . . 0 . 0 . 
. 0 0 0 0 . 0 . 0 . 
0 . . . . . 0 . . 0 
 with color grey at (0,0)
  _01: rectangle with size (3,1) with model Full with color red at (7,7)
  _011: rectangle with size (1,2) with model Full with color red at (9,7)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,8) with model Full with color grey at (0,0)
  _01: rectangle with size (10,10) with mask 
0 0 0 0 . 0 0 0 0 0 
0 0 0 0 . 0 0 0 . 0 
0 . 0 . 0 0 . 0 0 0 
0 . 0 . 0 0 . . 0 0 
0 . . . . 0 0 0 . 0 
0 0 0 . 0 . 0 . . 0 
. 0 . . 0 . 0 0 0 0 
0 0 0 . . . 0 . 0 . 
. 0 0 0 0 . 0 . 0 . 
0 . . . . . 0 . . 0 
 with color grey at (0,0)
  _011: rectangle with size (3,2) with model Full with color red at (7,7)
  + 2 delta pixels
diff: 
! 16 wrong pixels (generated / expected)

TRAIN e5062a87.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,3) with model Full with color grey at (3,7)
  _01: rectangle with size (10,10) with mask 
. 0 0 0 . 0 0 0 0 . 
0 0 0 . 0 0 0 0 . 0 
. . 0 0 0 0 . 0 . . 
. . 0 0 0 0 . 0 0 0 
. . 0 0 0 . . . . 0 
0 0 . . . . . 0 0 0 
. . 0 0 . . . 0 0 0 
. 0 0 0 0 0 0 . . . 
0 0 . . 0 0 0 . . . 
0 . 0 . 0 . . 0 . . 
 with color grey at (0,0)
  _011: rectangle with size (3,2) with model Full with color red at (4,5)
  + 3 delta pixels
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,3) with model Full with color grey at (0,5)
  _01: rectangle with size (10,10) with mask 
. 0 0 0 . 0 0 0 0 . 
0 0 0 . 0 0 0 0 . 0 
. . 0 0 0 0 . 0 . . 
. . 0 0 0 0 . 0 0 0 
. . 0 0 0 . . . . 0 
0 0 . . . . . 0 0 0 
. . 0 0 . . . 0 0 0 
. 0 0 0 0 0 0 . . . 
0 0 . . 0 0 0 . . . 
0 . 0 . 0 . . 0 . . 
 with color grey at (0,0)
  _011: rectangle with size (3,2) with model Full with color red at (4,5)
  + 4 delta pixels
diff: 
! 20 wrong pixels (generated / expected)

TEST e5062a87.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.4 sec (59.4 sec/task)
bits-train-error = 5793.7 bits (5793.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-37] Checking task e509e548.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 278262.2 = 278264.5
DL output with Mo: L = 2.3 + 278262.2 = 278264.5
DL input+output M: L = 4.6 + 556524.3 = 556529.0

# learning a model for train pairs
2.000	
1.159	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.318	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.283	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.248	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.215	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.183	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.161	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.139	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.126	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.113	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.101	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.088	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.084	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.045	
0.044	IN  GEN ^ = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 180.9 + 10828.5 = 11009.3
DL output with Mo: L = 153.4 + 12142.1 = 12295.5
DL input+output M: L = 334.3 + 22970.6 = 23304.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 153.4 + 12142.1 = 12295.5
DL input+output M: L = 155.7 + 12142.1 = 12297.8

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 
0 0 0 3 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 3 3 3 3 0 0 0 0 0 3 3 3 0 0 0 0 0 0 
0 0 0 3 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 
0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 
0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 
3 3 3 3 0 0 3 3 3 3 3 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 3 3 3 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 3 0 0 0 
0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 3 0 3 0 0 0 
0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (19,21) and color black and layers
  _0: rectangle with size (5,4) with mask 
. 0 0 . 
. 0 . . 
. 0 . . 
. 0 . . 
0 0 0 0 
 with color red at (9,0)
  _01: rectangle with size (4,3) with mask 
0 0 0 
0 . . 
0 . . 
0 0 0 
 with color pink at (4,12)
  _011: rectangle with size (4,3) with mask 
0 0 0 
0 . 0 
0 . 0 
. . 0 
 with color pink at (15,15)
  _0111: rectangle with size (3,4) with mask 
0 . . 0 
0 0 0 0 
0 . . . 
 with color red at (3,3)
  _01111: rectangle with size (3,5) with mask 
0 0 0 0 0 
0 . . . . 
0 . . . . 
 with color blue at (13,6)
  + 12 delta pixels
diff: 
   (777.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 
0 0 0 3 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 3 3 3 3 0 0 0 0 0 3 3 3 0 0 0 0 0 0 
0 0 0 3 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 
0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 
0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 
3 3 3 3 0 0 3 3 3 3 3 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 3 3 3 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 3 0 0 0 
0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 3 0 3 0 0 0 
0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 

diff: 
! size mismatch, 10x10 instead of 19x21

TRAIN e509e548.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
3 3 3 0 0 0 0 0 0 0 0 
0 0 3 0 0 0 3 3 3 3 0 
0 0 3 0 0 0 3 0 0 3 0 
0 0 0 0 0 0 3 0 0 3 0 
0 0 0 0 0 0 3 0 0 3 0 
0 0 0 0 0 0 0 0 0 0 0 
3 3 3 3 3 0 0 0 0 0 0 
0 0 3 0 0 0 0 0 0 0 0 
0 0 3 0 0 0 0 0 0 0 0 
0 0 3 3 3 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (10,11) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 0 0 
0 . . 0 
0 . . 0 
0 . . 0 
 with color pink at (1,6)
  _01: rectangle with size (3,3) with mask 
0 0 0 
. . 0 
. . 0 
 with color blue at (0,0)
  _011: rectangle with size (1,5) with model Full with color red at (6,0)
  _0111: rectangle with size (4,1) with model Full with color red at (6,2)
  _01111: rectangle with size (1,3) with model Full with color red at (9,2)
diff: 
   (204.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
3 3 3 0 0 0 0 0 0 0 0 
0 0 3 0 0 0 3 3 3 3 0 
0 0 3 0 0 0 3 0 0 3 0 
0 0 0 0 0 0 3 0 0 3 0 
0 0 0 0 0 0 3 0 0 3 0 
0 0 0 0 0 0 0 0 0 0 0 
3 3 3 3 3 0 0 0 0 0 0 
0 0 3 0 0 0 0 0 0 0 0 
0 0 3 0 0 0 0 0 0 0 0 
0 0 3 3 3 0 0 0 0 0 0 

diff: 
! size mismatch, 10x10 instead of 10x11

TRAIN e509e548.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 
0 3 0 0 0 0 0 0 0 3 0 0 
0 3 0 0 0 0 0 0 0 3 3 3 
0 3 0 0 0 3 0 0 0 0 0 0 
0 3 3 3 3 3 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 3 0 0 0 0 
0 0 0 0 0 3 3 3 0 0 0 0 
0 0 0 0 0 3 0 3 0 0 0 0 
0 0 0 0 0 3 0 3 0 0 0 0 
3 3 3 0 0 0 0 0 0 0 0 0 
0 0 3 0 0 0 0 0 0 3 0 3 
0 0 0 0 0 0 0 0 0 3 3 3 

diff: 
   (0.0 bits)
data: a background with size (14,12) and color black and layers
  _0: rectangle with size (4,5) with mask 
0 . . . . 
0 . . . . 
0 . . . 0 
0 0 0 0 0 
 with color pink at (1,1)
  _01: rectangle with size (4,3) with mask 
. . 0 
0 0 0 
0 . 0 
0 . 0 
 with color red at (7,5)
  _011: rectangle with size (2,3) with mask 
0 . 0 
0 0 0 
 with color pink at (12,9)
  _0111: rectangle with size (2,3) with mask 
0 . . 
0 0 0 
 with color blue at (1,9)
  _01111: rectangle with size (2,3) with mask 
0 0 0 
. . 0 
 with color blue at (11,0)
diff: 
   (232.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 
0 3 0 0 0 0 0 0 0 3 0 0 
0 3 0 0 0 0 0 0 0 3 3 3 
0 3 0 0 0 3 0 0 0 0 0 0 
0 3 3 3 3 3 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 3 0 0 0 0 
0 0 0 0 0 3 3 3 0 0 0 0 
0 0 0 0 0 3 0 3 0 0 0 0 
0 0 0 0 0 3 0 3 0 0 0 0 
3 3 3 0 0 0 0 0 0 0 0 0 
0 0 3 0 0 0 0 0 0 3 0 3 
0 0 0 0 0 0 0 0 0 3 3 3 

diff: 
! size mismatch, 10x10 instead of 14x12

TRAIN e509e548.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 3 0 3 0 0 0 0 0 0 0 0 3 0 0 0 
0 3 0 3 0 0 0 0 0 0 0 0 3 0 0 0 
0 3 3 3 0 0 0 0 0 0 0 0 3 3 3 0 
0 0 0 0 0 0 0 0 0 0 0 0 3 0 3 0 
0 0 0 0 0 0 3 3 0 0 0 0 0 0 3 0 
0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 
0 0 0 3 3 3 3 3 0 0 3 3 3 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 
0 0 0 0 0 0 0 0 0 3 3 3 3 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 
0 3 3 3 3 3 3 0 0 0 0 3 0 0 0 0 
0 0 0 0 0 0 3 0 0 0 0 3 3 3 0 0 
0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 

diff: 
! size mismatch, 10x10 instead of 14x16

TEST e509e548.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.9 sec (59.9 sec/task)
bits-train-error = 12142.1 bits (12142.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-36] Checking task e50d258f.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 20576.4 = 20578.8
DL input+output M: L = 4.6 + 140352.3 = 140356.9

# learning a model for train pairs
2.000	
1.312	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.856	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.595	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.506	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.456	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.422	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.388	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.369	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.350	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.344	OUT SPE ^.layer_01.pos.i = ^.layer_01.pos.i + 2
0.333	OUT SPE ^.layer_0.pos = ^.layer_011.pos / '3
0.326	OUT SPE ^.layer_0.shape.color = ^.layer_011.shape.color
0.320	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.314	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.308	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.303	OUT SPE ^.layer_011.pos.j = ^.layer_01.pos.i
0.298	OUT SPE ^.layer_011.pos.i = ^.layer_01.pos.j / '2
0.293	OUT SPE ^.layer_0.shape.mask.model = ^.layer_011111.shape.mask.model
0.288	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_01111.shape.mask.size.i
0.281	OUT SPE ^.size.i = ^.layer_011.shape.mask.size.i + ^.layer_01111.pos.j - ^.layer_011.pos.j
0.277	OUT SPE ^.layer_01.pos.j = bottom(^.layer_011) - ^.layer_01.shape.mask.size.i
0.140	
0.140	IN  DEL ^.layer_0111111

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (^.layer_011.shape.mask.size.i + ^.layer_01111.pos.j - ^.layer_011.pos.j,?) and color ? and layers
  _0: rectangle with size (^.layer_01111.shape.mask.size.i,?) with model ^.layer_011111.shape.mask.model with color ^.layer_011.shape.color at ^.layer_011.pos / '3
  _01: point with color ? at (^.layer_01.pos.i + 2,bottom(^.layer_011) - ^.layer_01.shape.mask.size.i)
  _011: point with color ? at (^.layer_01.pos.j / '2,^.layer_01.pos.i)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111111: point with color ? at (?,?)

DL input  with Mi: L = 198.5 + 16459.7 = 16658.2
DL output with Mo: L = 332.1 + 2502.7 = 2834.8
DL input+output M: L = 530.6 + 18962.4 = 19493.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (^.layer_011.shape.mask.size.i + ^.layer_01111.pos.j - ^.layer_011.pos.j,?) and color ? and layers
  _0: rectangle with size (^.layer_01111.shape.mask.size.i,?) with model ^.layer_011111.shape.mask.model with color ^.layer_011.shape.color at ^.layer_011.pos / '3
  _01: point with color ? at (^.layer_01.pos.i + 2,bottom(^.layer_011) - ^.layer_01.shape.mask.size.i)
  _011: point with color ? at (^.layer_01.pos.j / '2,^.layer_01.pos.i)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 180.9 + 51.7 = 232.6
DL output with Mo: L = 332.1 + 2502.7 = 2834.8
DL input+output M: L = 513.0 + 2554.4 = 3067.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color cyan and layers
  _0: rectangle with size (10,10) with mask 
0 0 0 0 0 0 . . . . 
0 . . . . 0 . . . . 
0 . . . . 0 . . . . 
0 . . . . 0 . . . . 
0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 
0 0 0 . . . . . . 0 
0 0 0 . . . . . . 0 
0 0 0 . . . . . . 0 
0 0 0 . . . . . . 0 
 with color black at (0,0)
  _01: rectangle with size (1,2) with model Full with color red at (1,7)
  _011: rectangle with size (1,1) with model Full with color red at (3,3)
  _0111: rectangle with size (1,1) with model Full with color blue at (2,2)
  _01111: rectangle with size (1,1) with model Full with color red at (3,7)
  _011111: rectangle with size (1,1) with model Full with color blue at (3,8)
  + 4 delta pixels
diff: 
   (2.0 bits)
data: a background with size (5,4) and color cyan and layers
  _0: rectangle with size (1,2) with model Full with color red at (1,1)
  _01: point with color blue at (3,2)
  _011: point with color red at (3,1)
diff: 
   (32.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color cyan and layers
  _0: rectangle with size (10,10) with mask 
0 0 0 0 0 0 . . . . 
0 . . . . 0 . . . . 
0 . . . . 0 . . . . 
0 . . . . 0 . . . . 
0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 
0 0 0 . . . . . . 0 
0 0 0 . . . . . . 0 
0 0 0 . . . . . . 0 
0 0 0 . . . . . . 0 
 with color black at (0,0)
  _01: rectangle with size (1,2) with model Full with color red at (1,7)
  _011: rectangle with size (1,1) with model Full with color blue at (2,2)
  _0111: rectangle with size (1,1) with model Full with color red at (3,3)
  _01111: rectangle with size (1,1) with model Full with color red at (3,7)
  _011111: rectangle with size (1,1) with model Full with color blue at (3,8)
  + 4 delta pixels
diff: 
! size mismatch, 6x10 instead of 5x4
>> Trial 2
data: a background with size (10,10) and color cyan and layers
  _0: rectangle with size (10,10) with mask 
0 0 0 0 0 0 . . . . 
0 . . . . 0 . . . . 
0 . . . . 0 . . . . 
0 . . . . 0 . . . . 
0 . . . . 0 . . . . 
0 0 0 0 0 0 0 0 0 0 
0 0 0 . . . . . . 0 
0 0 0 . . . . . . 0 
0 0 0 . . . . . . 0 
0 0 0 . . . . . . 0 
 with color black at (0,0)
  _01: rectangle with size (1,2) with model Full with color red at (1,7)
  _011: rectangle with size (1,1) with model Full with color red at (3,3)
  _0111: rectangle with size (1,1) with model Full with color blue at (2,2)
  _01111: rectangle with size (1,1) with model Full with color red at (3,7)
  _011111: rectangle with size (1,1) with model Full with color blue at (3,8)
  + 4 delta pixels
diff: 
! size mismatch, 5x10 instead of 5x4

TRAIN e50d258f.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color cyan and layers
  _0: rectangle with size (10,10) with mask 
. . . . 0 0 0 0 0 0 
. . . . 0 . . . . . 
. . . . 0 . . . . . 
. . . . 0 . . . . . 
. . . . 0 . . . . . 
0 0 0 0 0 . . . . . 
0 0 0 0 0 . . . . . 
0 . . . 0 . . . . . 
0 . . . 0 0 0 0 0 0 
0 . . . 0 0 0 0 0 0 
 with color black at (0,0)
  _01: rectangle with size (5,4) with mask 
0 0 0 . 
0 . 0 0 
. . . 0 
0 0 0 . 
. 0 . . 
 with color blue at (0,0)
  _011: rectangle with size (3,4) with mask 
. . . 0 
0 0 . 0 
. 0 0 . 
 with color blue at (5,5)
  _0111: rectangle with size (3,3) with mask 
. 0 0 
0 0 . 
0 . . 
 with color red at (7,1)
  _01111: rectangle with size (2,2) with model Even Checkboard with color blue at (1,5)
  _011111: rectangle with size (2,2) with model Odd Checkboard with color blue at (8,2)
  + 8 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color red and layers
  _0: rectangle with size (2,2) with model Odd Checkboard with color blue at (1,1)
  _01: point with color cyan at (2,2)
  _011: point with color cyan at (0,0)
diff: 
   (32.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color cyan and layers
  _0: rectangle with size (10,10) with mask 
. . . . 0 0 0 0 0 0 
. . . . 0 . . . . . 
. . . . 0 . . . . . 
. . . . 0 . . . . . 
. . . . 0 . . . . . 
0 0 0 0 0 . . . . . 
0 0 0 0 0 . . . . . 
0 . . . 0 . . . . . 
0 . . . 0 0 0 0 0 0 
0 . . . 0 0 0 0 0 0 
 with color black at (0,0)
  _01: rectangle with size (5,4) with mask 
0 0 0 . 
0 . 0 0 
. . . 0 
0 0 0 . 
. 0 . . 
 with color blue at (0,0)
  _011: rectangle with size (3,4) with mask 
. . . 0 
0 0 . 0 
. 0 0 . 
 with color blue at (5,5)
  _0111: rectangle with size (3,3) with mask 
. 0 0 
0 0 . 
0 . . 
 with color red at (7,1)
  _01111: rectangle with size (2,2) with model Even Checkboard with color blue at (1,5)
  _011111: rectangle with size (2,2) with model Odd Checkboard with color blue at (8,2)
  + 8 delta pixels
diff: 
! size mismatch, 3x10 instead of 3x3
>> Trial 2
data: a background with size (10,10) and color cyan and layers
  _0: rectangle with size (10,10) with mask 
. . . . 0 0 0 0 0 0 
. . . . 0 . . . . . 
. . . . 0 . . . . . 
. . . . 0 . . . . . 
. . . . 0 . . . . . 
0 0 0 0 0 . . . . . 
0 0 0 0 0 . . . . . 
0 . . . 0 . . . . . 
0 . . . 0 0 0 0 0 0 
0 . . . 0 0 0 0 0 0 
 with color black at (0,0)
  _01: rectangle with size (5,4) with mask 
0 0 0 . 
0 . 0 0 
. . . 0 
0 0 0 . 
. 0 . . 
 with color blue at (0,0)
  _011: rectangle with size (3,4) with mask 
. . . 0 
0 0 . 0 
. 0 0 . 
 with color blue at (5,5)
  _0111: rectangle with size (3,3) with mask 
. 0 0 
0 0 . 
0 . . 
 with color red at (7,1)
  _01111: rectangle with size (2,2) with model Even Checkboard with color blue at (1,5)
  _011111: rectangle with size (1,3) with model Full with color red at (4,7)
  + 9 delta pixels
diff: 
! size mismatch, 3x10 instead of 3x3

TRAIN e50d258f.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,4) with model Full with color cyan at (0,0)
  _01: rectangle with size (6,4) with mask 
. 0 0 . 
0 0 . 0 
0 . 0 0 
0 0 0 . 
. 0 0 0 
0 0 . 0 
 with color cyan at (3,6)
  _011: rectangle with size (5,1) with model Full with color blue at (3,6)
  _0111: rectangle with size (5,1) with model Full with color blue at (4,8)
  _01111: rectangle with size (1,1) with model Full with color red at (5,7)
  _011111: rectangle with size (1,1) with model Full with color red at (3,9)
  + 8 delta pixels
diff: 
   (3.2 bits)
data: a background with size (6,4) and color cyan and layers
  _0: rectangle with size (1,1) with model Full with color blue at (1,2)
  _01: point with color blue at (5,1)
  _011: point with color red at (3,3)
  + 4 delta pixels
diff: 
   (185.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,4) with model Full with color cyan at (0,0)
  _01: rectangle with size (6,4) with mask 
. 0 0 . 
0 0 . 0 
0 . 0 0 
0 0 0 . 
. 0 0 0 
0 0 . 0 
 with color cyan at (3,6)
  _011: rectangle with size (5,1) with model Full with color blue at (3,6)
  _0111: rectangle with size (5,1) with model Full with color blue at (4,8)
  _01111: rectangle with size (1,1) with model Full with color red at (3,9)
  _011111: rectangle with size (1,1) with model Full with color red at (5,7)
  + 8 delta pixels
diff: 
! size mismatch, 8x10 instead of 6x4
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,4) with model Full with color cyan at (0,0)
  _01: rectangle with size (6,4) with mask 
. 0 0 . 
0 0 . 0 
0 . 0 0 
0 0 0 . 
. 0 0 0 
0 0 . 0 
 with color cyan at (3,6)
  _011: rectangle with size (5,1) with model Full with color blue at (3,6)
  _0111: rectangle with size (5,1) with model Full with color blue at (4,8)
  _01111: rectangle with size (1,1) with model Full with color red at (5,7)
  _011111: rectangle with size (1,1) with model Full with color red at (3,9)
  + 8 delta pixels
diff: 
! size mismatch, 6x10 instead of 6x4

TRAIN e50d258f.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
undefined expression: ScaleDown: not an integer

TEST e50d258f.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 18.1 sec (18.1 sec/task)
bits-train-error = 2502.7 bits (2502.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-35] Checking task e6721834.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 368695.5 = 368697.8
DL output with Mo: L = 2.3 + 180466.4 = 180468.8
DL input+output M: L = 4.6 + 549161.9 = 549166.6

# learning a model for train pairs
2.000	
1.175	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.692	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.299	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.225	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.172	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.135	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.109	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.093	OUT ADD ^.layer_010 = ^.layer_01.shape at (?,?)
0.081	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.073	OUT ADD ^.layer_00 = ^.layer_011.shape at (?,?)
0.069	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.066	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.063	OUT SPE ^.layer_01.shape = ^.layer_01111.shape
0.062	OUT SPE ^.layer_01.pos.i = bottom(^.layer_01111) - 2
0.061	OUT SPE ^.layer_010.pos.j = bottom(^.layer_011) / '2
0.060	OUT SPE ^.layer_0.pos.j = min(^.layer_0.pos.i, ^.layer_01111.pos.i) + 2
0.060	OUT SPE ^.layer_01.pos.j = max(^.layer_01.pos.i, ^.layer_011.pos.i) - ^.layer_01.shape.mask.size.j
0.059	OUT SPE ^.layer_0.shape.mask.size.j = area(^.layer_0111.shape) / '2
0.058	OUT SPE ^.layer_0.shape.mask.size.i = 1
0.058	OUT SPE ^.layer_010.pos.i = max(^.layer_01.pos.i, ^.layer_0111.pos.i) + ^.layer_01111.pos.j - ^.layer_011.pos.j
0.057	OUT SPE ^.layer_00.pos.i = average(^.layer_0.pos.j, ^.layer_011.pos.j) - ^.layer_01111.pos.i - ^.layer_01.pos.i
0.057	OUT SPE ^.layer_0.shape.mask.model = Full
0.057	IN  SPE ^.layer_01111.shape.mask.model = Full
0.012	
0.012	IN  GEN ^.layer_01111.shape.mask.model = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color ? and layers
  _00: ^.layer_011.shape at (average(^.layer_0.pos.j, ^.layer_011.pos.j) - ^.layer_01111.pos.i - ^.layer_01.pos.i,?)
  _0: rectangle with size (1,area(^.layer_0111.shape) / '2) with model Full with color ? at (?,min(^.layer_0.pos.i, ^.layer_01111.pos.i) + 2)
  _010: ^.layer_01.shape at (max(^.layer_01.pos.i, ^.layer_0111.pos.i) + ^.layer_01111.pos.j - ^.layer_011.pos.j,bottom(^.layer_011) / '2)
  _01: ^.layer_01111.shape at (bottom(^.layer_01111) - 2,max(^.layer_01.pos.i, ^.layer_011.pos.i) - ^.layer_01.shape.mask.size.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 153.9 + 16528.9 = 16682.8
DL output with Mo: L = 508.8 + 1568.4 = 2077.2
DL input+output M: L = 662.7 + 18097.3 = 18760.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color ? and layers
  _00: ^.layer_011.shape at (average(^.layer_0.pos.j, ^.layer_011.pos.j) - ^.layer_01111.pos.i - ^.layer_01.pos.i,?)
  _0: rectangle with size (1,area(^.layer_0111.shape) / '2) with model Full with color ? at (?,min(^.layer_0.pos.i, ^.layer_01111.pos.i) + 2)
  _010: ^.layer_01.shape at (max(^.layer_01.pos.i, ^.layer_0111.pos.i) + ^.layer_01111.pos.j - ^.layer_011.pos.j,bottom(^.layer_011) / '2)
  _01: ^.layer_01111.shape at (bottom(^.layer_01111) - 2,max(^.layer_01.pos.i, ^.layer_011.pos.i) - ^.layer_01.shape.mask.size.j)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 153.4 + 31.7 = 185.1
DL output with Mo: L = 508.8 + 1568.4 = 2077.2
DL input+output M: L = 662.2 + 1600.1 = 2262.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (30,17) and color cyan and layers
  _0: rectangle with size (15,17) with model Full with color black at (15,0)
  _01: rectangle with size (5,4) with mask 
0 0 . 0 
0 . 0 0 
0 0 0 0 
0 . 0 0 
0 0 . 0 
 with color blue at (7,2)
  _011: rectangle with size (2,7) with mask 
0 0 0 . 0 0 0 
0 . 0 0 0 . 0 
 with color blue at (4,2)
  _0111: rectangle with size (3,5) with mask 
0 0 0 . 0 
0 . 0 . 0 
0 . 0 0 0 
 with color blue at (8,10)
  _01111: rectangle with size (5,2) with model Full with color green at (7,3)
  + 14 delta pixels
diff: 
   (0.0 bits)
data: a background with size (15,17) and color black and layers
  _00: 
1 1 1 . 1 1 1 
1 . 1 1 1 . 1 
 at (1,8)
  _0: rectangle with size (1,5) with model Full with color red at (2,9)
  _010: 
1 1 . 1 
1 . 1 1 
1 1 1 1 
1 . 1 1 
1 1 . 1 
 at (9,2)
  _01: 
3 3 
3 3 
3 3 
3 3 
3 3 
 at (9,3)
  + 1 delta pixels
diff: 
   (63.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (30,17) and color cyan and layers
  _0: rectangle with size (15,17) with model Full with color black at (15,0)
  _01: rectangle with size (5,4) with mask 
0 0 . 0 
0 . 0 0 
0 0 0 0 
0 . 0 0 
0 0 . 0 
 with color blue at (7,2)
  _011: rectangle with size (2,7) with mask 
0 0 0 . 0 0 0 
0 . 0 0 0 . 0 
 with color blue at (4,2)
  _0111: rectangle with size (3,5) with mask 
0 0 0 . 0 
0 . 0 . 0 
0 . 0 0 0 
 with color blue at (8,10)
  _01111: rectangle with size (5,2) with model Full with color green at (7,3)
  + 14 delta pixels
diff: 
! 30 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (30,17) and color cyan and layers
  _0: rectangle with size (15,17) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 . 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color black at (15,0)
  _01: rectangle with size (5,4) with model Full with color blue at (7,2)
  _011: rectangle with size (2,7) with mask 
0 0 0 . 0 0 0 
0 . 0 0 0 . 0 
 with color blue at (4,2)
  _0111: rectangle with size (3,5) with mask 
0 0 0 . 0 
0 . 0 . 0 
0 . 0 0 0 
 with color blue at (8,10)
  _01111: rectangle with size (5,2) with model Full with color green at (24,3)
  + 14 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (30,17) and color cyan and layers
  _0: rectangle with size (15,17) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 . 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 . 0 0 0 . 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color black at (15,0)
  _01: rectangle with size (5,4) with mask 
0 0 . 0 
0 . 0 0 
0 0 0 0 
0 . 0 0 
0 0 . 0 
 with color blue at (7,2)
  _011: rectangle with size (2,7) with mask 
0 0 0 . 0 0 0 
0 . 0 0 0 . 0 
 with color blue at (4,2)
  _0111: rectangle with size (3,5) with model Full with color blue at (8,10)
  _01111: rectangle with size (22,2) with model Full with color green at (7,3)
  + 16 delta pixels
diff: 
! 36 wrong pixels (generated / expected)

TRAIN e6721834.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (11,20) and color pink and layers
  _0: rectangle with size (11,10) with mask 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 . 0 . 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 0 
0 0 . 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
 with color blue at (0,10)
  _01: rectangle with size (4,3) with mask 
0 0 0 
. 0 . 
0 0 0 
0 0 0 
 with color green at (2,2)
  _011: rectangle with size (3,4) with mask 
0 0 0 . 
0 . 0 0 
0 0 0 0 
 with color green at (8,4)
  _0111: rectangle with size (1,3) with model Full with color cyan at (1,15)
  _01111: rectangle with size (1,3) with model Full with color cyan at (3,2)
  + 4 delta pixels
diff: 
   (3.2 bits)
data: a background with size (11,10) and color blue and layers
  _00: 
3 3 3 . 
3 . 3 3 
3 3 3 3 
 at (6,1)
  _0: rectangle with size (1,1) with model Full with color red at (7,2)
  _010: 
3 3 3 
. 3 . 
3 3 3 
3 3 3 
 at (0,5)
  _01: 
8 8 8 
 at (1,5)
  + 1 delta pixels
diff: 
   (67.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,20) and color pink and layers
  _0: rectangle with size (11,10) with mask 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 . 0 . 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 0 
0 0 . 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
 with color blue at (0,10)
  _01: rectangle with size (4,3) with mask 
0 0 0 
. 0 . 
0 0 0 
0 0 0 
 with color green at (2,2)
  _011: rectangle with size (3,4) with model Full with color green at (8,4)
  _0111: rectangle with size (1,3) with model Full with color cyan at (1,15)
  _01111: rectangle with size (1,3) with model Full with color cyan at (3,2)
  + 4 delta pixels
diff: 
! 90 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (11,20) and color pink and layers
  _0: rectangle with size (11,10) with mask 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 . 0 . 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 0 
0 0 . 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
 with color blue at (0,10)
  _01: rectangle with size (4,3) with mask 
0 0 0 
. 0 . 
0 0 0 
0 0 0 
 with color green at (2,2)
  _011: rectangle with size (3,4) with model Full with color green at (8,4)
  _0111: rectangle with size (1,3) with model Full with color cyan at (3,2)
  _01111: rectangle with size (1,3) with model Full with color cyan at (1,15)
  + 4 delta pixels
diff: 
! 107 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (11,20) and color pink and layers
  _0: rectangle with size (11,10) with mask 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 . 0 . 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 0 
0 0 . 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 
 with color blue at (0,10)
  _01: rectangle with size (4,3) with mask 
0 0 0 
. 0 . 
0 0 0 
0 0 0 
 with color green at (2,2)
  _011: rectangle with size (3,4) with mask 
0 0 0 . 
0 . 0 0 
0 0 0 0 
 with color green at (8,4)
  _0111: rectangle with size (1,3) with model Full with color cyan at (1,15)
  _01111: rectangle with size (1,3) with model Full with color cyan at (3,2)
  + 4 delta pixels
diff: 
! 92 wrong pixels (generated / expected)

TRAIN e6721834.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,16) and color yellow and layers
  _0: rectangle with size (10,8) with mask 
0 0 0 0 0 0 0 0 
0 . . . 0 0 0 0 
0 . . . 0 0 0 0 
0 . . . 0 0 0 0 
0 . . . 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 . . . 0 0 0 
0 0 . . . 0 0 0 
0 0 0 0 0 0 0 0 
 with color cyan at (0,8)
  _01: rectangle with size (4,3) with mask 
0 0 0 
. 0 0 
0 0 0 
. 0 0 
 with color blue at (1,9)
  _011: rectangle with size (2,3) with mask 
0 0 . 
0 0 0 
 with color blue at (7,10)
  _0111: rectangle with size (3,1) with model Full with color red at (2,4)
  _01111: rectangle with size (3,1) with model Full with color red at (2,9)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,8) and color yellow and layers
  _00: 
1 1 . 
1 1 1 
 at (8,0)
  _0: rectangle with size (1,1) with model Full with color pink at (8,2)
  _010: 
1 1 1 
. 1 1 
1 1 1 
. 1 1 
 at (1,4)
  _01: 
2 
2 
2 
 at (2,4)
diff: 
   (25.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,16) and color yellow and layers
  _0: rectangle with size (10,8) with mask 
0 0 0 0 0 0 0 0 
0 . . . 0 0 0 0 
0 . . . 0 0 0 0 
0 . . . 0 0 0 0 
0 . . . 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 . . . 0 0 0 
0 0 . . . 0 0 0 
0 0 0 0 0 0 0 0 
 with color cyan at (0,8)
  _01: rectangle with size (4,3) with mask 
0 0 0 
. 0 0 
0 0 0 
. 0 0 
 with color blue at (1,9)
  _011: rectangle with size (2,3) with mask 
0 0 . 
0 0 0 
 with color blue at (7,10)
  _0111: rectangle with size (3,1) with model Full with color red at (2,4)
  _01111: rectangle with size (3,1) with model Full with color red at (2,9)
  + 3 delta pixels
diff: 
! 63 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,16) and color cyan and layers
  _0: rectangle with size (10,8) with mask 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 
0 0 . 0 0 0 0 0 
0 0 0 0 0 0 0 0 
 with color yellow at (0,0)
  _01: rectangle with size (4,3) with mask 
0 0 0 
. 0 0 
0 0 0 
. 0 0 
 with color blue at (1,9)
  _011: rectangle with size (2,3) with mask 
0 0 . 
0 0 0 
 with color blue at (7,10)
  _0111: rectangle with size (1,6) with model Full with color red at (2,4)
  _01111: rectangle with size (1,6) with model Full with color red at (4,4)
  + 4 delta pixels
diff: 
! 79 wrong pixels (generated / expected)

TRAIN e6721834.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (24,12) and color red and layers
  _0: rectangle with size (12,12) with model Full with color yellow at (0,0)
  _01: rectangle with size (3,5) with mask 
0 0 0 0 0 
0 0 0 . 0 
0 0 0 0 . 
 with color cyan at (15,3)
  _011: rectangle with size (3,5) with model Full with color cyan at (20,6)
  _0111: rectangle with size (4,2) with mask 
0 0 
. 0 
0 0 
0 0 
 with color cyan at (19,1)
  _01111: rectangle with size (2,2) with model Full with color blue at (16,6)
  + 9 delta pixels
diff: 
! 141 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (24,12) and color red and layers
  _0: rectangle with size (12,12) with model Full with color yellow at (0,0)
  _01: rectangle with size (3,5) with mask 
0 0 0 0 0 
0 0 0 . 0 
0 0 0 0 . 
 with color cyan at (15,3)
  _011: rectangle with size (3,5) with mask 
0 0 . 0 0 
. 0 0 0 0 
0 0 . 0 0 
 with color cyan at (20,6)
  _0111: rectangle with size (4,2) with model Full with color cyan at (19,1)
  _01111: rectangle with size (2,2) with model Full with color blue at (16,6)
  + 9 delta pixels
diff: 
! 141 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (24,12) and color red and layers
  _0: rectangle with size (12,12) with model Full with color yellow at (0,0)
  _01: rectangle with size (3,5) with mask 
0 0 0 0 0 
0 0 0 . 0 
0 0 0 0 . 
 with color cyan at (15,3)
  _011: rectangle with size (3,5) with mask 
0 0 . 0 0 
. 0 0 0 0 
0 0 . 0 0 
 with color cyan at (20,6)
  _0111: rectangle with size (4,2) with mask 
0 0 
. 0 
0 0 
0 0 
 with color cyan at (19,1)
  _01111: rectangle with size (2,2) with model Full with color blue at (16,6)
  + 9 delta pixels
diff: 
! 141 wrong pixels (generated / expected)

TEST e6721834.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 29.3 sec (29.3 sec/task)
bits-train-error = 1568.4 bits (1568.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-34] Checking task e73095fd.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 282801.8 = 282804.2
DL output with Mo: L = 2.3 + 282801.8 = 282804.2
DL input+output M: L = 4.6 + 565603.7 = 565608.3

# learning a model for train pairs
2.000	
1.286	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.643	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.385	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.103	OUT ADD ^.layer_0 = ^.layer_0
0.066	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.050	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.048	OUT SPE ^.size = ^.size
0.045	OUT ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.045	OUT SPE ^.layer_01.shape.mask.size.i = 3
0.044	IN  SPE ^.layer_0.shape.color = grey
0.044	OUT SPE ^.layer_01.shape.color = yellow
0.043	OUT SPE ^.layer_011.shape.color = yellow
0.043	OUT SPE ^.layer_00.shape.mask.model = Full
0.042	OUT SPE ^.layer_01.shape.mask.model = Full
0.042	OUT SPE ^.layer_011.shape.mask.model = Full
0.042	IN  SPE ^.color = black
0.042	OUT SPE ^.color = black
0.014	
0.014	IN  GEN ^.layer_0.shape.color = ?
0.014	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0: ^.layer_0
  _01: rectangle with size (3,?) with model Full with color yellow at (?,?)
  _011: rectangle with size (?,?) with model Full with color yellow at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)

DL input  with Mi: L = 45.4 + 7755.7 = 7801.1
DL output with Mo: L = 111.7 + 3842.7 = 3954.4
DL input+output M: L = 157.1 + 11598.4 = 11755.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0: ^.layer_0
  _01: rectangle with size (3,?) with model Full with color yellow at (?,?)
  _011: rectangle with size (?,?) with model Full with color yellow at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 111.7 + 3842.7 = 3954.4
DL input+output M: L = 153.7 + 3842.7 = 3996.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (12,19) and color black and layers
  _0: rectangle with size (12,19) with mask 
. . . . . . . . . . . . . 0 . . . 0 0 
0 0 . . . 0 0 0 0 . . . . 0 . . . 0 . 
. 0 0 0 0 0 . . 0 0 0 0 0 0 0 0 0 0 . 
0 0 . . . 0 . . 0 . . . . 0 . . . 0 . 
. . . . . 0 . . 0 . . . . 0 . . . 0 0 
. . . . . 0 . . 0 . . 0 0 0 0 . . . . 
. . . . . 0 . . 0 . . 0 . . 0 . . . . 
. . . . . 0 0 0 0 . . 0 . . 0 0 0 0 0 
. . . . . . 0 . . . . 0 0 0 0 . . . . 
. . . . . . 0 . . . . . . 0 . . . . . 
. . . . . . 0 . . . . . . 0 . . . . . 
. . . . . . 0 . . . . . . 0 . . . . . 
 with color grey at (0,0)
diff: 
   (0.0 bits)
data: a background with size (12,19) and color black and layers
  _00: rectangle with size (5,2) with model Full with color yellow at (2,6)
  _0: 
. . . . . . . . . . . . . 5#. . . 5#5#
5#5#. . . 5#5#5#5#. . . . 5#. . . 5#. 
. 5#5#5#5#5#. . 5#5#5#5#5#5#5#5#5#5#. 
5#5#. . . 5#. . 5#. . . . 5#. . . 5#. 
. . . . . 5#. . 5#. . . . 5#. . . 5#5#
. . . . . 5#. . 5#. . 5#5#5#5#. . . . 
. . . . . 5#. . 5#. . 5#. . 5#. . . . 
. . . . . 5#5#5#5#. . 5#. . 5#5#5#5#5#
. . . . . . 5#. . . . 5#5#5#5#. . . . 
. . . . . . 5#. . . . . . 5#. . . . . 
. . . . . . 5#. . . . . . 5#. . . . . 
. . . . . . 5#. . . . . . 5#. . . . . 
 at (0,0)
  _01: rectangle with size (3,1) with model Full with color yellow at (1,18)
  _011: rectangle with size (2,2) with model Full with color yellow at (6,12)
  + 1 delta pixels
diff: 
   (113.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,19) and color black and layers
  _0: rectangle with size (12,19) with mask 
. . . . . . . . . . . . . 0 . . . 0 0 
0 0 . . . 0 0 0 0 . . . . 0 . . . 0 . 
. 0 0 0 0 0 . . 0 0 0 0 0 0 0 0 0 0 . 
0 0 . . . 0 . . 0 . . . . 0 . . . 0 . 
. . . . . 0 . . 0 . . . . 0 . . . 0 0 
. . . . . 0 . . 0 . . 0 0 0 0 . . . . 
. . . . . 0 . . 0 . . 0 . . 0 . . . . 
. . . . . 0 0 0 0 . . 0 . . 0 0 0 0 0 
. . . . . . 0 . . . . 0 0 0 0 . . . . 
. . . . . . 0 . . . . . . 0 . . . . . 
. . . . . . 0 . . . . . . 0 . . . . . 
. . . . . . 0 . . . . . . 0 . . . . . 
 with color grey at (0,0)
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,19) and color black and layers
  _0: rectangle with size (1,17) with model Full with color grey at (2,1)
  + 55 delta pixels
diff: 
! 72 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,19) and color black and layers
  _0: rectangle with size (1,10) with model Full with color grey at (2,8)
  + 58 delta pixels
diff: 
! 77 wrong pixels (generated / expected)

TRAIN e73095fd.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (13,16) and color black and layers
  _0: rectangle with size (13,16) with mask 
. . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . 
. . . 0 0 0 0 0 . . . 0 . . 0 0 
. . . 0 . . . 0 . . . 0 . . 0 . 
. . . 0 . . . 0 0 0 0 0 0 0 0 . 
. . . 0 . . . 0 . . . . . . 0 . 
. . . 0 0 0 0 0 . . . . . . 0 0 
. . . . . 0 . . . . . . . . . . 
. . . . . 0 . . . . . . . . . . 
0 0 0 0 0 0 . . . . . . . . . . 
. . . . . 0 . . . . . . . . . . 
 with color grey at (0,0)
diff: 
   (0.0 bits)
data: a background with size (13,16) and color black and layers
  _00: rectangle with size (13,1) with model Full with color grey at (0,5)
  _0: 
. . . . . 5#. . . . . 5#. . . . 
. . . . . 5#. . . . . 5#. . . . 
. . . . . 5#. . . . . 5#. . . . 
. . . . . 5#. . . . . 5#. . . . 
. . . 5#5#5#5#5#. . . 5#. . 5#5#
. . . 5#. . . 5#. . . 5#. . 5#. 
. . . 5#. . . 5#5#5#5#5#5#5#5#. 
. . . 5#. . . 5#. . . . . . 5#. 
. . . 5#5#5#5#5#. . . . . . 5#5#
. . . . . 5#. . . . . . . . . . 
. . . . . 5#. . . . . . . . . . 
5#5#5#5#5#5#. . . . . . . . . . 
. . . . . 5#. . . . . . . . . . 
 at (0,0)
  _01: rectangle with size (3,3) with model Full with color yellow at (5,4)
  _011: rectangle with size (3,1) with model Full with color yellow at (5,15)
  + 3 delta pixels
diff: 
   (198.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,16) and color black and layers
  _0: rectangle with size (13,16) with mask 
. . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . 0 . . . . 
. . . 0 0 0 0 0 . . . 0 . . 0 0 
. . . 0 . . . 0 . . . 0 . . 0 . 
. . . 0 . . . 0 0 0 0 0 0 0 0 . 
. . . 0 . . . 0 . . . . . . 0 . 
. . . 0 0 0 0 0 . . . . . . 0 0 
. . . . . 0 . . . . . . . . . . 
. . . . . 0 . . . . . . . . . . 
0 0 0 0 0 0 . . . . . . . . . . 
. . . . . 0 . . . . . . . . . . 
 with color grey at (0,0)
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,16) and color black and layers
  _0: rectangle with size (1,8) with model Full with color grey at (6,7)
  + 40 delta pixels
diff: 
! 58 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (13,16) and color black and layers
  _0: rectangle with size (7,1) with model Full with color grey at (0,11)
  + 41 delta pixels
diff: 
! 59 wrong pixels (generated / expected)

TRAIN e73095fd.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (15,17) and color black and layers
  _0: rectangle with size (15,17) with mask 
. . . . . 0 . . . . . . . . . . . 
. . . . . 0 . . . . . 0 0 0 0 0 . 
0 0 0 0 0 0 0 0 0 0 0 0 . . . 0 . 
. . . . . 0 . . . . . 0 . . . 0 0 
. . . 0 0 0 0 . . . . 0 . . . 0 . 
0 0 0 0 . . 0 . . . . 0 0 0 0 0 . 
. . . 0 . . 0 . . . . . 0 . . . . 
. . . 0 . . 0 . . . . . 0 . . . . 
. . . 0 0 0 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . . 0 . . . . 
. . . . . 0 . . . . 0 0 0 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 . . 0 . . . 
. . . . . 0 . . . . 0 . . 0 . . . 
. . . . . 0 . . . . 0 0 0 0 . . . 
. . . . . 0 . . . . . . 0 . . . . 
 with color grey at (0,0)
diff: 
   (0.0 bits)
data: a background with size (15,17) and color black and layers
  _00: rectangle with size (3,3) with model Full with color yellow at (2,12)
  _0: 
. . . . . 5#. . . . . . . . . . . 
. . . . . 5#. . . . . 5#5#5#5#5#. 
5#5#5#5#5#5#5#5#5#5#5#5#. . . 5#. 
. . . . . 5#. . . . . 5#. . . 5#5#
. . . 5#5#5#5#. . . . 5#. . . 5#. 
5#5#5#5#. . 5#. . . . 5#5#5#5#5#. 
. . . 5#. . 5#. . . . . 5#. . . . 
. . . 5#. . 5#. . . . . 5#. . . . 
. . . 5#5#5#5#. . . . . 5#. . . . 
. . . . . 5#. . . . . . 5#. . . . 
. . . . . 5#. . . . 5#5#5#5#. . . 
5#5#5#5#5#5#5#5#5#5#5#. . 5#. . . 
. . . . . 5#. . . . 5#. . 5#. . . 
. . . . . 5#. . . . 5#5#5#5#. . . 
. . . . . 5#. . . . . . 5#. . . . 
 at (0,0)
  _01: rectangle with size (3,2) with model Full with color yellow at (5,4)
  _011: rectangle with size (2,2) with model Full with color yellow at (11,11)
diff: 
   (72.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,17) and color black and layers
  _0: rectangle with size (15,17) with mask 
. . . . . 0 . . . . . . . . . . . 
. . . . . 0 . . . . . 0 0 0 0 0 . 
0 0 0 0 0 0 0 0 0 0 0 0 . . . 0 . 
. . . . . 0 . . . . . 0 . . . 0 0 
. . . 0 0 0 0 . . . . 0 . . . 0 . 
0 0 0 0 . . 0 . . . . 0 0 0 0 0 . 
. . . 0 . . 0 . . . . . 0 . . . . 
. . . 0 . . 0 . . . . . 0 . . . . 
. . . 0 0 0 0 . . . . . 0 . . . . 
. . . . . 0 . . . . . . 0 . . . . 
. . . . . 0 . . . . 0 0 0 0 . . . 
0 0 0 0 0 0 0 0 0 0 0 . . 0 . . . 
. . . . . 0 . . . . 0 . . 0 . . . 
. . . . . 0 . . . . 0 0 0 0 . . . 
. . . . . 0 . . . . . . 0 . . . . 
 with color grey at (0,0)
diff: 
! 23 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,17) and color black and layers
  _0: rectangle with size (1,12) with model Full with color grey at (2,0)
  + 68 delta pixels
diff: 
! 91 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,17) and color black and layers
  _0: rectangle with size (1,11) with model Full with color grey at (11,0)
  + 69 delta pixels
diff: 
! 92 wrong pixels (generated / expected)

TRAIN e73095fd.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (16,18) and color black and layers
  _0: rectangle with size (16,18) with mask 
. . . . . . . 0 . . . . . . . . . . 
. . . . . . . 0 . . . . . . . . . . 
0 0 0 . . . . 0 . . . . . . . . . . 
. . 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 . . . . 0 . . . . . . 0 . . . 
. . . . . . . 0 . . . . . . 0 . . . 
. . . . . . . 0 . . . . . . 0 . . . 
. . . . . . . 0 . . . . . 0 0 0 0 . 
. . . . . 0 0 0 0 0 . . . 0 . . 0 . 
0 0 0 0 0 0 . . . 0 0 0 0 0 . . 0 0 
. 0 . . . 0 . . . 0 . . . 0 . . 0 . 
. 0 . . . 0 0 0 0 0 . . . 0 0 0 0 . 
. 0 . . . . . 0 . . . . . . . . . . 
0 0 0 . . . . 0 . . . . . . . . . . 
0 . 0 . . . . 0 . . . . . . . . . . 
0 0 0 . . . . 0 . . . . . . . . . . 
 with color grey at (0,0)
diff: 
! 19 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (16,18) and color black and layers
  _0: rectangle with size (1,16) with model Full with color grey at (3,2)
  + 68 delta pixels
diff: 
! 87 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (16,18) and color black and layers
  _0: rectangle with size (16,1) with model Full with color grey at (0,7)
  + 72 delta pixels
diff: 
! 89 wrong pixels (generated / expected)

TEST e73095fd.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 20.9 sec (20.9 sec/task)
bits-train-error = 3842.7 bits (3842.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-33] Checking task e76a88a6.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79850.6 = 79852.9
DL output with Mo: L = 2.3 + 79850.6 = 79852.9
DL input+output M: L = 4.6 + 159701.1 = 159705.8

# learning a model for train pairs
2.000	
1.320	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.640	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.545	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.449	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.402	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.348	OUT ADD ^.layer_0 = ^.layer_011
0.296	OUT ADD ^.layer_01 = ^.layer_011.shape at (?,?)
0.245	OUT ADD ^.layer_011 = ^.layer_011.shape at (?,?)
0.209	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.164	OUT ADD ^.layer_0111 = ^.layer_0111
0.122	OUT ADD ^.layer_01111 = ^.layer_0111.shape at (?,?)
0.080	OUT ADD ^.layer_01110 = ^.layer_0111.shape at (?,?)
0.075	OUT SPE ^.size = ^.size
0.072	OUT SPE ^.layer_01111.pos = ^.layer_01.pos
0.069	OUT SPE ^.layer_01110.pos = ^.layer_0.pos
0.066	OUT SPE ^.layer_01.pos = ^.layer_01.pos + (1, 0)
0.064	OUT SPE ^.layer_011.pos = ^.layer_0.pos + (1, 0)
0.062	IN  SPE ^.layer_0.shape.color = grey
0.061	IN  SPE ^.layer_01.shape.color = grey
0.060	IN  SPE ^.layer_0.shape.mask.model = Full
0.060	IN  SPE ^.layer_01.shape.mask.model = Full
0.059	IN  SPE ^.layer_0111.shape.mask.model = Full
0.058	IN  SPE ^.color = black
0.058	OUT SPE ^.color = black
0.019	
0.019	IN  GEN ^.layer_01.shape.color = ?
0.019	IN  GEN ^.layer_0.shape.color = ?
0.019	IN  GEN ^.layer_0111.shape.mask.model = ?
0.019	IN  GEN ^.layer_01.shape.mask.model = ?
0.019	IN  GEN ^.layer_0.shape.mask.model = ?
0.019	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_011
  _01: ^.layer_011.shape at ^.layer_01.pos + (1, 0)
  _011: ^.layer_011.shape at ^.layer_0.pos + (1, 0)
  _01110: ^.layer_0111.shape at ^.layer_0.pos
  _0111: ^.layer_0111
  _01111: ^.layer_0111.shape at ^.layer_01.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color grey at (?,?)
  _01: rectangle with size (?,?) with model Full with color grey at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 134.1 + 3106.9 = 3241.0
DL output with Mo: L = 135.5 + 1225.7 = 1361.2
DL input+output M: L = 269.6 + 4332.6 = 4602.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_011
  _01: ^.layer_011.shape at ^.layer_01.pos + (1, 0)
  _011: ^.layer_011.shape at ^.layer_0.pos + (1, 0)
  _01110: ^.layer_0111.shape at ^.layer_0.pos
  _0111: ^.layer_0111
  _01111: ^.layer_0111.shape at ^.layer_01.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 0.0 = 125.8
DL output with Mo: L = 135.5 + 1225.7 = 1361.2
DL input+output M: L = 261.3 + 1225.7 = 1487.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Full with color grey at (4,6)
  _01: rectangle with size (3,3) with model Full with color grey at (7,2)
  _011: rectangle with size (2,3) with mask 
. 0 0 
0 0 0 
 with color yellow at (2,1)
  _0111: rectangle with size (2,3) with model Full with color red at (1,1)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
. 4 4 
4 4 4 
 at (2,1)
  _01: 
. 4 4 
4 4 4 
 at (8,2)
  _011: 
. 4 4 
4 4 4 
 at (5,6)
  _01110: 
2 2 2 
2 2 2 
 at (4,6)
  _0111: 
2 2 2 
2 2 2 
 at (1,1)
  _01111: 
2 2 2 
2 2 2 
 at (7,2)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Full with color grey at (4,6)
  _01: rectangle with size (3,3) with model Full with color grey at (7,2)
  _011: rectangle with size (2,3) with mask 
. 0 0 
0 0 0 
 with color yellow at (2,1)
  _0111: rectangle with size (2,3) with model Full with color red at (1,1)
diff: 
correct output grid

TRAIN e76a88a6.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,4) with model Full with color grey at (0,6)
  _01: rectangle with size (3,4) with model Full with color grey at (5,4)
  _011: rectangle with size (2,4) with mask 
0 0 . 0 
. 0 0 0 
 with color cyan at (2,1)
  _0111: rectangle with size (2,4) with model Full with color pink at (1,1)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
8 8 . 8 
. 8 8 8 
 at (2,1)
  _01: 
8 8 . 8 
. 8 8 8 
 at (6,4)
  _011: 
8 8 . 8 
. 8 8 8 
 at (1,6)
  _01110: 
6 6 6 6 
6 6 6 6 
 at (0,6)
  _0111: 
6 6 6 6 
6 6 6 6 
 at (1,1)
  _01111: 
6 6 6 6 
6 6 6 6 
 at (5,4)
  + 3 delta pixels
diff: 
   (122.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,4) with model Full with color grey at (0,6)
  _01: rectangle with size (3,4) with model Full with color grey at (5,4)
  _011: rectangle with size (2,4) with mask 
0 0 . 0 
. 0 0 0 
 with color cyan at (2,1)
  _0111: rectangle with size (2,4) with model Full with color pink at (1,1)
  + 1 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,4) with model Full with color grey at (0,6)
  _01: rectangle with size (2,4) with mask 
0 0 . 0 
. 0 0 0 
 with color cyan at (2,1)
  _011: rectangle with size (3,4) with model Full with color grey at (5,4)
  _0111: rectangle with size (2,4) with model Full with color pink at (1,1)
  + 1 delta pixels
diff: 
! 38 wrong pixels (generated / expected)

TRAIN e76a88a6.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,3) with model Full with color grey at (1,6)
  _01: rectangle with size (4,3) with model Full with color grey at (5,2)
  _011: rectangle with size (4,3) with model Full with color grey at (6,7)
  _0111: rectangle with size (3,3) with model Full with color yellow at (0,1)
  + 6 delta pixels
diff: 
! 42 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,3) with model Full with color grey at (1,6)
  _01: rectangle with size (4,3) with model Full with color grey at (6,7)
  _011: rectangle with size (4,3) with model Full with color grey at (5,2)
  _0111: rectangle with size (3,3) with model Full with color yellow at (0,1)
  + 6 delta pixels
diff: 
! 39 wrong pixels (generated / expected)

TEST e76a88a6.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 9.3 sec (9.3 sec/task)
bits-train-error = 1225.7 bits (1225.7 bits/task)
acc-train-micro = 0.50 tasks (50.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.50
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-32] Checking task e8593010.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.267	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.534	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.304	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.270	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.249	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.230	OUT ADD ^.layer_00 = ^.layer_0
0.207	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.186	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.173	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.161	OUT ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.148	OUT ADD ^.layer_0111111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.143	OUT SPE ^.size = ^.size
0.139	OUT SPE ^.layer_011111.shape = scaleTo(coloring(periodicFactor(transparent, ^.layer_0.shape), red), '(2, 1))
0.138	IN  SPE ^.layer_0.shape.color = grey
0.136	OUT SPE ^.layer_011.shape.color = blue
0.135	OUT SPE ^.layer_01111.pos.i = '0
0.134	OUT SPE ^.layer_0.shape.color = red
0.133	OUT SPE ^.layer_01111.shape.mask.size.i = 1
0.132	OUT SPE ^.layer_0111111.shape.mask.size.j = 1
0.131	OUT SPE ^.layer_01.shape.mask.size.j = 1
0.130	OUT SPE ^.layer_0111.shape.color = blue
0.128	OUT SPE ^.layer_01.pos.i = 2
0.128	OUT SPE ^.layer_0.shape.mask.model = Full
0.127	OUT SPE ^.layer_01.shape.mask.model = Full
0.126	OUT SPE ^.layer_011.shape.mask.model = Full
0.126	OUT SPE ^.layer_0111.shape.mask.model = Full
0.125	OUT SPE ^.layer_01111.shape.mask.model = Full
0.124	OUT SPE ^.layer_0111111.shape.mask.model = Full
0.124	IN  SPE ^.color = black
0.123	OUT SPE ^.color = black
0.089	
0.089	IN  GEN ^.layer_0.shape.color = ?
0.089	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model Full with color red at (?,?)
  _01: rectangle with size (?,1) with model Full with color ? at (2,?)
  _011: rectangle with size (?,?) with model Full with color blue at (?,?)
  _0111: rectangle with size (?,?) with model Full with color blue at (?,?)
  _01111: rectangle with size (1,?) with model Full with color ? at ('0,?)
  _011111: scaleTo(coloring(periodicFactor(transparent, ^.layer_0.shape), red), '(2, 1)) at (?,?)
  _0111111: rectangle with size (?,1) with model Full with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)

DL input  with Mi: L = 45.4 + 4123.6 = 4169.0
DL output with Mo: L = 274.4 + 10288.1 = 10562.5
DL input+output M: L = 319.9 + 14411.7 = 14731.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model Full with color red at (?,?)
  _01: rectangle with size (?,1) with model Full with color ? at (2,?)
  _011: rectangle with size (?,?) with model Full with color blue at (?,?)
  _0111: rectangle with size (?,?) with model Full with color blue at (?,?)
  _01111: rectangle with size (1,?) with model Full with color ? at ('0,?)
  _011111: scaleTo(coloring(periodicFactor(transparent, ^.layer_0.shape), red), '(2, 1)) at (?,?)
  _0111111: rectangle with size (?,1) with model Full with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 274.4 + 10288.1 = 10562.5
DL input+output M: L = 316.4 + 10288.1 = 10604.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
0 0 0 0 . 0 0 0 . 0 
. . 0 0 0 0 0 0 0 0 
. 0 0 0 0 0 . . 0 . 
0 0 . 0 0 0 0 . 0 . 
0 0 0 0 . . 0 0 0 0 
. 0 . 0 0 0 0 . 0 . 
. 0 0 0 . . 0 0 0 . 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 . 
. 0 0 0 0 0 0 . 0 . 
 with color grey at (0,0)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
5#5#5#5#. 5#5#5#. 5#
. . 5#5#5#5#5#5#5#5#
. 5#5#5#5#5#. . 5#. 
5#5#. 5#5#5#5#. 5#. 
5#5#5#5#. . 5#5#5#5#
. 5#. 5#5#5#5#. 5#. 
. 5#5#5#. . 5#5#5#. 
5#5#5#5#5#5#5#5#5#5#
5#5#5#5#5#5#5#5#5#. 
. 5#5#5#5#5#5#. 5#. 
 at (0,0)
  _0: rectangle with size (3,2) with model Full with color red at (4,4)
  _01: rectangle with size (8,1) with model Full with color red at (2,9)
  _011: rectangle with size (2,2) with model Full with color blue at (1,0)
  _0111: rectangle with size (2,2) with model Full with color blue at (2,6)
  _01111: rectangle with size (1,5) with model Full with color green at (0,4)
  _011111: 
2 
2 
 at (5,0)
  _0111111: rectangle with size (3,1) with model Full with color green at (3,2)
  + 3 delta pixels
diff: 
   (264.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
0 0 0 0 . 0 0 0 . 0 
. . 0 0 0 0 0 0 0 0 
. 0 0 0 0 0 . . 0 . 
0 0 . 0 0 0 0 . 0 . 
0 0 0 0 . . 0 0 0 0 
. 0 . 0 0 0 0 . 0 . 
. 0 0 0 . . 0 0 0 . 
0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 . 
. 0 0 0 0 0 0 . 0 . 
 with color grey at (0,0)
diff: 
! 25 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color grey and layers
  _0: rectangle with size (8,1) with model Full with color black at (2,9)
  + 21 delta pixels
diff: 
! 100 wrong pixels (generated / expected)

TRAIN e8593010.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
0 0 0 0 0 . . 0 0 0 
. . 0 . 0 0 0 0 0 . 
0 0 0 0 0 . 0 . . 0 
0 . 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 . 0 
0 0 0 0 . 0 0 0 0 0 
. . 0 0 . 0 . . 0 . 
0 0 0 0 0 0 0 . 0 0 
. 0 0 0 0 0 . 0 0 . 
. . 0 0 0 0 0 0 . 0 
 with color grey at (0,0)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
5#5#5#5#5#. . 5#5#5#
. . 5#. 5#5#5#5#5#. 
5#5#5#5#5#. 5#. . 5#
5#. 5#5#5#. 5#5#5#5#
5#5#5#5#5#5#5#5#. 5#
5#5#5#5#. 5#5#5#5#5#
. . 5#5#. 5#. . 5#. 
5#5#5#5#5#5#5#. 5#5#
. 5#5#5#5#5#. 5#5#. 
. . 5#5#5#5#5#5#. 5#
 at (0,0)
  _0: rectangle with size (6,2) with model Full with color red at (1,0)
  _01: rectangle with size (2,1) with model Full with color red at (2,5)
  _011: rectangle with size (2,2) with model Full with color blue at (6,6)
  _0111: rectangle with size (2,2) with model Full with color blue at (8,0)
  _01111: rectangle with size (1,2) with model Full with color red at (0,5)
  _011111: 
2 
2 
 at (5,4)
  _0111111: rectangle with size (8,1) with model Full with color green at (1,9)
  + 7 delta pixels
diff: 
   (422.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
0 0 0 0 0 . . 0 0 0 
. . 0 . 0 0 0 0 0 . 
0 0 0 0 0 . 0 . . 0 
0 . 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 0 0 . 0 
0 0 0 0 . 0 0 0 0 0 
. . 0 0 . 0 . . 0 . 
0 0 0 0 0 0 0 . 0 0 
. 0 0 0 0 0 . 0 0 . 
. . 0 0 0 0 0 0 . 0 
 with color grey at (0,0)
diff: 
! 24 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color grey and layers
  _0: rectangle with size (3,2) with mask 
0 0 
. 0 
0 . 
 with color black at (6,6)
  + 22 delta pixels
diff: 
! 98 wrong pixels (generated / expected)

TRAIN e8593010.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
. . 0 0 . 0 0 0 . 0 
0 0 . . 0 0 0 0 . 0 
0 . 0 . 0 . 0 0 . 0 
0 . 0 0 . 0 0 0 0 0 
0 0 0 . . 0 0 . 0 . 
0 0 . 0 0 0 0 . 0 . 
0 0 . 0 0 . 0 0 0 0 
0 0 0 . 0 0 0 0 0 0 
0 . 0 0 0 . 0 . 0 0 
0 0 . 0 0 0 0 0 0 0 
 with color grey at (0,0)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
. . 5#5#. 5#5#5#. 5#
5#5#. . 5#5#5#5#. 5#
5#. 5#. 5#. 5#5#. 5#
5#. 5#5#. 5#5#5#5#5#
5#5#5#. . 5#5#. 5#. 
5#5#. 5#5#5#5#. 5#. 
5#5#. 5#5#. 5#5#5#5#
5#5#5#. 5#5#5#5#5#5#
5#. 5#5#5#. 5#. 5#5#
5#5#. 5#5#5#5#5#5#5#
 at (0,0)
  _0: rectangle with size (2,3) with model Full with color red at (4,7)
  _01: rectangle with size (7,1) with model Full with color green at (2,5)
  _011: rectangle with size (4,3) with model Full with color blue at (1,2)
  _0111: rectangle with size (3,1) with model Full with color blue at (0,8)
  _01111: rectangle with size (1,2) with model Full with color red at (0,0)
  _011111: 
2 
2 
 at (2,1)
  _0111111: rectangle with size (2,1) with model Full with color red at (5,2)
  + 5 delta pixels
diff: 
   (342.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
. . 0 0 . 0 0 0 . 0 
0 0 . . 0 0 0 0 . 0 
0 . 0 . 0 . 0 0 . 0 
0 . 0 0 . 0 0 0 0 0 
0 0 0 . . 0 0 . 0 . 
0 0 . 0 0 0 0 . 0 . 
0 0 . 0 0 . 0 0 0 0 
0 0 0 . 0 0 0 0 0 0 
0 . 0 0 0 . 0 . 0 0 
0 0 . 0 0 0 0 0 0 0 
 with color grey at (0,0)
diff: 
! 25 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color grey and layers
  _0: rectangle with size (3,1) with model Full with color black at (0,8)
  + 24 delta pixels
diff: 
! 98 wrong pixels (generated / expected)

TRAIN e8593010.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
. 0 0 0 0 0 . . 0 0 
0 0 0 . 0 0 . 0 . 0 
0 0 . 0 0 0 0 0 . 0 
0 . . 0 0 0 0 0 0 0 
. 0 0 0 0 0 . 0 0 0 
. 0 0 . 0 0 . 0 . . 
0 0 . 0 0 0 0 0 . 0 
0 0 . 0 0 0 0 0 0 . 
. . 0 0 0 0 . 0 0 0 
0 0 0 0 . 0 . . 0 . 
 with color grey at (0,0)
diff: 
! 28 wrong pixels (generated / expected)

TEST e8593010.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 31.1 sec (31.1 sec/task)
bits-train-error = 10288.1 bits (10288.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-31] Checking task e8dc4411.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 225605.2 = 225607.6
DL output with Mo: L = 2.3 + 225605.2 = 225607.6
DL input+output M: L = 4.6 + 451210.5 = 451215.1

# learning a model for train pairs
2.000	
1.057	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.186	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.118	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.077	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.036	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.030	OUT SPE ^.layer_0 = ^.layer_0
0.026	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.024	OUT SPE ^.size = ^.size
0.022	OUT SPE ^.color = ^.color
0.022	IN  SPE ^.layer_0.shape.color = black
0.021	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.009	
0.009	IN  GEN ^.layer_0.shape.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.color and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color black at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 63.9 + 2623.8 = 2687.7
DL output with Mo: L = 46.5 + 1968.7 = 2015.2
DL input+output M: L = 110.4 + 4592.5 = 4702.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.color and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 60.4 + 0.0 = 60.4
DL output with Mo: L = 46.5 + 1968.7 = 2015.2
DL input+output M: L = 106.9 + 1968.7 = 2075.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (12,14) and color cyan and layers
  _0: rectangle with size (3,3) with model Odd Checkboard with color black at (3,3)
  _01: point with color red at (5,6)
diff: 
   (0.0 bits)
data: a background with size (12,14) and color cyan and layers
  _0: 
. 0 . 
0 . 0 
. 0 . 
 at (3,3)
  _01: rectangle with size (7,8) with mask 
. 0 . . . . . . 
0 . 0 . . . . . 
. 0 . 0 . . . . 
. . 0 . 0 . . . 
. . . 0 . 0 . . 
. . . . 0 . 0 . 
. . . . . 0 . 0 
 with color red at (5,5)
diff: 
   (77.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,14) and color cyan and layers
  _0: rectangle with size (3,3) with model Odd Checkboard with color black at (3,3)
  _01: point with color red at (5,6)
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,14) and color black and layers
  _0: rectangle with size (12,14) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 0 0 0 0 0 0 0 0 
0 0 0 . 0 . 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 . 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color cyan at (0,0)
  _01: point with color red at (5,6)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,14) and color cyan and layers
  _0: rectangle with size (1,1) with model Full with color black at (3,4)
  _01: point with color red at (5,6)
  + 3 delta pixels
diff: 
! 20 wrong pixels (generated / expected)

TRAIN e8dc4411.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (13,15) and color blue and layers
  _0: rectangle with size (3,3) with model +-cross with color black at (5,5)
  _01: point with color green at (7,4)
diff: 
   (0.0 bits)
data: a background with size (13,15) and color blue and layers
  _0: 
. 0 . 
0 0 0 
. 0 . 
 at (5,5)
  _01: rectangle with size (6,6) with mask 
. . . . 0 . 
. . . 0 0 0 
. . 0 . 0 . 
. 0 0 0 . . 
0 . 0 . . . 
0 0 . . . . 
 with color green at (7,0)
diff: 
   (66.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,15) and color blue and layers
  _0: rectangle with size (3,3) with model +-cross with color black at (5,5)
  _01: point with color green at (7,4)
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,15) and color black and layers
  _0: rectangle with size (13,15) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 . 0 0 0 0 0 0 0 0 
0 0 0 0 0 . . . 0 0 0 0 0 0 0 
0 0 0 0 . 0 . 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color blue at (0,0)
  _01: point with color green at (7,4)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (13,15) and color blue and layers
  _0: rectangle with size (3,1) with model Full with color black at (5,6)
  _01: point with color green at (7,4)
  + 2 delta pixels
diff: 
! 19 wrong pixels (generated / expected)

TRAIN e8dc4411.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (12,16) and color yellow and layers
  _0: rectangle with size (5,5) with mask 
0 0 . 0 0 
0 0 . 0 0 
. . 0 . . 
0 0 . 0 0 
0 0 . 0 0 
 with color black at (5,6)
  _01: point with color cyan at (4,11)
diff: 
   (0.0 bits)
data: a background with size (12,16) and color yellow and layers
  _0: 
0 0 . 0 0 
0 0 . 0 0 
. . 0 . . 
0 0 . 0 0 
0 0 . 0 0 
 at (5,6)
  _01: rectangle with size (5,5) with mask 
0 0 . 0 0 
0 0 . 0 0 
. . 0 . . 
0 0 . 0 0 
0 0 . 0 0 
 with color cyan at (0,11)
diff: 
   (53.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,16) and color yellow and layers
  _0: rectangle with size (5,5) with mask 
0 0 . 0 0 
0 0 . 0 0 
. . 0 . . 
0 0 . 0 0 
0 0 . 0 0 
 with color black at (5,6)
  _01: point with color cyan at (4,11)
diff: 
! 21 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,16) and color black and layers
  _0: rectangle with size (12,16) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 . 0 0 0 0 
0 0 0 0 0 0 . . 0 . . 0 0 0 0 0 
0 0 0 0 0 0 . . 0 . . 0 0 0 0 0 
0 0 0 0 0 0 0 0 . 0 0 0 0 0 0 0 
0 0 0 0 0 0 . . 0 . . 0 0 0 0 0 
0 0 0 0 0 0 . . 0 . . 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color yellow at (0,0)
  _01: point with color cyan at (4,11)
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,16) and color yellow and layers
  _0: rectangle with size (5,5) with model Full with color black at (5,6)
  _01: point with color cyan at (4,11)
  + 8 delta pixels
diff: 
! 29 wrong pixels (generated / expected)

TRAIN e8dc4411.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (18,16) and color green and layers
  _0: rectangle with size (3,3) with model Even Checkboard with color black at (6,4)
  _01: point with color pink at (5,3)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (18,16) and color black and layers
  _0: rectangle with size (18,16) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 . 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 . 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 . 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . 0 . 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color green at (0,0)
  _01: point with color pink at (5,3)
diff: 
! 7 wrong pixels (generated / expected)

TEST e8dc4411.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 5.7 sec (5.7 sec/task)
bits-train-error = 1968.7 bits (1968.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-30] Checking task e9614598.json: 2 train, 2 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 79850.6 = 79852.9
DL output with Mo: L = 2.3 + 79850.6 = 79852.9
DL input+output M: L = 4.6 + 159701.1 = 159705.8

# learning a model for train pairs
2.000	
1.026	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.103	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.062	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.057	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.051	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.045	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.039	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.034	OUT SPE ^.size = ^.size
0.029	OUT SPE ^.layer_01 = ^.layer_01
0.025	OUT SPE ^.layer_0.shape.mask = 
. 0 . 
0 0 0 
. 0 . 

0.020	OUT SPE ^.layer_011 = ^.layer_0
0.018	OUT SPE ^.layer_0.pos = average(^.layer_0.pos, ^.layer_01.pos) - (1, 1)
0.017	IN  SPE ^.layer_0.shape.color = blue
0.015	IN  SPE ^.layer_01.shape.color = blue
0.014	OUT SPE ^.layer_0.shape.color = green
0.013	IN  SPE ^.color = black
0.013	OUT SPE ^.color = black
0.002	
0.002	IN  GEN ^.layer_01.shape.color = ?
0.002	IN  GEN ^.layer_0.shape.color = ?
0.002	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
. 0 . 
0 0 0 
. 0 . 
 with color green at average(^.layer_0.pos, ^.layer_01.pos) - (1, 1)
  _01: ^.layer_01
  _011: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color blue at (?,?)
  _01: point with color blue at (?,?)

DL input  with Mi: L = 57.4 + 850.1 = 907.5
DL output with Mo: L = 93.7 + 0.0 = 93.7
DL input+output M: L = 151.1 + 850.1 = 1001.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: 
. 0 . 
0 0 0 
. 0 . 
 with color green at average(^.layer_0.pos, ^.layer_01.pos) - (1, 1)
  _01: ^.layer_01
  _011: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 50.6 + 0.0 = 50.6
DL output with Mo: L = 93.7 + 0.0 = 93.7
DL input+output M: L = 144.3 + 0.0 = 144.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color blue at (4,1)
  _01: point with color blue at (4,7)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
. 0 . 
0 0 0 
. 0 . 
 with color green at (3,3)
  _01: 
1 
 at (4,7)
  _011: 
1 
 at (4,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (4,1)
  _01: point with color blue at (4,7)
diff: 
correct output grid

TRAIN e9614598.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: point with color blue at (0,3)
  _01: point with color blue at (8,3)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
. 0 . 
0 0 0 
. 0 . 
 with color green at (3,2)
  _01: 
1 
 at (8,3)
  _011: 
1 
 at (0,3)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: point with color blue at (0,3)
  _01: point with color blue at (8,3)
diff: 
correct output grid

TRAIN e9614598.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: point with color blue at (3,1)
  _01: point with color blue at (3,11)
diff: 
correct output grid

TEST e9614598.json/1: 1 1st (SUCCESS)

## instance 2

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,6) and color black and layers
  _0: point with color blue at (0,3)
  _01: point with color blue at (6,3)
diff: 
correct output grid

TEST e9614598.json/2: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 4.8 sec (4.8 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-29] Checking task e98196ab.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 145705.7 = 145708.0
DL output with Mo: L = 2.3 + 64895.5 = 64897.8
DL input+output M: L = 4.6 + 210601.2 = 210605.9

# learning a model for train pairs
2.000	
1.209	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.466	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.383	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.361	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.350	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.340	OUT ADD ^.layer_011 = point with color ? at (?,?)
0.329	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.319	OUT ADD ^.layer_01111 = point with color ? at (?,?)
0.309	OUT ADD ^.layer_011111 = point with color ? at (?,?)
0.298	OUT ADD ^.layer_0111111 = point with color ? at (?,?)
0.288	OUT ADD ^.layer_01111111 = point with color ? at (?,?)
0.163	
0.162	IN  GEN ^ = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 18244.2 = 18286.2
DL output with Mo: L = 176.9 + 10362.8 = 10539.7
DL input+output M: L = 218.9 + 28607.0 = 28825.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)
  _01111: point with color ? at (?,?)
  _011111: point with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 176.9 + 10362.8 = 10539.7
DL input+output M: L = 179.2 + 10362.8 = 10542.0

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 0 8 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 8 0 0 0 8 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 8 0 0 0 0 0 0 0 8 0 
5#5#5#5#5#5#5#5#5#5#5#
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 1 0 1 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 1 0 0 0 0 0 1 0 0 
1 0 0 0 0 0 0 0 0 0 1 

diff: 
   (0.0 bits)
data: a background with size (5,11) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (0,5)
  _01: rectangle with size (1,1) with model Full with color blue at (1,4)
  _011: point with color blue at (1,6)
  _0111: point with color cyan at (2,3)
  _01111: point with color cyan at (2,7)
  _011111: point with color blue at (3,2)
  _0111111: point with color blue at (3,8)
  _01111111: point with color blue at (4,0)
  + 3 delta pixels
diff: 
   (288.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 8 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 8 0 0 0 8 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 8 0 0 0 0 0 0 0 8 0 
5#5#5#5#5#5#5#5#5#5#5#
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 1 0 1 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 1 0 0 0 0 0 1 0 0 
1 0 0 0 0 0 0 0 0 0 1 

diff: 
! size mismatch, 10x10 instead of 5x11

TRAIN e98196ab.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
0 3 0 0 0 3 0 0 0 3 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 3 0 0 0 0 3 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 3 0 0 0 0 0 0 0 0 0 
5#5#5#5#5#5#5#5#5#5#5#
0 0 0 0 0 0 0 0 0 0 7#
7#0 0 0 0 0 0 0 7#0 0 
0 0 7#0 7#0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
7#0 0 0 0 0 7#0 0 0 7#

diff: 
   (0.0 bits)
data: a background with size (5,11) and color black and layers
  _0: rectangle with size (1,3) with model Full with color orange at (2,2)
  _01: rectangle with size (1,1) with model Full with color green at (0,1)
  _011: point with color green at (0,5)
  _0111: point with color green at (0,9)
  _01111: point with color orange at (0,10)
  _011111: point with color orange at (1,0)
  _0111111: point with color orange at (1,8)
  _01111111: point with color green at (2,8)
  + 5 delta pixels
diff: 
   (369.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 3 0 0 0 3 0 0 0 3 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 3 0 0 0 0 3 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 3 0 0 0 0 0 0 0 0 0 
5#5#5#5#5#5#5#5#5#5#5#
0 0 0 0 0 0 0 0 0 0 7#
7#0 0 0 0 0 0 0 7#0 0 
0 0 7#0 7#0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
7#0 0 0 0 0 7#0 0 0 7#

diff: 
! size mismatch, 10x10 instead of 5x11

TRAIN e98196ab.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 
0 1 0 1 1 0 1 0 0 1 0 
0 0 0 0 0 0 1 0 0 0 0 
0 0 1 0 1 0 0 1 0 0 0 
0 0 0 0 0 0 0 0 0 0 1 
5#5#5#5#5#5#5#5#5#5#5#
2 0 0 0 0 2 0 0 0 0 2 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
2 0 0 0 2 0 0 0 2 0 0 

diff: 
   (0.0 bits)
data: a background with size (5,11) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 . 
0 . 
. 0 
 with color blue at (1,6)
  _01: rectangle with size (1,2) with model Full with color blue at (1,3)
  _011: point with color red at (0,0)
  _0111: point with color red at (0,5)
  _01111: point with color red at (0,10)
  _011111: point with color blue at (1,1)
  _0111111: point with color blue at (1,9)
  _01111111: point with color blue at (3,2)
  + 5 delta pixels
diff: 
   (378.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 
0 1 0 1 1 0 1 0 0 1 0 
0 0 0 0 0 0 1 0 0 0 0 
0 0 1 0 1 0 0 1 0 0 0 
0 0 0 0 0 0 0 0 0 0 1 
5#5#5#5#5#5#5#5#5#5#5#
2 0 0 0 0 2 0 0 0 0 2 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
2 0 0 0 2 0 0 0 2 0 0 

diff: 
! size mismatch, 10x10 instead of 5x11

TRAIN e98196ab.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 7#
0 0 7#7#0 0 0 0 7#0 0 
0 0 0 0 0 0 7#0 0 0 0 
0 7#0 7#0 0 0 0 0 0 7#
0 0 0 0 0 0 7#0 0 0 0 
5#5#5#5#5#5#5#5#5#5#5#
6 0 0 0 6 0 6 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 6 
6 0 0 0 6 0 0 0 0 0 6 
0 0 0 0 0 0 0 0 0 6 0 
6 0 0 6 0 0 0 0 0 0 0 

diff: 
! size mismatch, 10x10 instead of 5x11

TEST e98196ab.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.1 sec (59.1 sec/task)
bits-train-error = 10362.8 bits (10362.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-28] Checking task e9afcf9a.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 9317.4 = 9319.7
DL output with Mo: L = 2.3 + 9317.4 = 9319.7
DL input+output M: L = 4.6 + 18634.8 = 18639.5

# learning a model for train pairs
2.000	
1.532	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.064	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.646	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.242	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.199	OUT SPE ^.layer_0.shape.mask = 
. 0 . 0 . 0 
0 . 0 . 0 . 

0.167	IN  SPE ^.layer_0.shape.mask = 
0 0 0 0 0 0 

0.137	OUT SPE ^.size = ^.size
0.118	OUT SPE ^.color = ^.color
0.101	OUT SPE ^.layer_0.pos = '(0, 0)
0.089	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.010	

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.color and layers
  _0: 
. 0 . 0 . 0 
0 . 0 . 0 . 
 with color ^.layer_0.shape.color at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 0 0 0 0 0 
 with color ? at (?,?)

DL input  with Mi: L = 40.5 + 732.8 = 773.3
DL output with Mo: L = 55.6 + 0.0 = 55.6
DL input+output M: L = 96.1 + 732.8 = 828.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.color and layers
  _0: 
. 0 . 0 . 0 
0 . 0 . 0 . 
 with color ^.layer_0.shape.color at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: 
0 0 0 0 0 0 
 with color ? at (?,?)

DL input  with Mi: L = 40.5 + 0.0 = 40.5
DL output with Mo: L = 55.6 + 0.0 = 55.6
DL input+output M: L = 96.1 + 0.0 = 96.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (2,6) and color green and layers
  _0: 
0 0 0 0 0 0 
 with color brown at (1,0)
diff: 
   (0.0 bits)
data: a background with size (2,6) and color green and layers
  _0: 
. 0 . 0 . 0 
0 . 0 . 0 . 
 with color brown at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (2,6) and color green and layers
  _0: 
0 0 0 0 0 0 
 with color brown at (1,0)
diff: 
correct output grid

TRAIN e9afcf9a.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (2,6) and color yellow and layers
  _0: 
0 0 0 0 0 0 
 with color cyan at (1,0)
diff: 
   (0.0 bits)
data: a background with size (2,6) and color yellow and layers
  _0: 
. 0 . 0 . 0 
0 . 0 . 0 . 
 with color cyan at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (2,6) and color yellow and layers
  _0: 
0 0 0 0 0 0 
 with color cyan at (1,0)
diff: 
correct output grid

TRAIN e9afcf9a.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (2,6) and color red and layers
  _0: 
0 0 0 0 0 0 
 with color pink at (0,0)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (2,6) and color pink and layers
  _0: 
0 0 0 0 0 0 
 with color red at (1,0)
diff: 
correct output grid

TEST e9afcf9a.json/1: 1 2nd (SUCCESS)

# Performance measures on task
runtime-learning = 2.5 sec (2.5 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 0.50

=====================================
[-27] Checking task ea32f347.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 159701.1 = 159703.5
DL output with Mo: L = 2.3 + 159701.1 = 159703.5
DL input+output M: L = 4.6 + 319402.3 = 319406.9

# learning a model for train pairs
2.000	
1.146	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.292	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.238	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.184	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.144	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.105	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.082	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.059	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.051	OUT SPE ^.layer_0 = coloring(^.layer_0, blue)
0.043	OUT SPE ^.layer_01 = coloring(^.layer_01, yellow)
0.035	OUT SPE ^.layer_011 = coloring(^.layer_011, red)
0.030	OUT SPE ^.size = ^.size
0.029	IN  SPE ^.layer_0.shape.color = grey
0.027	IN  SPE ^.layer_01.shape.color = grey
0.026	IN  SPE ^.layer_011.shape.color = grey
0.025	IN  SPE ^.layer_0.shape.mask.model = Full
0.025	IN  SPE ^.layer_01.shape.mask.model = Full
0.024	IN  SPE ^.layer_011.shape.mask.model = Full
0.023	IN  SPE ^.color = black
0.023	OUT SPE ^.color = black
0.001	
0.001	IN  GEN ^.layer_011.shape.color = ?
0.001	IN  GEN ^.layer_01.shape.color = ?
0.001	IN  GEN ^.layer_0.shape.color = ?
0.001	IN  GEN ^.layer_011.shape.mask.model = ?
0.001	IN  GEN ^.layer_01.shape.mask.model = ?
0.001	IN  GEN ^.layer_0.shape.mask.model = ?
0.001	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, blue)
  _01: coloring(^.layer_01, yellow)
  _011: coloring(^.layer_011, red)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color grey at (?,?)
  _01: rectangle with size (?,?) with model Full with color grey at (?,?)
  _011: rectangle with size (?,?) with model Full with color grey at (?,?)

DL input  with Mi: L = 109.7 + 3463.0 = 3572.7
DL output with Mo: L = 53.7 + 0.0 = 53.7
DL input+output M: L = 163.4 + 3463.0 = 3626.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, blue)
  _01: coloring(^.layer_01, yellow)
  _011: coloring(^.layer_011, red)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 98.1 + 0.0 = 98.1
DL output with Mo: L = 53.7 + 0.0 = 53.7
DL input+output M: L = 151.8 + 0.0 = 151.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,1) with model Full with color grey at (1,1)
  _01: rectangle with size (5,1) with model Full with color grey at (2,4)
  _011: rectangle with size (3,1) with model Full with color grey at (4,7)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
1 
1 
1 
1 
1 
1 
 at (1,1)
  _01: 
4 
4 
4 
4 
4 
 at (2,4)
  _011: 
2 
2 
2 
 at (4,7)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,1) with model Full with color grey at (1,1)
  _01: rectangle with size (5,1) with model Full with color grey at (2,4)
  _011: rectangle with size (3,1) with model Full with color grey at (4,7)
diff: 
correct output grid

TRAIN ea32f347.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,1) with model Full with color grey at (1,4)
  _01: rectangle with size (4,1) with model Full with color grey at (3,1)
  _011: rectangle with size (2,1) with model Full with color grey at (5,7)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
1 
1 
1 
1 
1 
1 
 at (1,4)
  _01: 
4 
4 
4 
4 
 at (3,1)
  _011: 
2 
2 
 at (5,7)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,1) with model Full with color grey at (1,4)
  _01: rectangle with size (4,1) with model Full with color grey at (3,1)
  _011: rectangle with size (2,1) with model Full with color grey at (5,7)
diff: 
correct output grid

TRAIN ea32f347.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,6) with model Full with color grey at (2,0)
  _01: rectangle with size (5,1) with model Full with color grey at (3,7)
  _011: rectangle with size (1,3) with model Full with color grey at (7,2)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
1 1 1 1 1 1 
 at (2,0)
  _01: 
4 
4 
4 
4 
4 
 at (3,7)
  _011: 
2 2 2 
 at (7,2)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,6) with model Full with color grey at (2,0)
  _01: rectangle with size (5,1) with model Full with color grey at (3,7)
  _011: rectangle with size (1,3) with model Full with color grey at (7,2)
diff: 
correct output grid

TRAIN ea32f347.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (7,1) with model Full with color grey at (1,7)
  _01: rectangle with size (1,5) with model Full with color grey at (5,1)
  _011: rectangle with size (1,4) with model Full with color grey at (2,1)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: 
1 
1 
1 
1 
1 
1 
1 
 at (1,7)
  _01: 
4 4 4 4 4 
 at (5,1)
  _011: 
2 2 2 2 
 at (2,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (7,1) with model Full with color grey at (1,7)
  _01: rectangle with size (1,5) with model Full with color grey at (5,1)
  _011: rectangle with size (1,4) with model Full with color grey at (2,1)
diff: 
correct output grid

TRAIN ea32f347.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (1,6) with model Full with color grey at (5,4)
  _01: rectangle with size (1,5) with model Full with color grey at (8,0)
  _011: rectangle with size (3,1) with model Full with color grey at (1,3)
diff: 
correct output grid

TEST ea32f347.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 6.0 sec (6.0 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-26] Checking task ea786f4a.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 32440.4 = 32442.7
DL output with Mo: L = 2.3 + 32440.4 = 32442.7
DL input+output M: L = 4.6 + 64880.8 = 64885.5

# learning a model for train pairs
2.000	
1.060	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.389	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.116	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.094	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.079	OUT SPE ^.size = ^.size
0.065	OUT SPE ^.layer_0.shape.mask.size = ^.size
0.057	OUT SPE ^.layer_0.pos = '(0, 0)
0.050	OUT SPE ^.color = ^.color
0.044	OUT SPE ^.layer_0.shape.mask.model = x-cross
0.039	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.034	IN  SPE ^.layer_0.shape.color = black
0.003	
0.003	IN  GEN ^.layer_0.shape.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.color and layers
  _0: rectangle with size ^.size with model x-cross with color ^.layer_0.shape.color at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color black at (?,?)

DL input  with Mi: L = 35.6 + 1010.5 = 1046.1
DL output with Mo: L = 51.0 + 0.0 = 51.0
DL input+output M: L = 86.6 + 1010.5 = 1097.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ^.color and layers
  _0: rectangle with size ^.size with model x-cross with color ^.layer_0.shape.color at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 0.0 = 32.2
DL output with Mo: L = 51.0 + 0.0 = 51.0
DL input+output M: L = 83.2 + 0.0 = 83.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color blue and layers
  _0: point with color black at (1,1)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color blue and layers
  _0: rectangle with size (3,3) with model x-cross with color black at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color blue and layers
  _0: point with color black at (1,1)
diff: 
correct output grid

TRAIN ea786f4a.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (5,5) and color red and layers
  _0: point with color black at (2,2)
diff: 
   (0.0 bits)
data: a background with size (5,5) and color red and layers
  _0: rectangle with size (5,5) with model x-cross with color black at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color red and layers
  _0: point with color black at (2,2)
diff: 
correct output grid

TRAIN ea786f4a.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (7,7) and color green and layers
  _0: point with color black at (3,3)
diff: 
   (0.0 bits)
data: a background with size (7,7) and color green and layers
  _0: rectangle with size (7,7) with model x-cross with color black at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color green and layers
  _0: point with color black at (3,3)
diff: 
correct output grid

TRAIN ea786f4a.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (11,11) and color pink and layers
  _0: point with color black at (5,5)
diff: 
correct output grid

TEST ea786f4a.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.5 sec (1.5 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-25] Checking task eb281b96.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 46903.4 = 46905.8
DL output with Mo: L = 2.3 + 152155.6 = 152157.9
DL input+output M: L = 4.6 + 199059.0 = 199063.6

# learning a model for train pairs
2.000	
1.360	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.737	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.393	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.082	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.081	OUT SPE ^.layer_0.pos = ^.layer_0.pos
0.079	OUT SPE ^.layer_0.shape.mask.size.j = ^.layer_0.shape.mask.size.j
0.078	OUT SPE ^.size.j = ^.size.j
0.077	IN  SPE ^.color = black
0.076	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.076	OUT SPE ^.color = black
0.028	
0.028	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,^.size.j) and color black and layers
  _0: rectangle with size (?,^.layer_0.shape.mask.size.j) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.1 + 2238.2 = 2280.3
DL output with Mo: L = 43.1 + 4053.6 = 4096.7
DL input+output M: L = 85.3 + 6291.8 = 6377.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,^.size.j) and color black and layers
  _0: rectangle with size (?,^.layer_0.shape.mask.size.j) with model ? with color ^.layer_0.shape.color at ^.layer_0.pos
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 43.1 + 4053.6 = 4096.7
DL input+output M: L = 85.1 + 4053.6 = 4138.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,17) and color black and layers
  _0: rectangle with size (3,17) with mask 
. . 0 . . . 0 . . . 0 . . . 0 . . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
0 . . . 0 . . . 0 . . . 0 . . . 0 
 with color cyan at (0,0)
diff: 
   (0.0 bits)
data: a background with size (9,17) and color black and layers
  _0: rectangle with size (9,17) with mask 
. . 0 . . . 0 . . . 0 . . . 0 . . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
0 . . . 0 . . . 0 . . . 0 . . . 0 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
. . 0 . . . 0 . . . 0 . . . 0 . . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
0 . . . 0 . . . 0 . . . 0 . . . 0 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
. . 0 . . . 0 . . . 0 . . . 0 . . 
 with color cyan at (0,0)
diff: 
   (166.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,17) and color black and layers
  _0: rectangle with size (3,17) with mask 
. . 0 . . . 0 . . . 0 . . . 0 . . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
0 . . . 0 . . . 0 . . . 0 . . . 0 
 with color cyan at (0,0)
diff: 
! size mismatch, 10x17 instead of 9x17
>> Trial 2
data: a background with size (3,17) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (0,2)
  + 16 delta pixels
diff: 
! size mismatch, 10x17 instead of 9x17
>> Trial 3
data: a background with size (3,17) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (0,6)
  + 16 delta pixels
diff: 
! size mismatch, 10x17 instead of 9x17

TRAIN eb281b96.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (4,17) and color black and layers
  _0: rectangle with size (4,17) with mask 
. . 0 . . . 0 . . . 0 . . . 0 . . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
0 . . . 0 . . . 0 . . . 0 . . . 0 
 with color red at (0,0)
diff: 
   (0.0 bits)
data: a background with size (13,17) and color black and layers
  _0: rectangle with size (13,17) with mask 
. . 0 . . . 0 . . . 0 . . . 0 . . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
0 . . . 0 . . . 0 . . . 0 . . . 0 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
. . 0 . . . 0 . . . 0 . . . 0 . . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
0 . . . 0 . . . 0 . . . 0 . . . 0 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
. . 0 . . . 0 . . . 0 . . . 0 . . 
 with color red at (0,0)
diff: 
   (238.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,17) and color black and layers
  _0: rectangle with size (4,17) with mask 
. . 0 . . . 0 . . . 0 . . . 0 . . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
0 . . . 0 . . . 0 . . . 0 . . . 0 
 with color red at (0,0)
diff: 
! size mismatch, 10x17 instead of 13x17
>> Trial 2
data: a background with size (4,17) and color black and layers
  _0: rectangle with size (2,1) with model Full with color red at (1,1)
  + 23 delta pixels
diff: 
! size mismatch, 10x17 instead of 13x17
>> Trial 3
data: a background with size (4,17) and color black and layers
  _0: rectangle with size (2,1) with model Full with color red at (1,3)
  + 23 delta pixels
diff: 
! size mismatch, 10x17 instead of 13x17

TRAIN eb281b96.json/2: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,17) and color black and layers
  _0: rectangle with size (5,17) with mask 
. . 0 . . . 0 . . . 0 . . . 0 . . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
. 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 
0 . . . 0 . . . 0 . . . 0 . . . 0 
 with color green at (0,0)
diff: 
! size mismatch, 10x17 instead of 17x17
>> Trial 2
data: a background with size (5,17) and color black and layers
  _0: rectangle with size (3,1) with model Full with color green at (1,1)
  + 30 delta pixels
diff: 
! size mismatch, 10x17 instead of 17x17
>> Trial 3
data: a background with size (5,17) and color black and layers
  _0: rectangle with size (3,1) with model Full with color green at (1,3)
  + 30 delta pixels
diff: 
! size mismatch, 10x17 instead of 17x17

TEST eb281b96.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.1 sec (3.1 sec/task)
bits-train-error = 4053.6 bits (4053.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-24] Checking task eb5a1d5d.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 686980.8 = 686983.1
DL output with Mo: L = 2.3 + 32440.4 = 32442.7
DL input+output M: L = 4.6 + 719421.2 = 719425.8

# learning a model for train pairs
2.000	
1.417	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.858	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.516	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.247	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.164	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.103	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.088	OUT SPE ^.layer_01.shape = scaleTo(^.layer_01.shape, '(3, 3))
0.081	OUT SPE ^.layer_0.shape.mask.size = span(^.layer_0.pos, ^.layer_01.pos) - ^.layer_0.pos - ^.layer_01.pos
0.074	OUT SPE ^.color = ^.color
0.069	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.066	OUT SPE ^.layer_01.pos.j = ^.layer_01.pos.j / '2
0.062	OUT SPE ^.layer_01.pos.i = ^.layer_01.pos.i / '2
0.062	IN  SPE ^.layer_01.shape.mask.model = Full
0.045	
0.045	IN  GEN ^.layer_01.shape.mask.model = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ^.color and layers
  _0: rectangle with size span(^.layer_0.pos, ^.layer_01.pos) - ^.layer_0.pos - ^.layer_01.pos with model ? with color ^.layer_0.shape.color at (?,?)
  _01: scaleTo(^.layer_01.shape, '(3, 3)) at (^.layer_01.pos.i / '2,^.layer_01.pos.j / '2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 70.7 + 11774.2 = 11844.9
DL output with Mo: L = 183.6 + 1259.6 = 1443.2
DL input+output M: L = 254.4 + 13033.7 = 13288.1

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ^.color and layers
  _0: rectangle with size span(^.layer_0.pos, ^.layer_01.pos) - ^.layer_0.pos - ^.layer_01.pos with model ? with color ^.layer_0.shape.color at (?,?)
  _01: scaleTo(^.layer_01.shape, '(3, 3)) at (^.layer_01.pos.i / '2,^.layer_01.pos.j / '2)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 31.7 = 101.9
DL output with Mo: L = 183.6 + 1259.6 = 1443.2
DL input+output M: L = 253.8 + 1291.3 = 1545.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (23,27) and color cyan and layers
  _0: rectangle with size (6,6) with model Full with color red at (9,6)
  _01: rectangle with size (16,18) with model Full with color green at (2,3)
diff: 
   (0.0 bits)
data: a background with size (5,5) and color cyan and layers
  _0: rectangle with size (1,1) with model Full with color red at (2,2)
  _01: 
3 3 3 
3 3 3 
3 3 3 
 at (1,1)
diff: 
   (28.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (23,27) and color cyan and layers
  _0: rectangle with size (6,6) with model Full with color red at (9,6)
  _01: rectangle with size (16,18) with model Full with color green at (2,3)
diff: 
! size mismatch, 10x10 instead of 5x5
>> Trial 2
data: a background with size (23,27) and color cyan and layers
  _0: rectangle with size (16,18) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 . . . . . . 0 0 0 0 0 0 0 0 0 
0 0 0 . . . . . . 0 0 0 0 0 0 0 0 0 
0 0 0 . . . . . . 0 0 0 0 0 0 0 0 0 
0 0 0 . . . . . . 0 0 0 0 0 0 0 0 0 
0 0 0 . . . . . . 0 0 0 0 0 0 0 0 0 
0 0 0 . . . . . . 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color green at (2,3)
  _01: rectangle with size (6,6) with model Full with color red at (9,6)
diff: 
! size mismatch, 10x10 instead of 5x5
>> Trial 3
data: a background with size (23,27) and color green and layers
  _0: rectangle with size (23,27) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 . . . . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color cyan at (0,0)
  _01: rectangle with size (6,6) with model Full with color red at (9,6)
diff: 
! size mismatch, 10x10 instead of 5x5

TRAIN eb5a1d5d.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (22,25) and color black and layers
  _0: rectangle with size (13,15) with model Full with color pink at (3,4)
  _01: rectangle with size (22,25) with model Full with color grey at (0,0)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color pink at (1,1)
  _01: 
5#5#5#
5#5#5#
5#5#5#
 at (0,0)
diff: 
   (23.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (22,25) and color black and layers
  _0: rectangle with size (13,15) with model Full with color pink at (3,4)
  _01: rectangle with size (22,25) with model Full with color grey at (0,0)
diff: 
! size mismatch, 10x10 instead of 3x3
>> Trial 2
data: a background with size (22,25) and color black and layers
  _0: rectangle with size (22,25) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 . . . . . . . . . . . . . . . 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color grey at (0,0)
  _01: rectangle with size (13,15) with model Full with color pink at (3,4)
diff: 
! size mismatch, 10x10 instead of 3x3
>> Trial 3
data: a background with size (22,25) and color pink and layers
  _0: rectangle with size (6,25) with model Full with color grey at (16,0)
  _01: rectangle with size (22,6) with model Full with color grey at (0,19)
  + 109 delta pixels
diff: 
! size mismatch, 10x10 instead of 3x3

TRAIN eb5a1d5d.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (21,22) and color green and layers
  _0: rectangle with size (14,14) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color cyan at (3,3)
  _01: rectangle with size (9,9) with model Full with color red at (5,5)
  + 15 delta pixels
diff: 
   (3.2 bits)
data: a background with size (7,7) and color green and layers
  _0: rectangle with size (5,5) with model Border with color cyan at (1,1)
  _01: 
2 2 2 
2 2 2 
2 2 2 
 at (2,2)
  + 1 delta pixels
diff: 
   (74.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (21,22) and color green and layers
  _0: rectangle with size (9,9) with model Full with color red at (5,5)
  _01: rectangle with size (14,14) with model Full with color cyan at (3,3)
  + 15 delta pixels
diff: 
! size mismatch, 10x10 instead of 7x7
>> Trial 2
data: a background with size (21,22) and color green and layers
  _0: rectangle with size (14,14) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 . . . . . . . . . 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 
 with color cyan at (3,3)
  _01: rectangle with size (9,9) with model Full with color red at (5,5)
  + 15 delta pixels
diff: 
! size mismatch, 10x10 instead of 7x7

TRAIN eb5a1d5d.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (26,27) and color red and layers
  _0: rectangle with size (14,14) with model Full with color green at (7,6)
  _01: rectangle with size (19,20) with model Full with color blue at (5,3)
  + 63 delta pixels
diff: 
! size mismatch, 10x10 instead of 9x9

TEST eb5a1d5d.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 32.1 sec (32.1 sec/task)
bits-train-error = 1259.6 bits (1259.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-23] Checking task ec883f72.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 129553.2 = 129555.5
DL output with Mo: L = 2.3 + 129553.2 = 129555.5
DL input+output M: L = 4.6 + 259106.4 = 259111.1

# learning a model for train pairs
2.000	
1.219	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.477	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.345	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.199	OUT ADD ^.layer_0 = ^.layer_0
0.145	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.089	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.059	OUT ADD ^.layer_011 = ^.layer_01
0.054	OUT SPE ^.size = ^.size
0.052	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.051	IN  SPE ^.layer_01.shape.mask.model = Full
0.050	IN  SPE ^.color = black
0.049	OUT SPE ^.color = black
0.017	
0.017	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at (?,?)
  _011: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 70.9 + 4140.0 = 4210.8
DL output with Mo: L = 53.0 + 2138.6 = 2191.6
DL input+output M: L = 123.8 + 6278.6 = 6402.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at (?,?)
  _011: ^.layer_01
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 70.7 + 0.0 = 70.7
DL output with Mo: L = 53.0 + 2138.6 = 2191.6
DL input+output M: L = 123.7 + 2138.6 = 2262.3

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . . 0 
. . . 0 
0 0 0 0 
 with color brown at (0,0)
  _01: rectangle with size (2,2) with model Full with color green at (0,0)
diff: 
   (0.0 bits)
data: a background with size (6,6) and color black and layers
  _0: 
. . . 9#
. . . 9#
. . . 9#
9#9#9#9#
 at (0,0)
  _01: rectangle with size (2,2) with model Even Checkboard with color green at (4,4)
  _011: 
3 3 
3 3 
 at (0,0)
diff: 
   (27.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . . 0 
. . . 0 
. . . 0 
0 0 0 0 
 with color brown at (0,0)
  _01: rectangle with size (2,2) with model Full with color green at (0,0)
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (2,2) with model Full with color green at (0,0)
  _01: rectangle with size (4,1) with model Full with color brown at (0,3)
  + 3 delta pixels
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (6,6) and color black and layers
  _0: rectangle with size (2,2) with model Full with color green at (0,0)
  _01: rectangle with size (1,4) with model Full with color brown at (3,0)
  + 3 delta pixels
diff: 
! 5 wrong pixels (generated / expected)

TRAIN ec883f72.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (8,8) and color black and layers
  _0: rectangle with size (3,5) with mask 
0 . . . 0 
0 . . . 0 
0 0 0 0 0 
 with color cyan at (0,2)
  _01: rectangle with size (1,1) with model Full with color pink at (0,4)
diff: 
   (0.0 bits)
data: a background with size (8,8) and color black and layers
  _0: 
8 . . . 8 
8 . . . 8 
8 8 8 8 8 
 at (0,2)
  _01: rectangle with size (2,2) with model Odd Checkboard with color pink at (3,0)
  _011: 
6 
 at (0,4)
  + 1 delta pixels
diff: 
   (68.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (3,5) with mask 
0 . . . 0 
0 . . . 0 
0 0 0 0 0 
 with color cyan at (0,2)
  _01: rectangle with size (1,1) with model Full with color pink at (0,4)
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (8,8) and color black and layers
  _0: rectangle with size (1,5) with model Full with color cyan at (2,2)
  _01: rectangle with size (3,1) with model Full with color cyan at (0,2)
  + 3 delta pixels
diff: 
! 10 wrong pixels (generated / expected)

TRAIN ec883f72.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (9,9) and color black and layers
  _0: rectangle with size (4,6) with mask 
0 0 0 0 0 0 
0 . . . . 0 
0 . . . . 0 
0 . . . . 0 
 with color yellow at (5,1)
  _01: rectangle with size (2,2) with model Full with color red at (7,3)
diff: 
   (0.0 bits)
data: a background with size (9,9) and color black and layers
  _0: 
4 4 4 4 4 4 
4 . . . . 4 
4 . . . . 4 
4 . . . . 4 
 at (5,1)
  _01: rectangle with size (2,2) with model Odd Checkboard with color red at (3,7)
  _011: 
2 2 
2 2 
 at (7,3)
  + 1 delta pixels
diff: 
   (69.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (4,6) with mask 
0 0 0 0 0 0 
0 . . . . 0 
0 . . . . 0 
0 . . . . 0 
 with color yellow at (5,1)
  _01: rectangle with size (2,2) with model Full with color red at (7,3)
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (1,6) with model Full with color yellow at (5,1)
  _01: rectangle with size (2,2) with model Full with color red at (7,3)
  + 6 delta pixels
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (9,9) and color black and layers
  _0: rectangle with size (2,2) with model Full with color red at (7,3)
  _01: rectangle with size (1,6) with model Full with color yellow at (5,1)
  + 6 delta pixels
diff: 
! 13 wrong pixels (generated / expected)

TRAIN ec883f72.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (7,6) with mask 
0 0 0 0 0 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
 with color grey at (5,0)
  _01: rectangle with size (5,4) with model Full with color yellow at (7,0)
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _0: 
5#5#5#5#5#5#
. . . . . 5#
. . . . . 5#
. . . . . 5#
. . . . . 5#
. . . . . 5#
. . . . . 5#
 at (5,0)
  _01: rectangle with size (5,5) with mask 
. . . . 0 
. . . 0 . 
. . 0 . . 
. 0 . . . 
0 . . . . 
 with color yellow at (0,6)
  _011: 
4 4 4 4 
4 4 4 4 
4 4 4 4 
4 4 4 4 
4 4 4 4 
 at (7,0)
diff: 
   (48.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (7,6) with mask 
0 0 0 0 0 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
 with color grey at (5,0)
  _01: rectangle with size (5,4) with model Full with color yellow at (7,0)
diff: 
! 9 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (5,4) with model Full with color yellow at (7,0)
  _01: rectangle with size (7,1) with model Full with color grey at (5,5)
  + 5 delta pixels
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (7,1) with model Full with color grey at (5,5)
  _01: rectangle with size (5,4) with model Full with color yellow at (7,0)
  + 5 delta pixels
diff: 
! 14 wrong pixels (generated / expected)

TRAIN ec883f72.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (5,6) with mask 
0 . . . . 0 
0 . . . . 0 
0 . . . . 0 
0 . . . . 0 
0 0 0 0 0 0 
 with color green at (0,4)
  _01: rectangle with size (3,2) with model Full with color yellow at (0,6)
diff: 
! 10 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (3,2) with model Full with color yellow at (0,6)
  _01: rectangle with size (1,6) with model Full with color green at (4,4)
  + 8 delta pixels
diff: 
! 18 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (1,6) with model Full with color green at (4,4)
  _01: rectangle with size (3,2) with model Full with color yellow at (0,6)
  + 8 delta pixels
diff: 
! 18 wrong pixels (generated / expected)

TEST ec883f72.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 6.4 sec (6.4 sec/task)
bits-train-error = 2138.6 bits (2138.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-22] Checking task ecdecbb3.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 247475.5 = 247477.8
DL output with Mo: L = 2.3 + 247475.5 = 247477.8
DL input+output M: L = 4.6 + 494950.9 = 494955.6

# learning a model for train pairs
2.000	
1.116	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.326	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.232	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.174	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.117	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.078	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.050	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.046	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.043	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.040	OUT SPE ^.size = ^.size
0.039	OUT SPE ^.layer_011.shape.color = ^.layer_011.shape.color
0.039	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.038	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.037	OUT SPE ^.layer_01.pos = min(^.layer_0.pos, ^.layer_01.pos) + translationOnto(^.layer_0, ^.layer_01)
0.036	IN  SPE ^.layer_01.shape.color = cyan
0.035	IN  SPE ^.layer_011.shape.color = red
0.035	OUT SPE ^.layer_0111.shape.color = red
0.034	OUT SPE ^.layer_011.pos.j = max(^.layer_01.pos.j, ^.layer_011.pos.j)
0.033	OUT SPE ^.layer_0.pos.j = ^.layer_011.pos.i - 2
0.033	OUT SPE ^.layer_0111.shape.mask.size.i = area(^.layer_011.shape) - ^.layer_0.pos.i - ^.layer_01.pos.i
0.032	OUT SPE ^.layer_0.pos.i = min(^.layer_0.pos.i, ^.layer_011.pos.i) * '3
0.032	OUT SPE ^.layer_011.shape.mask.size.j = 1
0.031	OUT SPE ^.layer_011.shape.mask.size.i = average(^.layer_0.shape.mask.size.j, ^.layer_01.shape.mask.size.j) - ^.layer_01.pos.i - ^.layer_0.pos.i
0.031	IN  SPE ^.layer_0.shape.mask.model = Full
0.031	IN  SPE ^.layer_01.shape.mask.model = Full
0.030	OUT SPE ^.layer_011.shape.mask.model = Full
0.030	OUT SPE ^.layer_0111.shape.mask.model = Full
0.030	IN  SPE ^.color = black
0.030	OUT SPE ^.color = black
0.017	
0.017	IN  GEN ^.layer_011.shape.color = ?
0.017	IN  GEN ^.layer_01.shape.mask.model = ?
0.017	IN  GEN ^.layer_0.shape.mask.model = ?
0.017	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (min(^.layer_0.pos.i, ^.layer_011.pos.i) * '3,^.layer_011.pos.i - 2)
  _01: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at min(^.layer_0.pos, ^.layer_01.pos) + translationOnto(^.layer_0, ^.layer_01)
  _011: rectangle with size (average(^.layer_0.shape.mask.size.j, ^.layer_01.shape.mask.size.j) - ^.layer_01.pos.i - ^.layer_0.pos.i,1) with model Full with color ^.layer_011.shape.color at (?,max(^.layer_01.pos.j, ^.layer_011.pos.j))
  _0111: rectangle with size (area(^.layer_011.shape) - ^.layer_0.pos.i - ^.layer_01.pos.i,?) with model Full with color red at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color cyan at (?,?)
  _011: point with color red at (?,?)

DL input  with Mi: L = 96.1 + 3122.9 = 3219.0
DL output with Mo: L = 402.6 + 3681.9 = 4084.5
DL input+output M: L = 498.7 + 6804.8 = 7303.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (min(^.layer_0.pos.i, ^.layer_011.pos.i) * '3,^.layer_011.pos.i - 2)
  _01: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at min(^.layer_0.pos, ^.layer_01.pos) + translationOnto(^.layer_0, ^.layer_01)
  _011: rectangle with size (average(^.layer_0.shape.mask.size.j, ^.layer_01.shape.mask.size.j) - ^.layer_01.pos.i - ^.layer_0.pos.i,1) with model Full with color ^.layer_011.shape.color at (?,max(^.layer_01.pos.j, ^.layer_011.pos.j))
  _0111: rectangle with size (area(^.layer_011.shape) - ^.layer_0.pos.i - ^.layer_01.pos.i,?) with model Full with color red at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color cyan at (?,?)
  _011: point with color ? at (?,?)

DL input  with Mi: L = 91.6 + 0.0 = 91.6
DL output with Mo: L = 402.6 + 3681.9 = 4084.5
DL input+output M: L = 494.2 + 3681.9 = 4176.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (2,2)
  _01: rectangle with size (1,13) with model Full with color cyan at (6,0)
  _011: point with color red at (10,8)
diff: 
   (0.0 bits)
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (6,8)
  _01: rectangle with size (3,13) with mask 
. 0 0 0 . . . 0 0 0 . . . 
0 0 . 0 0 0 0 0 . 0 0 0 0 
. 0 0 0 . . . 0 0 0 . . . 
 with color cyan at (5,0)
  _011: rectangle with size (3,1) with model Full with color red at (8,8)
  _0111: rectangle with size (5,1) with model Full with color red at (2,2)
diff: 
   (89.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (2,2)
  _01: rectangle with size (1,13) with model Full with color cyan at (6,0)
  _011: point with color red at (10,8)
diff: 
! 41 wrong pixels (generated / expected)

TRAIN ecdecbb3.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (13,18) and color black and layers
  _0: rectangle with size (13,1) with model Full with color cyan at (0,3)
  _01: rectangle with size (13,1) with model Full with color cyan at (0,14)
  _011: point with color red at (4,8)
diff: 
   (0.0 bits)
data: a background with size (13,18) and color black and layers
  _0: rectangle with size (13,3) with mask 
. 0 . 
. 0 . 
. 0 . 
0 0 0 
0 . 0 
0 0 0 
. 0 . 
. 0 . 
. 0 . 
. 0 . 
. 0 . 
. 0 . 
. 0 . 
 with color cyan at (0,2)
  _01: rectangle with size (13,3) with mask 
. 0 . 
. 0 . 
. 0 . 
0 0 0 
0 . 0 
0 0 0 
. 0 . 
. 0 . 
. 0 . 
. 0 . 
. 0 . 
. 0 . 
. 0 . 
 with color cyan at (0,13)
  _011: rectangle with size (1,1) with model Full with color red at (4,14)
  _0111: rectangle with size (1,10) with model Full with color red at (4,3)
diff: 
   (146.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,18) and color black and layers
  _0: rectangle with size (13,1) with model Full with color cyan at (0,3)
  _01: rectangle with size (13,1) with model Full with color cyan at (0,14)
  _011: point with color red at (4,8)
diff: 
! 48 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,18) and color black and layers
  _0: rectangle with size (13,1) with model Full with color cyan at (0,14)
  _01: rectangle with size (13,1) with model Full with color cyan at (0,3)
  _011: point with color red at (4,8)
diff: 
! 49 wrong pixels (generated / expected)

TRAIN ecdecbb3.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (17,12) and color black and layers
  _0: rectangle with size (1,12) with model Full with color cyan at (7,0)
  _01: rectangle with size (1,12) with model Full with color cyan at (13,0)
  _011: point with color red at (2,8)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (17,12) and color black and layers
  _0: rectangle with size (3,12) with mask 
. . . 0 0 0 . 0 0 0 . . 
0 0 0 0 . 0 0 0 . 0 0 0 
. . . 0 0 0 . 0 0 0 . . 
 with color cyan at (6,0)
  _01: rectangle with size (3,12) with mask 
. . . 0 0 0 . . . . . . 
0 0 0 0 . 0 0 0 0 0 0 0 
. . . 0 0 0 . . . . . . 
 with color cyan at (12,0)
  _011: rectangle with size (6,1) with model Full with color red at (2,8)
  _0111: rectangle with size (7,1) with model Full with color red at (7,4)
diff: 
   (132.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,12) and color black and layers
  _0: rectangle with size (1,12) with model Full with color cyan at (7,0)
  _01: rectangle with size (1,12) with model Full with color cyan at (13,0)
  _011: point with color red at (2,8)
  + 1 delta pixels
diff: 
! 59 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,12) and color black and layers
  _0: rectangle with size (1,12) with model Full with color cyan at (7,0)
  _01: rectangle with size (1,12) with model Full with color cyan at (13,0)
  _011: point with color red at (10,4)
  + 1 delta pixels
diff: 
! 69 wrong pixels (generated / expected)

TRAIN ecdecbb3.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,19) and color black and layers
  _0: rectangle with size (17,1) with model Full with color cyan at (0,4)
  _01: rectangle with size (17,1) with model Full with color cyan at (0,12)
  _011: point with color red at (1,15)
  + 3 delta pixels
diff: 
! 77 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,19) and color black and layers
  _0: rectangle with size (17,1) with model Full with color cyan at (0,4)
  _01: rectangle with size (17,1) with model Full with color cyan at (0,12)
  _011: point with color red at (2,1)
  + 3 delta pixels
diff: 
! 77 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (17,19) and color black and layers
  _0: rectangle with size (17,1) with model Full with color cyan at (0,12)
  _01: rectangle with size (17,1) with model Full with color cyan at (0,4)
  _011: point with color red at (1,15)
  + 3 delta pixels
diff: 
! 80 wrong pixels (generated / expected)

TEST ecdecbb3.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 21.2 sec (21.2 sec/task)
bits-train-error = 3681.9 bits (3681.9 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-21] Checking task ed36ccf7.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 14046.4 = 14048.7
DL output with Mo: L = 2.3 + 14046.4 = 14048.7
DL input+output M: L = 4.6 + 28092.8 = 28097.5

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = applySym(rotate270, ^)
0.436	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.150	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.134	IN  SPE ^.layer_0.shape.color = black
0.004	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
applySym(rotate270, ^)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color black at (?,?)

DL input  with Mi: L = 45.4 + 1820.3 = 1865.7
DL output with Mo: L = 12.3 + 0.0 = 12.3
DL input+output M: L = 57.8 + 1820.3 = 1878.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
applySym(rotate270, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 12.3 + 0.0 = 12.3
DL input+output M: L = 14.6 + 0.0 = 14.6

# train input/output grids

## instance 1

> Input and output best reading:

data: 
9#0 0 
9#9#9#
9#9#9#

diff: 
   (0.0 bits)
data: 
0 9#9#
0 9#9#
9#9#9#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
9#0 0 
9#9#9#
9#9#9#

diff: 
correct output grid

TRAIN ed36ccf7.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
6 6 6 
0 0 0 
6 6 0 

diff: 
   (0.0 bits)
data: 
6 0 0 
6 0 6 
6 0 6 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
6 6 6 
0 0 0 
6 6 0 

diff: 
correct output grid

TRAIN ed36ccf7.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 0 9#
0 0 9#
9#9#9#

diff: 
   (0.0 bits)
data: 
9#9#9#
0 0 9#
0 0 9#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 9#
0 0 9#
9#9#9#

diff: 
correct output grid

TRAIN ed36ccf7.json/3: 1 1st (SUCCESS)

## instance 4

> Input and output best reading:

data: 
2 0 2 
0 0 2 
0 2 2 

diff: 
   (0.0 bits)
data: 
2 2 2 
0 0 2 
2 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 0 2 
0 0 2 
0 2 2 

diff: 
correct output grid

TRAIN ed36ccf7.json/4: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 
5#0 0 
0 5#5#

diff: 
correct output grid

TEST ed36ccf7.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 0.6 sec (0.6 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-20] Checking task ef135b50.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.369	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.820	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.612	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.498	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.383	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.312	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.257	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.235	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.230	OUT SPE ^.size = ^.size
0.229	OUT SPE ^.layer_01111.shape.color = brown
0.227	OUT SPE ^.layer_01.pos.i = 2
0.226	OUT SPE ^.layer_0.pos.j = ^.layer_0.pos.i
0.225	OUT SPE ^.layer_011.pos.i = ^.layer_0.pos.i * '2
0.224	OUT SPE ^.layer_01111.pos.i = ^.layer_0.pos.i + 3
0.223	OUT SPE ^.layer_0.shape.mask.model = Full
0.222	OUT SPE ^.layer_0111.shape.mask.model = Full
0.222	OUT SPE ^.layer_01111.shape.mask.model = Full
0.062	

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,^.layer_0.pos.i)
  _01: rectangle with size (?,?) with model ? with color ? at (2,?)
  _011: rectangle with size (?,?) with model ? with color ? at (^.layer_0.pos.i * '2,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color brown at (^.layer_0.pos.i + 3,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 19184.9 = 19226.9
DL output with Mo: L = 213.4 + 7114.7 = 7328.1
DL input+output M: L = 255.4 + 26299.7 = 26555.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _0: rectangle with size (?,?) with model Full with color ? at (?,^.layer_0.pos.i)
  _01: rectangle with size (?,?) with model ? with color ? at (2,?)
  _011: rectangle with size (?,?) with model ? with color ? at (^.layer_0.pos.i * '2,?)
  _0111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01111: rectangle with size (?,?) with model Full with color brown at (^.layer_0.pos.i + 3,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 213.4 + 7114.7 = 7328.1
DL input+output M: L = 255.4 + 7114.7 = 7370.1

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,2) with model Full with color red at (3,7)
  + 17 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,4) with model Full with color brown at (3,3)
  _01: rectangle with size (3,3) with model Full with color red at (2,0)
  _011: rectangle with size (4,2) with model Full with color red at (6,3)
  _0111: rectangle with size (5,2) with model Full with color red at (3,7)
  _01111: rectangle with size (2,2) with model Full with color brown at (6,5)
diff: 
   (126.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,2) with model Full with color red at (3,7)
  + 17 delta pixels
diff: 
! 51 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,3) with model Full with color red at (2,0)
  + 18 delta pixels
diff: 
! 51 wrong pixels (generated / expected)

TRAIN ef135b50.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,3) with model Full with color red at (2,7)
  + 24 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color red and layers
  _0: rectangle with size (2,8) with model Full with color black at (0,2)
  _01: rectangle with size (2,5) with model Full with color brown at (2,2)
  _011: rectangle with size (6,7) with mask 
0 0 0 0 0 0 0 
0 0 0 . . . . 
0 0 0 . . . . 
0 0 0 . . . . 
0 0 0 . . . . 
0 0 0 0 0 0 . 
 with color black at (4,0)
  _0111: rectangle with size (2,5) with model Full with color black at (6,5)
  _01111: rectangle with size (1,2) with model Full with color brown at (5,5)
  + 1 delta pixels
diff: 
   (221.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,3) with model Full with color red at (2,7)
  + 24 delta pixels
diff: 
! 59 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,2) with model Full with color red at (0,0)
  + 28 delta pixels
diff: 
! 51 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,2) with model Full with color red at (5,3)
  + 28 delta pixels
diff: 
! 57 wrong pixels (generated / expected)

TRAIN ef135b50.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color red and layers
  _0: rectangle with size (10,10) with mask 
0 0 0 0 0 0 . . . . 
. . . . 0 0 . . . . 
. . . . 0 0 0 0 0 0 
. . . . 0 . . . 0 0 
0 0 0 0 0 . . . 0 0 
0 0 0 0 0 . . . 0 0 
0 0 0 0 0 . . . 0 . 
. . . . 0 . . . 0 . 
. . . . 0 . . . 0 . 
. . . . 0 0 0 0 0 . 
 with color black at (0,0)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color red and layers
  _0: rectangle with size (3,5) with model Full with color black at (4,0)
  _01: rectangle with size (4,6) with mask 
0 0 0 0 0 0 
. . . . 0 0 
. . . . 0 0 
. . . . 0 0 
 with color black at (2,4)
  _011: rectangle with size (1,6) with model Full with color black at (0,0)
  _0111: rectangle with size (1,5) with model Full with color black at (9,4)
  _01111: rectangle with size (6,1) with model Full with color brown at (3,4)
  + 5 delta pixels
diff: 
   (363.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color red and layers
  _0: rectangle with size (10,10) with mask 
0 0 0 0 0 0 . . . . 
. . . . 0 0 . . . . 
. . . . 0 0 0 0 0 0 
. . . . 0 . . . 0 0 
0 0 0 0 0 . . . 0 0 
0 0 0 0 0 . . . 0 0 
0 0 0 0 0 . . . 0 . 
. . . . 0 . . . 0 . 
. . . . 0 . . . 0 . 
. . . . 0 0 0 0 0 . 
 with color black at (0,0)
diff: 
! 66 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color red and layers
  _0: rectangle with size (3,5) with model Full with color black at (4,0)
  + 31 delta pixels
diff: 
! 66 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,3) with model Full with color red at (3,5)
  + 36 delta pixels
diff: 
! 68 wrong pixels (generated / expected)

TRAIN ef135b50.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (5,3) with model Full with color red at (3,1)
  + 26 delta pixels
diff: 
! 55 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (3,4) with model Full with color red at (1,6)
  + 29 delta pixels
diff: 
! 53 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (2,4) with model Full with color red at (5,5)
  + 33 delta pixels
diff: 
! 57 wrong pixels (generated / expected)

TEST ef135b50.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 31.8 sec (31.8 sec/task)
bits-train-error = 7114.7 bits (7114.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-19] Checking task f15e1fac.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 197693.5 = 197695.8
DL output with Mo: L = 2.3 + 197693.5 = 197695.8
DL input+output M: L = 4.6 + 395387.0 = 395391.7

# learning a model for train pairs
2.000	
1.037	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.320	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.178	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.107	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.085	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.082	OUT ADD ^.layer_0111 = point with color ? at (?,?)
0.078	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.075	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.071	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.068	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.064	IN  ADD ^.layer_01111 = point with color ? at (?,?)
0.061	OUT SPE ^.size = ^.size
0.058	OUT SPE ^.layer_0111 = ^.layer_0111
0.057	IN  SPE ^.layer_0111.shape.color = red
0.057	OUT SPE ^.layer_0.pos.i = '0
0.056	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.055	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.054	IN  SPE ^.layer_0.shape.color = cyan
0.053	IN  SPE ^.layer_01.shape.color = cyan
0.052	IN  SPE ^.layer_01111.shape.color = red
0.051	OUT SPE ^.layer_01.pos.i = average(^.layer_0.pos.i, ^.layer_01.pos.i)
0.051	OUT SPE ^.layer_011.pos.j = min(^.layer_011.pos.j, ^.layer_0111.pos.j)
0.050	OUT SPE ^.layer_011.pos.i = ^.layer_01111.pos.i - ^.layer_01.pos.i - ^.layer_0.pos.i
0.049	OUT SPE ^.layer_0.pos = projJ(^.layer_01.pos) + translationSym(flipWidth, ^.layer_011, ^.layer_01)
0.049	IN  SPE ^.color = black
0.049	OUT SPE ^.color = black
0.033	
0.033	IN  GEN ^.layer_01.shape.color = ?
0.033	IN  GEN ^.layer_0.shape.color = ?
0.033	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at projJ(^.layer_01.pos) + translationSym(flipWidth, ^.layer_011, ^.layer_01)
  _01: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at (average(^.layer_0.pos.i, ^.layer_01.pos.i),?)
  _011: rectangle with size (?,?) with model ? with color ? at (^.layer_01111.pos.i - ^.layer_01.pos.i - ^.layer_0.pos.i,min(^.layer_011.pos.j, ^.layer_0111.pos.j))
  _0111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color cyan at (?,?)
  _01: point with color cyan at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color red at (?,?)
  _01111: point with color red at (?,?)

DL input  with Mi: L = 117.7 + 3028.3 = 3146.0
DL output with Mo: L = 250.2 + 6225.2 = 6475.4
DL input+output M: L = 368.0 + 9253.5 = 9621.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at projJ(^.layer_01.pos) + translationSym(flipWidth, ^.layer_011, ^.layer_01)
  _01: rectangle with size (?,?) with model ? with color ^.layer_01.shape.color at (average(^.layer_0.pos.i, ^.layer_01.pos.i),?)
  _011: rectangle with size (?,?) with model ? with color ? at (^.layer_01111.pos.i - ^.layer_01.pos.i - ^.layer_0.pos.i,min(^.layer_011.pos.j, ^.layer_0111.pos.j))
  _0111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color red at (?,?)
  _01111: point with color red at (?,?)

DL input  with Mi: L = 111.0 + 0.0 = 111.0
DL output with Mo: L = 250.2 + 6225.2 = 6475.4
DL input+output M: L = 361.2 + 6225.2 = 6586.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (17,12) and color black and layers
  _0: point with color cyan at (0,1)
  _01: point with color cyan at (0,5)
  _011: point with color cyan at (0,7)
  _0111: point with color red at (4,0)
  _01111: point with color red at (10,0)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (17,12) and color black and layers
  _0: rectangle with size (17,3) with mask 
0 . . 
0 . . 
0 . . 
0 . . 
. 0 . 
. 0 . 
. 0 . 
. 0 . 
. 0 . 
. 0 . 
. . 0 
. . 0 
. . 0 
. . 0 
. . 0 
. . 0 
. . 0 
 with color cyan at (0,1)
  _01: rectangle with size (17,7) with mask 
0 . 0 . 0 . . 
0 . 0 . 0 . . 
0 . 0 . 0 . . 
0 . 0 . 0 . . 
. 0 . 0 . 0 . 
. 0 . 0 . 0 . 
. 0 . 0 . 0 . 
. 0 . 0 . 0 . 
. 0 . 0 . 0 . 
. 0 . 0 . 0 . 
. . 0 . 0 . 0 
. . 0 . 0 . 0 
. . 0 . 0 . 0 
. . 0 . 0 . 0 
. . 0 . 0 . 0 
. . 0 . 0 . 0 
. . 0 . 0 . 0 
 with color cyan at (0,5)
  _011: rectangle with size (1,1) with model Full with color red at (10,0)
  _0111: 
2 
 at (4,0)
diff: 
   (230.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,12) and color black and layers
  _0: point with color cyan at (0,1)
  _01: point with color cyan at (0,5)
  _011: point with color cyan at (0,7)
  _0111: point with color red at (4,0)
  _01111: point with color red at (10,0)
  + 1 delta pixels
diff: 
! 74 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,12) and color black and layers
  _0: point with color cyan at (0,1)
  _01: point with color cyan at (0,5)
  _011: point with color cyan at (0,7)
  _0111: point with color red at (10,0)
  _01111: point with color red at (4,0)
  + 1 delta pixels
diff: 
! 74 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (17,12) and color black and layers
  _0: point with color cyan at (0,1)
  _01: point with color cyan at (0,5)
  _011: point with color cyan at (0,9)
  _0111: point with color red at (4,0)
  _01111: point with color red at (10,0)
  + 1 delta pixels
diff: 
! 72 wrong pixels (generated / expected)

TRAIN f15e1fac.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (14,10) and color black and layers
  _0: point with color cyan at (0,2)
  _01: point with color cyan at (0,6)
  _011: point with color red at (3,9)
  _0111: point with color red at (7,9)
  _01111: point with color red at (11,9)
diff: 
   (0.0 bits)
data: a background with size (14,10) and color black and layers
  _0: rectangle with size (11,3) with mask 
. . 0 
. . 0 
. . 0 
. 0 . 
. 0 . 
. 0 . 
. 0 . 
0 . . 
0 . . 
0 . . 
0 . . 
 with color cyan at (0,0)
  _01: rectangle with size (14,4) with mask 
. . . 0 
. . . 0 
. . . 0 
. . 0 . 
. . 0 . 
. . 0 . 
. . 0 . 
. 0 . . 
. 0 . . 
. 0 . . 
. 0 . . 
0 . . . 
0 . . . 
0 . . . 
 with color cyan at (0,3)
  _011: rectangle with size (1,1) with model Full with color red at (11,9)
  _0111: 
2 
 at (7,9)
  + 1 delta pixels
diff: 
   (179.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,10) and color black and layers
  _0: point with color cyan at (0,2)
  _01: point with color cyan at (0,6)
  _011: point with color red at (3,9)
  _0111: point with color red at (7,9)
  _01111: point with color red at (11,9)
diff: 
! 32 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,10) and color black and layers
  _0: point with color cyan at (0,2)
  _01: point with color cyan at (0,6)
  _011: point with color red at (3,9)
  _0111: point with color red at (11,9)
  _01111: point with color red at (7,9)
diff: 
! 32 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (14,10) and color black and layers
  _0: point with color cyan at (0,2)
  _01: point with color cyan at (0,6)
  _011: point with color red at (7,9)
  _0111: point with color red at (3,9)
  _01111: point with color red at (11,9)
diff: 
! 32 wrong pixels (generated / expected)

TRAIN f15e1fac.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: point with color cyan at (2,0)
  _01: point with color cyan at (6,0)
  _011: point with color cyan at (9,0)
  _0111: point with color red at (11,4)
  _01111: point with color red at (11,8)
diff: 
   (0.0 bits)
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (3,12) with mask 
. . . . . . . . 0 0 0 0 
. . . . 0 0 0 0 . . . . 
0 0 0 0 . . . . . . . . 
 with color cyan at (0,0)
  _01: rectangle with size (3,12) with mask 
. . . . . . . . 0 0 0 0 
. . . . 0 0 0 0 . . . . 
0 0 0 0 . . . . . . . . 
 with color cyan at (4,0)
  _011: rectangle with size (3,12) with mask 
. . . . . . . . 0 0 0 0 
. . . . 0 0 0 0 . . . . 
0 0 0 0 . . . . . . . . 
 with color cyan at (7,0)
  _0111: 
2 
 at (11,4)
  + 1 delta pixels
diff: 
   (212.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: point with color cyan at (2,0)
  _01: point with color cyan at (6,0)
  _011: point with color cyan at (9,0)
  _0111: point with color red at (11,4)
  _01111: point with color red at (11,8)
diff: 
! 49 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: point with color cyan at (2,0)
  _01: point with color cyan at (6,0)
  _011: point with color cyan at (9,0)
  _0111: point with color red at (11,8)
  _01111: point with color red at (11,4)
diff: 
! 49 wrong pixels (generated / expected)

TRAIN f15e1fac.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
undefined expression: Average: not an integer

TEST f15e1fac.json/1: 0 - (ERROR)

# Performance measures on task
runtime-learning = 58.7 sec (58.7 sec/task)
bits-train-error = 6225.2 bits (6225.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-18] Checking task f1cefba8.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 324660.3 = 324662.6
DL output with Mo: L = 2.3 + 324660.3 = 324662.6
DL input+output M: L = 4.6 + 649320.6 = 649325.2

# learning a model for train pairs
2.000	
1.486	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.011	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.683	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.414	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.212	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.128	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.093	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.072	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.055	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.039	
0.039	IN  GEN ^ = ?
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 5008.9 = 5079.2
DL output with Mo: L = 153.4 + 12538.5 = 12691.8
DL input+output M: L = 223.6 + 17547.4 = 17771.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 153.4 + 12538.5 = 12691.8
DL input+output M: L = 155.7 + 12538.5 = 12694.2

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 8 8 8 8 8 8 8 8 8 8 8 0 
0 8 8 8 8 8 8 2 8 8 8 8 0 
0 8 8 2 2 2 2 2 2 2 8 8 0 
0 8 8 2 2 2 2 2 2 2 8 8 0 
0 8 8 2 2 2 2 2 2 2 2 8 0 
0 8 8 2 2 2 2 2 2 2 8 8 0 
0 8 8 2 2 2 2 2 2 2 8 8 0 
0 8 8 2 2 2 2 2 2 2 8 8 0 
0 8 8 2 2 2 2 2 2 2 8 8 0 
0 8 8 2 2 2 2 2 2 2 8 8 0 
0 8 8 2 2 2 2 2 2 2 8 8 0 
0 8 8 8 2 8 8 8 8 8 8 8 0 
0 8 8 8 8 8 8 8 8 8 8 8 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (19,13) and color black and layers
  _0: rectangle with size (13,11) with mask 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 . 0 . . 0 . . 0 0 
0 0 . 0 . . 0 . . 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 . 0 . . 0 . . 0 0 
0 0 . 0 . . 0 . . 0 0 
0 0 . 0 . . 0 . . 0 0 
0 0 . 0 . . 0 . . 0 0 
0 0 . 0 . . 0 . . 0 0 
0 0 . 0 . . 0 . . 0 0 
0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 
 with color cyan at (2,1)
  _01: rectangle with size (6,7) with model Full with color red at (7,3)
  _011: rectangle with size (2,7) with model Full with color red at (4,3)
  _0111: rectangle with size (19,1) with model Full with color red at (0,4)
  _01111: rectangle with size (19,1) with model Full with color red at (0,7)
  + 2 delta pixels
diff: 
   (421.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 8 8 8 8 8 8 8 8 8 8 8 0 
0 8 8 8 8 8 8 2 8 8 8 8 0 
0 8 8 2 2 2 2 2 2 2 8 8 0 
0 8 8 2 2 2 2 2 2 2 8 8 0 
0 8 8 2 2 2 2 2 2 2 2 8 0 
0 8 8 2 2 2 2 2 2 2 8 8 0 
0 8 8 2 2 2 2 2 2 2 8 8 0 
0 8 8 2 2 2 2 2 2 2 8 8 0 
0 8 8 2 2 2 2 2 2 2 8 8 0 
0 8 8 2 2 2 2 2 2 2 8 8 0 
0 8 8 2 2 2 2 2 2 2 8 8 0 
0 8 8 8 2 8 8 8 8 8 8 8 0 
0 8 8 8 8 8 8 8 8 8 8 8 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
! size mismatch, 10x10 instead of 19x13

TRAIN f1cefba8.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 
0 0 1 1 1 1 4 1 1 1 1 1 1 1 0 0 0 
0 0 1 1 4 4 4 4 4 4 4 4 1 1 0 0 0 
0 0 1 1 4 4 4 4 4 4 4 4 4 1 0 0 0 
0 0 1 1 4 4 4 4 4 4 4 4 1 1 0 0 0 
0 0 1 1 4 4 4 4 4 4 4 4 1 1 0 0 0 
0 0 1 1 1 1 1 1 4 1 1 1 1 1 0 0 0 
0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (15,17) and color black and layers
  _0: rectangle with size (8,12) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . 0 . 0 . . . 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . 0 . 0 . . . 0 0 
0 0 . . 0 . 0 . . . 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color blue at (4,2)
  _01: rectangle with size (2,8) with model Full with color yellow at (8,4)
  _011: rectangle with size (15,1) with model Full with color yellow at (0,6)
  _0111: rectangle with size (15,1) with model Full with color yellow at (0,8)
  _01111: rectangle with size (1,8) with model Full with color yellow at (6,4)
  + 5 delta pixels
diff: 
   (483.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 
0 0 1 1 1 1 4 1 1 1 1 1 1 1 0 0 0 
0 0 1 1 4 4 4 4 4 4 4 4 1 1 0 0 0 
0 0 1 1 4 4 4 4 4 4 4 4 4 1 0 0 0 
0 0 1 1 4 4 4 4 4 4 4 4 1 1 0 0 0 
0 0 1 1 4 4 4 4 4 4 4 4 1 1 0 0 0 
0 0 1 1 1 1 1 1 4 1 1 1 1 1 0 0 0 
0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
! size mismatch, 10x10 instead of 15x17

TRAIN f1cefba8.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 0 
0 0 0 0 2 2 2 2 2 2 2 3 2 2 2 2 0 0 
0 0 0 0 2 2 3 3 3 3 3 3 3 3 2 2 0 0 
0 0 0 0 2 2 3 3 3 3 3 3 3 3 2 2 0 0 
0 0 0 0 2 2 3 3 3 3 3 3 3 3 2 2 0 0 
0 0 0 0 2 3 3 3 3 3 3 3 3 3 2 2 0 0 
0 0 0 0 2 2 3 3 3 3 3 3 3 3 2 2 0 0 
0 0 0 0 2 2 3 3 3 3 3 3 3 3 2 2 0 0 
0 0 0 0 2 2 3 3 3 3 3 3 3 3 2 2 0 0 
0 0 0 0 2 2 3 3 3 3 3 3 3 3 2 2 0 0 
0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 0 
0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (16,18) and color black and layers
  _0: rectangle with size (12,12) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . 0 . . 0 0 
0 0 . . . . . 0 . . 0 0 
0 0 . . . . . 0 . . 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 . . . . . 0 . . 0 0 
0 0 . . . . . 0 . . 0 0 
0 0 . . . . . 0 . . 0 0 
0 0 . . . . . 0 . . 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color red at (3,4)
  _01: rectangle with size (8,5) with model Full with color green at (5,6)
  _011: rectangle with size (8,2) with model Full with color green at (5,12)
  _0111: rectangle with size (1,18) with model Full with color green at (8,0)
  _01111: rectangle with size (16,1) with model Full with color green at (0,11)
diff: 
   (348.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 0 
0 0 0 0 2 2 2 2 2 2 2 3 2 2 2 2 0 0 
0 0 0 0 2 2 3 3 3 3 3 3 3 3 2 2 0 0 
0 0 0 0 2 2 3 3 3 3 3 3 3 3 2 2 0 0 
0 0 0 0 2 2 3 3 3 3 3 3 3 3 2 2 0 0 
0 0 0 0 2 3 3 3 3 3 3 3 3 3 2 2 0 0 
0 0 0 0 2 2 3 3 3 3 3 3 3 3 2 2 0 0 
0 0 0 0 2 2 3 3 3 3 3 3 3 3 2 2 0 0 
0 0 0 0 2 2 3 3 3 3 3 3 3 3 2 2 0 0 
0 0 0 0 2 2 3 3 3 3 3 3 3 3 2 2 0 0 
0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 0 
0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
! size mismatch, 10x10 instead of 16x18

TRAIN f1cefba8.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 
0 1 1 1 1 1 8 1 1 1 8 1 1 1 1 0 0 0 
0 1 1 8 8 8 8 8 8 8 8 8 8 1 1 0 0 0 
0 1 1 8 8 8 8 8 8 8 8 8 8 1 1 0 0 0 
0 1 1 8 8 8 8 8 8 8 8 8 8 1 1 0 0 0 
0 1 1 8 8 8 8 8 8 8 8 8 8 1 1 0 0 0 
0 1 8 8 8 8 8 8 8 8 8 8 8 1 1 0 0 0 
0 1 1 8 8 8 8 8 8 8 8 8 8 1 1 0 0 0 
0 1 1 8 8 8 8 8 8 8 8 8 8 1 1 0 0 0 
0 1 1 8 8 8 8 8 8 8 8 8 8 1 1 0 0 0 
0 1 1 8 8 8 8 8 8 8 8 8 8 1 1 0 0 0 
0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 
0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 

diff: 
! size mismatch, 10x10 instead of 19x18

TEST f1cefba8.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.8 sec (59.8 sec/task)
bits-train-error = 12538.5 bits (12538.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-17] Checking task f25fbde4.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 96473.4 = 96475.7
DL output with Mo: L = 2.3 + 51689.5 = 51691.9
DL input+output M: L = 4.6 + 148163.0 = 148167.6

# learning a model for train pairs
2.000	
1.000	OUT SPE ^ = strip(^) * '2
0.082	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.020	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.019	IN  SPE ^.layer_0.shape.color = yellow
0.018	IN  SPE ^.color = black
0.001	
0.000	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
strip(^) * '2
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color yellow at (?,?)

DL input  with Mi: L = 45.4 + 1632.0 = 1677.4
DL output with Mo: L = 24.5 + 0.0 = 24.5
DL input+output M: L = 69.9 + 1632.0 = 1701.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
strip(^) * '2
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 24.5 + 0.0 = 24.5
DL input+output M: L = 26.8 + 0.0 = 26.8

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 4 4 0 0 0 0 0 
0 4 4 4 4 0 0 0 0 
0 0 4 4 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
0 0 4 4 4 4 0 0 
0 0 4 4 4 4 0 0 
4 4 4 4 4 4 4 4 
4 4 4 4 4 4 4 4 
0 0 4 4 4 4 0 0 
0 0 4 4 4 4 0 0 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 4 4 0 0 0 0 0 
0 4 4 4 4 0 0 0 0 
0 0 4 4 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN f25fbde4.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 4 0 0 0 0 
0 0 0 4 4 0 0 0 0 
0 0 0 0 0 4 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
0 0 4 4 0 0 
0 0 4 4 0 0 
4 4 4 4 0 0 
4 4 4 4 0 0 
0 0 0 0 4 4 
0 0 0 0 4 4 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 4 0 0 0 0 
0 0 0 4 4 0 0 0 0 
0 0 0 0 0 4 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN f25fbde4.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 4 0 0 0 0 0 0 
0 4 4 0 0 0 0 0 0 
0 0 4 0 0 0 0 0 0 
0 0 4 4 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: 
0 0 4 4 0 0 
0 0 4 4 0 0 
4 4 4 4 0 0 
4 4 4 4 0 0 
0 0 4 4 0 0 
0 0 4 4 0 0 
0 0 4 4 4 4 
0 0 4 4 4 4 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 4 0 0 0 0 0 0 
0 4 4 0 0 0 0 0 0 
0 0 4 0 0 0 0 0 0 
0 0 4 4 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TRAIN f25fbde4.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 0 0 
0 0 0 0 4 0 4 0 0 
0 0 0 4 0 4 0 4 0 
0 0 0 0 4 0 4 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 

diff: 
correct output grid

TEST f25fbde4.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.0 sec (1.0 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-16] Checking task f25ffba3.json: 2 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 31262.0 = 31264.3
DL output with Mo: L = 2.3 + 31262.0 = 31264.3
DL input+output M: L = 4.6 + 62524.0 = 62528.6

# learning a model for train pairs
2.000	
1.001	OUT SPE ^ = closeSym(flipHeight; , black, ^)
0.299	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.196	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.130	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.087	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.078	IN  SPE ^.layer_0.shape.mask = 
0 
0 
0 
0 
0 

0.073	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.066	IN  SPE ^.layer_011.shape.mask = 
0 
0 

0.062	IN  SPE ^.layer_01.shape.color = green
0.061	IN  SPE ^.color = black
0.004	
0.001	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
closeSym(flipHeight; , black, ^)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: 
0 
0 
0 
0 
0 
 with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color green at (?,?)
  _011: 
0 
0 
 with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 111.9 + 1768.8 = 1880.7
DL output with Mo: L = 18.1 + 0.0 = 18.1
DL input+output M: L = 130.0 + 1768.8 = 1898.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
closeSym(flipHeight; , black, ^)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 18.1 + 0.0 = 18.1
DL input+output M: L = 20.4 + 0.0 = 20.4

# train input/output grids

## instance 1

> Input and output best reading:

data: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 9#
0 0 3 9#
0 0 3 9#
2 0 3 9#
2 4 3 9#

diff: 
   (0.0 bits)
data: 
2 4 3 9#
2 0 3 9#
0 0 3 9#
0 0 3 9#
0 0 0 9#
0 0 0 9#
0 0 3 9#
0 0 3 9#
2 0 3 9#
2 4 3 9#

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 9#
0 0 3 9#
0 0 3 9#
2 0 3 9#
2 4 3 9#

diff: 
correct output grid

TRAIN f25ffba3.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 2 
0 0 0 2 
0 8 0 2 
0 3 8 2 
3 3 8 2 

diff: 
   (0.0 bits)
data: 
3 3 8 2 
0 3 8 2 
0 8 0 2 
0 0 0 2 
0 0 0 2 
0 0 0 2 
0 0 0 2 
0 8 0 2 
0 3 8 2 
3 3 8 2 

diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 2 
0 0 0 2 
0 8 0 2 
0 3 8 2 
3 3 8 2 

diff: 
correct output grid

TRAIN f25ffba3.json/2: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 1 0 0 
7#1 0 0 
7#1 3 0 
7#1 3 3 
7#1 4 4 

diff: 
correct output grid

TEST f25ffba3.json/1: 1 1st (SUCCESS)

# Performance measures on task
runtime-learning = 1.5 sec (1.5 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 1.00 tasks (100.00%)
acc-test-macro = 1.00 tasks (100.00%)
acc-test-mrr = 1.00

=====================================
[-15] Checking task f2829549.json: 5 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 54413.2 = 54415.5
DL output with Mo: L = 2.3 + 23293.6 = 23295.9
DL input+output M: L = 4.6 + 77706.8 = 77711.4

# learning a model for train pairs
2.000	
1.342	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.880	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.664	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.503	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.381	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.287	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.258	OUT SPE ^.size = projI(^.size) + (0, 3)
0.246	IN  SPE ^.layer_01.shape.mask = 
0 
0 
0 
0 

0.234	OUT SPE ^.layer_0.shape.color = green
0.227	OUT SPE ^.layer_0.pos.j = max(^.layer_0.pos.j, ^.layer_01.pos.j) - 3
0.222	OUT SPE ^.color = black
0.217	IN  SPE ^.layer_01.shape.color = blue
0.214	IN  SPE ^.color = black
0.213	OUT SPE ^.layer_0.pos.i = ^.layer_011.pos.j / '2
0.206	IN  ADD ^.layer_0110 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.204	IN  SPE ^.layer_011.shape.mask.model = Full
0.201	OUT SPE ^.layer_0.shape.mask.size.i = ^.layer_011.shape.mask.size.i + area(^.layer_011.shape)
0.058	
0.058	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size projI(^.size) + (0, 3) and color black and layers
  _0: rectangle with size (^.layer_011.shape.mask.size.i + area(^.layer_011.shape),?) with model ? with color green at (^.layer_011.pos.j / '2,max(^.layer_0.pos.j, ^.layer_01.pos.j) - 3)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: 
0 
0 
0 
0 
 with color blue at (?,?)
  _0110: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 126.8 + 7810.6 = 7937.4
DL output with Mo: L = 176.8 + 1099.3 = 1276.1
DL input+output M: L = 303.6 + 8909.9 = 9213.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size projI(^.size) + (0, 3) and color black and layers
  _0: rectangle with size (^.layer_011.shape.mask.size.i + area(^.layer_011.shape),?) with model ? with color green at (^.layer_011.pos.j / '2,max(^.layer_0.pos.j, ^.layer_01.pos.j) - 3)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: 
0 
0 
0 
0 
 with color blue at (?,?)
  _0110: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model Full with color ? at (?,?)

DL input  with Mi: L = 126.7 + 31.7 = 158.4
DL output with Mo: L = 176.8 + 1099.3 = 1276.1
DL input+output M: L = 303.5 + 1131.0 = 1434.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (4,7) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 . . 
0 . . 
0 . 0 
0 0 . 
 with color grey at (0,4)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (1,2) with model Full with color orange at (0,0)
  _011: rectangle with size (2,1) with model Full with color orange at (0,0)
diff: 
   (0.0 bits)
data: a background with size (4,3) and color black and layers
  _0: rectangle with size (4,2) with mask 
. 0 
0 0 
0 . 
. 0 
 with color green at (0,1)
diff: 
   (14.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,7) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 . . 
0 . . 
0 . 0 
0 0 . 
 with color grey at (0,4)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (1,2) with model Full with color orange at (0,0)
  _011: rectangle with size (2,1) with model Full with color orange at (0,0)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,7) and color black and layers
  _0: rectangle with size (4,3) with mask 
0 . . 
0 . . 
0 . 0 
0 0 . 
 with color grey at (0,4)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (2,1) with model Full with color orange at (0,0)
  _011: rectangle with size (1,2) with model Full with color orange at (0,0)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (4,7) and color black and layers
  _0: rectangle with size (1,2) with model Full with color orange at (0,0)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (4,3) with mask 
0 . . 
0 . . 
0 . 0 
0 0 . 
 with color grey at (0,4)
  _011: rectangle with size (2,1) with model Full with color orange at (0,0)
diff: 
! 9 wrong pixels (generated / expected)

TRAIN f2829549.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (4,7) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 . 
. 0 0 
 with color orange at (2,0)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color grey at (2,4)
  _011: rectangle with size (1,2) with model Full with color orange at (0,0)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. . 0 
 with color green at (0,0)
diff: 
   (17.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,7) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 . 
. 0 0 
 with color orange at (2,0)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color grey at (2,4)
  _011: rectangle with size (1,2) with model Full with color orange at (0,0)
  + 1 delta pixels
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,7) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 . 
. 0 0 
 with color orange at (2,0)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (2,2) with mask 
0 . 
0 0 
 with color grey at (2,4)
  _011: rectangle with size (1,1) with model Full with color grey at (0,4)
  + 2 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN f2829549.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (4,7) and color black and layers
  _0: rectangle with size (4,2) with mask 
0 0 
. 0 
0 . 
. 0 
 with color orange at (0,1)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (1,2) with model Full with color grey at (1,5)
  _011: rectangle with size (1,1) with model Full with color grey at (0,4)
  + 2 delta pixels
diff: 
   (3.2 bits)
data: a background with size (4,3) and color black and layers
  _0: rectangle with size (2,3) with mask 
. . 0 
0 0 . 
 with color green at (2,0)
  + 1 delta pixels
diff: 
   (52.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,7) and color black and layers
  _0: rectangle with size (4,2) with mask 
0 0 
. 0 
0 . 
. 0 
 with color orange at (0,1)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (1,2) with model Full with color grey at (1,5)
  _011: rectangle with size (1,2) with model Full with color grey at (2,4)
  + 1 delta pixels
diff: 
! 4 wrong pixels (generated / expected)

TRAIN f2829549.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (4,7) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 . 
. 0 . 
 with color orange at (0,0)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (2,3) with mask 
0 0 . 
0 0 0 
 with color grey at (0,4)
  _011: rectangle with size (1,1) with model Full with color grey at (3,4)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,3) and color black and layers
  _0: rectangle with size (2,3) with model Even Checkboard with color green at (2,0)
diff: 
   (13.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,7) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 . 
. 0 . 
 with color orange at (0,0)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (2,3) with mask 
0 0 . 
0 0 0 
 with color grey at (0,4)
  _011: rectangle with size (1,1) with model Full with color grey at (3,4)
  + 1 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,7) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
0 0 . 
. 0 . 
 with color orange at (0,0)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (2,3) with mask 
0 0 . 
0 0 0 
 with color grey at (0,4)
  _011: rectangle with size (1,1) with model Full with color grey at (3,6)
  + 1 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (4,7) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 . 
0 0 0 
 with color grey at (0,4)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (3,3) with mask 
0 . 0 
0 0 . 
. 0 . 
 with color orange at (0,0)
  _011: rectangle with size (1,1) with model Full with color grey at (3,4)
  + 1 delta pixels
diff: 
! 3 wrong pixels (generated / expected)

TRAIN f2829549.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: a background with size (4,7) and color black and layers
  _0: rectangle with size (4,3) with mask 
. 0 . 
0 . . 
0 0 0 
0 0 0 
 with color grey at (0,4)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (1,3) with model Full with color orange at (3,0)
  _011: rectangle with size (1,1) with model Full with color orange at (0,0)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (4,3) and color black and layers
  _0: rectangle with size (2,2) with model Odd Checkboard with color green at (0,1)
diff: 
   (12.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,7) and color black and layers
  _0: rectangle with size (4,3) with mask 
. 0 . 
0 . . 
0 0 0 
0 0 0 
 with color grey at (0,4)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (1,3) with model Full with color orange at (3,0)
  _011: rectangle with size (1,1) with model Full with color orange at (0,0)
  + 1 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,7) and color black and layers
  _0: rectangle with size (4,3) with mask 
. 0 . 
0 . . 
0 0 0 
0 0 0 
 with color grey at (0,4)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (1,3) with model Full with color orange at (3,0)
  _011: rectangle with size (1,1) with model Full with color orange at (1,2)
  + 1 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (4,7) and color black and layers
  _0: rectangle with size (4,3) with mask 
. 0 . 
0 . . 
0 0 0 
0 0 0 
 with color grey at (0,4)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (1,1) with model Full with color orange at (0,0)
  _011: rectangle with size (1,3) with model Full with color orange at (3,0)
  + 1 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TRAIN f2829549.json/5: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,7) and color black and layers
  _0: rectangle with size (4,3) with mask 
. 0 . 
0 0 . 
0 . . 
0 0 0 
 with color grey at (0,4)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (1,3) with model Full with color orange at (1,0)
  _011: rectangle with size (1,1) with model Full with color orange at (3,0)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,7) and color black and layers
  _0: rectangle with size (4,3) with mask 
. 0 . 
0 0 . 
0 . . 
0 0 0 
 with color grey at (0,4)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (1,1) with model Full with color orange at (3,0)
  _011: rectangle with size (1,3) with model Full with color orange at (1,0)
diff: 
! 6 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (4,7) and color black and layers
  _0: rectangle with size (1,3) with model Full with color orange at (1,0)
  _01: 
0 
0 
0 
0 
 with color blue at (0,3)
  _0110: rectangle with size (4,3) with mask 
. 0 . 
0 0 . 
0 . . 
0 0 0 
 with color grey at (0,4)
  _011: rectangle with size (1,1) with model Full with color orange at (3,0)
diff: 
! 6 wrong pixels (generated / expected)

TEST f2829549.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 13.4 sec (13.4 sec/task)
bits-train-error = 1099.3 bits (1099.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-14] Checking task f35d900a.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 401074.1 = 401076.4
DL output with Mo: L = 2.3 + 401074.1 = 401076.4
DL input+output M: L = 4.6 + 802148.2 = 802152.9

# learning a model for train pairs
2.000	
1.019	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.218	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.189	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.160	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.131	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.102	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.099	OUT ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.097	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.092	OUT ADD ^.layer_00 = ^.layer_0
0.089	OUT ADD ^.layer_010 = ^.layer_0.shape at (?,?)
0.087	OUT SPE ^.layer_0.shape = tiling(^.layer_0.shape, 3, 3)
0.085	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.081	OUT ADD ^.layer_0110 = ^.layer_01
0.078	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.076	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.074	OUT SPE ^.size = ^.size
0.072	OUT SPE ^.layer_01.shape = tiling(^.layer_01.shape, 3, 3)
0.069	OUT SPE ^.layer_0111.shape = tiling(^.layer_0111.shape, 3, 3)
0.060	
0.060	IN  DEL ^.layer_011
TIMEOUT

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _00: ^.layer_0
  _0: tiling(^.layer_0.shape, 3, 3) at (?,?)
  _010: ^.layer_0.shape at (?,?)
  _01: tiling(^.layer_01.shape, 3, 3) at (?,?)
  _0110: ^.layer_01
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: tiling(^.layer_0111.shape, 3, 3) at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 86.6 + 3908.9 = 3995.5
DL output with Mo: L = 185.6 + 23686.6 = 23872.2
DL input+output M: L = 272.2 + 27595.5 = 27867.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color ? and layers
  _00: ^.layer_0
  _0: tiling(^.layer_0.shape, 3, 3) at (?,?)
  _010: ^.layer_0.shape at (?,?)
  _01: tiling(^.layer_01.shape, 3, 3) at (?,?)
  _0110: ^.layer_01
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: tiling(^.layer_0111.shape, 3, 3) at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)
  _01: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 68.7 + 0.0 = 68.7
DL output with Mo: L = 185.6 + 23686.6 = 23872.2
DL input+output M: L = 254.3 + 23686.6 = 23940.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (14,14) and color black and layers
  _0: point with color red at (2,1)
  _01: point with color green at (2,6)
  _0111: point with color green at (8,1)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (14,14) and color black and layers
  _00: 
2 
 at (2,1)
  _0: 
2 2 2 
2 2 2 
2 2 2 
 at (7,0)
  _010: 
2 
 at (8,6)
  _01: 
3 3 3 
3 3 3 
3 3 3 
 at (1,0)
  _0110: 
3 
 at (2,6)
  _011: rectangle with size (3,3) with model Full with color red at (1,5)
  _0111: 
3 3 3 
3 3 3 
3 3 3 
 at (7,5)
  _01111: rectangle with size (1,2) with model Full with color grey at (2,3)
  + 7 delta pixels
diff: 
   (404.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (14,14) and color black and layers
  _0: point with color red at (2,1)
  _01: point with color green at (2,6)
  _0111: point with color green at (8,1)
  + 1 delta pixels
diff: 
! 45 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (14,14) and color black and layers
  _0: point with color red at (2,1)
  _01: point with color green at (8,1)
  _0111: point with color green at (2,6)
  + 1 delta pixels
diff: 
! 45 wrong pixels (generated / expected)

TRAIN f35d900a.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (17,14) and color black and layers
  _0: point with color blue at (3,2)
  _01: point with color cyan at (3,10)
  _0111: point with color cyan at (14,2)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (17,14) and color black and layers
  _00: 
1 
 at (3,2)
  _0: 
1 1 1 
1 1 1 
1 1 1 
 at (13,1)
  _010: 
1 
 at (14,10)
  _01: 
8 8 8 
8 8 8 
8 8 8 
 at (2,1)
  _0110: 
8 
 at (3,10)
  _011: rectangle with size (3,3) with model Full with color blue at (2,9)
  _0111: 
8 8 8 
8 8 8 
8 8 8 
 at (13,9)
  _01111: rectangle with size (1,1) with model Full with color grey at (3,4)
  + 14 delta pixels
diff: 
   (692.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,14) and color black and layers
  _0: point with color blue at (3,2)
  _01: point with color cyan at (3,10)
  _0111: point with color cyan at (14,2)
  + 1 delta pixels
diff: 
! 55 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,14) and color black and layers
  _0: point with color blue at (3,2)
  _01: point with color cyan at (14,2)
  _0111: point with color cyan at (3,10)
  + 1 delta pixels
diff: 
! 55 wrong pixels (generated / expected)

TRAIN f35d900a.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (17,16) and color black and layers
  _0: point with color red at (3,2)
  _01: point with color yellow at (3,13)
  _0111: point with color yellow at (13,2)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (17,16) and color black and layers
  _00: 
2 
 at (3,2)
  _0: 
2 2 2 
2 2 2 
2 2 2 
 at (12,1)
  _010: 
2 
 at (13,13)
  _01: 
4 4 4 
4 4 4 
4 4 4 
 at (2,1)
  _0110: 
4 
 at (3,13)
  _011: rectangle with size (3,3) with model Full with color red at (2,12)
  _0111: 
4 4 4 
4 4 4 
4 4 4 
 at (12,12)
  _01111: rectangle with size (1,1) with model Full with color grey at (3,4)
  + 16 delta pixels
diff: 
   (779.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,16) and color black and layers
  _0: point with color red at (3,2)
  _01: point with color yellow at (3,13)
  _0111: point with color yellow at (13,2)
  + 1 delta pixels
diff: 
! 57 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,16) and color black and layers
  _0: point with color red at (3,2)
  _01: point with color yellow at (13,2)
  _0111: point with color yellow at (3,13)
  + 1 delta pixels
diff: 
! 57 wrong pixels (generated / expected)

TRAIN f35d900a.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (17,16) and color black and layers
  _0: point with color green at (3,4)
  _01: point with color cyan at (3,12)
  _0111: point with color cyan at (8,4)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (17,16) and color black and layers
  _00: 
3 
 at (3,4)
  _0: 
3 3 3 
3 3 3 
3 3 3 
 at (7,3)
  _010: 
3 
 at (8,12)
  _01: 
8 8 8 
8 8 8 
8 8 8 
 at (2,3)
  _0110: 
8 
 at (3,12)
  _011: rectangle with size (3,3) with model Full with color green at (2,11)
  _0111: 
8 8 8 
8 8 8 
8 8 8 
 at (7,11)
  _01111: rectangle with size (2,1) with model Full with color grey at (5,4)
  + 9 delta pixels
diff: 
   (492.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,16) and color black and layers
  _0: point with color green at (3,4)
  _01: point with color cyan at (3,12)
  _0111: point with color cyan at (8,4)
  + 1 delta pixels
diff: 
! 53 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,16) and color black and layers
  _0: point with color green at (3,4)
  _01: point with color cyan at (8,4)
  _0111: point with color cyan at (3,12)
  + 1 delta pixels
diff: 
! 53 wrong pixels (generated / expected)

TRAIN f35d900a.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,18) and color black and layers
  _0: point with color yellow at (4,2)
  _01: point with color blue at (4,12)
  _0111: point with color blue at (15,2)
  + 1 delta pixels
diff: 
! 59 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,18) and color black and layers
  _0: point with color yellow at (4,2)
  _01: point with color blue at (15,2)
  _0111: point with color blue at (4,12)
  + 1 delta pixels
diff: 
! 59 wrong pixels (generated / expected)

TEST f35d900a.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 59.4 sec (59.4 sec/task)
bits-train-error = 23686.6 bits (23686.6 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-13] Checking task f5b8619d.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 19172.9 = 19175.2
DL output with Mo: L = 2.3 + 78335.3 = 78337.6
DL input+output M: L = 4.6 + 97508.2 = 97512.8

# learning a model for train pairs
2.000	
1.146	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.397	OUT SPE ^ = tiling to size (?,?)
of grid ?
0.281	OUT SPE ^.grid = a background with size (?,?) and color ? and layers
0.201	OUT ADD ^.grid.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.164	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.150	OUT ADD ^.grid.layer_01 = ^.layer_0
0.143	OUT SPE ^.size = tiling(^.size, 2, 2)
0.138	OUT SPE ^.grid.size = ^.size
0.134	IN  SPE ^.color = black
0.133	OUT SPE ^.grid.layer_0.shape.mask.size.j = ^.size.j / '2
0.132	OUT SPE ^.grid.layer_0.shape.mask.model = Full
0.132	OUT SPE ^.grid.layer_0.pos.i = ^.layer_0.pos.j
0.028	
0.028	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
tiling to size tiling(^.size, 2, 2)
of grid a background with size ^.size and color ? and layers
  _0: rectangle with size (?,^.size.j / '2) with model Full with color ? at (^.layer_0.pos.j,?)
  _01: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.3 + 2010.8 = 2043.2
DL output with Mo: L = 115.3 + 1853.3 = 1968.7
DL input+output M: L = 147.7 + 3864.2 = 4011.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
tiling to size tiling(^.size, 2, 2)
of grid a background with size ^.size and color ? and layers
  _0: rectangle with size (?,^.size.j / '2) with model Full with color ? at (^.layer_0.pos.j,?)
  _01: ^.layer_0
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 20.0 = 52.2
DL output with Mo: L = 115.3 + 1853.3 = 1968.7
DL input+output M: L = 147.5 + 1873.3 = 2020.9

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color black and layers
  _0: point with color red at (0,0)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: tiling to size (6,6)
of grid a background with size (3,3) and color cyan and layers
  _0: rectangle with size (3,1) with model Full with color black at (0,1)
  _01: 
2 
 at (0,0)
  + 1 delta pixels
diff: 
   (63.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color black and layers
  _0: point with color red at (0,0)
  + 1 delta pixels
diff: 
! 24 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (3,3) and color black and layers
  _0: point with color red at (2,2)
  + 1 delta pixels
diff: 
! 20 wrong pixels (generated / expected)

TRAIN f5b8619d.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (6,6) and color black and layers
  _0: point with color grey at (4,0)
  + 2 delta pixels
diff: 
   (2.0 bits)
data: tiling to size (12,12)
of grid a background with size (6,6) and color cyan and layers
  _0: rectangle with size (6,3) with model Full with color black at (0,2)
  _01: 
5#
 at (4,0)
  + 2 delta pixels
diff: 
   (107.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,6) and color black and layers
  _0: point with color grey at (0,1)
  + 2 delta pixels
diff: 
! 76 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,6) and color black and layers
  _0: point with color grey at (4,0)
  + 2 delta pixels
diff: 
! 76 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (6,6) and color black and layers
  _0: point with color grey at (4,5)
  + 2 delta pixels
diff: 
! 72 wrong pixels (generated / expected)

TRAIN f5b8619d.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (2,2) and color black and layers
  _0: point with color yellow at (0,1)
diff: 
   (0.0 bits)
data: tiling to size (4,4)
of grid a background with size (2,2) and color black and layers
  _0: rectangle with size (1,1) with model Full with color cyan at (1,1)
  _01: 
4 
 at (0,1)
diff: 
   (14.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (2,2) and color black and layers
  _0: point with color yellow at (0,1)
diff: 
! 8 wrong pixels (generated / expected)

TRAIN f5b8619d.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,4) and color black and layers
  _0: point with color green at (0,2)
  + 2 delta pixels
diff: 
! 52 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (4,4) and color black and layers
  _0: point with color green at (2,3)
  + 2 delta pixels
diff: 
! 48 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (4,4) and color black and layers
  _0: point with color green at (3,0)
  + 2 delta pixels
diff: 
! 52 wrong pixels (generated / expected)

TEST f5b8619d.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 2.9 sec (2.9 sec/task)
bits-train-error = 1853.3 bits (1853.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-12] Checking task f76d97a5.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 22921.2 = 22923.5
DL output with Mo: L = 2.3 + 22921.2 = 22923.5
DL input+output M: L = 4.6 + 45842.4 = 45847.0

# learning a model for train pairs
2.000	
1.375	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.756	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.484	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.216	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.153	OUT SPE ^.layer_0 = coloring(^.layer_0, ^.color)
0.134	OUT SPE ^.size = ^.size
0.126	IN  SPE ^.layer_0.shape.color = grey
0.123	OUT SPE ^.color = black
0.020	
0.020	IN  GEN ^.layer_0.shape.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, ^.color)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color grey at (?,?)

DL input  with Mi: L = 45.3 + 2359.2 = 2404.5
DL output with Mo: L = 26.2 + 395.2 = 421.4
DL input+output M: L = 71.5 + 2754.4 = 2825.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: coloring(^.layer_0, ^.color)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 26.2 + 395.2 = 421.4
DL input+output M: L = 68.2 + 395.2 = 463.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (3,3) and color yellow and layers
  _0: rectangle with size (3,3) with model +-cross with color grey at (0,0)
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: 
. 4 . 
4 4 4 
. 4 . 
 at (0,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (3,3) and color yellow and layers
  _0: rectangle with size (3,3) with model +-cross with color grey at (0,0)
diff: 
correct output grid

TRAIN f76d97a5.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (5,5) and color pink and layers
  _0: rectangle with size (5,5) with mask 
0 0 . . . 
. 0 0 . . 
. . 0 0 . 
. . . 0 0 
. . . . 0 
 with color grey at (0,0)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: 
6 6 . . . 
. 6 6 . . 
. . 6 6 . 
. . . 6 6 
. . . . 6 
 at (0,0)
  + 1 delta pixels
diff: 
   (39.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color pink and layers
  _0: rectangle with size (5,5) with mask 
0 0 . . . 
. 0 0 . . 
. . 0 0 . 
. . . 0 0 
. . . . 0 
 with color grey at (0,0)
  + 1 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,5) and color grey and layers
  _0: rectangle with size (4,4) with mask 
0 . . . 
0 0 . . 
0 0 0 . 
. 0 0 0 
 with color pink at (1,0)
  + 6 delta pixels
diff: 
! 19 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (5,5) and color pink and layers
  _0: rectangle with size (1,2) with model Full with color grey at (0,0)
  + 8 delta pixels
diff: 
! 8 wrong pixels (generated / expected)

TRAIN f76d97a5.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (5,5) and color brown and layers
  _0: rectangle with size (5,4) with mask 
0 . . . 
. 0 0 . 
0 . . . 
. 0 . . 
. . 0 0 
 with color grey at (0,1)
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: 
9#. . . 
. 9#9#. 
9#. . . 
. 9#. . 
. . 9#9#
 at (0,1)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color brown and layers
  _0: rectangle with size (5,4) with mask 
0 . . . 
. 0 0 . 
0 . . . 
. 0 . . 
. . 0 0 
 with color grey at (0,1)
diff: 
correct output grid

TRAIN f76d97a5.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color grey and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 . 0 
0 . 0 0 0 
0 . . 0 . 
0 0 0 . 0 
. . . 0 0 
 with color green at (0,0)
diff: 
! 25 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,5) and color green and layers
  _0: rectangle with size (4,5) with mask 
. 0 . . . 
. 0 0 . 0 
. . . 0 . 
0 0 0 . . 
 with color grey at (1,0)
  + 1 delta pixels
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (5,5) and color green and layers
  _0: rectangle with size (1,3) with model Full with color grey at (4,0)
  + 6 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TEST f76d97a5.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 2.4 sec (2.4 sec/task)
bits-train-error = 395.2 bits (395.2 bits/task)
acc-train-micro = 0.67 tasks (66.67%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.67
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-11] Checking task f8a8fe49.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 276019.4 = 276021.8
DL output with Mo: L = 2.3 + 276019.4 = 276021.8
DL input+output M: L = 4.6 + 552038.9 = 552043.5

# learning a model for train pairs
2.000	
1.111	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.223	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.189	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.151	OUT ADD ^.layer_0 = ^.layer_0
0.118	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.079	OUT ADD ^.layer_01 = ^.layer_01
0.064	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.048	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.039	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.029	OUT ADD ^.layer_0111 = ^.layer_0111.shape at (?,?)
0.027	OUT SPE ^.size = ^.size
0.025	OUT SPE ^.layer_011.shape.mask.size = ^.layer_011.shape.mask.size
0.024	OUT SPE ^.layer_0111.pos = ^.layer_0111.pos + translationOnto(^.layer_0, ^.layer_01)
0.023	OUT SPE ^.layer_011.pos = ^.layer_011.pos + translationSym(rotate180, ^.layer_0111, ^.layer_011)
0.022	OUT SPE ^.layer_011.shape.color = ^.layer_011.shape.color
0.022	IN  SPE ^.layer_0.shape.color = red
0.021	IN  SPE ^.layer_01.shape.color = red
0.020	IN  SPE ^.layer_011.shape.color = grey
0.020	IN  SPE ^.layer_0111.shape.color = grey
0.019	IN  SPE ^.layer_0111.shape.mask.model = Full
0.019	IN  SPE ^.color = black
0.019	OUT SPE ^.color = black
0.002	
0.002	IN  GEN ^.layer_0111.shape.color = ?
0.002	IN  GEN ^.layer_011.shape.color = ?
0.002	IN  GEN ^.layer_01.shape.color = ?
0.002	IN  GEN ^.layer_0.shape.color = ?
0.002	IN  GEN ^.layer_0111.shape.mask.model = ?
0.002	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_01
  _011: rectangle with size ^.layer_011.shape.mask.size with model ? with color ^.layer_011.shape.color at ^.layer_011.pos + translationSym(rotate180, ^.layer_0111, ^.layer_011)
  _0111: ^.layer_0111.shape at ^.layer_0111.pos + translationOnto(^.layer_0, ^.layer_01)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at (?,?)
  _01: rectangle with size (?,?) with model ? with color red at (?,?)
  _011: rectangle with size (?,?) with model ? with color grey at (?,?)
  _0111: rectangle with size (?,?) with model Full with color grey at (?,?)

DL input  with Mi: L = 139.7 + 4744.9 = 4884.6
DL output with Mo: L = 110.7 + 226.7 = 337.4
DL input+output M: L = 250.3 + 4971.6 = 5222.0

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _0: ^.layer_0
  _01: ^.layer_01
  _011: rectangle with size ^.layer_011.shape.mask.size with model ? with color ^.layer_011.shape.color at ^.layer_011.pos + translationSym(rotate180, ^.layer_0111, ^.layer_011)
  _0111: ^.layer_0111.shape at ^.layer_0111.pos + translationOnto(^.layer_0, ^.layer_01)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 0.0 = 125.8
DL output with Mo: L = 110.7 + 226.7 = 337.4
DL input+output M: L = 236.5 + 226.7 = 463.2

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (2,7) with mask 
0 0 0 0 0 0 0 
0 . . . . . 0 
 with color red at (4,4)
  _01: rectangle with size (2,7) with mask 
0 . . . . . 0 
0 0 0 0 0 0 0 
 with color red at (10,4)
  _011: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color grey at (6,6)
  _0111: rectangle with size (1,1) with model Full with color grey at (9,7)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: 
2 2 2 2 2 2 2 
2 . . . . . 2 
 at (4,4)
  _01: 
2 . . . . . 2 
2 2 2 2 2 2 2 
 at (10,4)
  _011: rectangle with size (2,3) with mask 
0 . 0 
0 0 0 
 with color grey at (1,6)
  _0111: 
5#
 at (13,7)
diff: 
   (5.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (2,7) with mask 
0 0 0 0 0 0 0 
0 . . . . . 0 
 with color red at (4,4)
  _01: rectangle with size (2,7) with mask 
0 . . . . . 0 
0 0 0 0 0 0 0 
 with color red at (10,4)
  _011: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color grey at (6,6)
  _0111: rectangle with size (1,1) with model Full with color grey at (9,7)
diff: 
! 1 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (2,7) with mask 
0 . . . . . 0 
0 0 0 0 0 0 0 
 with color red at (10,4)
  _01: rectangle with size (2,7) with mask 
0 0 0 0 0 0 0 
0 . . . . . 0 
 with color red at (4,4)
  _011: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color grey at (6,6)
  _0111: rectangle with size (1,1) with model Full with color grey at (9,7)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (2,7) with mask 
0 0 0 0 0 0 0 
0 . . . . . 0 
 with color red at (4,4)
  _01: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color grey at (6,6)
  _011: rectangle with size (2,7) with mask 
0 . . . . . 0 
0 0 0 0 0 0 0 
 with color red at (10,4)
  _0111: rectangle with size (1,1) with model Full with color grey at (9,7)
diff: 
! 34 wrong pixels (generated / expected)

TRAIN f8a8fe49.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (8,2) with mask 
0 0 
0 . 
0 . 
0 . 
0 . 
0 . 
0 . 
0 0 
 with color red at (3,3)
  _01: rectangle with size (8,2) with mask 
0 0 
. 0 
. 0 
. 0 
. 0 
. 0 
. 0 
0 0 
 with color red at (3,9)
  _011: rectangle with size (4,2) with mask 
0 . 
. 0 
. 0 
0 . 
 with color grey at (5,5)
  _0111: rectangle with size (4,1) with model Full with color grey at (5,8)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: 
2 2 
2 . 
2 . 
2 . 
2 . 
2 . 
2 . 
2 2 
 at (3,3)
  _01: 
2 2 
. 2 
. 2 
. 2 
. 2 
. 2 
. 2 
2 2 
 at (3,9)
  _011: rectangle with size (4,2) with mask 
. 0 
0 . 
0 . 
. 0 
 with color grey at (5,0)
  _0111: 
5#
5#
5#
5#
 at (5,12)
diff: 
   (9.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (8,2) with mask 
0 0 
0 . 
0 . 
0 . 
0 . 
0 . 
0 . 
0 0 
 with color red at (3,3)
  _01: rectangle with size (8,2) with mask 
0 0 
. 0 
. 0 
. 0 
. 0 
. 0 
. 0 
0 0 
 with color red at (3,9)
  _011: rectangle with size (4,2) with mask 
0 . 
. 0 
. 0 
0 . 
 with color grey at (5,5)
  _0111: rectangle with size (4,1) with model Full with color grey at (5,8)
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (8,2) with mask 
0 0 
0 . 
0 . 
0 . 
0 . 
0 . 
0 . 
0 0 
 with color red at (3,3)
  _01: rectangle with size (8,2) with mask 
0 0 
. 0 
. 0 
. 0 
. 0 
. 0 
. 0 
0 0 
 with color red at (3,9)
  _011: rectangle with size (4,1) with model Full with color grey at (5,8)
  _0111: rectangle with size (4,2) with mask 
0 . 
. 0 
. 0 
0 . 
 with color grey at (5,5)
diff: 
! 14 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (8,2) with mask 
0 0 
. 0 
. 0 
. 0 
. 0 
. 0 
. 0 
0 0 
 with color red at (3,9)
  _01: rectangle with size (8,2) with mask 
0 0 
0 . 
0 . 
0 . 
0 . 
0 . 
0 . 
0 0 
 with color red at (3,3)
  _011: rectangle with size (4,2) with mask 
0 . 
. 0 
. 0 
0 . 
 with color grey at (5,5)
  _0111: rectangle with size (4,1) with model Full with color grey at (5,8)
diff: 
! 12 wrong pixels (generated / expected)

TRAIN f8a8fe49.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (15,15) and color black and layers
  _0: rectangle with size (5,2) with mask 
0 0 
0 . 
0 . 
0 . 
0 0 
 with color red at (3,3)
  _01: rectangle with size (5,2) with mask 
0 0 
. 0 
. 0 
. 0 
0 0 
 with color red at (3,9)
  _011: rectangle with size (3,2) with mask 
0 . 
0 0 
. 0 
 with color grey at (4,5)
  _0111: rectangle with size (3,1) with model Full with color grey at (4,8)
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: 
2 2 
2 . 
2 . 
2 . 
2 2 
 at (3,3)
  _01: 
2 2 
. 2 
. 2 
. 2 
2 2 
 at (3,9)
  _011: rectangle with size (3,2) with mask 
. 0 
0 0 
0 . 
 with color grey at (4,0)
  _0111: 
5#
5#
5#
 at (4,12)
diff: 
   (7.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (5,2) with mask 
0 0 
0 . 
0 . 
0 . 
0 0 
 with color red at (3,3)
  _01: rectangle with size (5,2) with mask 
0 0 
. 0 
. 0 
. 0 
0 0 
 with color red at (3,9)
  _011: rectangle with size (3,2) with mask 
0 . 
0 0 
. 0 
 with color grey at (4,5)
  _0111: rectangle with size (3,1) with model Full with color grey at (4,8)
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (5,2) with mask 
0 0 
0 . 
0 . 
0 . 
0 0 
 with color red at (3,3)
  _01: rectangle with size (5,2) with mask 
0 0 
. 0 
. 0 
. 0 
0 0 
 with color red at (3,9)
  _011: rectangle with size (3,1) with model Full with color grey at (4,8)
  _0111: rectangle with size (3,2) with mask 
0 . 
0 0 
. 0 
 with color grey at (4,5)
diff: 
! 12 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (5,2) with mask 
0 0 
. 0 
. 0 
. 0 
0 0 
 with color red at (3,9)
  _01: rectangle with size (5,2) with mask 
0 0 
0 . 
0 . 
0 . 
0 0 
 with color red at (3,3)
  _011: rectangle with size (3,2) with mask 
0 . 
0 0 
. 0 
 with color grey at (4,5)
  _0111: rectangle with size (3,1) with model Full with color grey at (4,8)
diff: 
! 8 wrong pixels (generated / expected)

TRAIN f8a8fe49.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (2,7) with mask 
0 0 0 0 0 0 0 
0 . . . . . 0 
 with color red at (4,4)
  _01: rectangle with size (2,7) with mask 
0 . . . . . 0 
0 0 0 0 0 0 0 
 with color red at (10,4)
  _011: rectangle with size (2,5) with mask 
. 0 0 0 0 
0 0 0 . . 
 with color grey at (6,5)
  _0111: rectangle with size (1,3) with model Full with color grey at (9,6)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (2,7) with mask 
0 0 0 0 0 0 0 
0 . . . . . 0 
 with color red at (4,4)
  _01: rectangle with size (2,5) with mask 
. 0 0 0 0 
0 0 0 . . 
 with color grey at (6,5)
  _011: rectangle with size (2,7) with mask 
0 . . . . . 0 
0 0 0 0 0 0 0 
 with color red at (10,4)
  _0111: rectangle with size (1,3) with model Full with color grey at (9,6)
diff: 
! 40 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (2,7) with mask 
0 . . . . . 0 
0 0 0 0 0 0 0 
 with color red at (10,4)
  _01: rectangle with size (2,7) with mask 
0 0 0 0 0 0 0 
0 . . . . . 0 
 with color red at (4,4)
  _011: rectangle with size (2,5) with mask 
. 0 0 0 0 
0 0 0 . . 
 with color grey at (6,5)
  _0111: rectangle with size (1,3) with model Full with color grey at (9,6)
diff: 
! 9 wrong pixels (generated / expected)

TEST f8a8fe49.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 10.7 sec (10.7 sec/task)
bits-train-error = 226.7 bits (226.7 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-10] Checking task f8b3ba0a.json: 4 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 274147.3 = 274149.6
DL output with Mo: L = 2.3 + 4972.2 = 4974.5
DL input+output M: L = 4.6 + 279119.4 = 279124.1

# learning a model for train pairs
2.000	
1.287	IN  SPE ^ = a background with size (?,?) and color ? and layers
1.021	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.833	OUT ADD ^.layer_0 = point with color ? at (?,?)
0.639	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.562	OUT SPE ^.size = '(3, 1)
0.491	OUT SPE ^.color = red
0.468	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.426	OUT SPE ^.layer_0.pos = projI(^.layer_0.pos) - (1, 0)
0.403	IN  ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.385	OUT SPE ^.layer_01.pos.j = '0
0.382	IN  ADD ^.layer_01 = point with color ? at (?,?)
0.363	OUT SPE ^.layer_01.pos.i = max(^.layer_01.pos.j, ^.layer_00.pos.j) - ^.layer_01.pos.i - ^.layer_0.pos.i
0.362	IN  SPE ^.layer_0.shape.mask.model = Full
0.362	IN  SPE ^.layer_00.shape.mask.model = Full
0.361	IN  SPE ^.color = black
0.119	
0.119	IN  GEN ^.layer_00.shape.mask.model = ?
0.119	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 1) and color red and layers
  _0: point with color ? at projI(^.layer_0.pos) - (1, 0)
  _01: point with color ? at (max(^.layer_01.pos.j, ^.layer_00.pos.j) - ^.layer_01.pos.i - ^.layer_0.pos.i,'0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 89.5 + 66557.6 = 66647.1
DL output with Mo: L = 138.0 + 450.4 = 588.3
DL input+output M: L = 227.4 + 67008.0 = 67235.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 1) and color red and layers
  _0: point with color ? at projI(^.layer_0.pos) - (1, 0)
  _01: point with color ? at (max(^.layer_01.pos.j, ^.layer_00.pos.j) - ^.layer_01.pos.i - ^.layer_0.pos.i,'0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model Full with color ? at (?,?)
  _01: point with color ? at (?,?)

DL input  with Mi: L = 88.8 + 51.7 = 140.5
DL output with Mo: L = 138.0 + 450.4 = 588.3
DL input+output M: L = 226.8 + 502.1 = 728.8

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _00: rectangle with size (1,11) with model Full with color blue at (11,1)
  _0: rectangle with size (1,8) with model Full with color blue at (1,4)
  _01: point with color green at (1,2)
  + 38 delta pixels
diff: 
   (2.0 bits)
data: a background with size (3,1) and color red and layers
  _0: point with color yellow at (0,0)
  _01: point with color green at (2,0)
diff: 
   (11.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _00: rectangle with size (1,11) with model Full with color blue at (11,1)
  _0: rectangle with size (1,8) with model Full with color blue at (1,4)
  _01: point with color green at (1,1)
  + 38 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,13) and color black and layers
  _00: rectangle with size (1,11) with model Full with color blue at (11,1)
  _0: rectangle with size (1,8) with model Full with color blue at (1,4)
  _01: point with color green at (1,2)
  + 38 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (13,13) and color black and layers
  _00: rectangle with size (1,11) with model Full with color blue at (11,1)
  _0: rectangle with size (1,8) with model Full with color blue at (1,4)
  _01: point with color blue at (3,1)
  + 38 delta pixels
diff: 
! 2 wrong pixels (generated / expected)

TRAIN f8b3ba0a.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (13,16) and color black and layers
  _00: rectangle with size (1,14) with model Full with color cyan at (11,1)
  _0: rectangle with size (1,11) with model Full with color cyan at (1,4)
  _01: point with color pink at (1,1)
  + 48 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,1) and color red and layers
  _0: point with color pink at (0,0)
  _01: point with color blue at (1,0)
diff: 
   (11.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,16) and color black and layers
  _00: rectangle with size (1,14) with model Full with color cyan at (11,1)
  _0: rectangle with size (1,11) with model Full with color cyan at (1,4)
  _01: point with color pink at (1,1)
  + 48 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,16) and color black and layers
  _00: rectangle with size (1,14) with model Full with color cyan at (11,1)
  _0: rectangle with size (1,11) with model Full with color cyan at (1,4)
  _01: point with color pink at (1,2)
  + 48 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (13,16) and color black and layers
  _00: rectangle with size (1,11) with model Full with color cyan at (1,4)
  _0: rectangle with size (1,14) with model Full with color cyan at (11,1)
  _01: point with color pink at (1,1)
  + 48 delta pixels
diff: 
! 2 wrong pixels (generated / expected)

TRAIN f8b3ba0a.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (13,10) and color black and layers
  _00: rectangle with size (1,8) with model Full with color green at (1,1)
  _0: rectangle with size (1,5) with model Full with color green at (3,4)
  _01: point with color blue at (3,1)
  + 28 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,1) and color red and layers
  _0: point with color blue at (2,0)
  _01: point with color cyan at (1,0)
diff: 
   (11.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,10) and color black and layers
  _00: rectangle with size (1,8) with model Full with color green at (1,1)
  _0: rectangle with size (1,5) with model Full with color green at (3,4)
  _01: point with color blue at (3,1)
  + 28 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,10) and color black and layers
  _00: rectangle with size (1,5) with model Full with color green at (3,4)
  _0: rectangle with size (1,8) with model Full with color green at (1,1)
  _01: point with color blue at (3,1)
  + 28 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (13,10) and color black and layers
  _00: rectangle with size (1,8) with model Full with color green at (1,1)
  _0: rectangle with size (1,5) with model Full with color green at (3,4)
  _01: point with color blue at (3,2)
  + 28 delta pixels
diff: 
! 2 wrong pixels (generated / expected)

TRAIN f8b3ba0a.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _00: rectangle with size (1,8) with model Full with color blue at (5,4)
  _0: rectangle with size (1,11) with model Full with color blue at (1,1)
  _01: point with color blue at (3,1)
  + 40 delta pixels
diff: 
   (3.2 bits)
data: a background with size (3,1) and color red and layers
  _0: point with color cyan at (0,0)
  _01: point with color yellow at (2,0)
diff: 
   (11.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _00: rectangle with size (1,11) with model Full with color blue at (1,1)
  _0: rectangle with size (1,8) with model Full with color blue at (5,4)
  _01: point with color blue at (3,1)
  + 40 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,13) and color black and layers
  _00: rectangle with size (1,8) with model Full with color blue at (5,4)
  _0: rectangle with size (1,11) with model Full with color blue at (1,1)
  _01: point with color blue at (3,1)
  + 40 delta pixels
diff: 
! 2 wrong pixels (generated / expected)

TRAIN f8b3ba0a.json/4: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,13) and color black and layers
  _00: rectangle with size (1,8) with model Full with color red at (9,4)
  _0: rectangle with size (1,5) with model Full with color red at (5,4)
  _01: point with color red at (1,1)
  + 48 delta pixels
diff: 
! 3 wrong pixels (generated / expected)

TEST f8b3ba0a.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 11.0 sec (11.0 sec/task)
bits-train-error = 450.4 bits (450.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-9] Checking task f8c80d96.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.189	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.612	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.467	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.368	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.270	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.202	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.155	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.113	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.102	OUT ADD ^.layer_00 = ^.layer_0
0.098	OUT SPE ^.layer_011 = ^.layer_01
0.093	OUT SPE ^.size = ^.size
0.091	OUT SPE ^.color = grey
0.089	OUT SPE ^.layer_01.shape.mask.size.i = ^.layer_0.shape.mask.size.i + ^.layer_01.shape.mask.size.i
0.087	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.086	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.085	OUT SPE ^.layer_01.pos.i = '0
0.083	OUT SPE ^.layer_0111.shape.color = majorityColor(^)
0.083	OUT SPE ^.layer_0111.shape.mask.size.i = ^.layer_01.shape.mask.size.i / '2
0.082	IN  SPE ^.color = black
0.034	
0.034	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color grey and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (?,?)
  _01: rectangle with size (^.layer_0.shape.mask.size.i + ^.layer_01.shape.mask.size.i,?) with model ? with color ^.layer_01.shape.color at ('0,?)
  _011: ^.layer_01
  _0111: rectangle with size (^.layer_01.shape.mask.size.i / '2,?) with model ? with color majorityColor(^) at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.3 + 5827.7 = 5898.1
DL output with Mo: L = 186.7 + 3728.4 = 3915.1
DL input+output M: L = 257.1 + 9556.1 = 9813.2

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color grey and layers
  _00: ^.layer_0
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (?,?)
  _01: rectangle with size (^.layer_0.shape.mask.size.i + ^.layer_01.shape.mask.size.i,?) with model ? with color ^.layer_01.shape.color at ('0,?)
  _011: ^.layer_01
  _0111: rectangle with size (^.layer_01.shape.mask.size.i / '2,?) with model ? with color majorityColor(^) at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 31.7 = 101.9
DL output with Mo: L = 186.7 + 3728.4 = 3915.1
DL input+output M: L = 256.9 + 3760.1 = 4017.0

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,6) with mask 
0 0 0 0 0 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
 with color cyan at (4,0)
  _01: rectangle with size (4,4) with mask 
0 0 0 0 
. . . 0 
. . . 0 
. . . 0 
 with color cyan at (6,0)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color grey and layers
  _00: 
8 8 8 8 8 8 
. . . . . 8 
. . . . . 8 
. . . . . 8 
. . . . . 8 
. . . . . 8 
 at (4,0)
  _0: rectangle with size (8,8) with mask 
0 0 0 0 0 0 0 0 
. . . . . . . 0 
. . . . . . . 0 
. . . . . . . 0 
. . . . . . . 0 
. . . . . . . 0 
. . . . . . . 0 
. . . . . . . 0 
 with color cyan at (2,0)
  _01: rectangle with size (10,10) with mask 
0 0 0 0 0 0 0 0 0 0 
. . . . . . . . . 0 
. . . . . . . . . 0 
. . . . . . . . . 0 
. . . . . . . . . 0 
. . . . . . . . . 0 
. . . . . . . . . 0 
. . . . . . . . . 0 
. . . . . . . . . 0 
. . . . . . . . . 0 
 with color cyan at (0,0)
  _011: 
8 8 8 8 
. . . 8 
. . . 8 
. . . 8 
 at (6,0)
  _0111: rectangle with size (2,2) with mask 
0 0 
. 0 
 with color cyan at (8,0)
diff: 
   (194.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,6) with mask 
0 0 0 0 0 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
 with color cyan at (4,0)
  _01: rectangle with size (4,4) with mask 
0 0 0 0 
. . . 0 
. . . 0 
. . . 0 
 with color cyan at (6,0)
  + 3 delta pixels
diff: 
! 39 wrong pixels (generated / expected)

TRAIN f8c80d96.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,6) with mask 
0 . . . . . 
0 . . . . . 
0 . . . . . 
0 . . . . . 
0 . . . . . 
0 0 0 0 0 0 
 with color blue at (0,4)
  _01: rectangle with size (3,1) with model Full with color blue at (0,7)
  + 2 delta pixels
diff: 
   (3.2 bits)
data: a background with size (10,10) and color grey and layers
  _00: 
1 . . . . . 
1 . . . . . 
1 . . . . . 
1 . . . . . 
1 . . . . . 
1 1 1 1 1 1 
 at (0,4)
  _0: rectangle with size (1,9) with model Full with color blue at (8,1)
  _01: rectangle with size (9,1) with model Full with color blue at (0,1)
  _011: 
1 
1 
1 
 at (0,7)
  _0111: rectangle with size (1,3) with model Full with color blue at (2,7)
diff: 
   (59.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,6) with mask 
0 . . . . . 
0 . . . . . 
0 . . . . . 
0 . . . . . 
0 . . . . . 
0 0 0 0 0 0 
 with color blue at (0,4)
  _01: rectangle with size (3,3) with mask 
0 . . 
0 . . 
0 0 0 
 with color blue at (0,7)
diff: 
! 17 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (6,6) with mask 
0 . . . . . 
0 . . . . . 
0 . . . . . 
0 . . . . . 
0 . . . . . 
0 0 0 0 0 0 
 with color blue at (0,4)
  _01: rectangle with size (3,1) with model Full with color blue at (0,7)
  + 2 delta pixels
diff: 
! 19 wrong pixels (generated / expected)

TRAIN f8c80d96.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,7) with mask 
0 . . . . . 0 
0 . . . . . 0 
0 . . . . . 0 
0 0 0 0 0 0 0 
 with color red at (0,1)
  _01: rectangle with size (2,3) with mask 
0 . 0 
0 0 0 
 with color red at (0,3)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color grey and layers
  _00: 
2 . . . . . 2 
2 . . . . . 2 
2 . . . . . 2 
2 2 2 2 2 2 2 
 at (0,1)
  _0: rectangle with size (1,10) with model Full with color red at (7,0)
  _01: rectangle with size (6,10) with mask 
. . . . . . . . . 0 
. . . . . . . . . 0 
. . . . . . . . . 0 
. . . . . . . . . 0 
. . . . . . . . . 0 
0 0 0 0 0 0 0 0 0 0 
 with color red at (0,0)
  _011: 
2 . 2 
2 2 2 
 at (0,3)
  _0111: rectangle with size (1,10) with model Full with color red at (9,0)
diff: 
   (119.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,7) with mask 
0 . . . . . 0 
0 . . . . . 0 
0 . . . . . 0 
0 0 0 0 0 0 0 
 with color red at (0,1)
  _01: rectangle with size (2,3) with mask 
0 . 0 
0 0 0 
 with color red at (0,3)
diff: 
! 39 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (4,7) with mask 
0 . . . . . 0 
0 . . . . . 0 
0 . . . . . 0 
0 0 0 0 0 0 0 
 with color red at (0,1)
  _01: rectangle with size (2,3) with model Full with color red at (0,3)
  + 1 delta pixels
diff: 
! 40 wrong pixels (generated / expected)

TRAIN f8c80d96.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,6) with mask 
0 0 0 0 0 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
. . . . . 0 
0 0 0 0 0 0 
 with color yellow at (0,0)
  _01: rectangle with size (4,3) with mask 
0 0 0 
. . 0 
. . 0 
0 0 0 
 with color yellow at (3,0)
diff: 
! 22 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color yellow and layers
  _0: rectangle with size (10,4) with model Full with color black at (0,6)
  _01: rectangle with size (8,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
. . . 0 0 
. . . 0 0 
. . . 0 0 
. . . 0 0 
0 0 0 0 0 
0 0 0 0 0 
 with color black at (1,0)
  + 4 delta pixels
diff: 
! 100 wrong pixels (generated / expected)

TEST f8c80d96.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 25.4 sec (25.4 sec/task)
bits-train-error = 3728.4 bits (3728.4 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-8] Checking task f8ff0b80.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 174280.1 = 174282.4
DL output with Mo: L = 2.3 + 3729.1 = 3731.5
DL input+output M: L = 4.6 + 178009.2 = 178013.9

# learning a model for train pairs
2.000	
1.153	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.887	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.701	OUT ADD ^.layer_0 = point with color ? at (?,?)
0.508	OUT ADD ^.layer_01 = point with color ? at (?,?)
0.431	OUT SPE ^.size = '(3, 1)
0.360	OUT SPE ^.color = red
0.298	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.248	OUT SPE ^.layer_0.pos = '(0, 0)
0.203	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.164	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.140	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.096	OUT SPE ^.layer_01.shape.color = ^.layer_01.shape.color
0.077	OUT SPE ^.layer_01.pos.i = span(^.layer_0.pos.i, ^.layer_011.pos.i) - area(^.layer_01.shape)
0.060	OUT SPE ^.layer_01.pos.j = '0
0.059	IN  SPE ^.layer_011.shape.color = red
0.059	IN  SPE ^.color = black
0.033	
0.033	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 1) and color red and layers
  _0: point with color ^.layer_0.shape.color at '(0, 0)
  _01: point with color ^.layer_01.shape.color at (span(^.layer_0.pos.i, ^.layer_011.pos.i) - area(^.layer_01.shape),'0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color red at (?,?)

DL input  with Mi: L = 101.5 + 4432.0 = 4533.6
DL output with Mo: L = 121.3 + 0.0 = 121.3
DL input+output M: L = 222.8 + 4432.0 = 4654.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 1) and color red and layers
  _0: point with color ^.layer_0.shape.color at '(0, 0)
  _01: point with color ^.layer_01.shape.color at (span(^.layer_0.pos.i, ^.layer_011.pos.i) - area(^.layer_01.shape),'0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color red at (?,?)

DL input  with Mi: L = 101.4 + 0.0 = 101.4
DL output with Mo: L = 121.3 + 0.0 = 121.3
DL input+output M: L = 222.7 + 0.0 = 222.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 0 . 
. 0 0 . 
. 0 0 0 
0 . . . 
 with color green at (1,1)
  _01: rectangle with size (3,3) with mask 
. 0 . 
0 0 . 
. . 0 
 with color cyan at (2,8)
  _011: rectangle with size (3,4) with mask 
. 0 0 . 
0 0 0 0 
. 0 . . 
 with color red at (6,3)
diff: 
   (0.0 bits)
data: a background with size (3,1) and color red and layers
  _0: point with color green at (0,0)
  _01: point with color cyan at (2,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (4,4) with mask 
. 0 0 . 
. 0 0 . 
. 0 0 0 
0 . . . 
 with color green at (1,1)
  _01: rectangle with size (3,3) with mask 
. 0 . 
0 0 . 
. . 0 
 with color cyan at (2,8)
  _011: rectangle with size (3,4) with mask 
. 0 0 . 
0 0 0 0 
. 0 . . 
 with color red at (6,3)
diff: 
correct output grid

TRAIN f8ff0b80.json/1: 1 1st (SUCCESS)

## instance 2

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 . 0 
0 0 0 . 
. . 0 0 
. 0 . . 
 with color blue at (1,7)
  _01: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. 0 0 
 with color orange at (8,8)
  _011: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color red at (7,2)
diff: 
   (0.0 bits)
data: a background with size (3,1) and color red and layers
  _0: point with color blue at (0,0)
  _01: point with color orange at (1,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (4,4) with mask 
0 0 . 0 
0 0 0 . 
. . 0 0 
. 0 . . 
 with color blue at (1,7)
  _01: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. 0 0 
 with color orange at (8,8)
  _011: rectangle with size (3,2) with mask 
. 0 
0 0 
. 0 
 with color red at (7,2)
diff: 
correct output grid

TRAIN f8ff0b80.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (12,12) and color black and layers
  _0: rectangle with size (4,5) with mask 
. . 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
. 0 . . . 
 with color yellow at (7,3)
  _01: rectangle with size (3,2) with mask 
0 . 
0 0 
0 0 
 with color blue at (2,8)
  _011: rectangle with size (3,4) with mask 
. . 0 . 
. 0 0 0 
0 0 0 . 
 with color red at (1,1)
diff: 
   (0.0 bits)
data: a background with size (3,1) and color red and layers
  _0: point with color yellow at (0,0)
  _01: point with color blue at (2,0)
diff: 
   (0.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (4,5) with mask 
. . 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
. 0 . . . 
 with color yellow at (7,3)
  _01: rectangle with size (3,2) with mask 
0 . 
0 0 
0 0 
 with color blue at (2,8)
  _011: rectangle with size (3,4) with mask 
. . 0 . 
. 0 0 0 
0 0 0 . 
 with color red at (1,1)
diff: 
correct output grid

TRAIN f8ff0b80.json/3: 1 1st (SUCCESS)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (4,4) with mask 
. . 0 . 
. 0 0 . 
0 . 0 0 
. . 0 . 
 with color pink at (8,5)
  _01: rectangle with size (2,3) with mask 
. 0 0 
0 0 0 
 with color blue at (5,3)
  _011: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color green at (1,1)
diff:   ^.layer_011.shape.color
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (2,3) with mask 
. 0 0 
0 0 0 
 with color blue at (5,3)
  _01: rectangle with size (4,4) with mask 
. . 0 . 
. 0 0 . 
0 . 0 0 
. . 0 . 
 with color pink at (8,5)
  _011: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color green at (1,1)
diff:   ^.layer_011.shape.color
! 3 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (12,12) and color black and layers
  _0: rectangle with size (2,3) with mask 
. 0 0 
0 0 0 
 with color blue at (5,3)
  _01: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color green at (1,1)
  _011: rectangle with size (4,4) with mask 
. . 0 . 
. 0 0 . 
0 . 0 0 
. . 0 . 
 with color pink at (8,5)
diff:   ^.layer_011.shape.color
! 3 wrong pixels (generated / expected)

TEST f8ff0b80.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.1 sec (3.1 sec/task)
bits-train-error = 0.0 bits (0.0 bits/task)
acc-train-micro = 1.00 tasks (100.00%)
acc-train-macro = 1.00 tasks (100.00%)
acc-train-mrr = 1.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-7] Checking task f9012d9b.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 35128.5 = 35130.8
DL output with Mo: L = 2.3 + 3724.3 = 3726.6
DL input+output M: L = 4.6 + 38852.7 = 38857.4

# learning a model for train pairs
2.000	
1.349	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.863	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.522	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.406	OUT ADD ^.layer_0 = point with color ? at (?,?)
0.330	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.258	OUT SPE ^.size = ^.layer_01.shape.mask.size
0.214	OUT SPE ^.layer_0.shape.color = ^.color
0.198	OUT SPE ^.layer_0.pos.j = ^.layer_01.pos.j / '3
0.182	OUT SPE ^.layer_0.pos.i = ^.layer_01.pos.i / '3
0.177	IN  SPE ^.layer_01.shape.color = black
0.175	IN  SPE ^.layer_01.shape.mask.model = Full
0.086	
0.086	IN  GEN ^.layer_01.shape.color = ?
0.086	IN  GEN ^.layer_01.shape.mask.model = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_01.shape.mask.size and color ? and layers
  _0: point with color ^.color at (^.layer_01.pos.i / '3,^.layer_01.pos.j / '3)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color black at (?,?)

DL input  with Mi: L = 74.2 + 3106.9 = 3181.1
DL output with Mo: L = 110.6 + 203.9 = 314.5
DL input+output M: L = 184.8 + 3310.8 = 3495.5

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_01.shape.mask.size and color ? and layers
  _0: point with color ^.color at (^.layer_01.pos.i / '3,^.layer_01.pos.j / '3)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 70.2 + 0.0 = 70.2
DL output with Mo: L = 110.6 + 203.9 = 314.5
DL input+output M: L = 180.8 + 203.9 = 384.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (5,5) and color red and layers
  _0: rectangle with size (5,5) with mask 
. 0 . 0 . 
0 0 0 0 0 
. 0 . 0 . 
. . 0 0 0 
. . . 0 . 
 with color blue at (0,0)
  _01: rectangle with size (2,2) with model Full with color black at (3,0)
diff: 
   (0.0 bits)
data: a background with size (2,2) and color blue and layers
  _0: point with color red at (1,0)
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (5,5) and color red and layers
  _0: rectangle with size (5,5) with mask 
. 0 . 0 . 
0 0 0 0 0 
. 0 . 0 . 
. . 0 0 0 
. . . 0 . 
 with color blue at (0,0)
  _01: rectangle with size (2,2) with model Full with color black at (3,0)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (5,5) and color red and layers
  _0: rectangle with size (2,2) with model Full with color black at (3,0)
  _01: rectangle with size (5,5) with mask 
. 0 . 0 . 
0 0 0 0 0 
. 0 . 0 . 
. . 0 0 0 
. . . 0 . 
 with color blue at (0,0)
diff: 
! size mismatch, 5x5 instead of 2x2

TRAIN f9012d9b.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (4,4) and color cyan and layers
  _0: rectangle with size (4,4) with model Odd Checkboard with color pink at (0,0)
  _01: rectangle with size (1,1) with model Full with color black at (0,2)
diff: 
   (0.0 bits)
data: a background with size (1,1) and color black and layers
  _0: point with color cyan at (0,0)
diff: 
   (2.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (4,4) and color cyan and layers
  _0: rectangle with size (4,4) with model Odd Checkboard with color pink at (0,0)
  _01: rectangle with size (1,1) with model Full with color black at (0,2)
diff: 
correct output grid

TRAIN f9012d9b.json/2: 1 1st (SUCCESS)

## instance 3

> Input and output best reading:

data: a background with size (7,7) and color red and layers
  _0: rectangle with size (7,7) with mask 
. . 0 . . 0 . 
. . 0 . . 0 . 
0 0 0 0 0 0 0 
. . 0 . . 0 . 
. . 0 . . 0 . 
0 0 0 0 0 . . 
. . 0 . . . . 
 with color grey at (0,0)
  _01: rectangle with size (2,2) with model Full with color black at (5,5)
diff: 
   (0.0 bits)
data: a background with size (2,2) and color grey and layers
  _0: point with color red at (1,1)
diff: 
   (9.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color red and layers
  _0: rectangle with size (7,7) with mask 
. . 0 . . 0 . 
. . 0 . . 0 . 
0 0 0 0 0 0 0 
. . 0 . . 0 . 
. . 0 . . 0 . 
0 0 0 0 0 . . 
. . 0 . . . . 
 with color grey at (0,0)
  _01: rectangle with size (2,2) with model Full with color black at (5,5)
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (7,7) and color red and layers
  _0: rectangle with size (2,2) with model Full with color black at (5,5)
  _01: rectangle with size (7,7) with mask 
. . 0 . . 0 . 
. . 0 . . 0 . 
0 0 0 0 0 0 0 
. . 0 . . 0 . 
. . 0 . . 0 . 
0 0 0 0 0 . . 
. . 0 . . . . 
 with color grey at (0,0)
diff: 
! size mismatch, 7x7 instead of 2x2

TRAIN f9012d9b.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (7,7) and color blue and layers
  _0: rectangle with size (3,3) with model Full with color black at (0,4)
  _01: rectangle with size (7,7) with mask 
0 . 0 0 . . . 
. 0 0 . . . . 
0 0 . 0 . . . 
0 . 0 0 . 0 0 
. 0 0 . 0 0 . 
0 0 . 0 0 . 0 
0 . 0 0 . 0 0 
 with color cyan at (0,0)
diff: 
! size mismatch, 7x7 instead of 3x3

TEST f9012d9b.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 5.6 sec (5.6 sec/task)
bits-train-error = 203.9 bits (203.9 bits/task)
acc-train-micro = 0.33 tasks (33.33%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.33
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-6] Checking task fafffa47.json: 5 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 34872.1 = 34874.5
DL output with Mo: L = 2.3 + 17558.0 = 17560.3
DL input+output M: L = 4.6 + 52430.1 = 52434.8

# learning a model for train pairs
2.000	
1.305	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.819	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.602	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.452	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.334	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.297	OUT SPE ^.size = ^.size - (3, 0)
0.281	OUT SPE ^.layer_0.shape.color = red
0.270	OUT SPE ^.layer_0.pos.i = ^.layer_0.pos.i
0.262	IN  SPE ^.layer_0.shape.color = brown
0.254	IN  SPE ^.layer_01.shape.color = blue
0.247	OUT SPE ^.color = black
0.244	IN  SPE ^.color = black
0.118	
0.117	IN  DEL ^.layer_01
0.117	IN  GEN ^.layer_0.shape.color = ?
0.117	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size - (3, 0) and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at (^.layer_0.pos.i,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color brown at (?,?)
  _01: rectangle with size (?,?) with model ? with color blue at (?,?)

DL input  with Mi: L = 77.0 + 4392.2 = 4469.2
DL output with Mo: L = 55.1 + 1974.5 = 2029.6
DL input+output M: L = 132.1 + 6366.8 = 6498.8

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size - (3, 0) and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at (^.layer_0.pos.i,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 42.0 + 0.0 = 42.0
DL output with Mo: L = 55.1 + 1974.5 = 2029.6
DL input+output M: L = 97.1 + 1974.5 = 2071.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (6,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
. 0 0 
0 0 0 
 with color brown at (0,0)
  + 5 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,1) with model Full with color red at (0,0)
diff: 
   (15.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
. 0 0 
0 0 0 
 with color brown at (0,0)
  + 5 delta pixels
diff: 
! 2 wrong pixels (generated / expected)

TRAIN fafffa47.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (6,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
. 0 0 
. . 0 
 with color brown at (0,0)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,1)
  + 1 delta pixels
diff: 
   (51.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
. 0 0 
. . 0 
 with color brown at (0,0)
  + 4 delta pixels
diff: 
! 4 wrong pixels (generated / expected)

TRAIN fafffa47.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (6,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 . 0 
0 . . 
 with color brown at (0,0)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
. 0 . 
. 0 0 
 with color red at (0,0)
diff: 
   (27.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 . 
0 . 0 
0 . . 
 with color brown at (0,0)
  + 2 delta pixels
diff: 
! 5 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,3) and color black and layers
  _0: rectangle with size (2,1) with model Full with color brown at (1,0)
  + 4 delta pixels
diff: 
! 5 wrong pixels (generated / expected)

TRAIN fafffa47.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (6,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. 0 . 
 with color brown at (0,0)
  + 4 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,1)
  + 1 delta pixels
diff: 
   (51.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. . 0 
0 0 0 
. 0 . 
 with color brown at (0,0)
  + 4 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . . 
. 0 0 
. . 0 
 with color blue at (3,0)
  + 5 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (6,3) and color black and layers
  _0: rectangle with size (1,3) with model Full with color brown at (1,0)
  + 6 delta pixels
diff: 
! 4 wrong pixels (generated / expected)

TRAIN fafffa47.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: a background with size (6,3) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 . 
0 0 
0 0 
 with color brown at (0,1)
  + 5 delta pixels
diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (0,0)
  + 1 delta pixels
diff: 
   (51.4 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,3) and color black and layers
  _0: rectangle with size (3,2) with mask 
0 . 
0 0 
0 0 
 with color brown at (0,1)
  + 5 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,3) and color black and layers
  _0: rectangle with size (2,3) with mask 
0 0 0 
0 . 0 
 with color blue at (4,0)
  + 5 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (6,3) and color black and layers
  _0: rectangle with size (2,2) with model Full with color brown at (1,1)
  + 6 delta pixels
diff: 
! 6 wrong pixels (generated / expected)

TRAIN fafffa47.json/5: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (6,3) and color brown and layers
  _0: rectangle with size (6,3) with mask 
. 0 . 
0 0 . 
. 0 . 
0 . . 
0 . 0 
. 0 0 
 with color black at (0,0)
  + 4 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (6,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
. 0 0 
. 0 . 
0 . . 
 with color blue at (3,0)
  + 5 delta pixels
diff: 
! 2 wrong pixels (generated / expected)

TEST fafffa47.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 3.8 sec (3.8 sec/task)
bits-train-error = 1974.5 bits (1974.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-5] Checking task fcb5c309.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 251690.9 = 251693.2
DL output with Mo: L = 2.3 + 54875.4 = 54877.7
DL input+output M: L = 4.6 + 306566.3 = 306570.9

# learning a model for train pairs
2.000	
1.264	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.711	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.305	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.197	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.134	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.114	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.104	OUT SPE ^.size = ^.layer_0.shape.mask.size
0.096	OUT SPE ^.layer_0.shape.mask.size = ^.layer_0.shape.mask.size - (2, 2)
0.090	OUT SPE ^.layer_0.pos = '(1, 1)
0.087	OUT SPE ^.layer_0.shape.color = black
0.085	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.080	OUT SPE ^.color = ^.layer_0111.shape.color
0.077	IN  ADD ^.layer_01111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.076	IN  ADD ^.layer_011111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.073	IN  ADD ^.layer_0111111 = point with color ? at (?,?)
0.070	IN  ADD ^.layer_01111111 = point with color ? at (?,?)
0.070	IN  SPE ^.layer_0.shape.mask.model = Border
0.069	IN  SPE ^.layer_01.shape.mask.model = Border
0.069	IN  SPE ^.layer_011111.shape.mask.model = Full
0.068	IN  SPE ^.color = black
0.011	
0.011	IN  DEL ^.layer_011111
0.011	IN  DEL ^.layer_01111
0.011	IN  DEL ^.layer_01111111
0.010	IN  DEL ^.layer_0111111
0.010	IN  GEN ^.layer_01.shape.mask.model = ?
0.010	IN  GEN ^.layer_0.shape.mask.model = ?
0.010	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color ^.layer_0111.shape.color and layers
  _0: rectangle with size ^.layer_0.shape.mask.size - (2, 2) with model ? with color black at '(1, 1)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model Border with color ? at (?,?)
  _01: rectangle with size (?,?) with model Border with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01111: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011111: rectangle with size (?,?) with model Full with color ? at (?,?)
  _0111111: point with color ? at (?,?)
  _01111111: point with color ? at (?,?)

DL input  with Mi: L = 223.4 + 14488.6 = 14712.0
DL output with Mo: L = 85.8 + 459.8 = 545.6
DL input+output M: L = 309.2 + 14948.4 = 15257.6

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_0.shape.mask.size and color ^.layer_0111.shape.color and layers
  _0: rectangle with size ^.layer_0.shape.mask.size - (2, 2) with model ? with color black at '(1, 1)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 125.8 + 0.0 = 125.8
DL output with Mo: L = 85.8 + 459.8 = 545.6
DL input+output M: L = 211.6 + 459.8 = 671.4

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (13,13) and color black and layers
  _0: rectangle with size (7,7) with model Border with color red at (2,0)
  _01: rectangle with size (4,3) with model Border with color red at (3,10)
  _011: rectangle with size (2,2) with model Odd Checkboard with color yellow at (9,9)
  _0111: rectangle with size (1,1) with model Full with color yellow at (0,4)
  + 6 delta pixels
diff: 
   (0.0 bits)
data: a background with size (7,7) and color yellow and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 0 0 
. 0 0 0 0 
0 0 0 0 0 
0 0 0 . 0 
0 0 0 0 0 
 with color black at (1,1)
diff: 
   (12.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (7,7) with model Border with color red at (2,0)
  _01: rectangle with size (4,3) with model Border with color red at (3,10)
  _011: rectangle with size (2,2) with model Odd Checkboard with color yellow at (9,9)
  _0111: rectangle with size (1,1) with model Full with color yellow at (0,4)
  + 6 delta pixels
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,13) and color black and layers
  _0: rectangle with size (4,3) with model Border with color red at (3,10)
  _01: rectangle with size (7,7) with model Border with color red at (2,0)
  _011: rectangle with size (2,2) with model Odd Checkboard with color yellow at (9,9)
  _0111: rectangle with size (1,1) with model Full with color yellow at (0,4)
  + 6 delta pixels
diff: 
! size mismatch, 4x3 instead of 7x7

TRAIN fcb5c309.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (13,16) and color black and layers
  _0: rectangle with size (6,7) with model Border with color blue at (2,8)
  _01: rectangle with size (5,6) with model Border with color blue at (7,1)
  _011: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color green at (11,10)
  _0111: rectangle with size (2,2) with model Odd Checkboard with color green at (1,3)
  + 11 delta pixels
diff: 
   (0.0 bits)
data: a background with size (6,7) and color green and layers
  _0: rectangle with size (4,5) with mask 
0 0 . 0 0 
0 0 0 0 0 
. 0 . 0 0 
0 0 0 0 0 
 with color black at (1,1)
diff: 
   (14.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (13,16) and color black and layers
  _0: rectangle with size (6,7) with model Border with color blue at (2,8)
  _01: rectangle with size (5,6) with model Border with color blue at (7,1)
  _011: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color green at (11,10)
  _0111: rectangle with size (2,2) with model Odd Checkboard with color green at (1,3)
  + 11 delta pixels
diff: 
! 3 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (13,16) and color black and layers
  _0: rectangle with size (5,6) with model Border with color blue at (7,1)
  _01: rectangle with size (6,7) with model Border with color blue at (2,8)
  _011: rectangle with size (2,2) with mask 
. 0 
0 0 
 with color green at (11,10)
  _0111: rectangle with size (2,2) with model Odd Checkboard with color green at (1,3)
  + 11 delta pixels
diff: 
! size mismatch, 5x6 instead of 6x7

TRAIN fcb5c309.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (15,16) and color black and layers
  _0: rectangle with size (7,7) with model Border with color green at (1,1)
  _01: rectangle with size (5,4) with model Border with color green at (3,10)
  _011: rectangle with size (4,3) with model Border with color green at (10,3)
  _0111: rectangle with size (1,1) with model Full with color red at (0,8)
  + 13 delta pixels
diff: 
   (0.0 bits)
data: a background with size (7,7) and color red and layers
  _0: rectangle with size (5,5) with mask 
0 . 0 . 0 
0 0 0 0 0 
0 0 0 0 0 
0 . 0 0 0 
0 0 0 0 . 
 with color black at (1,1)
diff: 
   (18.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (15,16) and color black and layers
  _0: rectangle with size (7,7) with model Border with color green at (1,1)
  _01: rectangle with size (5,4) with model Border with color green at (3,10)
  _011: rectangle with size (4,3) with model Border with color green at (10,3)
  _0111: rectangle with size (1,1) with model Full with color red at (0,8)
  + 13 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (15,16) and color black and layers
  _0: rectangle with size (5,4) with model Border with color green at (3,10)
  _01: rectangle with size (7,7) with model Border with color green at (1,1)
  _011: rectangle with size (4,3) with model Border with color green at (10,3)
  _0111: rectangle with size (1,1) with model Full with color red at (0,8)
  + 13 delta pixels
diff: 
! size mismatch, 5x4 instead of 7x7

TRAIN fcb5c309.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (8,8) with model Border with color blue at (1,4)
  _01: rectangle with size (5,6) with model Border with color blue at (11,10)
  _011: rectangle with size (3,3) with model Border with color blue at (2,0)
  _0111: rectangle with size (2,3) with mask 
. . 0 
0 0 . 
 with color cyan at (13,3)
  + 20 delta pixels
diff: 
! 4 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (17,17) and color black and layers
  _0: rectangle with size (5,6) with model Border with color blue at (11,10)
  _01: rectangle with size (8,8) with model Border with color blue at (1,4)
  _011: rectangle with size (3,3) with model Border with color blue at (2,0)
  _0111: rectangle with size (2,3) with mask 
. . 0 
0 0 . 
 with color cyan at (13,3)
  + 20 delta pixels
diff: 
! size mismatch, 5x6 instead of 8x8

TEST fcb5c309.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 8.5 sec (8.5 sec/task)
bits-train-error = 459.8 bits (459.8 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-4] Checking task fcc82909.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 119775.8 = 119778.2
DL output with Mo: L = 2.3 + 119775.8 = 119778.2
DL input+output M: L = 4.6 + 239551.7 = 239556.3

# learning a model for train pairs
2.000	
1.100	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.319	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.250	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.218	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.203	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.187	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.168	OUT ADD ^.layer_00 = ^.layer_0
0.155	OUT ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.143	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.131	IN  ADD ^.layer_00 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.120	OUT ADD ^.layer_001 = ^.layer_00
0.109	OUT ADD ^.layer_010 = ^.layer_01
0.103	IN  ADD ^.layer_011 = point with color ? at (?,?)
0.096	OUT SPE ^.layer_011 = ^.layer_011
0.090	IN  ADD ^.layer_0111 = point with color ? at (?,?)
0.083	OUT SPE ^.layer_0111 = ^.layer_0111
0.078	OUT SPE ^.size = ^.size
0.075	OUT SPE ^.layer_01.shape.mask = 
0 0 
0 0 

0.072	OUT SPE ^.layer_01.pos = ^.layer_0.pos + projI(^.layer_01.shape.mask.size)
0.071	OUT SPE ^.layer_0.shape.color = green
0.069	OUT SPE ^.layer_01.shape.color = green
0.068	OUT SPE ^.layer_0.shape.mask.size.j = area(^.layer_00.shape)
0.067	OUT SPE ^.layer_0.pos.i = ^.layer_011.pos.i + 2
0.066	OUT SPE ^.layer_0.pos = min(^.layer_011.pos, ^.layer_0111.pos) + (2, 0)
0.065	IN  SPE ^.layer_01.shape.mask.model = Full
0.064	IN  SPE ^.color = black
0.064	OUT SPE ^.color = black
0.017	
0.017	IN  GEN ^.layer_01.shape.mask.model = ?
0.017	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _001: ^.layer_00
  _0: rectangle with size (?,area(^.layer_00.shape)) with model ? with color green at min(^.layer_011.pos, ^.layer_0111.pos) + (2, 0)
  _010: ^.layer_01
  _01: 
0 0 
0 0 
 with color green at ^.layer_0.pos + projI(^.layer_01.shape.mask.size)
  _011: ^.layer_011
  _0111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color black and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model Full with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 134.4 + 5543.5 = 5678.0
DL output with Mo: L = 196.3 + 1763.5 = 1959.7
DL input+output M: L = 330.7 + 7307.0 = 7637.7

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.size and color black and layers
  _00: ^.layer_0
  _001: ^.layer_00
  _0: rectangle with size (?,area(^.layer_00.shape)) with model ? with color green at min(^.layer_011.pos, ^.layer_0111.pos) + (2, 0)
  _010: ^.layer_01
  _01: 
0 0 
0 0 
 with color green at ^.layer_0.pos + projI(^.layer_01.shape.mask.size)
  _011: ^.layer_011
  _0111: ^.layer_0111
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _00: rectangle with size (?,?) with model ? with color ? at (?,?)
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: point with color ? at (?,?)
  _0111: point with color ? at (?,?)

DL input  with Mi: L = 133.8 + 0.0 = 133.8
DL output with Mo: L = 196.3 + 1763.5 = 1959.7
DL input+output M: L = 330.0 + 1763.5 = 2093.5

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _00: rectangle with size (1,2) with model Full with color brown at (2,1)
  _0: rectangle with size (1,2) with model Full with color pink at (3,1)
  _01: rectangle with size (1,2) with model Full with color orange at (6,5)
  _011: point with color cyan at (5,5)
  _0111: point with color yellow at (5,6)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
6 6 
 at (3,1)
  _001: 
9#9#
 at (2,1)
  _0: rectangle with size (3,2) with model Full with color green at (7,5)
  _010: 
7#7#
 at (6,5)
  _01: 
0 0 
0 0 
 with color green at (4,1)
  _011: 
8 
 at (5,5)
  _0111: 
4 
 at (5,6)
diff: 
   (9.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (1,2) with model Full with color brown at (2,1)
  _0: rectangle with size (1,2) with model Full with color pink at (3,1)
  _01: rectangle with size (1,2) with model Full with color orange at (6,5)
  _011: point with color cyan at (5,5)
  _0111: point with color yellow at (5,6)
diff: 
! 2 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (1,2) with model Full with color brown at (2,1)
  _0: rectangle with size (1,2) with model Full with color orange at (6,5)
  _01: rectangle with size (1,2) with model Full with color pink at (3,1)
  _011: point with color cyan at (5,5)
  _0111: point with color yellow at (5,6)
diff: 
! 6 wrong pixels (generated / expected)

TRAIN fcc82909.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _00: rectangle with size (2,2) with model Even Checkboard with color yellow at (1,2)
  _0: rectangle with size (2,2) with model Odd Checkboard with color blue at (4,6)
  _01: rectangle with size (2,2) with model Full with color red at (4,6)
  _011: point with color cyan at (1,3)
  _0111: point with color brown at (2,2)
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
. 1 
1 . 
 at (4,6)
  _001: 
4 . 
. 4 
 at (1,2)
  _0: rectangle with size (3,2) with model Full with color green at (3,2)
  _010: 
2 2 
2 2 
 at (4,6)
  _01: 
0 0 
0 0 
 with color green at (6,6)
  _011: 
8 
 at (1,3)
  _0111: 
9#
 at (2,2)
diff: 
   (9.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (2,2) with model Even Checkboard with color yellow at (1,2)
  _0: rectangle with size (2,2) with model Odd Checkboard with color blue at (4,6)
  _01: rectangle with size (2,2) with model Full with color red at (4,6)
  _011: point with color cyan at (1,3)
  _0111: point with color brown at (2,2)
diff: 
! 2 wrong pixels (generated / expected)

TRAIN fcc82909.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (10,10) and color black and layers
  _00: rectangle with size (2,2) with model Full with color pink at (5,4)
  _0: rectangle with size (2,2) with model Odd Checkboard with color cyan at (1,6)
  _01: rectangle with size (2,2) with model Full with color brown at (1,6)
  _011: point with color red at (1,2)
  _0111: point with color yellow at (1,3)
  + 3 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _00: 
. 8 
8 . 
 at (1,6)
  _001: 
6 6 
6 6 
 at (5,4)
  _0: rectangle with size (6,4) with mask 
0 0 . . 
0 0 . . 
0 0 . . 
0 0 . . 
. . 0 0 
. . 0 0 
 with color green at (3,2)
  _010: 
9#9#
9#9#
 at (1,6)
  _01: 
0 0 
0 0 
 with color green at (3,6)
  _011: 
2 
 at (1,2)
  _0111: 
4 
 at (1,3)
  + 3 delta pixels
diff: 
   (157.7 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (2,2) with model Full with color pink at (5,4)
  _0: rectangle with size (2,2) with model Odd Checkboard with color cyan at (1,6)
  _01: rectangle with size (2,2) with model Full with color brown at (1,6)
  _011: point with color red at (1,2)
  _0111: point with color yellow at (1,3)
  + 3 delta pixels
diff: 
! 15 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (2,2) with model Full with color pink at (5,4)
  _0: rectangle with size (2,2) with model Odd Checkboard with color cyan at (1,6)
  _01: rectangle with size (2,2) with model Full with color brown at (1,6)
  _011: point with color red at (1,2)
  _0111: point with color pink at (2,2)
  + 3 delta pixels
diff: 
! 15 wrong pixels (generated / expected)

TRAIN fcc82909.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (2,2) with model Full with color blue at (1,0)
  _0: rectangle with size (2,2) with model Even Checkboard with color yellow at (3,3)
  _01: rectangle with size (1,1) with model Full with color red at (1,6)
  _011: point with color brown at (1,7)
  _0111: point with color blue at (2,6)
  + 4 delta pixels
diff: 
! 20 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (10,10) and color black and layers
  _00: rectangle with size (2,2) with model Full with color blue at (1,0)
  _0: rectangle with size (2,2) with model Even Checkboard with color yellow at (3,3)
  _01: rectangle with size (1,1) with model Full with color red at (1,6)
  _011: point with color brown at (1,7)
  _0111: point with color pink at (2,7)
  + 4 delta pixels
diff: 
! 22 wrong pixels (generated / expected)

TEST fcc82909.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 26.6 sec (26.6 sec/task)
bits-train-error = 1763.5 bits (1763.5 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-3] Checking task feca6190.json: 5 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 9977.9 = 9980.3
DL output with Mo: L = 2.3 + 243347.8 = 243350.1
DL input+output M: L = 4.6 + 253325.8 = 253330.4

# learning a model for train pairs
2.000	
1.173	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.611	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.493	IN  ADD ^.layer_0 = point with color ? at (?,?)
0.434	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.396	OUT ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.375	OUT ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.362	IN  SPE ^.color = black
0.360	OUT SPE ^.size.j = ^.size.j * colorCount(^)
0.359	OUT SPE ^.size.i = ^.size.j * colorCount(^)
0.357	OUT SPE ^.layer_0.shape.color = ^.layer_0.shape.color
0.356	OUT SPE ^.layer_0.pos.i = ^.layer_0.pos.j
0.355	OUT SPE ^.layer_01.pos.i = center(^.layer_0) + 1
0.355	OUT SPE ^.color = black
0.050	
0.050	IN  GEN ^.color = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size (^.size.j * colorCount(^),^.size.j * colorCount(^)) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (^.layer_0.pos.j,?)
  _01: rectangle with size (?,?) with model ? with color ? at (center(^.layer_0) + 1,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.3 + 3037.5 = 3069.9
DL output with Mo: L = 167.2 + 11302.3 = 11469.5
DL input+output M: L = 199.5 + 14339.8 = 14539.4

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size (^.size.j * colorCount(^),^.size.j * colorCount(^)) and color black and layers
  _0: rectangle with size (?,?) with model ? with color ^.layer_0.shape.color at (^.layer_0.pos.j,?)
  _01: rectangle with size (?,?) with model ? with color ? at (center(^.layer_0) + 1,?)
  _011: rectangle with size (?,?) with model ? with color ? at (?,?)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: point with color ? at (?,?)

DL input  with Mi: L = 32.2 + 0.0 = 32.2
DL output with Mo: L = 167.2 + 11302.3 = 11469.5
DL input+output M: L = 199.4 + 11302.3 = 11501.7

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (1,5) and color black and layers
  _0: point with color blue at (0,0)
  + 1 delta pixels
diff: 
   (0.0 bits)
data: a background with size (10,10) and color black and layers
  _0: rectangle with size (10,10) with mask 
. . . . . . . . . 0 
. . . . . . . . 0 . 
. . . . . . . 0 . . 
. . . . . . 0 . . . 
. . . . . 0 . . . . 
. . . . 0 . . . . . 
. . . 0 . . . . . . 
. . 0 . . . . . . . 
. 0 . . . . . . . . 
0 . . . . . . . . . 
 with color blue at (0,0)
  _01: rectangle with size (1,1) with model Full with color orange at (2,9)
  _011: rectangle with size (1,1) with model Full with color orange at (3,8)
  + 6 delta pixels
diff: 
   (366.0 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (1,5) and color black and layers
  _0: point with color blue at (0,0)
  + 1 delta pixels
diff: 
! 26 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (1,5) and color black and layers
  _0: point with color orange at (0,2)
  + 1 delta pixels
diff: 
! 30 wrong pixels (generated / expected)

TRAIN feca6190.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (1,5) and color black and layers
  _0: point with color red at (0,2)
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (1,1) with model Full with color red at (2,4)
  _01: rectangle with size (1,1) with model Full with color red at (4,2)
  _011: rectangle with size (1,1) with model Full with color red at (3,3)
diff: 
   (58.3 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (1,5) and color black and layers
  _0: point with color red at (0,2)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (1,5) and color red and layers
  _0: point with color black at (0,0)
  + 3 delta pixels
diff: 
! 7 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (1,5) and color red and layers
  _0: point with color black at (0,1)
  + 3 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN feca6190.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (1,5) and color black and layers
  _0: point with color yellow at (0,0)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (15,15) with mask 
. . . . . . . . . . . . . . 0 
. . . . . . . . . . . . . 0 . 
. . . . . . . . . . . . 0 . . 
. . . . . . . . . . . 0 . . . 
. . . . . . . . . . 0 . . . . 
. . . . . . . . . 0 . . . . . 
. . . . . . . . 0 . . . . . . 
. . . . . . . 0 . . . . . . . 
. . . . . . 0 . . . . . . . . 
. . . . . 0 . . . . . . . . . 
. . . . 0 . . . . . . . . . . 
. . . 0 . . . . . . . . . . . 
. . 0 . . . . . . . . . . . . 
. 0 . . . . . . . . . . . . . 
0 . . . . . . . . . . . . . . 
 with color yellow at (0,0)
  _01: rectangle with size (13,13) with mask 
. . . . . . . . . . . . 0 
. . . . . . . . . . . 0 . 
. . . . . . . . . . 0 . . 
. . . . . . . . . 0 . . . 
. . . . . . . . 0 . . . . 
. . . . . . . 0 . . . . . 
. . . . . . 0 . . . . . . 
. . . . . 0 . . . . . . . 
. . . . 0 . . . . . . . . 
. . . 0 . . . . . . . . . 
. . 0 . . . . . . . . . . 
. 0 . . . . . . . . . . . 
0 . . . . . . . . . . . . 
 with color pink at (2,2)
  _011: rectangle with size (11,11) with mask 
. . . . . . . . . . 0 
. . . . . . . . . 0 . 
. . . . . . . . 0 . . 
. . . . . . . 0 . . . 
. . . . . . 0 . . . . 
. . . . . 0 . . . . . 
. . . . 0 . . . . . . 
. . . 0 . . . . . . . 
. . 0 . . . . . . . . 
. 0 . . . . . . . . . 
0 . . . . . . . . . . 
 with color cyan at (4,4)
diff: 
   (311.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (1,5) and color black and layers
  _0: point with color yellow at (0,0)
  + 2 delta pixels
diff: 
! 47 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (1,5) and color black and layers
  _0: point with color pink at (0,2)
  + 2 delta pixels
diff: 
! 51 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (1,5) and color black and layers
  _0: point with color cyan at (0,4)
  + 2 delta pixels
diff: 
! 51 wrong pixels (generated / expected)

TRAIN feca6190.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: a background with size (1,5) and color black and layers
  _0: point with color brown at (0,1)
  + 2 delta pixels
diff: 
   (0.0 bits)
data: a background with size (15,15) and color black and layers
  _0: rectangle with size (14,14) with mask 
. . . . . . . . . . . . . 0 
. . . . . . . . . . . . 0 . 
. . . . . . . . . . . 0 . . 
. . . . . . . . . . 0 . . . 
. . . . . . . . . 0 . . . . 
. . . . . . . . 0 . . . . . 
. . . . . . . 0 . . . . . . 
. . . . . . 0 . . . . . . . 
. . . . . 0 . . . . . . . . 
. . . . 0 . . . . . . . . . 
. . . 0 . . . . . . . . . . 
. . 0 . . . . . . . . . . . 
. 0 . . . . . . . . . . . . 
0 . . . . . . . . . . . . . 
 with color brown at (1,1)
  _01: rectangle with size (12,12) with mask 
. . . . . . . . . . . 0 
. . . . . . . . . . 0 . 
. . . . . . . . . 0 . . 
. . . . . . . . 0 . . . 
. . . . . . . 0 . . . . 
. . . . . . 0 . . . . . 
. . . . . 0 . . . . . . 
. . . . 0 . . . . . . . 
. . . 0 . . . . . . . . 
. . 0 . . . . . . . . . 
. 0 . . . . . . . . . . 
0 . . . . . . . . . . . 
 with color cyan at (3,3)
  _011: rectangle with size (11,11) with mask 
. . . . . . . . . . 0 
. . . . . . . . . 0 . 
. . . . . . . . 0 . . 
. . . . . . . 0 . . . 
. . . . . . 0 . . . . 
. . . . . 0 . . . . . 
. . . . 0 . . . . . . 
. . . 0 . . . . . . . 
. . 0 . . . . . . . . 
. 0 . . . . . . . . . 
0 . . . . . . . . . . 
 with color yellow at (4,4)
diff: 
   (296.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (1,5) and color black and layers
  _0: point with color brown at (0,1)
  + 2 delta pixels
diff: 
! 47 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (1,5) and color black and layers
  _0: point with color cyan at (0,3)
  + 2 delta pixels
diff: 
! 49 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (1,5) and color black and layers
  _0: point with color yellow at (0,4)
  + 2 delta pixels
diff: 
! 49 wrong pixels (generated / expected)

TRAIN feca6190.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: a background with size (1,5) and color black and layers
  _0: point with color yellow at (0,1)
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (1,1) with model Full with color yellow at (1,4)
  _01: rectangle with size (1,1) with model Full with color yellow at (3,2)
  _011: rectangle with size (1,1) with model Full with color yellow at (2,3)
  + 1 delta pixels
diff: 
   (97.8 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (1,5) and color black and layers
  _0: point with color yellow at (0,1)
diff: 
! 13 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (1,5) and color yellow and layers
  _0: point with color black at (0,0)
  + 3 delta pixels
diff: 
! 8 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (1,5) and color yellow and layers
  _0: point with color black at (0,2)
  + 3 delta pixels
diff: 
! 9 wrong pixels (generated / expected)

TRAIN feca6190.json/5: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (1,5) and color black and layers
  _0: point with color pink at (0,1)
  + 3 delta pixels
diff: 
! 80 wrong pixels (generated / expected)
>> Trial 2
data: a background with size (1,5) and color black and layers
  _0: point with color orange at (0,2)
  + 3 delta pixels
diff: 
! 82 wrong pixels (generated / expected)
>> Trial 3
data: a background with size (1,5) and color black and layers
  _0: point with color cyan at (0,3)
  + 3 delta pixels
diff: 
! 82 wrong pixels (generated / expected)

TEST feca6190.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 55.0 sec (55.0 sec/task)
bits-train-error = 11302.3 bits (11302.3 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-2] Checking task ff28f65a.json: 8 train, 3 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 113859.5 = 113861.9
DL output with Mo: L = 2.3 + 28092.8 = 28095.1
DL input+output M: L = 4.6 + 141952.3 = 141957.0

# learning a model for train pairs
2.000	
1.314	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.640	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.469	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.327	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.290	OUT SPE ^.size = '(3, 3)
0.268	OUT SPE ^.layer_0.pos = '(0, 0)
0.252	OUT SPE ^.layer_0.shape.color = blue
0.245	OUT SPE ^.color = black
0.241	IN  SPE ^.layer_0.shape.color = red
0.240	IN  SPE ^.color = black
0.074	
0.073	IN  GEN ^ = ?

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: rectangle with size (?,?) with model ? with color blue at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color black and layers
  _0: rectangle with size (?,?) with model ? with color red at (?,?)

DL input  with Mi: L = 45.4 + 18899.8 = 18945.3
DL output with Mo: L = 56.5 + 1998.1 = 2054.6
DL input+output M: L = 101.9 + 20897.9 = 20999.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size '(3, 3) and color black and layers
  _0: rectangle with size (?,?) with model ? with color blue at '(0, 0)
WHERE (Mi)
?

DL input  with Mi: L = 2.3 + 0.0 = 2.3
DL output with Mo: L = 56.5 + 1998.1 = 2054.6
DL input+output M: L = 58.8 + 1998.1 = 2056.9

# train input/output grids

## instance 1

> Input and output best reading:

data: 
2 2 0 0 0 
2 2 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color blue at (0,0)
diff: 
   (9.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 2 0 0 0 
2 2 0 0 0 
0 0 0 0 0 
0 0 0 0 0 
0 0 0 0 0 

diff: 
! 3 wrong pixels (generated / expected)

TRAIN ff28f65a.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: 
0 0 0 0 0 
0 2 2 0 0 
0 2 2 0 0 
0 0 0 2 2 
0 0 0 2 2 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color blue at (0,0)
  + 1 delta pixels
diff: 
   (47.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 
0 2 2 0 0 
0 2 2 0 0 
0 0 0 2 2 
0 0 0 2 2 

diff: 
! 4 wrong pixels (generated / expected)

TRAIN ff28f65a.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: 
0 0 0 0 0 0 0 
0 2 2 0 0 0 0 
0 2 2 0 2 2 0 
0 0 0 0 2 2 0 
0 0 2 2 0 0 0 
0 0 2 2 0 0 0 
0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (2,3) with model Even Checkboard with color blue at (0,0)
diff: 
   (18.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 
0 2 2 0 0 0 0 
0 2 2 0 2 2 0 
0 0 0 0 2 2 0 
0 0 2 2 0 0 0 
0 0 2 2 0 0 0 
0 0 0 0 0 0 0 

diff: 
! 3 wrong pixels (generated / expected)

TRAIN ff28f65a.json/3: 0 - (FAILURE)

## instance 4

> Input and output best reading:

data: 
0 0 0 0 0 0 
0 2 2 0 0 0 
0 2 2 0 0 0 
0 0 0 0 0 0 
0 0 2 2 0 0 
0 0 2 2 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color blue at (0,0)
  + 1 delta pixels
diff: 
   (47.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 
0 2 2 0 0 0 
0 2 2 0 0 0 
0 0 0 0 0 0 
0 0 2 2 0 0 
0 0 2 2 0 0 

diff: 
! 4 wrong pixels (generated / expected)

TRAIN ff28f65a.json/4: 0 - (FAILURE)

## instance 5

> Input and output best reading:

data: 
0 0 0 
0 2 2 
0 2 2 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (1,1) with model Full with color blue at (0,0)
diff: 
   (9.5 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 
0 2 2 
0 2 2 

diff: 
! 3 wrong pixels (generated / expected)

TRAIN ff28f65a.json/5: 0 - (FAILURE)

## instance 6

> Input and output best reading:

data: 
0 0 0 0 2 2 0 
0 0 0 0 2 2 0 
0 2 2 0 0 0 0 
0 2 2 0 2 2 0 
0 0 0 0 2 2 0 
0 2 2 0 0 0 0 
0 2 2 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
. 0 . 
0 . . 
 with color blue at (0,0)
diff: 
   (23.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 2 2 0 
0 0 0 0 2 2 0 
0 2 2 0 0 0 0 
0 2 2 0 2 2 0 
0 0 0 0 2 2 0 
0 2 2 0 0 0 0 
0 2 2 0 0 0 0 

diff: 
! 4 wrong pixels (generated / expected)

TRAIN ff28f65a.json/6: 0 - (FAILURE)

## instance 7

> Input and output best reading:

data: 
0 0 0 0 2 2 0 
0 2 2 0 2 2 0 
0 2 2 0 0 0 0 
0 0 0 0 0 2 2 
2 2 0 0 0 2 2 
2 2 0 2 2 0 0 
0 0 0 2 2 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with model Even Checkboard with color blue at (0,0)
diff: 
   (19.6 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 2 2 0 
0 2 2 0 2 2 0 
0 2 2 0 0 0 0 
0 0 0 0 0 2 2 
2 2 0 0 0 2 2 
2 2 0 2 2 0 0 
0 0 0 2 2 0 0 

diff: 
! 5 wrong pixels (generated / expected)

TRAIN ff28f65a.json/7: 0 - (FAILURE)

## instance 8

> Input and output best reading:

data: 
0 0 2 2 0 2 2 
0 0 2 2 0 2 2 
2 2 0 0 0 0 0 
2 2 0 2 2 0 0 
0 0 0 2 2 0 0 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 

diff: 
   (0.0 bits)
data: a background with size (3,3) and color black and layers
  _0: rectangle with size (3,3) with mask 
0 . 0 
. 0 . 
0 . . 
 with color blue at (0,0)
diff: 
   (23.9 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 2 2 0 2 2 
0 0 2 2 0 2 2 
2 2 0 0 0 0 0 
2 2 0 2 2 0 0 
0 0 0 2 2 0 0 
0 0 0 0 0 0 0 
0 0 0 0 0 0 0 

diff: 
! 4 wrong pixels (generated / expected)

TRAIN ff28f65a.json/8: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 2 2 0 
2 2 0 2 2 0 
2 2 0 0 0 0 
0 0 2 2 0 0 
0 0 2 2 0 0 
0 0 0 0 0 0 

diff: 
! 3 wrong pixels (generated / expected)

TEST ff28f65a.json/1: 0 - (FAILURE)

## instance 2

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
0 0 0 0 0 0 0 
2 2 0 2 2 0 0 
2 2 0 2 2 0 0 
0 0 0 0 0 2 2 
0 0 2 2 0 2 2 
0 0 2 2 0 0 0 
0 0 0 0 0 0 0 

diff: 
! 4 wrong pixels (generated / expected)

TEST ff28f65a.json/2: 0 - (FAILURE)

## instance 3

> Output prediction from input (up to 3 trials):
>> Trial 1
data: 
2 2 0 2 2 0 0 
2 2 0 2 2 0 0 
0 0 0 0 0 2 2 
0 2 2 0 0 2 2 
0 2 2 0 0 0 0 
0 0 0 0 2 2 0 
0 0 0 0 2 2 0 

diff: 
! 5 wrong pixels (generated / expected)

TEST ff28f65a.json/3: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 1.7 sec (1.7 sec/task)
bits-train-error = 1998.1 bits (1998.1 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00

=====================================
[-1] Checking task ff805c23.json: 3 train, 1 test

# evaluating init_model
DL input  with Mi: L = 2.3 + 728099.8 = 728102.1
DL output with Mo: L = 2.3 + 29114.4 = 29116.7
DL input+output M: L = 4.6 + 757214.2 = 757218.8

# learning a model for train pairs
2.000	
1.300	OUT SPE ^ = a background with size (?,?) and color ? and layers
0.888	IN  SPE ^ = a background with size (?,?) and color ? and layers
0.631	IN  ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.420	OUT ADD ^.layer_0 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.343	IN  ADD ^.layer_01 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.305	IN  ADD ^.layer_011 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.271	IN  ADD ^.layer_0111 = rectangle with size (?,?) with model ? with color ? at (?,?)
0.255	OUT SPE ^.size = ^.layer_011.shape.mask.size - (1, 1)
0.240	OUT SPE ^.layer_0.shape.mask.size = ^.layer_011.shape.mask.size - (1, 1)
0.230	OUT SPE ^.layer_0.pos = '(0, 0)
0.228	OUT SPE ^.color = black
0.227	IN  SPE ^.layer_011.shape.color = green
0.046	
0.046	IN  DEL ^.layer_0111
0.046	IN  DEL ^.layer_01
0.046	IN  DEL ^.layer_0

# Learned model (decriptive, before pruning):
CONSTRUCT (Mo)
a background with size ^.layer_011.shape.mask.size - (1, 1) and color black and layers
  _0: rectangle with size ^.layer_011.shape.mask.size - (1, 1) with model ? with color ? at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _0: rectangle with size (?,?) with model ? with color ? at (?,?)
  _01: rectangle with size (?,?) with model ? with color ? at (?,?)
  _011: rectangle with size (?,?) with model ? with color green at (?,?)
  _0111: rectangle with size (?,?) with model ? with color ? at (?,?)

DL input  with Mi: L = 129.1 + 131950.4 = 132079.5
DL output with Mo: L = 96.2 + 1244.2 = 1340.3
DL input+output M: L = 225.3 + 133194.6 = 133419.9

# Learned model (predictive, after pruning):
CONSTRUCT (Mo)
a background with size ^.layer_011.shape.mask.size - (1, 1) and color black and layers
  _0: rectangle with size ^.layer_011.shape.mask.size - (1, 1) with model ? with color ? at '(0, 0)
WHERE (Mi)
a background with size (?,?) and color ? and layers
  _011: rectangle with size (?,?) with model ? with color green at (?,?)

DL input  with Mi: L = 45.3 + 0.0 = 45.3
DL output with Mo: L = 96.2 + 1244.2 = 1340.3
DL input+output M: L = 141.5 + 1244.2 = 1385.6

# train input/output grids

## instance 1

> Input and output best reading:

data: a background with size (24,24) and color red and layers
  _011: rectangle with size (6,6) with model Full with color green at (0,0)
  + 277 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (5,5) with mask 
. 0 0 0 0 
. 0 0 0 0 
0 . . 0 0 
0 0 0 . 0 
0 0 0 . 0 
 with color green at (0,0)
diff: 
   (28.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (24,24) and color black and layers
  _011: rectangle with size (24,24) with mask 
. . . . . . . 0 0 0 . . . . 0 0 0 . . . . . . . 
. . . . . . 0 0 . 0 0 . . 0 0 . 0 0 . . . . . . 
. . . . . . 0 . . 0 . . . . 0 . . 0 . . . . . . 
. . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 . . . . . . 
. . . . . . . 0 . 0 0 0 0 0 0 . 0 . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 . . . . . . . . . 
. 0 0 0 . . 0 . . 0 0 0 0 0 0 . . 0 . . 0 0 0 . 
0 0 . 0 0 . . 0 0 . 0 0 0 0 . 0 0 . . 0 0 . 0 0 
0 . . 0 . . . 0 0 . . 0 0 . . 0 0 . . . 0 . . 0 
0 0 0 0 0 0 0 . . 0 0 0 0 0 0 . . 0 0 0 0 0 0 0 
. 0 . 0 0 0 0 0 . 0 . 0 0 . 0 . 0 0 0 0 0 . 0 . 
. . . 0 0 0 0 0 0 0 0 . . 0 0 0 0 0 0 0 0 . . . 
. . . 0 0 0 0 0 0 0 0 . . 0 0 0 0 0 0 0 0 . . . 
. 0 . 0 0 0 0 0 . 0 . 0 0 . 0 . 0 0 0 0 0 . 0 . 
0 0 0 0 0 0 0 . . 0 0 0 0 0 0 . . 0 0 0 0 0 0 0 
0 . . 0 . . . 0 0 . . 0 0 . . 0 0 . . . 0 . . 0 
0 0 . 0 0 . . 0 0 . 0 0 0 0 . 0 0 . . 0 0 . 0 0 
. 0 0 0 . . 0 . . 0 0 0 0 0 0 . . 0 . . 0 0 0 . 
. . . . . . . . . 0 0 0 0 0 0 . . . . . . . . . 
. . . . . . . 0 . 0 0 0 0 0 0 . 0 . . . . . . . 
. . . . . . 0 0 0 0 0 0 0 0 0 0 0 0 . . . . . . 
. . . . . . 0 . . 0 . . . . 0 . . 0 . . . . . . 
. . . . . . 0 0 . 0 0 . . 0 0 . 0 0 . . . . . . 
. . . . . . . 0 0 0 . . . . 0 0 0 . . . . . . . 
 with color red at (0,0)
  + 114 delta pixels
diff:   ^.layer_011.shape.color
! size mismatch, 23x23 instead of 5x5
>> Trial 2
data: a background with size (24,24) and color red and layers
  _011: rectangle with size (6,6) with model Full with color green at (0,0)
  + 277 delta pixels
diff: 
! 25 wrong pixels (generated / expected)

TRAIN ff805c23.json/1: 0 - (FAILURE)

## instance 2

> Input and output best reading:

data: a background with size (24,24) and color black and layers
  _011: rectangle with size (6,6) with mask 
. 0 0 0 . 0 
0 . 0 . 0 . 
0 0 0 0 0 0 
0 . 0 . 0 0 
. 0 0 0 . . 
0 . 0 0 . . 
 with color green at (0,0)
  + 357 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (5,5) with mask 
0 0 0 0 0 
0 0 0 0 0 
0 0 . 0 0 
0 0 0 0 0 
0 . . 0 . 
 with color pink at (0,0)
diff: 
   (24.2 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (24,24) and color black and layers
  _011: rectangle with size (12,12) with mask 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 . 0 0 0 0 0 0 . 0 0 
0 . . 0 . 0 0 . 0 . . 0 
0 0 0 0 0 0 0 0 0 0 0 0 
0 0 . 0 0 0 0 0 0 . 0 0 
. . . . . . . 0 0 0 0 0 
. . . . . . . 0 0 0 0 0 
. . . . . 0 0 0 0 . 0 0 
. . . . . 0 0 0 0 0 0 0 
. . . . . 0 0 . 0 . . 0 
0 0 . 0 0 0 0 0 0 . 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 
 with color pink at (6,6)
  + 281 delta pixels
diff:   ^.layer_011.shape.color
! size mismatch, 11x11 instead of 5x5
>> Trial 2
data: a background with size (24,24) and color cyan and layers
  _011: rectangle with size (24,24) with mask 
. . . . . . . . . 0 . . . . 0 . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 . . . . . . . . . 
. . . . . . . . . 0 . . . . 0 . . . . . . . . . 
. . . 0 . . 0 0 0 . 0 . . 0 . 0 0 0 . . 0 . . . 
. . . . 0 0 . 0 . 0 0 . . 0 0 . 0 . 0 0 . . . . 
. . . . 0 . . 0 . . . 0 0 . . . 0 . . 0 . . . . 
. . . 0 . . . . . . . . . . . . . . . . 0 . . . 
. . . 0 0 0 . . . . . . . . . . . . 0 0 0 . . . 
. . . 0 . . . . . . . . . . . . . . . . 0 . . . 
0 0 0 . 0 . . . . . . . . . . . . . . 0 . 0 0 0 
. 0 . 0 0 . . . . . . . . . . . . . . 0 0 . 0 . 
. 0 . . . 0 . . . . . . . . . . . . 0 . . . 0 . 
. 0 . . . 0 . . . . . . . . . . . . 0 . . . 0 . 
. 0 . 0 0 . . . . . . . . . . . . . . 0 0 . 0 . 
0 0 0 . 0 . . . . . . . . . . . . . . 0 . 0 0 0 
. . . 0 . . . . . . . . . . . . . . . . 0 . . . 
. . . 0 0 0 . . . . . . . . . . . . 0 0 0 . . . 
. . . 0 . . . . . . . . . . . . . . . . 0 . . . 
. . . . 0 . . 0 . . . 0 0 . . . 0 . . 0 . . . . 
. . . . 0 0 . 0 . 0 0 . . 0 0 . 0 . 0 0 . . . . 
. . . 0 . . 0 0 0 . 0 . . 0 . 0 0 0 . . 0 . . . 
. . . . . . . . . 0 . . . . 0 . . . . . . . . . 
. . . . . . . . . 0 0 0 0 0 0 . . . . . . . . . 
. . . . . . . . . 0 . . . . 0 . . . . . . . . . 
 with color black at (0,0)
  + 288 delta pixels
diff:   ^.layer_011.shape.color
! size mismatch, 23x23 instead of 5x5

TRAIN ff805c23.json/2: 0 - (FAILURE)

## instance 3

> Input and output best reading:

data: a background with size (24,24) and color black and layers
  _011: rectangle with size (6,6) with mask 
. 0 0 0 0 . 
0 0 0 0 0 0 
0 0 0 . . . 
0 0 . . . . 
0 0 . . . . 
. 0 . . . . 
 with color green at (0,0)
  + 312 delta pixels
diff: 
   (0.0 bits)
data: a background with size (5,5) and color black and layers
  _0: rectangle with size (5,5) with mask 
. 0 0 . . 
. 0 0 . . 
0 0 0 0 . 
. . . . 0 
. . . . 0 
 with color grey at (0,0)
  + 1 delta pixels
diff: 
   (72.1 bits)

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (24,24) and color grey and layers
  _011: rectangle with size (24,24) with mask 
. . . . . . . . . 0 0 . . 0 0 . . . . . . . . . 
. . . . . . . . 0 0 0 0 0 0 0 0 . . . . . . . . 
. . . 0 0 0 . 0 0 . . 0 0 . . 0 0 . 0 0 0 . . . 
. . 0 0 . . 0 0 . 0 . . . . 0 . 0 0 . . 0 0 . . 
. . 0 . . 0 0 0 . . 0 0 0 0 . . 0 0 0 . . 0 . . 
. . 0 . 0 . . 0 0 . 0 0 0 0 . 0 0 . . 0 . 0 . . 
. . . 0 0 . 0 . 0 0 . . . . 0 0 . 0 . 0 0 . . . 
. . 0 0 0 0 . . . 0 0 . . 0 0 . . . 0 0 0 0 . . 
. 0 0 . . 0 0 . . . 0 . . 0 . . . 0 0 . . 0 0 . 
0 0 . 0 . . 0 0 . . . . . . . . 0 0 . . 0 . 0 0 
0 0 . . 0 0 . 0 0 . . . . . . 0 0 . 0 0 . . 0 0 
. 0 0 . 0 0 . . . . . . . . . . . . 0 0 . 0 0 . 
. 0 0 . 0 0 . . . . . . . . . . . . 0 0 . 0 0 . 
0 0 . . 0 0 . 0 0 . . . . . . 0 0 . 0 0 . . 0 0 
0 0 . 0 . . 0 0 . . . . . . . . 0 0 . . 0 . 0 0 
. 0 0 . . 0 0 . . . . . . . . . . 0 0 . . 0 0 . 
. . 0 0 0 0 . . . 0 . . . . . . . . 0 0 0 0 . . 
. . . 0 0 . 0 . 0 0 . . . . . 0 . 0 . 0 0 . . . 
. . 0 . 0 . . 0 0 . . . . . . 0 0 . . 0 . 0 . . 
. . 0 . . 0 0 0 . . . . . . . . 0 0 0 . . 0 . . 
. . 0 0 . . 0 0 . 0 . . . . 0 . 0 0 . . 0 0 . . 
. . . 0 0 0 . 0 0 . . 0 0 . . 0 0 . 0 0 0 . . . 
. . . . . . . . 0 0 0 0 0 0 0 0 . . . . . . . . 
. . . . . . . . . 0 0 . . 0 0 . . . . . . . . . 
 with color black at (0,0)
  + 141 delta pixels
diff:   ^.layer_011.shape.color
! size mismatch, 23x23 instead of 5x5
>> Trial 2
data: a background with size (24,24) and color black and layers
  _011: rectangle with size (17,20) with mask 
. . . . . . . 0 0 . . 0 0 . . . . . . . 
. . . . . . 0 . 0 0 0 0 . 0 . . . . . . 
. . . . . . 0 0 . . . . 0 0 . . . . . . 
. . . . 0 . . 0 . . . . 0 . . 0 . . . . 
. . . 0 . 0 . . 0 0 0 0 . . 0 . 0 . . . 
. . . . 0 0 0 . . 0 0 . . 0 0 0 . . . . 
. 0 0 . . 0 0 0 . 0 0 . 0 0 0 . . 0 0 . 
0 . 0 0 . . 0 0 0 0 0 0 0 0 . . 0 0 . 0 
0 0 . . 0 . . 0 . 0 0 . 0 . . 0 . . 0 0 
. 0 . . 0 0 0 0 0 . . 0 0 0 0 0 . . 0 . 
. 0 . . 0 0 0 0 0 . . 0 0 0 0 0 . . 0 . 
0 0 . . 0 . . 0 . 0 0 . 0 . . 0 . . 0 0 
0 . 0 0 . . 0 0 0 0 0 0 0 0 . . 0 0 . 0 
. 0 0 . . 0 0 0 . . . . . 0 0 . . 0 0 . 
. . . . 0 0 0 . . . . . . 0 0 0 . . . . 
. . . 0 . 0 . . . . . . . . 0 . 0 . . . 
. . . . 0 . . . . . . . . . . 0 . . . . 
 with color grey at (2,2)
  + 191 delta pixels
diff:   ^.layer_011.shape.color
! size mismatch, 16x19 instead of 5x5
>> Trial 3
data: a background with size (24,24) and color black and layers
  _011: rectangle with size (5,5) with model Full with color blue at (15,10)
  + 305 delta pixels
diff:   ^.layer_011.shape.color
! size mismatch, 4x4 instead of 5x5

TRAIN ff805c23.json/3: 0 - (FAILURE)

# Test input/output grids

## instance 1

> Output prediction from input (up to 3 trials):
>> Trial 1
data: a background with size (24,24) and color green and layers
  _011: rectangle with size (12,12) with model Full with color cyan at (6,6)
  + 293 delta pixels
diff:   ^.layer_011.shape.color
! size mismatch, 11x11 instead of 5x5
>> Trial 2
data: a background with size (24,24) and color green and layers
  _011: rectangle with size (24,24) with mask 
. . . . . . . . . . 0 0 0 0 . . . . . . . . . . 
. . . . . . . . . . 0 . . 0 . . . . . . . . . . 
. . . . . . . . 0 0 . . . . 0 0 . . . . . . . . 
. . . . . . . . 0 0 . . . . 0 0 . . . . . . . . 
. . . . . . 0 0 . . 0 . . 0 . . 0 0 . . . . . . 
. . . . . 0 0 . . . . . . . . . . 0 0 . . . . . 
. . . . 0 0 . . . . . . . . . . . . 0 0 . . . . 
. . . . 0 . . . . . . . . . . . . . . 0 . . . . 
. . 0 0 . . . . . . . . . . . . . . . . 0 0 . . 
. . 0 0 . . . . . . . . . . . . . . . . 0 0 . . 
0 0 . . 0 . . . . . . . . . . . . . . 0 . . 0 0 
0 . . . . . . . . . . . . . . . . . . . . . . 0 
0 . . . . . . . . . . . . . . . . . . . . . . 0 
0 0 . . 0 . . . . . . . . . . . . . . 0 . . 0 0 
. . 0 0 . . . . . . . . . . . . . . . . 0 0 . . 
. . 0 0 . . . . . . . . . . . . . . . . 0 0 . . 
. . . . 0 . . . . . . . . . . . . . . 0 . . . . 
. . . . 0 0 . . . . . . . . . . . . 0 0 . . . . 
. . . . . 0 0 . . . . . . . . . . 0 0 . . . . . 
. . . . . . 0 0 . . 0 . . 0 . . 0 0 . . . . . . 
. . . . . . . . 0 0 . . . . 0 0 . . . . . . . . 
. . . . . . . . 0 0 . . . . 0 0 . . . . . . . . 
. . . . . . . . . . 0 . . 0 . . . . . . . . . . 
. . . . . . . . . . 0 0 0 0 . . . . . . . . . . 
 with color black at (0,0)
  + 292 delta pixels
diff:   ^.layer_011.shape.color
! size mismatch, 23x23 instead of 5x5

TEST ff805c23.json/1: 0 - (FAILURE)

# Performance measures on task
runtime-learning = 53.1 sec (53.1 sec/task)
bits-train-error = 1244.2 bits (1244.2 bits/task)
acc-train-micro = 0.00 tasks (0.00%)
acc-train-macro = 0.00 tasks (0.00%)
acc-train-mrr = 0.00
acc-test-micro = 0.00 tasks (0.00%)
acc-test-macro = 0.00 tasks (0.00%)
acc-test-mrr = 0.00


## performance measures averaged over 400 tasks
runtime-learning = 8698.4 sec (21.7 sec/task)
bits-train-error = 2818167.3 bits (7045.4 bits/task)
acc-train-micro = 112.58 tasks (28.15%)
acc-train-macro = 102.00 tasks (25.50%)
acc-train-mrr = 0.27
acc-test-micro = 96.50 tasks (24.12%)
acc-test-macro = 96.00 tasks (24.00%)
acc-test-mrr = 0.23

// Profiling...
#calls	#calls/s	Time (s)	Percentage	Section
//      1295	  455024.6	    0.0	  0.0%	Model2.model_refinements_prune
//     12216	  857323.3	    0.0	  0.0%	Model2.shape_refinements
//     30613	  220681.9	    0.1	  0.0%	Grid.split_part
//      2894	    3069.0	    0.9	  0.0%	Grid.segment_by_color
//      4184	    3988.0	    1.0	  0.0%	Model2.write_grid
//     14222	    9036.5	    1.6	  0.0%	Model2.defs_refinements/val_matrix
//      1717	     408.3	    4.2	  0.0%	Model2.apply_model
//   1001955	   98010.9	   10.2	  0.1%	Grid.points
//   1001955	   21363.6	   46.9	  0.5%	Grid.rectangles
//    339683	    2000.5	  169.8	  2.0%	Model2.root_template_of_data/add_parse_grid
//     14222	      83.4	  170.5	  2.0%	Model2.defs_refinements/first/by_path
//     14222	      79.3	  179.4	  2.1%	Model2.defs_expressions
//     14211	      45.6	  311.8	  3.6%	Model2.defs_refinements/others
//     14222	       5.2	 2717.3	 31.2%	Model2.defs_refinements/first/by_expr
//     14222	       4.4	 3201.8	 36.8%	Model2.defs_refinements
//      7111	       2.2	 3201.8	 36.8%	Model2.model_refinements_build
//  81256902	   18051.5	 4501.4	 51.7%	Model2.parse_layers/seq
//  80138037	   16188.7	 4950.3	 56.9%	Model2.parse_grid_background/seq
//   4092975	     750.1	 5456.4	 62.7%	Model2.read_grid/first_parses
//   4175279	     760.5	 5490.4	 63.1%	Model2.read_grid
//    455902	      83.0	 5495.0	 63.1%	Model2.read_grid_pairs
//       400	       0.0	 8698.4	100.0%	Model2.learn_model
//       400	       0.0	 8702.7	100.0%	Test.print_learned_model
